{
  "title": "Memetic Proxy",
  "story": [
    {
      "type": "paragraph",
      "id": "dbb4129d1cead0c3",
      "text": "A memetic proxy refers to the use of a symbol or representation as a surrogate for a cultural meme or idea. In this context, a meme is a unit of cultural information, such as a concept, belief, or behavior, that is transmitted from one individual to another through communication. A memetic proxy can serve as a shorthand for a complex idea or concept and can be used to quickly convey that idea in a way that is easily recognized and understood by others. This can be useful for communication and can help to spread ideas and information more efficiently within a culture or community. The term is often used in the context of marketing, advertising, and social media, where memes and other forms of viral content are used to promote products or ideas. -- chat.openai"
    },
    {
      "type": "pagefold",
      "id": "a213313c23ac3604",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "427d2a8fff752451",
      "text": "Memetic Algorithm [https://en.wikipedia.org/wiki/Memetic_algorithm wikipedia]"
    },
    {
      "type": "paragraph",
      "id": "b4fb06bd22da18d4",
      "text": "BERRIOS TORRES, ANTONIO, 2022. Language models for patents: exploring prompt engineering for the [[Patent]] domain. 2022. ⇒ [[Establish Rules]] ⇒ [[Real Constraint]] ⇒ [[Constraint]]"
    },
    {
      "type": "markdown",
      "id": "d92eada1c56151b8",
      "text": "> For example, the ability of computational systems to [[establish]] [[Rule]]s as genuine constraints where an analogous human legal system can only [[penalize]] violations makes possible [[Patterns of Organization]] that can only be approximated in society.\n"
    },
    {
      "type": "paragraph",
      "id": "02cface9ce6b0cb5",
      "text": "HEWETT, Joe and LEEKE, Matthew, 2022. Developing a GPT-3-Based Automated Victim for Advance Fee Fraud Disruption. In: 2022 IEEE 27th Pacific Rim International Symposium on Dependable Computing (PRDC). IEEE. 2022. p. 205–211. \n\n"
    },
    {
      "type": "paragraph",
      "id": "6dda9995166fe6ee",
      "text": "REYNOLDS, Laria and MCDONELL, Kyle, 2021. Prompt programming for large language models: Beyond the few-shot paradigm. In: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. 2021. p. 1–7. ⇒ [[Task Specification by Memetic Proxy]]\n"
    },
    {
      "type": "paragraph",
      "id": "bcc5be4f07be7deb",
      "text": "LUNDBLAD, Jonathan, THÖRN, Edwin and THÖRN, Linus, 2023. The impact of task specification on code generated via ChatGPT. 2023. [https://www.diva-portal.org/smash/record.jsf?pid=diva2:1776870 page] [Accessed 18 February 2024]. \n"
    },
    {
      "type": "paragraph",
      "id": "4f6b4d9a0482fabc",
      "text": "ChatGPT has made large language models more accessible and made it possible to code using natural language prompts. This study conducted an experiment comparing prompt engineering techniques called [[Task Specification]] and investigated their impact on code generation in terms of correctness and variety. The hypotheses of this study focused on whether the baseline method had a statistically significant difference in code correctness compared to the other methods. Code is evaluated using a software requirement specification that measures functional and syntactical correctness. Additionally, code variance is measured to identify patterns in code generation. The results show that there is a statistically significant difference in some code correctness criteria between the baseline and the other task specification methods, and the code variance measurements indicate a variety in the generated solutions. Future work could include using another large language model; different programming tasks and programming languages; and other prompt engineering techniques."
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Memetic Proxy",
        "story": []
      },
      "date": 1675746455222
    },
    {
      "item": {
        "type": "factory",
        "id": "dbb4129d1cead0c3"
      },
      "id": "dbb4129d1cead0c3",
      "type": "add",
      "date": 1675746467974
    },
    {
      "type": "edit",
      "id": "dbb4129d1cead0c3",
      "item": {
        "type": "paragraph",
        "id": "dbb4129d1cead0c3",
        "text": "A memetic proxy refers to the use of a symbol or representation as a surrogate for a cultural meme or idea. In this context, a meme is a unit of cultural information, such as a concept, belief, or behavior, that is transmitted from one individual to another through communication. A memetic proxy can serve as a shorthand for a complex idea or concept and can be used to quickly convey that idea in a way that is easily recognized and understood by others. This can be useful for communication and can help to spread ideas and information more efficiently within a culture or community. The term is often used in the context of marketing, advertising, and social media, where memes and other forms of viral content are used to promote products or ideas. -- chat.openai"
      },
      "date": 1675746474831
    },
    {
      "item": {
        "type": "factory",
        "id": "a213313c23ac3604"
      },
      "id": "a213313c23ac3604",
      "type": "add",
      "after": "dbb4129d1cead0c3",
      "date": 1675746548800
    },
    {
      "type": "edit",
      "id": "a213313c23ac3604",
      "item": {
        "type": "pagefold",
        "id": "a213313c23ac3604",
        "text": "~"
      },
      "date": 1675746551565
    },
    {
      "item": {
        "type": "factory",
        "id": "427d2a8fff752451"
      },
      "id": "427d2a8fff752451",
      "type": "add",
      "after": "a213313c23ac3604",
      "date": 1675746555327
    },
    {
      "type": "edit",
      "id": "427d2a8fff752451",
      "item": {
        "type": "paragraph",
        "id": "427d2a8fff752451",
        "text": "Memetic Algorithm"
      },
      "date": 1675746558966
    },
    {
      "type": "edit",
      "id": "427d2a8fff752451",
      "item": {
        "type": "paragraph",
        "id": "427d2a8fff752451",
        "text": "Memetic Algorithm [https://en.wikipedia.org/wiki/Memetic_algorithm wikipedia]"
      },
      "date": 1675746570040
    },
    {
      "item": {
        "type": "factory",
        "id": "b4fb06bd22da18d4"
      },
      "id": "b4fb06bd22da18d4",
      "type": "add",
      "after": "427d2a8fff752451",
      "date": 1675746647628
    },
    {
      "type": "edit",
      "id": "b4fb06bd22da18d4",
      "item": {
        "type": "paragraph",
        "id": "b4fb06bd22da18d4",
        "text": "\nBERRIOS TORRES, ANTONIO, 2022. Language models for patents: exploring prompt engineering for the patent domain. . 2022. \n\nHEWETT, Joe and LEEKE, Matthew, 2022. Developing a GPT-3-Based Automated Victim for Advance Fee Fraud Disruption. In: 2022 IEEE 27th Pacific Rim International Symposium on Dependable Computing (PRDC). IEEE. 2022. p. 205–211. \n\nREYNOLDS, Laria and MCDONELL, Kyle, 2021. Prompt programming for large language models: Beyond the few-shot paradigm. In: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. 2021. p. 1–7. \n"
      },
      "date": 1675746650166
    },
    {
      "type": "edit",
      "id": "b4fb06bd22da18d4",
      "item": {
        "type": "paragraph",
        "id": "b4fb06bd22da18d4",
        "text": "BERRIOS TORRES, ANTONIO, 2022. Language models for patents: exploring prompt engineering for the patent domain. 2022. \n\nHEWETT, Joe and LEEKE, Matthew, 2022. Developing a GPT-3-Based Automated Victim for Advance Fee Fraud Disruption. In: 2022 IEEE 27th Pacific Rim International Symposium on Dependable Computing (PRDC). IEEE. 2022. p. 205–211. \n\nREYNOLDS, Laria and MCDONELL, Kyle, 2021. Prompt programming for large language models: Beyond the few-shot paradigm. In: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. 2021. p. 1–7. \n"
      },
      "date": 1675746660798
    },
    {
      "type": "edit",
      "id": "b4fb06bd22da18d4",
      "item": {
        "type": "paragraph",
        "id": "b4fb06bd22da18d4",
        "text": "BERRIOS TORRES, ANTONIO, 2022. Language models for patents: exploring prompt engineering for the patent domain. 2022. \n\nHEWETT, Joe and LEEKE, Matthew, 2022. Developing a GPT-3-Based Automated Victim for Advance Fee Fraud Disruption. In: 2022 IEEE 27th Pacific Rim International Symposium on Dependable Computing (PRDC). IEEE. 2022. p. 205–211. \n\n"
      },
      "date": 1675746695665
    },
    {
      "type": "add",
      "id": "6dda9995166fe6ee",
      "item": {
        "type": "paragraph",
        "id": "6dda9995166fe6ee",
        "text": "REYNOLDS, Laria and MCDONELL, Kyle, 2021. Prompt programming for large language models: Beyond the few-shot paradigm. In: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. 2021. p. 1–7. ⇒ [[Task Specification by Memetic Proxy]]\n"
      },
      "after": "b4fb06bd22da18d4",
      "date": 1675746698381
    },
    {
      "type": "edit",
      "id": "b4fb06bd22da18d4",
      "item": {
        "type": "paragraph",
        "id": "b4fb06bd22da18d4",
        "text": "BERRIOS TORRES, ANTONIO, 2022. Language models for patents: exploring prompt engineering for the patent domain. 2022. "
      },
      "date": 1675746855699
    },
    {
      "type": "add",
      "id": "02cface9ce6b0cb5",
      "item": {
        "type": "paragraph",
        "id": "02cface9ce6b0cb5",
        "text": "\nHEWETT, Joe and LEEKE, Matthew, 2022. Developing a GPT-3-Based Automated Victim for Advance Fee Fraud Disruption. In: 2022 IEEE 27th Pacific Rim International Symposium on Dependable Computing (PRDC). IEEE. 2022. p. 205–211. \n\n"
      },
      "after": "b4fb06bd22da18d4",
      "date": 1675746857411
    },
    {
      "type": "edit",
      "id": "b4fb06bd22da18d4",
      "item": {
        "type": "paragraph",
        "id": "b4fb06bd22da18d4",
        "text": "BERRIOS TORRES, ANTONIO, 2022. Language models for patents: exploring prompt engineering for the patent domain. 2022. [[Establish Rules]]"
      },
      "date": 1675746868647
    },
    {
      "type": "edit",
      "id": "b4fb06bd22da18d4",
      "item": {
        "type": "paragraph",
        "id": "b4fb06bd22da18d4",
        "text": "BERRIOS TORRES, ANTONIO, 2022. Language models for patents: exploring prompt engineering for the patent domain. 2022. ⇒ [[Establish Rules]]"
      },
      "date": 1675746877546
    },
    {
      "id": "d92eada1c56151b8",
      "type": "add",
      "item": {
        "type": "paragraph",
        "id": "d92eada1c56151b8",
        "text": "For example, the ability of computational systems to [[establish]] [[Rule]]s as genuine constraints where an analogous human legal system can only [[penalize]] violations makes possible [[Patterns of Organization]] that can only be approximated in society.\n"
      },
      "after": "b4fb06bd22da18d4",
      "date": 1675746895125
    },
    {
      "type": "edit",
      "id": "d92eada1c56151b8",
      "item": {
        "type": "paragraph",
        "id": "d92eada1c56151b8",
        "text": "> For example, the ability of computational systems to [[establish]] [[Rule]]s as genuine constraints where an analogous human legal system can only [[penalize]] violations makes possible [[Patterns of Organization]] that can only be approximated in society.\n"
      },
      "date": 1675746898608
    },
    {
      "type": "edit",
      "id": "d92eada1c56151b8",
      "item": {
        "type": "markdown",
        "id": "d92eada1c56151b8",
        "text": "> For example, the ability of computational systems to [[establish]] [[Rule]]s as genuine constraints where an analogous human legal system can only [[penalize]] violations makes possible [[Patterns of Organization]] that can only be approximated in society.\n"
      },
      "date": 1675746899615
    },
    {
      "type": "edit",
      "id": "b4fb06bd22da18d4",
      "item": {
        "type": "paragraph",
        "id": "b4fb06bd22da18d4",
        "text": "BERRIOS TORRES, ANTONIO, 2022. Language models for patents: exploring prompt engineering for the patent domain. 2022. ⇒ [[Establish Rules]] ⇒ [Real Constraint]]"
      },
      "date": 1675746988775
    },
    {
      "type": "edit",
      "id": "b4fb06bd22da18d4",
      "item": {
        "type": "paragraph",
        "id": "b4fb06bd22da18d4",
        "text": "BERRIOS TORRES, ANTONIO, 2022. Language models for patents: exploring prompt engineering for the patent domain. 2022. ⇒ [[Establish Rules]] ⇒ [[Real Constraint]]"
      },
      "date": 1675746993626
    },
    {
      "type": "edit",
      "id": "b4fb06bd22da18d4",
      "item": {
        "type": "paragraph",
        "id": "b4fb06bd22da18d4",
        "text": "BERRIOS TORRES, ANTONIO, 2022. Language models for patents: exploring prompt engineering for the patent domain. 2022. ⇒ [[Establish Rules]] ⇒ [[Real Constraint]] ⇒ [[Constraint]]"
      },
      "date": 1675747086197
    },
    {
      "type": "edit",
      "id": "02cface9ce6b0cb5",
      "item": {
        "type": "paragraph",
        "id": "02cface9ce6b0cb5",
        "text": "HEWETT, Joe and LEEKE, Matthew, 2022. Developing a GPT-3-Based Automated Victim for Advance Fee Fraud Disruption. In: 2022 IEEE 27th Pacific Rim International Symposium on Dependable Computing (PRDC). IEEE. 2022. p. 205–211. \n\n"
      },
      "date": 1675747290682
    },
    {
      "type": "edit",
      "id": "b4fb06bd22da18d4",
      "item": {
        "type": "paragraph",
        "id": "b4fb06bd22da18d4",
        "text": "BERRIOS TORRES, ANTONIO, 2022. Language models for patents: exploring prompt engineering for the [[Patent]] domain. 2022. ⇒ [[Establish Rules]] ⇒ [[Real Constraint]] ⇒ [[Constraint]]"
      },
      "date": 1675747338899
    },
    {
      "item": {
        "type": "factory",
        "id": "bcc5be4f07be7deb"
      },
      "id": "bcc5be4f07be7deb",
      "type": "add",
      "after": "6dda9995166fe6ee",
      "date": 1708292238685
    },
    {
      "type": "edit",
      "id": "bcc5be4f07be7deb",
      "item": {
        "type": "paragraph",
        "id": "bcc5be4f07be7deb",
        "text": "\nLUNDBLAD, Jonathan, THÖRN, Edwin and THÖRN, Linus, 2023. The impact of task specification on code generated via ChatGPT. 2023. Available from: https://www.diva-portal.org/smash/record.jsf?pid=diva2:1776870 [Accessed 18 February 2024]. \n"
      },
      "date": 1708292245309
    },
    {
      "type": "edit",
      "id": "bcc5be4f07be7deb",
      "item": {
        "type": "paragraph",
        "id": "bcc5be4f07be7deb",
        "text": "LUNDBLAD, Jonathan, THÖRN, Edwin and THÖRN, Linus, 2023. The impact of task specification on code generated via ChatGPT. 2023. [https://www.diva-portal.org/smash/record.jsf?pid=diva2:1776870 page] [Accessed 18 February 2024]. \n"
      },
      "date": 1708292267309
    },
    {
      "item": {
        "type": "factory",
        "id": "4f6b4d9a0482fabc"
      },
      "id": "4f6b4d9a0482fabc",
      "type": "add",
      "after": "bcc5be4f07be7deb",
      "date": 1708292291875
    },
    {
      "type": "edit",
      "id": "4f6b4d9a0482fabc",
      "item": {
        "type": "paragraph",
        "id": "4f6b4d9a0482fabc",
        "text": "ChatGPT has made large language models more accessible and made it possible to code using natural language prompts. This study conducted an experiment comparing prompt engineering techniques called task specification and investigated their impacton code generation in terms of correctness and variety. The hypotheses of this study focused on whether the baseline method had a statistically significant difference in code correctness compared to the other methods. Code is evaluated using a software requirement specification that measures functional and syntactical correctness. Additionally, code variance is measured to identify patterns in code generation. The results show that there is a statistically significant difference in some code correctness criteria between the baseline and the other task specification methods, and the code variance measurements indicate a variety in the generated solutions. Future work could include using another large language model; different programming tasks andprogramming languages; and other prompt engineering techniques."
      },
      "date": 1708292294342
    },
    {
      "type": "edit",
      "id": "4f6b4d9a0482fabc",
      "item": {
        "type": "paragraph",
        "id": "4f6b4d9a0482fabc",
        "text": "ChatGPT has made large language models more accessible and made it possible to code using natural language prompts. This study conducted an experiment comparing prompt engineering techniques called [[Task Specification]] and investigated their impacton code generation in terms of correctness and variety. The hypotheses of this study focused on whether the baseline method had a statistically significant difference in code correctness compared to the other methods. Code is evaluated using a software requirement specification that measures functional and syntactical correctness. Additionally, code variance is measured to identify patterns in code generation. The results show that there is a statistically significant difference in some code correctness criteria between the baseline and the other task specification methods, and the code variance measurements indicate a variety in the generated solutions. Future work could include using another large language model; different programming tasks andprogramming languages; and other prompt engineering techniques."
      },
      "date": 1708292333912
    },
    {
      "type": "edit",
      "id": "4f6b4d9a0482fabc",
      "item": {
        "type": "paragraph",
        "id": "4f6b4d9a0482fabc",
        "text": "ChatGPT has made large language models more accessible and made it possible to code using natural language prompts. This study conducted an experiment comparing prompt engineering techniques called [[Task Specification]] and investigated their impacton code generation in terms of correctness and variety. The hypotheses of this study focused on whether the baseline method had a statistically significant difference in code correctness compared to the other methods. Code is evaluated using a software requirement specification that measures functional and syntactical correctness. Additionally, code variance is measured to identify patterns in code generation. The results show that there is a statistically significant difference in some code correctness criteria between the baseline and the other task specification methods, and the code variance measurements indicate a variety in the generated solutions. Future work could include using another large language model; different programming tasks and programming languages; and other prompt engineering techniques."
      },
      "date": 1708292378554
    },
    {
      "type": "edit",
      "id": "4f6b4d9a0482fabc",
      "item": {
        "type": "paragraph",
        "id": "4f6b4d9a0482fabc",
        "text": "ChatGPT has made large language models more accessible and made it possible to code using natural language prompts. This study conducted an experiment comparing prompt engineering techniques called [[Task Specification]] and investigated their impact on code generation in terms of correctness and variety. The hypotheses of this study focused on whether the baseline method had a statistically significant difference in code correctness compared to the other methods. Code is evaluated using a software requirement specification that measures functional and syntactical correctness. Additionally, code variance is measured to identify patterns in code generation. The results show that there is a statistically significant difference in some code correctness criteria between the baseline and the other task specification methods, and the code variance measurements indicate a variety in the generated solutions. Future work could include using another large language model; different programming tasks and programming languages; and other prompt engineering techniques."
      },
      "date": 1708292403873
    }
  ]
}