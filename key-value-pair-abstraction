{
  "title": "Key-Value Pair Abstraction",
  "story": [
    {
      "type": "paragraph",
      "id": "fd5c296fc0198427",
      "text": "\nCHEN, Rong and CHEN, Haibo, 2013. Tiled-MapReduce: Efficient and Flexible MapReduce Processing on Multicore with Tiling. ACM Transactions on Architecture and Code Optimization. April 2013. Vol. 10, no. 1, p. 1–30. DOI 10.1145/2445572.2445575. \nThe prevalence of chip multiprocessors opens opportunities of running data-parallel applications originally in clusters on a single machine with many cores. MapReduce, a simple and elegant programming model to program large-scale clusters, has recently been shown a promising alternative to harness the multicore platform.\n            \n              The differences such as memory hierarchy and communication patterns between clusters and multicore platforms raise new challenges to design and implement an efficient MapReduce system on multicore. This article argues that it is more efficient for MapReduce to iteratively process small chunks of data in turn than processing a large chunk of data at a time on shared memory multicore platforms. Based on the argument, we extend the general MapReduce programming model with a “tiling strategy”, called\n              Tiled\n              -\n              MapReduce\n              (TMR). TMR partitions a large MapReduce job into a number of small subjobs and iteratively processes one subjob at a time with efficient use of resources; TMR finally merges the results of all subjobs for output. Based on Tiled-MapReduce, we design and implement several optimizing techniques targeting multicore, including the reuse of the input buffer among subjobs, a NUCA/NUMA-aware scheduler, and pipelining a subjob’s reduce phase with the successive subjob’s map phase, to optimize the memory, cache, and CPU resources accordingly. Further, we demonstrate that Tiled-MapReduce supports fine-grained fault tolerance and enables several usage scenarios such as online and incremental computing on multicore machines.\n            \n            Performance evaluation with our prototype system called Ostrich on a 48-core machine shows that Ostrich saves up to 87.6% memory, causes less cache misses, and makes more efficient use of CPU cores, resulting in a speedup ranging from 1.86x to 3.07x over Phoenix. Ostrich also efficiently supports fine-grained fault tolerance, online, and incremental computing with small performance penalty.\n\nKHAN, Awais, SIM, Hyogi, VAZHKUDAI, Sudharshan S. and KIM, Youngjae, 2021. MOSIQS: Persistent memory object storage with metadata indexing and querying for scientific computing. IEEE Access. 2021. Vol. 9, p. 85217–85231. \n\nLESKOVEC, Jure, RAJARAMAN, Anand and ULLMAN, Jeffrey David, 2020. Mining of massive data sets. Online. Cambridge university press. Available from: https://books.google.com/books?hl=de&lr=&id=S4HCDwAAQBAJ&oi=fnd&pg=PR9&dq=%22Key-Value+Pair+Abstraction%22&ots=iRmggikDSh&sig=whV5FQNmROZThYQ4JUsSEtXudjs [Accessed 13 April 2024]. \n\nMEJÍAS, Boris, GUTIÉRREZ, Gustavo, VAN ROY, Peter, THOMSON, John and TREZENTOS, Paulo, 2010. Lock-Free Decentralized Storage for Transactional Upgrade Rollback. In: 2010 19th IEEE International Workshops on Enabling Technologies: Infrastructures for Collaborative Enterprises. Online. IEEE. 2010. p. 229–234. Available from: https://ieeexplore.ieee.org/abstract/document/5541775/ [Accessed 13 April 2024]. \n\nRAO, Praveen, 2008. Building an Internet-Scale Service for Publishing and Locating XML Documents on PlanetLab. Online. UMKC, Tech. Rep. TR-DB-2008-02, June 2008, http://r. faculty. umkc. edu …. Available from: http://r.web.umkc.edu/raopr/TR-DB-2008-02.pdf [Accessed 13 April 2024]. \n\nRAO, Praveen and MOON, Bongki, 2009. An internet-scale service for publishing and locating XML documents. In: 2009 IEEE 25th International Conference on Data Engineering. Online. IEEE. 2009. p. 1459–1462. Available from: https://ieeexplore.ieee.org/abstract/document/4812547/ [Accessed 13 April 2024]. \n\nSEDGEWICK, ROBERT and WAYNE, KEVIN, [no date]. 3.1 SYMBOL TABLES. . Online. Available from: https://www.cs.princeton.edu/courses/archive/fall13/cos226/lectures/31ElementarySymbolTables+32BSTs-2x2.pdf [Accessed 13 April 2024]. \n\nSMITH, Randy and MEEHEAN, Joe, [no date]. A Case for Dynamic File Attributes. . Online. Available from: https://pages.cs.wisc.edu/~jmeehean/ClassProjects/DynamicFileAttrib.pdf [Accessed 13 April 2024]. \n\nZHANG, Zhao, 2014. Enabling efficient parallel scripting on large-scale computers. Online. The University of Chicago. Available from: https://search.proquest.com/openview/4829ba5f4d6b31858aeacb8e1dbe1a69/1?pq-origsite=gscholar&cbl=18750 [Accessed 13 April 2024]. \n"
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Key-Value Pair Abstraction",
        "story": []
      },
      "date": 1713038469376
    },
    {
      "type": "edit",
      "id": "fd5c296fc0198427",
      "item": {
        "type": "paragraph",
        "id": "fd5c296fc0198427",
        "text": "\nCHEN, Rong and CHEN, Haibo, 2013. Tiled-MapReduce: Efficient and Flexible MapReduce Processing on Multicore with Tiling. ACM Transactions on Architecture and Code Optimization. April 2013. Vol. 10, no. 1, p. 1–30. DOI 10.1145/2445572.2445575. \nThe prevalence of chip multiprocessors opens opportunities of running data-parallel applications originally in clusters on a single machine with many cores. MapReduce, a simple and elegant programming model to program large-scale clusters, has recently been shown a promising alternative to harness the multicore platform.\n            \n              The differences such as memory hierarchy and communication patterns between clusters and multicore platforms raise new challenges to design and implement an efficient MapReduce system on multicore. This article argues that it is more efficient for MapReduce to iteratively process small chunks of data in turn than processing a large chunk of data at a time on shared memory multicore platforms. Based on the argument, we extend the general MapReduce programming model with a “tiling strategy”, called\n              Tiled\n              -\n              MapReduce\n              (TMR). TMR partitions a large MapReduce job into a number of small subjobs and iteratively processes one subjob at a time with efficient use of resources; TMR finally merges the results of all subjobs for output. Based on Tiled-MapReduce, we design and implement several optimizing techniques targeting multicore, including the reuse of the input buffer among subjobs, a NUCA/NUMA-aware scheduler, and pipelining a subjob’s reduce phase with the successive subjob’s map phase, to optimize the memory, cache, and CPU resources accordingly. Further, we demonstrate that Tiled-MapReduce supports fine-grained fault tolerance and enables several usage scenarios such as online and incremental computing on multicore machines.\n            \n            Performance evaluation with our prototype system called Ostrich on a 48-core machine shows that Ostrich saves up to 87.6% memory, causes less cache misses, and makes more efficient use of CPU cores, resulting in a speedup ranging from 1.86x to 3.07x over Phoenix. Ostrich also efficiently supports fine-grained fault tolerance, online, and incremental computing with small performance penalty.\n\nKHAN, Awais, SIM, Hyogi, VAZHKUDAI, Sudharshan S. and KIM, Youngjae, 2021. MOSIQS: Persistent memory object storage with metadata indexing and querying for scientific computing. IEEE Access. 2021. Vol. 9, p. 85217–85231. \n\nLESKOVEC, Jure, RAJARAMAN, Anand and ULLMAN, Jeffrey David, 2020. Mining of massive data sets. Online. Cambridge university press. Available from: https://books.google.com/books?hl=de&lr=&id=S4HCDwAAQBAJ&oi=fnd&pg=PR9&dq=%22Key-Value+Pair+Abstraction%22&ots=iRmggikDSh&sig=whV5FQNmROZThYQ4JUsSEtXudjs [Accessed 13 April 2024]. \n\nMEJÍAS, Boris, GUTIÉRREZ, Gustavo, VAN ROY, Peter, THOMSON, John and TREZENTOS, Paulo, 2010. Lock-Free Decentralized Storage for Transactional Upgrade Rollback. In: 2010 19th IEEE International Workshops on Enabling Technologies: Infrastructures for Collaborative Enterprises. Online. IEEE. 2010. p. 229–234. Available from: https://ieeexplore.ieee.org/abstract/document/5541775/ [Accessed 13 April 2024]. \n\nRAO, Praveen, 2008. Building an Internet-Scale Service for Publishing and Locating XML Documents on PlanetLab. Online. UMKC, Tech. Rep. TR-DB-2008-02, June 2008, http://r. faculty. umkc. edu …. Available from: http://r.web.umkc.edu/raopr/TR-DB-2008-02.pdf [Accessed 13 April 2024]. \n\nRAO, Praveen and MOON, Bongki, 2009. An internet-scale service for publishing and locating XML documents. In: 2009 IEEE 25th International Conference on Data Engineering. Online. IEEE. 2009. p. 1459–1462. Available from: https://ieeexplore.ieee.org/abstract/document/4812547/ [Accessed 13 April 2024]. \n\nSEDGEWICK, ROBERT and WAYNE, KEVIN, [no date]. 3.1 SYMBOL TABLES. . Online. Available from: https://www.cs.princeton.edu/courses/archive/fall13/cos226/lectures/31ElementarySymbolTables+32BSTs-2x2.pdf [Accessed 13 April 2024]. \n\nSMITH, Randy and MEEHEAN, Joe, [no date]. A Case for Dynamic File Attributes. . Online. Available from: https://pages.cs.wisc.edu/~jmeehean/ClassProjects/DynamicFileAttrib.pdf [Accessed 13 April 2024]. \n\nZHANG, Zhao, 2014. Enabling efficient parallel scripting on large-scale computers. Online. The University of Chicago. Available from: https://search.proquest.com/openview/4829ba5f4d6b31858aeacb8e1dbe1a69/1?pq-origsite=gscholar&cbl=18750 [Accessed 13 April 2024]. \n"
      },
      "date": 1713038472318
    },
    {
      "type": "fork",
      "date": 1713041676839
    },
    {
      "type": "fork",
      "site": "localhost:3000",
      "date": 1713532604668
    }
  ]
}