{
  "title": "Probability Tables",
  "story": [
    {
      "type": "paragraph",
      "id": "c4a0ab965f97ee61",
      "text": "[[Samantha Quiñones]] works with generative machines. Everything from Markov chain generators to GPT-3. [https://lucha.nyc/@ieatkillerbees/109961947877248377 post]"
    },
    {
      "type": "markdown",
      "id": "0e7e7cddb90d5f6e",
      "text": "> I’ve trained and tuned many models with GPT2 and 3, all with the intent of simulating human interaction. \n>\n> I know a fair bit about generative machines, both how they work, and how to tune and interact with them to get particular results.\n>\n> I need you to hear this: they do not know or understand anything. They are complex probability tables. "
    },
    {
      "type": "paragraph",
      "id": "df19f3badf5e1f5e",
      "text": "Thanks to very clever programming and increasingly powerful GPUs, they are deeply complex and precise probability tables, but they are still only inferring based on what they’ve seen in the past.\n\nWe don’t understand how organic brains learn. Building an electronic brain remains science fiction.\n\n"
    },
    {
      "type": "paragraph",
      "id": "704fd331824ec46c",
      "text": "LLMs produce an impressive [[Simulacra]] of human language, but there is no there there. [⇒ [[Simulacres et Simulation]]] >> simulacra\n\n"
    },
    {
      "type": "markdown",
      "id": "dab8555ecc528bb3",
      "text": "> I jokingly say that they “make shit up,” but that implies intent and ability to conceptualize."
    },
    {
      "type": "paragraph",
      "id": "be400bfd4b7663c1",
      "text": "These machines can do neither. They produce strings of tokens that statistically appear like they were produced by a human.\n\nTo an LLM the statements “Neil Armstrong was the first man to walk on the moon” and “Neil Armstrong was the first man to walk on Mars” are differentiated only in that more people have written the former than the latter.\n\nThat’s it.\n\n"
    },
    {
      "type": "paragraph",
      "id": "4a6c4d57101be002",
      "text": "AI doesn’t exist and companies letting what we DO have make decisions is just a way to avoid culpability for the results. [⇒ [[Organized Irresponsibility]]] >> culpability"
    },
    {
      "type": "pagefold",
      "id": "21a723d274db779a",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "4e810fb49651555b",
      "text": "Mar 4\nmwop@phpc.social\nMatthew Weier O'Phinney @mwop@phpc.social\n\n@ieatkillerbees I studied AI briefly in college 30 years ago, and have been watching all the hype around \"AI\" lately with amusement. It's exactly what you say - just fancy [[Lookup Table]]s and [[Decision Tree]]s.  Sometimes it puts fun things together, but it's accidental. >> lookup table decision tree"
    },
    {
      "type": "paragraph",
      "id": "7c5d01e64c85e41d",
      "text": "(The reason I left CS was because I got interested in what it means to be human... due to studying AI. Debates about ethically turning off an AI felt ... Hugely premature. There's no being with a sense of self to turn off...)"
    },
    {
      "type": "pagefold",
      "id": "965d687462f5ac5f",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "8250656442f6c9d6",
      "text": "@mwop They’re totally cool and it’s impressive we’ve been able to develop machines that appear non-deterministic at the scale of human observation (helped by our nature, as a species, to recognize intelligence in other things that seem human). Still, machines they are."
    },
    {
      "type": "pagefold",
      "id": "4947b4c6eb295f5b",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "e33c9d2b7c53d9cf",
      "text": "\nWILCOXON, Frank, 1947. Probability Tables for Individual Comparisons by Ranking Methods. Biometrics. 1947. Vol. 3, no. 3, p. 119–122. DOI 10.2307/3001946. \n"
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Probability Tables",
        "story": []
      },
      "date": 1679641739626
    },
    {
      "id": "c4a0ab965f97ee61",
      "type": "add",
      "item": {
        "type": "paragraph",
        "id": "c4a0ab965f97ee61",
        "text": "[[Samantha Quiñones]] works with generative machines. Everything from Markov chain generators to GPT-3. [https://lucha.nyc/@ieatkillerbees/109961947877248377 post]"
      },
      "attribution": {
        "page": "2023-03-24"
      },
      "date": 1679641741617
    },
    {
      "id": "0e7e7cddb90d5f6e",
      "type": "add",
      "item": {
        "type": "markdown",
        "id": "0e7e7cddb90d5f6e",
        "text": "> I’ve trained and tuned many models with GPT2 and 3, all with the intent of simulating human interaction. \n>\n> I know a fair bit about generative machines, both how they work, and how to tune and interact with them to get particular results.\n>\n> I need you to hear this: they do not know or understand anything. They are complex probability tables. "
      },
      "after": "c4a0ab965f97ee61",
      "attribution": {
        "page": "2023-03-24"
      },
      "date": 1679641743081
    },
    {
      "item": {
        "type": "factory",
        "id": "4947b4c6eb295f5b"
      },
      "id": "4947b4c6eb295f5b",
      "type": "add",
      "after": "0e7e7cddb90d5f6e",
      "date": 1679641956375
    },
    {
      "type": "edit",
      "id": "4947b4c6eb295f5b",
      "item": {
        "type": "pagefold",
        "id": "4947b4c6eb295f5b",
        "text": "~"
      },
      "date": 1679641960011
    },
    {
      "item": {
        "type": "factory",
        "id": "e33c9d2b7c53d9cf"
      },
      "id": "e33c9d2b7c53d9cf",
      "type": "add",
      "after": "4947b4c6eb295f5b",
      "date": 1679641963449
    },
    {
      "type": "edit",
      "id": "e33c9d2b7c53d9cf",
      "item": {
        "type": "paragraph",
        "id": "e33c9d2b7c53d9cf",
        "text": "\nWILCOXON, Frank, 1947. Probability Tables for Individual Comparisons by Ranking Methods. Biometrics. 1947. Vol. 3, no. 3, p. 119–122. DOI 10.2307/3001946. \n"
      },
      "date": 1679641968669
    },
    {
      "type": "fork",
      "site": "wiki.ralfbarkow.ch",
      "date": 1679642083919
    },
    {
      "item": {
        "type": "factory",
        "id": "df19f3badf5e1f5e"
      },
      "id": "df19f3badf5e1f5e",
      "type": "add",
      "after": "e33c9d2b7c53d9cf",
      "date": 1679642218108
    },
    {
      "id": "df19f3badf5e1f5e",
      "type": "move",
      "order": [
        "c4a0ab965f97ee61",
        "0e7e7cddb90d5f6e",
        "df19f3badf5e1f5e",
        "4947b4c6eb295f5b",
        "e33c9d2b7c53d9cf"
      ],
      "date": 1679642219626
    },
    {
      "type": "edit",
      "id": "df19f3badf5e1f5e",
      "item": {
        "type": "paragraph",
        "id": "df19f3badf5e1f5e",
        "text": "Thanks to very clever programming and increasingly powerful GPUs, they are deeply complex and precise probability tables, but they are still only inferring based on what they’ve seen in the past.\n\nWe don’t understand how organic brains learn. Building an electronic brain remains science fiction.\n\nLLMs produce an impressive simulacra of human language, but there is no there there. \n\nI jokingly say that they “make shit up,” but that implies intent and ability to conceptualize."
      },
      "date": 1679642221178
    },
    {
      "type": "edit",
      "id": "df19f3badf5e1f5e",
      "item": {
        "type": "paragraph",
        "id": "df19f3badf5e1f5e",
        "text": "Thanks to very clever programming and increasingly powerful GPUs, they are deeply complex and precise probability tables, but they are still only inferring based on what they’ve seen in the past.\n\nWe don’t understand how organic brains learn. Building an electronic brain remains science fiction.\n\nLLMs produce an impressive simulacra of human language, but there is no there there. [[Simulacres et Simulation]]\n\nI jokingly say that they “make shit up,” but that implies intent and ability to conceptualize."
      },
      "date": 1679642305042
    },
    {
      "type": "edit",
      "id": "df19f3badf5e1f5e",
      "item": {
        "type": "paragraph",
        "id": "df19f3badf5e1f5e",
        "text": "Thanks to very clever programming and increasingly powerful GPUs, they are deeply complex and precise probability tables, but they are still only inferring based on what they’ve seen in the past.\n\nWe don’t understand how organic brains learn. Building an electronic brain remains science fiction.\n\nLLMs produce an impressive simulacra of human language, but there is no there there. [⇒ [[Simulacres et Simulation]]]\n\nI jokingly say that they “make shit up,” but that implies intent and ability to conceptualize."
      },
      "date": 1679642325176
    },
    {
      "type": "edit",
      "id": "df19f3badf5e1f5e",
      "item": {
        "type": "paragraph",
        "id": "df19f3badf5e1f5e",
        "text": "Thanks to very clever programming and increasingly powerful GPUs, they are deeply complex and precise probability tables, but they are still only inferring based on what they’ve seen in the past.\n\nWe don’t understand how organic brains learn. Building an electronic brain remains science fiction.\n\n"
      },
      "date": 1679642479110
    },
    {
      "type": "add",
      "id": "704fd331824ec46c",
      "item": {
        "type": "paragraph",
        "id": "704fd331824ec46c",
        "text": "LLMs produce an impressive simulacra of human language, but there is no there there. [⇒ [[Simulacres et Simulation]]] >> simulacra\n\n"
      },
      "after": "df19f3badf5e1f5e",
      "date": 1679642484278
    },
    {
      "type": "add",
      "id": "dab8555ecc528bb3",
      "item": {
        "type": "paragraph",
        "id": "dab8555ecc528bb3",
        "text": "> I jokingly say that they “make shit up,” but that implies intent and ability to conceptualize."
      },
      "after": "704fd331824ec46c",
      "date": 1679642485137
    },
    {
      "type": "edit",
      "id": "704fd331824ec46c",
      "item": {
        "type": "paragraph",
        "id": "704fd331824ec46c",
        "text": "LLMs produce an impressive [[Simulacra]] of human language, but there is no there there. [⇒ [[Simulacres et Simulation]]] >> simulacra\n\n"
      },
      "date": 1679642497276
    },
    {
      "type": "add",
      "id": "be400bfd4b7663c1",
      "item": {
        "type": "paragraph",
        "id": "be400bfd4b7663c1",
        "text": "These machines can do neither. They produce strings of tokens that statistically appear like they were produced by a human.\n\nTo an LLM the statements “Neil Armstrong was the first man to walk on the moon” and “Neil Armstrong was the first man to walk on Mars” are differentiated only in that more people have written the former than the latter.\n\nThat’s it.\n\nAI doesn’t exist and companies letting what we DO have make decisions is just a way to avoid culpability for the results."
      },
      "after": "dab8555ecc528bb3",
      "date": 1679642624498
    },
    {
      "type": "edit",
      "id": "dab8555ecc528bb3",
      "item": {
        "type": "markdown",
        "id": "dab8555ecc528bb3",
        "text": "> I jokingly say that they “make shit up,” but that implies intent and ability to conceptualize."
      },
      "date": 1679642625305
    },
    {
      "type": "edit",
      "id": "be400bfd4b7663c1",
      "item": {
        "type": "paragraph",
        "id": "be400bfd4b7663c1",
        "text": "These machines can do neither. They produce strings of tokens that statistically appear like they were produced by a human.\n\nTo an LLM the statements “Neil Armstrong was the first man to walk on the moon” and “Neil Armstrong was the first man to walk on Mars” are differentiated only in that more people have written the former than the latter.\n\nThat’s it.\n\n"
      },
      "date": 1679643068363
    },
    {
      "type": "add",
      "id": "4a6c4d57101be002",
      "item": {
        "type": "paragraph",
        "id": "4a6c4d57101be002",
        "text": "AI doesn’t exist and companies letting what we DO have make decisions is just a way to avoid culpability for the results. [⇒ [[Organized Irresponsibility]]]"
      },
      "after": "be400bfd4b7663c1",
      "date": 1679643090142
    },
    {
      "type": "edit",
      "id": "4a6c4d57101be002",
      "item": {
        "type": "paragraph",
        "id": "4a6c4d57101be002",
        "text": "AI doesn’t exist and companies letting what we DO have make decisions is just a way to avoid culpability for the results. [⇒ [[Organized Irresponsibility]]] >> culpability"
      },
      "date": 1679643201806
    },
    {
      "type": "add",
      "id": "4e810fb49651555b",
      "item": {
        "type": "paragraph",
        "id": "4e810fb49651555b",
        "text": "Mar 4\nmwop@phpc.social\nMatthew Weier O'Phinney @mwop@phpc.social\n\n@ieatkillerbees I studied AI briefly in college 30 years ago, and have been watching all the hype around \"AI\" lately with amusement. It's exactly what you say - just fancy lookup tables and decision trees.  Sometimes it puts fun things together, but it's accidental.\n\n(The reason I left CS was because I got interested in what it means to be human... due to studying AI. Debates about ethically turning off an AI felt ... Hugely premature. There's no being with a sense of self to turn off...)"
      },
      "after": "4a6c4d57101be002",
      "date": 1679643290494
    },
    {
      "item": {
        "type": "factory",
        "id": "21a723d274db779a"
      },
      "id": "21a723d274db779a",
      "type": "add",
      "after": "e33c9d2b7c53d9cf",
      "date": 1679643293637
    },
    {
      "id": "21a723d274db779a",
      "type": "move",
      "order": [
        "c4a0ab965f97ee61",
        "0e7e7cddb90d5f6e",
        "df19f3badf5e1f5e",
        "704fd331824ec46c",
        "dab8555ecc528bb3",
        "be400bfd4b7663c1",
        "4a6c4d57101be002",
        "21a723d274db779a",
        "4e810fb49651555b",
        "4947b4c6eb295f5b",
        "e33c9d2b7c53d9cf"
      ],
      "date": 1679643295978
    },
    {
      "type": "edit",
      "id": "21a723d274db779a",
      "item": {
        "type": "pagefold",
        "id": "21a723d274db779a",
        "text": "~"
      },
      "date": 1679643298850
    },
    {
      "item": {
        "type": "factory",
        "id": "8250656442f6c9d6"
      },
      "id": "8250656442f6c9d6",
      "type": "add",
      "after": "e33c9d2b7c53d9cf",
      "date": 1679643300993
    },
    {
      "id": "8250656442f6c9d6",
      "type": "move",
      "order": [
        "c4a0ab965f97ee61",
        "0e7e7cddb90d5f6e",
        "df19f3badf5e1f5e",
        "704fd331824ec46c",
        "dab8555ecc528bb3",
        "be400bfd4b7663c1",
        "4a6c4d57101be002",
        "21a723d274db779a",
        "4e810fb49651555b",
        "8250656442f6c9d6",
        "4947b4c6eb295f5b",
        "e33c9d2b7c53d9cf"
      ],
      "date": 1679643303491
    },
    {
      "item": {
        "type": "factory",
        "id": "965d687462f5ac5f"
      },
      "id": "965d687462f5ac5f",
      "type": "add",
      "after": "e33c9d2b7c53d9cf",
      "date": 1679643305524
    },
    {
      "id": "965d687462f5ac5f",
      "type": "move",
      "order": [
        "c4a0ab965f97ee61",
        "0e7e7cddb90d5f6e",
        "df19f3badf5e1f5e",
        "704fd331824ec46c",
        "dab8555ecc528bb3",
        "be400bfd4b7663c1",
        "4a6c4d57101be002",
        "21a723d274db779a",
        "4e810fb49651555b",
        "965d687462f5ac5f",
        "8250656442f6c9d6",
        "4947b4c6eb295f5b",
        "e33c9d2b7c53d9cf"
      ],
      "date": 1679643308790
    },
    {
      "type": "edit",
      "id": "965d687462f5ac5f",
      "item": {
        "type": "pagefold",
        "id": "965d687462f5ac5f",
        "text": "~"
      },
      "date": 1679643311603
    },
    {
      "type": "edit",
      "id": "8250656442f6c9d6",
      "item": {
        "type": "paragraph",
        "id": "8250656442f6c9d6",
        "text": "@mwop They’re totally cool and it’s impressive we’ve been able to develop machines that appear non-deterministic at the scale of human observation (helped by our nature, as a species, to recognize intelligence in other things that seem human). Still, machines they are."
      },
      "date": 1679643326113
    },
    {
      "type": "edit",
      "id": "4e810fb49651555b",
      "item": {
        "type": "paragraph",
        "id": "4e810fb49651555b",
        "text": "Mar 4\nmwop@phpc.social\nMatthew Weier O'Phinney @mwop@phpc.social\n\n@ieatkillerbees I studied AI briefly in college 30 years ago, and have been watching all the hype around \"AI\" lately with amusement. It's exactly what you say - just fancy [[Lookup Table]]s and [[Decision Tree]]s.  Sometimes it puts fun things together, but it's accidental. >> lookup table decision tree"
      },
      "date": 1679643442799
    },
    {
      "type": "add",
      "id": "7c5d01e64c85e41d",
      "item": {
        "type": "paragraph",
        "id": "7c5d01e64c85e41d",
        "text": "(The reason I left CS was because I got interested in what it means to be human... due to studying AI. Debates about ethically turning off an AI felt ... Hugely premature. There's no being with a sense of self to turn off...)"
      },
      "after": "4e810fb49651555b",
      "date": 1679643444421
    },
    {
      "type": "fork",
      "site": "papers.dreyeck.ch",
      "date": 1679643681436
    }
  ]
}