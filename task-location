{
  "title": "Task Location",
  "story": [
    {
      "type": "paragraph",
      "id": "138790c38aba36f2",
      "text": "Contrary to the interpretation of the title of the original GPT-3 paper by Brown et al [3] that language models are \"few-shot learners\", we argue that GPT-3 often does not actually learn the [[Task]] at runtime from \"few-shot examples\". "
    },
    {
      "type": "paragraph",
      "id": "80c3af94317bed46",
      "text": "Rather than [[Instruction]], the method’s primary function is task location in the model’s existing space of learned tasks [⇒ [[Model Free Method Zoo]] ⇒ [[Understanding Machines]] ⇒ [[Table Lookup]] ⇒ [[Interrupt Vector Table]] ⇒ [[Dispatch Table]] ⇒ [[Table Lookup and Dispatch]]]. This is evidenced by the effectiveness of alternative prompts which, with no examples, can elicit comparable or superior performance to the few-shot format. >> task location table lookup dispatch table"
    },
    {
      "type": "paragraph",
      "id": "83e9d866da15d1fa",
      "text": "This motivates new approaches which explicitly pursue the goal of task location. We propose exploring more general methods of [[Prompt Programming]] and specifically techniques for communicating task intention and structure to a self-supervised model in the modality it was trained: [[Natural Language]]. With a few caveats, we want to find prompts which we would expect a human to complete in a way that accomplishes the desired [[Task]]."
    },
    {
      "type": "paragraph",
      "id": "17770d206f29f370",
      "text": "In this work, we investigate the few-shot paradigm and find that its performance can be matched or exceeded by simple 0-shot prompts. We explore the nature of successful 0-shot prompts and propose general methods of prompt programming through the lens of natural language [[Semiotics]]. We demonstrate novel prompts which force a language model to break a problem into components before producing a verdict, and we introduce the concept of metaprompt programming, an approach which offloads the job of writing a task-specific prompt to the language model itself. Finally, we discuss how these ideas can be incorporated into existing and future benchmarks to allow us to better probe the capabilities of large language models."
    },
    {
      "type": "pagefold",
      "id": "6e47d9b56b60e738",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "7f97a6bb8fcf767c",
      "text": "REYNOLDS, Laria and MCDONELL, Kyle, 2021. [[Prompt Programming]] for [[Large Language Model]]s: Beyond the Few-Shot Paradigm. In: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. Online. New York, NY, USA: Association for Computing Machinery. 2021. p. 1–7. [Accessed 29 January 2023]. CHI EA ’21. ISBN 978-1-4503-8095-9. DOI 10.1145/3411763.3451760. "
    },
    {
      "type": "paragraph",
      "id": "82395f15b0492722",
      "text": "[3] Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. arXiv preprint arXiv:2005.14165 (2020)."
    },
    {
      "type": "paragraph",
      "id": "2bfe61fbf03b1188",
      "text": "⇒ [[Direct Task Specification]]"
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Task Location",
        "story": []
      },
      "date": 1675074522838
    },
    {
      "item": {
        "type": "factory",
        "id": "138790c38aba36f2"
      },
      "id": "138790c38aba36f2",
      "type": "add",
      "date": 1675074534101
    },
    {
      "type": "edit",
      "id": "138790c38aba36f2",
      "item": {
        "type": "paragraph",
        "id": "138790c38aba36f2",
        "text": "Contrary to the interpretation of implied by the title of the original GPT-3 paper by Brown et al. [3], Language models are few-shot learners, we argue that GPT-3 is often not actually learning the task during run time from few-shot examples. Rather than instruction, the method’s primary function is task location in the model’s existing space of learned tasks. This is evidenced by the effectiveness of alternative prompts which, with no examples, can elicit comparable or superior performance to the few-shot format."
      },
      "date": 1675074535756
    },
    {
      "item": {
        "type": "factory",
        "id": "6e47d9b56b60e738"
      },
      "id": "6e47d9b56b60e738",
      "type": "add",
      "after": "138790c38aba36f2",
      "date": 1675074546620
    },
    {
      "type": "edit",
      "id": "6e47d9b56b60e738",
      "item": {
        "type": "pagefold",
        "id": "6e47d9b56b60e738",
        "text": "~"
      },
      "date": 1675074549631
    },
    {
      "item": {
        "type": "factory",
        "id": "7f97a6bb8fcf767c"
      },
      "id": "7f97a6bb8fcf767c",
      "type": "add",
      "after": "6e47d9b56b60e738",
      "date": 1675074550858
    },
    {
      "type": "edit",
      "id": "7f97a6bb8fcf767c",
      "item": {
        "type": "paragraph",
        "id": "7f97a6bb8fcf767c",
        "text": "REYNOLDS, Laria and MCDONELL, Kyle, 2021. Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm. In: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. Online. New York, NY, USA: Association for Computing Machinery. 2021. p. 1–7. [Accessed 29 January 2023]. CHI EA ’21. ISBN 978-1-4503-8095-9. DOI 10.1145/3411763.3451760. "
      },
      "date": 1675074562827
    },
    {
      "type": "edit",
      "id": "7f97a6bb8fcf767c",
      "item": {
        "type": "paragraph",
        "id": "7f97a6bb8fcf767c",
        "text": "REYNOLDS, Laria and MCDONELL, Kyle, 2021. [[Prompt Programming]] for [[Large Language Model]]s: Beyond the Few-Shot Paradigm. In: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. Online. New York, NY, USA: Association for Computing Machinery. 2021. p. 1–7. [Accessed 29 January 2023]. CHI EA ’21. ISBN 978-1-4503-8095-9. DOI 10.1145/3411763.3451760. "
      },
      "date": 1675074579761
    },
    {
      "type": "edit",
      "id": "138790c38aba36f2",
      "item": {
        "type": "paragraph",
        "id": "138790c38aba36f2",
        "text": "Contrary to the interpretation of implied by the title of the original GPT-3 paper by Brown et al. [3], Language models are few-shot learners, we argue that GPT-3 is often not actually learning the task during run time from few-shot examples. "
      },
      "date": 1675074633378
    },
    {
      "type": "add",
      "id": "80c3af94317bed46",
      "item": {
        "type": "paragraph",
        "id": "80c3af94317bed46",
        "text": "Rather than [[Instruction]], the method’s primary function is task location in the model’s existing space of learned tasks. This is evidenced by the effectiveness of alternative prompts which, with no examples, can elicit comparable or superior performance to the few-shot format."
      },
      "after": "138790c38aba36f2",
      "date": 1675074645370
    },
    {
      "type": "add",
      "id": "83e9d866da15d1fa",
      "item": {
        "type": "paragraph",
        "id": "83e9d866da15d1fa",
        "text": "This motivates new approaches which explicitly pursue the goal of task location. We propose exploring more general methods of prompt programming and specifically techniques for communicating task intention and structure to a self-supervised model in the modality it was trained: natural language. With a few caveats, we want to find prompts which we would expect a human to complete in a way that accomplishes the desired task."
      },
      "after": "80c3af94317bed46",
      "date": 1675074729751
    },
    {
      "type": "edit",
      "id": "83e9d866da15d1fa",
      "item": {
        "type": "paragraph",
        "id": "83e9d866da15d1fa",
        "text": "This motivates new approaches which explicitly pursue the goal of task location. We propose exploring more general methods of prompt programming and specifically techniques for communicating task intention and structure to a self-supervised model in the modality it was trained: [[Natural Language]]. With a few caveats, we want to find prompts which we would expect a human to complete in a way that accomplishes the desired task."
      },
      "date": 1675074760299
    },
    {
      "type": "edit",
      "id": "83e9d866da15d1fa",
      "item": {
        "type": "paragraph",
        "id": "83e9d866da15d1fa",
        "text": "This motivates new approaches which explicitly pursue the goal of task location. We propose exploring more general methods of [[Prompt Programming]] and specifically techniques for communicating task intention and structure to a self-supervised model in the modality it was trained: [[Natural Language]]. With a few caveats, we want to find prompts which we would expect a human to complete in a way that accomplishes the desired task."
      },
      "date": 1675075028822
    },
    {
      "type": "add",
      "id": "17770d206f29f370",
      "item": {
        "type": "paragraph",
        "id": "17770d206f29f370",
        "text": "In this work, we investigate the few-shot paradigm and find that its performance can be matched or exceeded by simple 0-shot prompts. We explore the nature of successful 0-shot prompts and propose general methods of prompt programming through the lens of natural language semiotics. We demonstrate novel prompts which force a language model to break a problem into components before producing a verdict, and we introduce the concept of metaprompt programming, an approach which offloads the job of writing a task-specific prompt to the language model itself. Finally, we discuss how these ideas can be incorporated into existing and future benchmarks to allow us to better probe the capabilities of large language models."
      },
      "after": "83e9d866da15d1fa",
      "date": 1675075064442
    },
    {
      "type": "edit",
      "id": "17770d206f29f370",
      "item": {
        "type": "paragraph",
        "id": "17770d206f29f370",
        "text": "In this work, we investigate the few-shot paradigm and find that its performance can be matched or exceeded by simple 0-shot prompts. We explore the nature of successful 0-shot prompts and propose general methods of prompt programming through the lens of natural language [[Semiotics]]. We demonstrate novel prompts which force a language model to break a problem into components before producing a verdict, and we introduce the concept of metaprompt programming, an approach which offloads the job of writing a task-specific prompt to the language model itself. Finally, we discuss how these ideas can be incorporated into existing and future benchmarks to allow us to better probe the capabilities of large language models."
      },
      "date": 1675075169152
    },
    {
      "item": {
        "type": "factory",
        "id": "2bfe61fbf03b1188"
      },
      "id": "2bfe61fbf03b1188",
      "type": "add",
      "after": "7f97a6bb8fcf767c",
      "date": 1675075894262
    },
    {
      "type": "edit",
      "id": "2bfe61fbf03b1188",
      "item": {
        "type": "paragraph",
        "id": "2bfe61fbf03b1188",
        "text": "⇒ [[Direct Task Specification]]"
      },
      "date": 1675075903575
    },
    {
      "type": "fork",
      "site": "dreyeck.wiki.ralfbarkow.ch",
      "date": 1679563087418
    },
    {
      "type": "edit",
      "id": "80c3af94317bed46",
      "item": {
        "type": "paragraph",
        "id": "80c3af94317bed46",
        "text": "Rather than [[Instruction]], the method’s primary function is task location in the model’s existing space of learned tasks [⇒ [[Table Lookup]]]. This is evidenced by the effectiveness of alternative prompts which, with no examples, can elicit comparable or superior performance to the few-shot format."
      },
      "date": 1679563363371
    },
    {
      "type": "edit",
      "id": "80c3af94317bed46",
      "item": {
        "type": "paragraph",
        "id": "80c3af94317bed46",
        "text": "Rather than [[Instruction]], the method’s primary function is task location in the model’s existing space of learned tasks [⇒ [[Table Lookup]]]. This is evidenced by the effectiveness of alternative prompts which, with no examples, can elicit comparable or superior performance to the few-shot format. >> task location table lookup"
      },
      "date": 1679563390103
    },
    {
      "type": "edit",
      "id": "80c3af94317bed46",
      "item": {
        "type": "paragraph",
        "id": "80c3af94317bed46",
        "text": "Rather than [[Instruction]], the method’s primary function is task location in the model’s existing space of learned tasks [⇒ [[Table Lookup]] ⇒ [[Interrupt Vector Table]]]. This is evidenced by the effectiveness of alternative prompts which, with no examples, can elicit comparable or superior performance to the few-shot format. >> task location table lookup"
      },
      "date": 1679563723240
    },
    {
      "type": "edit",
      "id": "80c3af94317bed46",
      "item": {
        "type": "paragraph",
        "id": "80c3af94317bed46",
        "text": "Rather than [[Instruction]], the method’s primary function is task location in the model’s existing space of learned tasks [⇒ [[Table Lookup]] ⇒ [[Interrupt Vector Table]] ⇒ [[Dispatch Table]]]. This is evidenced by the effectiveness of alternative prompts which, with no examples, can elicit comparable or superior performance to the few-shot format. >> task location table lookup"
      },
      "date": 1679563801765
    },
    {
      "type": "edit",
      "id": "80c3af94317bed46",
      "item": {
        "type": "paragraph",
        "id": "80c3af94317bed46",
        "text": "Rather than [[Instruction]], the method’s primary function is task location in the model’s existing space of learned tasks [⇒ [[Table Lookup]] ⇒ [[Interrupt Vector Table]] ⇒ [[Dispatch Table]]]. This is evidenced by the effectiveness of alternative prompts which, with no examples, can elicit comparable or superior performance to the few-shot format. >> task location table lookup dispatch table"
      },
      "date": 1679563892597
    },
    {
      "item": {
        "type": "factory",
        "id": "82395f15b0492722"
      },
      "id": "82395f15b0492722",
      "type": "add",
      "after": "2bfe61fbf03b1188",
      "date": 1679601427450
    },
    {
      "type": "edit",
      "id": "82395f15b0492722",
      "item": {
        "type": "paragraph",
        "id": "82395f15b0492722",
        "text": "3] Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. arXiv preprint arXiv:2005.14165 (2020)."
      },
      "date": 1679601430948
    },
    {
      "type": "edit",
      "id": "82395f15b0492722",
      "item": {
        "type": "paragraph",
        "id": "82395f15b0492722",
        "text": "[3] Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. arXiv preprint arXiv:2005.14165 (2020)."
      },
      "date": 1679601438461
    },
    {
      "id": "82395f15b0492722",
      "type": "move",
      "order": [
        "138790c38aba36f2",
        "80c3af94317bed46",
        "83e9d866da15d1fa",
        "17770d206f29f370",
        "6e47d9b56b60e738",
        "7f97a6bb8fcf767c",
        "82395f15b0492722",
        "2bfe61fbf03b1188"
      ],
      "date": 1679601440317
    },
    {
      "type": "fork",
      "site": "papers.dreyeck.ch",
      "date": 1679601567266
    },
    {
      "type": "edit",
      "id": "138790c38aba36f2",
      "item": {
        "type": "paragraph",
        "id": "138790c38aba36f2",
        "text": "Contrary to the interpretation of the title of the original GPT-3 paper by Brown et al [3] that language models are \"few-shot learners\", we argue that GPT-3 often does not actually learn the task at runtime from \"few-shot examples\". "
      },
      "date": 1679605346774
    },
    {
      "type": "fork",
      "site": "wiki.ralfbarkow.ch",
      "date": 1679605688205
    },
    {
      "type": "edit",
      "id": "80c3af94317bed46",
      "item": {
        "type": "paragraph",
        "id": "80c3af94317bed46",
        "text": "Rather than [[Instruction]], the method’s primary function is task location in the model’s existing space of learned tasks [⇒ [[Model Free Method Zoo]] ⇒ [[Understanding Machines]] ⇒ [[Table Lookup]] ⇒ [[Interrupt Vector Table]] ⇒ [[Dispatch Table]]]. This is evidenced by the effectiveness of alternative prompts which, with no examples, can elicit comparable or superior performance to the few-shot format. >> task location table lookup dispatch table"
      },
      "date": 1679607489905
    },
    {
      "type": "edit",
      "id": "80c3af94317bed46",
      "item": {
        "type": "paragraph",
        "id": "80c3af94317bed46",
        "text": "Rather than [[Instruction]], the method’s primary function is task location in the model’s existing space of learned tasks [⇒ [[Model Free Method Zoo]] ⇒ [[Understanding Machines]] ⇒ [[Table Lookup]] ⇒ [[Interrupt Vector Table]] ⇒ [[Dispatch Table]] ⇒ [[Table Lookup and Dispatch]]]. This is evidenced by the effectiveness of alternative prompts which, with no examples, can elicit comparable or superior performance to the few-shot format. >> task location table lookup dispatch table"
      },
      "date": 1679607571135
    },
    {
      "type": "edit",
      "id": "83e9d866da15d1fa",
      "item": {
        "type": "paragraph",
        "id": "83e9d866da15d1fa",
        "text": "This motivates new approaches which explicitly pursue the goal of task location. We propose exploring more general methods of [[Prompt Programming]] and specifically techniques for communicating task intention and structure to a self-supervised model in the modality it was trained: [[Natural Language]]. With a few caveats, we want to find prompts which we would expect a human to complete in a way that accomplishes the desired [[Task]]."
      },
      "date": 1679609498061
    },
    {
      "type": "edit",
      "id": "138790c38aba36f2",
      "item": {
        "type": "paragraph",
        "id": "138790c38aba36f2",
        "text": "Contrary to the interpretation of the title of the original GPT-3 paper by Brown et al [3] that language models are \"few-shot learners\", we argue that GPT-3 often does not actually learn the [[Task]] at runtime from \"few-shot examples\". "
      },
      "date": 1679648452653
    },
    {
      "type": "fork",
      "site": "code.dreyeck.ch",
      "date": 1679852784071
    }
  ]
}