{
  "title": "Mental Model",
  "story": [
    {
      "type": "paragraph",
      "id": "073b0654f5f77f49",
      "text": "While [[3D Scene Graph]]s can serve as an advanced “mental model” for robots, how to [[build]] such a rich representation in real-time remains uncharted territory. "
    },
    {
      "type": "pagefold",
      "id": "889918abd298b2a9",
      "text": "~"
    },
    {
      "type": "markdown",
      "id": "0f95146fb90e8e1a",
      "text": "HUGHES, Nathan, CHANG, Yun and CARLONE, Luca, 2022. Hydra: A Real-time Spatial Perception System for 3D Scene Graph Construction and Optimization. arXiv. Online. 2022. [Accessed 22 November 2022]. Available from: https://dspace.mit.edu/handle/1721.1/145300\n"
    },
    {
      "type": "reference",
      "id": "2e398fc700eb67c2",
      "site": "don.noyes.asia.wiki.org",
      "slug": "team-learning",
      "title": "Team Learning",
      "text": "One of the disciplines of a [[Learning Organization]]. A team is any group that \"pulls together\". [[Team Learning]] is about dialogue, conversation, development, creating meaning in teams and groups of people. Usually one participant - or an invited outsider - takes on the role of moderator (= mediating the dialogue) or facilitator (= making the learning easier). [[Team Learning]] can use tools and methods like [[Systems Thinking]] [[Shared Vision]] and a [[Mental Model]]."
    },
    {
      "type": "reference",
      "id": "1673e48d5a74830c",
      "site": "dayton.fed.wiki",
      "slug": "systems-thinking",
      "title": "Systems Thinking",
      "text": "There are three critical types of thinking necessary to be empowered creators in the new economy – three types of thinking we are challenged to develop in our students."
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Mental Model",
        "story": []
      },
      "date": 1669144039131
    },
    {
      "item": {
        "type": "factory",
        "id": "2e398fc700eb67c2"
      },
      "id": "2e398fc700eb67c2",
      "type": "add",
      "date": 1669144041377
    },
    {
      "type": "edit",
      "id": "2e398fc700eb67c2",
      "item": {
        "type": "reference",
        "id": "2e398fc700eb67c2",
        "site": "don.noyes.asia.wiki.org",
        "slug": "team-learning",
        "title": "Team Learning",
        "text": "One of the disciplines of a [[Learning Organization]]. A team is any group that \"pulls together\". [[Team Learning]] is about dialogue, conversation, development, creating meaning in teams and groups of people. Usually one participant - or an invited outsider - takes on the role of moderator (= mediating the dialogue) or facilitator (= making the learning easier). [[Team Learning]] can use tools and methods like [[Systems Thinking]] [[Shared Vision]] and a [[Mental Model]]."
      },
      "date": 1669144044521
    },
    {
      "item": {
        "type": "factory",
        "id": "1673e48d5a74830c"
      },
      "id": "1673e48d5a74830c",
      "type": "add",
      "after": "2e398fc700eb67c2",
      "date": 1669144078661
    },
    {
      "type": "edit",
      "id": "1673e48d5a74830c",
      "item": {
        "type": "reference",
        "id": "1673e48d5a74830c",
        "site": "dayton.fed.wiki",
        "slug": "systems-thinking",
        "title": "Systems Thinking",
        "text": "There are three critical types of thinking necessary to be empowered creators in the new economy – three types of thinking we are challenged to develop in our students."
      },
      "date": 1669144081310
    },
    {
      "item": {
        "type": "factory",
        "id": "889918abd298b2a9"
      },
      "id": "889918abd298b2a9",
      "type": "add",
      "after": "1673e48d5a74830c",
      "date": 1669159260755
    },
    {
      "type": "edit",
      "id": "889918abd298b2a9",
      "item": {
        "type": "pagefold",
        "id": "889918abd298b2a9",
        "text": "~"
      },
      "date": 1669159264089
    },
    {
      "id": "889918abd298b2a9",
      "type": "move",
      "order": [
        "889918abd298b2a9",
        "2e398fc700eb67c2",
        "1673e48d5a74830c"
      ],
      "date": 1669159266690
    },
    {
      "item": {
        "type": "factory",
        "id": "073b0654f5f77f49"
      },
      "id": "073b0654f5f77f49",
      "type": "add",
      "after": "1673e48d5a74830c",
      "date": 1669159268192
    },
    {
      "id": "073b0654f5f77f49",
      "type": "move",
      "order": [
        "073b0654f5f77f49",
        "889918abd298b2a9",
        "2e398fc700eb67c2",
        "1673e48d5a74830c"
      ],
      "date": 1669159270700
    },
    {
      "type": "edit",
      "id": "073b0654f5f77f49",
      "item": {
        "type": "paragraph",
        "id": "073b0654f5f77f49",
        "text": "While 3D scene graphs can serve as an advanced “mental\nmodel” for robots, how to build such a rich representation in\nreal-time remains uncharted territory. The works [26, 63, 67]\nallow real-time operation but are restricted to “flat” 3D scene\ngraphs and are mostly concerned with objects and their\nrelations while disregarding the top layers in Fig. 1. The\nworks [4, 49, 50], which focus on building truly hierarchical\nrepresentations, run offline and require several minutes to build\na 3D scene graph ([4] even assumes the availability of a correct\nand complete metric-semantic mesh of the environment built\nbeforehand). Extending our prior works [49, 50] to operate\nin real-time is non-trivial. These works utilize an Euclidean\nSigned Distance Function (ESDF) of the entire environment to\nbuild the 3D scene graph. Unfortunately, the memory required\nfor ESDFs scale poorly in the size of the environment [43].\nMoreover, the extraction of places and rooms in [49, 50]\ninvolves batch algorithms that process the entire ESDF, whose\ncomputational cost grows over time and is incompatible with\nreal-time operation. Finally, the ESDF is reconstructed from\nthe robot trajectory estimate which keeps changing in response\nto loop closures. The approaches in [49, 50] would therefore\nneed to rebuild the scene graph from scratch after every loop\nclosure, clashing with real-time operation."
      },
      "date": 1669159272192
    },
    {
      "item": {
        "type": "factory",
        "id": "0f95146fb90e8e1a"
      },
      "id": "0f95146fb90e8e1a",
      "type": "add",
      "after": "1673e48d5a74830c",
      "date": 1669159319167
    },
    {
      "id": "0f95146fb90e8e1a",
      "type": "move",
      "order": [
        "073b0654f5f77f49",
        "889918abd298b2a9",
        "0f95146fb90e8e1a",
        "2e398fc700eb67c2",
        "1673e48d5a74830c"
      ],
      "date": 1669159321785
    },
    {
      "type": "edit",
      "id": "0f95146fb90e8e1a",
      "item": {
        "type": "paragraph",
        "id": "0f95146fb90e8e1a",
        "text": "HUGHES, Nathan, CHANG, Yun and CARLONE, Luca, 2022. Hydra: A Real-time Spatial Perception System for 3D Scene Graph Construction and Optimization. arXiv. Online. 2022. [Accessed 22 November 2022]. Available from: https://dspace.mit.edu/handle/1721.1/145300\n"
      },
      "date": 1669159341931
    },
    {
      "type": "edit",
      "id": "0f95146fb90e8e1a",
      "item": {
        "type": "markdown",
        "id": "0f95146fb90e8e1a",
        "text": "HUGHES, Nathan, CHANG, Yun and CARLONE, Luca, 2022. Hydra: A Real-time Spatial Perception System for 3D Scene Graph Construction and Optimization. arXiv. Online. 2022. [Accessed 22 November 2022]. Available from: https://dspace.mit.edu/handle/1721.1/145300\n"
      },
      "date": 1669159343725
    },
    {
      "type": "edit",
      "id": "073b0654f5f77f49",
      "item": {
        "type": "paragraph",
        "id": "073b0654f5f77f49",
        "text": "While [[3D scene graph]]s can serve as an advanced “mental\nmodel” for robots, how to build such a rich representation in\nreal-time remains uncharted territory. The works [26, 63, 67]\nallow real-time operation but are restricted to “flat” 3D scene\ngraphs and are mostly concerned with objects and their\nrelations while disregarding the top layers in Fig. 1. The\nworks [4, 49, 50], which focus on building truly hierarchical\nrepresentations, run offline and require several minutes to build\na 3D scene graph ([4] even assumes the availability of a correct\nand complete metric-semantic mesh of the environment built\nbeforehand). Extending our prior works [49, 50] to operate\nin real-time is non-trivial. These works utilize an Euclidean\nSigned Distance Function (ESDF) of the entire environment to\nbuild the 3D scene graph. Unfortunately, the memory required\nfor ESDFs scale poorly in the size of the environment [43].\nMoreover, the extraction of places and rooms in [49, 50]\ninvolves batch algorithms that process the entire ESDF, whose\ncomputational cost grows over time and is incompatible with\nreal-time operation. Finally, the ESDF is reconstructed from\nthe robot trajectory estimate which keeps changing in response\nto loop closures. The approaches in [49, 50] would therefore\nneed to rebuild the scene graph from scratch after every loop\nclosure, clashing with real-time operation."
      },
      "date": 1669159364732
    },
    {
      "type": "edit",
      "id": "073b0654f5f77f49",
      "item": {
        "type": "paragraph",
        "id": "073b0654f5f77f49",
        "text": "While [[3D Scene Graph]]s can serve as an advanced “mental\nmodel” for robots, how to build such a rich representation in\nreal-time remains uncharted territory. The works [26, 63, 67]\nallow real-time operation but are restricted to “flat” 3D scene\ngraphs and are mostly concerned with objects and their\nrelations while disregarding the top layers in Fig. 1. The\nworks [4, 49, 50], which focus on building truly hierarchical\nrepresentations, run offline and require several minutes to build\na 3D scene graph ([4] even assumes the availability of a correct\nand complete metric-semantic mesh of the environment built\nbeforehand). Extending our prior works [49, 50] to operate\nin real-time is non-trivial. These works utilize an Euclidean\nSigned Distance Function (ESDF) of the entire environment to\nbuild the 3D scene graph. Unfortunately, the memory required\nfor ESDFs scale poorly in the size of the environment [43].\nMoreover, the extraction of places and rooms in [49, 50]\ninvolves batch algorithms that process the entire ESDF, whose\ncomputational cost grows over time and is incompatible with\nreal-time operation. Finally, the ESDF is reconstructed from\nthe robot trajectory estimate which keeps changing in response\nto loop closures. The approaches in [49, 50] would therefore\nneed to rebuild the scene graph from scratch after every loop\nclosure, clashing with real-time operation."
      },
      "date": 1669159379385
    },
    {
      "type": "edit",
      "id": "073b0654f5f77f49",
      "item": {
        "type": "paragraph",
        "id": "073b0654f5f77f49",
        "text": "While [[3D Scene Graph]]s can serve as an advanced “mental\nmodel” for robots, how to [[build]] such a rich representation in\nreal-time remains uncharted territory. The works [26, 63, 67]\nallow real-time operation but are restricted to “flat” 3D scene\ngraphs and are mostly concerned with objects and their\nrelations while disregarding the top layers in Fig. 1. The\nworks [4, 49, 50], which focus on building truly hierarchical\nrepresentations, run offline and require several minutes to build\na 3D scene graph ([4] even assumes the availability of a correct\nand complete metric-semantic mesh of the environment built\nbeforehand). Extending our prior works [49, 50] to operate\nin real-time is non-trivial. These works utilize an Euclidean\nSigned Distance Function (ESDF) of the entire environment to\nbuild the 3D scene graph. Unfortunately, the memory required\nfor ESDFs scale poorly in the size of the environment [43].\nMoreover, the extraction of places and rooms in [49, 50]\ninvolves batch algorithms that process the entire ESDF, whose\ncomputational cost grows over time and is incompatible with\nreal-time operation. Finally, the ESDF is reconstructed from\nthe robot trajectory estimate which keeps changing in response\nto loop closures. The approaches in [49, 50] would therefore\nneed to rebuild the scene graph from scratch after every loop\nclosure, clashing with real-time operation."
      },
      "date": 1669159550373
    },
    {
      "type": "edit",
      "id": "073b0654f5f77f49",
      "item": {
        "type": "paragraph",
        "id": "073b0654f5f77f49",
        "text": "While [[3D Scene Graph]]s can serve as an advanced “mental model” for robots, how to [[build]] such a rich representation in real-time remains uncharted territory. The works [26, 63, 67] allow real-time operation but are restricted to “flat” 3D scene\ngraphs and are mostly concerned with objects and their\nrelations while disregarding the top layers in Fig. 1. The works [4, 49, 50], which focus on building truly hierarchical representations, run offline and require several minutes to build a 3D scene graph ([4] even assumes the availability of a correct and complete metric-semantic mesh of the environment built\nbeforehand). Extending our prior works [49, 50] to operate in real-time is non-trivial. These works utilize an Euclidean Signed Distance Function (ESDF) of the entire environment to build the 3D scene graph. Unfortunately, the memory required for ESDFs scale poorly in the size of the environment [43].\nMoreover, the extraction of places and rooms in [49, 50] involves batch algorithms that process the entire ESDF, whose computational cost grows over time and is incompatible with real-time operation. Finally, the ESDF is reconstructed from the robot trajectory estimate which keeps changing in response\nto loop closures. The approaches in [49, 50] would therefore need to rebuild the scene graph from scratch after every loop closure, clashing with real-time operation."
      },
      "date": 1669159702659
    },
    {
      "type": "edit",
      "id": "073b0654f5f77f49",
      "item": {
        "type": "paragraph",
        "id": "073b0654f5f77f49",
        "text": "While [[3D Scene Graph]]s can serve as an advanced “mental model” for robots, how to [[build]] such a rich representation in real-time remains uncharted territory. "
      },
      "date": 1669159876236
    }
  ]
}