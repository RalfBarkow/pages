{
  "title": "Some thoughts on the current AI storm und drang",
  "story": [
    {
      "type": "markdown",
      "id": "364bf00d3af08e1f",
      "text": "There is a massive miasma of hype and misinformation around topics related to AI, ML, and chat programs and how they might be used&#8212;or misused.  I remember previous hype cycles around 5th-generation systems, robotics, and automatic language translation (as examples). The enthusiasm each time resulted in some advancements that weren't as profound as predicted. That enthusiasm faded as limitations became apparent and new bright, shiny technologies appeared to be chased."
    },
    {
      "type": "paragraph",
      "id": "2c590887962d56e8",
      "text": "The current hype seems even more frantic for several reasons, not least of which is that there are many more potential market opportunities for the current developments. Perhaps the entities that see new AI systems as a way to reduce expenses by cutting headcount and replacing people with AI are one of the biggest drivers causing both enthusiasm and concern (see, for example, [https://www.businessinsider.com/chatgpt-jobs-at-risk-replacement-artificialintelligence-ai-labor-trends-2023-02?op=1#teachers-5 https://www.businessinsider.com/chatgpt-jobs-at-risk-replacement-artificialintelligence-ai-labor-trends-2023-02?op=1#teachers-5]). That was a driver of the robotics craze some years back, too. The current cycle has already had an impact on some creative media, including being an issue of contention in the media writers' strike in the US. It also is raising serious questions in academia, politics, and the military."
    },
    {
      "type": "markdown",
      "id": "9b626eddddac2baf",
      "text": "There's also the usual hype cycle FOMO (fear of missing out) and the urge to be among the early adopters, as well as those speculating about the most severe forms of misuse.  That has led to all sorts of predictions of outlandish capabilities and dire doom scenarios&#8212;neither of which is likely wholly accurate. AI, generally, is still a developing field and will produce some real benefits over time. The limitations of today's systems may or may not be present in future systems.  However, there are many caveats about the systems we have now and those that may be available soon that justify genuine concern."
    },
    {
      "type": "markdown",
      "id": "a0a3ce1e092c654a",
      "text": "First, LLMs such as ChatGPT, Bard, et al. are NOT really &quot;intelligent.&quot; [...] Second, these systems are not accountable in current practice and law.  [...] Third, the inability of much of the general public to understand teh limitations of current systems means that any use may introduce a bias into how people make their own decisions and choices.  [...]"
    },
    {
      "type": "paragraph",
      "id": "db235dfe892df077",
      "text": "  [Long item PGN-ed for RISKS.  Check in with Spaf if you want the entire   piece.]"
    },
    {
      "type": "markdown",
      "id": "fb9ee541c3dbb859",
      "text": "Source: Gene Spafford via [https://catless.ncl.ac.uk/Risks/33/72/#subj20.1 The Risks Digest]"
    }
  ],
  "journal": [
    {
      "type": "create",
      "date": 1685930465000,
      "item": {
        "title": "Some thoughts on the current AI storm und drang",
        "story": [
          {
            "type": "markdown",
            "id": "364bf00d3af08e1f",
            "text": "There is a massive miasma of hype and misinformation around topics related to AI, ML, and chat programs and how they might be used&#8212;or misused.  I remember previous hype cycles around 5th-generation systems, robotics, and automatic language translation (as examples). The enthusiasm each time resulted in some advancements that weren't as profound as predicted. That enthusiasm faded as limitations became apparent and new bright, shiny technologies appeared to be chased."
          },
          {
            "type": "paragraph",
            "id": "2c590887962d56e8",
            "text": "The current hype seems even more frantic for several reasons, not least of which is that there are many more potential market opportunities for the current developments. Perhaps the entities that see new AI systems as a way to reduce expenses by cutting headcount and replacing people with AI are one of the biggest drivers causing both enthusiasm and concern (see, for example, [https://www.businessinsider.com/chatgpt-jobs-at-risk-replacement-artificialintelligence-ai-labor-trends-2023-02?op=1#teachers-5 https://www.businessinsider.com/chatgpt-jobs-at-risk-replacement-artificialintelligence-ai-labor-trends-2023-02?op=1#teachers-5]). That was a driver of the robotics craze some years back, too. The current cycle has already had an impact on some creative media, including being an issue of contention in the media writers' strike in the US. It also is raising serious questions in academia, politics, and the military."
          },
          {
            "type": "markdown",
            "id": "9b626eddddac2baf",
            "text": "There's also the usual hype cycle FOMO (fear of missing out) and the urge to be among the early adopters, as well as those speculating about the most severe forms of misuse.  That has led to all sorts of predictions of outlandish capabilities and dire doom scenarios&#8212;neither of which is likely wholly accurate. AI, generally, is still a developing field and will produce some real benefits over time. The limitations of today's systems may or may not be present in future systems.  However, there are many caveats about the systems we have now and those that may be available soon that justify genuine concern."
          },
          {
            "type": "markdown",
            "id": "a0a3ce1e092c654a",
            "text": "First, LLMs such as ChatGPT, Bard, et al. are NOT really &quot;intelligent.&quot; [...] Second, these systems are not accountable in current practice and law.  [...] Third, the inability of much of the general public to understand teh limitations of current systems means that any use may introduce a bias into how people make their own decisions and choices.  [...]"
          },
          {
            "type": "paragraph",
            "id": "db235dfe892df077",
            "text": "  [Long item PGN-ed for RISKS.  Check in with Spaf if you want the entire   piece.]"
          },
          {
            "type": "markdown",
            "id": "fb9ee541c3dbb859",
            "text": "Source: Gene Spafford via [https://catless.ncl.ac.uk/Risks/33/72/#subj20.1 The Risks Digest]"
          }
        ]
      }
    },
    {
      "type": "fork",
      "site": "risks.rodwell.me",
      "date": 1686124118355
    }
  ]
}