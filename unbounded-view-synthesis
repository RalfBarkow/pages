{
  "title": "Unbounded View Synthesis",
  "story": [
    {
      "type": "paragraph",
      "id": "848a3a99af92bd46",
      "text": "The authors explain an advance in synthetic image construction from still views. We enjoy the pleasant patter and the pretty pictures. [https://jonbarron.info/mipnerf360/ post]"
    },
    {
      "type": "video",
      "id": "bac2f387c81feaa8",
      "text": "YOUTUBE zBSH-k9GbV4\nPublished Mar 1, 2022."
    },
    {
      "type": "paragraph",
      "id": "c1f8aeeabb70060a",
      "text": "Though neural radiance fields (NeRF) have demonstrated impressive view synthesis results on objects and small bounded regions of space, they struggle on \"unbounded\" scenes, where the camera may point in any direction and content may exist at any distance. "
    },
    {
      "type": "paragraph",
      "id": "302652261177e43d",
      "text": "Our model, which we dub \"mip-NeRF 360\" as we target scenes in which the camera rotates 360 degrees around a point, reduces mean-squared error by 54% compared to mip-NeRF, and is able to produce realistic synthesized views and detailed depth maps for highly intricate, unbounded real-world scenes."
    },
    {
      "type": "pagefold",
      "id": "2dad11bbfdb387e7",
      "text": "."
    },
    {
      "type": "paragraph",
      "id": "db9b69c767431e95",
      "text": "In this article, we will start with an explanation of what is Computer Graphics with a brief on volume rendering and view synthesis. We will then have an overview of what is Neural Radiance Fields and how it is used in view synthesis. [https://medium.com/swlh/nerf-neural-radiance-fields-79531da37734 medium]"
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Unbounded View Synthesis",
        "story": []
      },
      "date": 1653960228301
    },
    {
      "item": {
        "type": "factory",
        "id": "848a3a99af92bd46"
      },
      "id": "848a3a99af92bd46",
      "type": "add",
      "date": 1653960258769
    },
    {
      "type": "edit",
      "id": "848a3a99af92bd46",
      "item": {
        "type": "paragraph",
        "id": "848a3a99af92bd46",
        "text": "The authors explain an advance in synthetic image construction from still views. We enjoy the pleasant patter and the pretty pictures."
      },
      "date": 1653960525291
    },
    {
      "item": {
        "type": "factory",
        "id": "bac2f387c81feaa8"
      },
      "id": "bac2f387c81feaa8",
      "type": "add",
      "after": "848a3a99af92bd46",
      "date": 1653960542856
    },
    {
      "type": "edit",
      "id": "bac2f387c81feaa8",
      "item": {
        "type": "video",
        "id": "bac2f387c81feaa8",
        "text": "YOUTUBE zBSH-k9GbV4\n(double-click to edit caption)\n"
      },
      "date": 1653960554325
    },
    {
      "type": "edit",
      "id": "bac2f387c81feaa8",
      "item": {
        "type": "video",
        "id": "bac2f387c81feaa8",
        "text": "YOUTUBE zBSH-k9GbV4\nPublished Mar 1, 2022."
      },
      "date": 1653960580069
    },
    {
      "item": {
        "type": "factory",
        "id": "c1f8aeeabb70060a"
      },
      "id": "c1f8aeeabb70060a",
      "type": "add",
      "after": "bac2f387c81feaa8",
      "date": 1653960652912
    },
    {
      "type": "edit",
      "id": "c1f8aeeabb70060a",
      "item": {
        "type": "paragraph",
        "id": "c1f8aeeabb70060a",
        "text": "Though neural radiance fields (NeRF) have demonstrated impressive view synthesis results on objects and small bounded regions of space, they struggle on \"unbounded\" scenes, where the camera may point in any direction and content may exist at any distance. "
      },
      "date": 1653960669228
    },
    {
      "type": "add",
      "id": "7c452093fc49b8e3",
      "item": {
        "type": "paragraph",
        "id": "7c452093fc49b8e3",
        "text": "In this setting, existing NeRF-like models often produce blurry or low-resolution renderings (due to the unbalanced detail and scale of nearby and distant objects), are slow to train, and may exhibit artifacts due to the inherent ambiguity of the task of reconstructing a large scene from a small set of images. We present an extension of mip-NeRF (a NeRF variant that addresses sampling and aliasing) that uses a non-linear scene parameterization, online distillation, and a novel distortion-based regularizer to overcome the challenges presented by unbounded scenes. "
      },
      "after": "c1f8aeeabb70060a",
      "date": 1653960684298
    },
    {
      "type": "add",
      "id": "302652261177e43d",
      "item": {
        "type": "paragraph",
        "id": "302652261177e43d",
        "text": "Our model, which we dub \"mip-NeRF 360\" as we target scenes in which the camera rotates 360 degrees around a point, reduces mean-squared error by 54% compared to mip-NeRF, and is able to produce realistic synthesized views and detailed depth maps for highly intricate, unbounded real-world scenes."
      },
      "after": "7c452093fc49b8e3",
      "date": 1653960687495
    },
    {
      "type": "remove",
      "id": "7c452093fc49b8e3",
      "date": 1653960693905
    },
    {
      "type": "edit",
      "id": "848a3a99af92bd46",
      "item": {
        "type": "paragraph",
        "id": "848a3a99af92bd46",
        "text": "The authors explain an advance in synthetic image construction from still views. We enjoy the pleasant patter and the pretty pictures. [https://jonbarron.info/mipnerf360/ post]"
      },
      "date": 1653960731263
    },
    {
      "item": {
        "type": "factory",
        "id": "2dad11bbfdb387e7"
      },
      "id": "2dad11bbfdb387e7",
      "type": "add",
      "after": "302652261177e43d",
      "date": 1653960778686
    },
    {
      "type": "edit",
      "id": "2dad11bbfdb387e7",
      "item": {
        "type": "pagefold",
        "id": "2dad11bbfdb387e7",
        "text": "."
      },
      "date": 1653960783433
    },
    {
      "item": {
        "type": "factory",
        "id": "db9b69c767431e95"
      },
      "id": "db9b69c767431e95",
      "type": "add",
      "after": "2dad11bbfdb387e7",
      "date": 1653960784987
    },
    {
      "type": "edit",
      "id": "db9b69c767431e95",
      "item": {
        "type": "paragraph",
        "id": "db9b69c767431e95",
        "text": "In this article, we will start with an explanation of what is Computer Graphics with a brief on volume rendering and view synthesis. We will then have an overview of what is Neural Radiance Fields and how it is used in view synthesis."
      },
      "date": 1653960818909
    },
    {
      "type": "edit",
      "id": "db9b69c767431e95",
      "item": {
        "type": "paragraph",
        "id": "db9b69c767431e95",
        "text": "In this article, we will start with an explanation of what is Computer Graphics with a brief on volume rendering and view synthesis. We will then have an overview of what is Neural Radiance Fields and how it is used in view synthesis. [https://medium.com/swlh/nerf-neural-radiance-fields-79531da37734 medium]"
      },
      "date": 1653960838021
    },
    {
      "type": "fork",
      "site": "found.ward.bay.wiki.org",
      "date": 1653984656530
    }
  ]
}