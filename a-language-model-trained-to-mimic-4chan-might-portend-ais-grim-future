{
  "title": "A Language Model Trained to Mimic 4chan Might Portend AI's Grim Future",
  "story": [
    {
      "type": "paragraph",
      "id": "13b4f5e985985668",
      "text": "A harbinger of the AI future?   [Excerpted from a note by Dan Geer.  PGN]"
    },
    {
      "type": "paragraph",
      "id": "2a10fe38ed30da6e",
      "text": "A Language Model Trained to Mimic 4chan Might Portend AI's Grim Future [https://cset.georgetown.edu/newsletter/june-16-2022/ https://cset.georgetown.edu/newsletter/june-16-2022/]"
    },
    {
      "type": "markdown",
      "id": "6ac53f396df24a34",
      "text": "  A machine learning researcher trained a language model on three and half   years' worth of 4chan posts to create what he dubbed &quot;the most horrible   model on the Internet,&quot; raising concerns about the public availability of   language models and sparking debate about their ethical use. Yannic   Kilcher, a Swiss ML expert who covers AI and ML advances on his popular   [30]YouTube channel, fine-tuned an existing open-source language model --   [31]EleutherAI's GPT-J-6B&#8212;using [32]a dataset of more than 130 million   posts from 4chan's &quot;Politically Incorrect&quot; board, an online forum with   [33]a longstanding reputation for toxicity and offensiveness. As Kilcher   described in [34]a video documenting the process, he then programmed a   team of bots to post on the board as often as they could. According to   Kilcher, the bots posted approximately 30,000 times during two separate   24-hour periods. While 4chan users were able to identify some of the bots   for what they were, this appeared to be due less to the model's   shortcomings and more to the bots' superhuman indefatigability&#8212;they   posted round-the-clock, as frequently as the site allowed. Kilcher's   experiment was criticized by a number of experts and observers, who   [35]called it irresponsible and unethical. While Kilcher made it possible   for anyone to use his [36]&quot;GPT-4chan&quot; by uploading it to Hugging Face, an   online repository for AI and ML code, the site quickly restricted   access. But the cat could be out of the bag: as Kilcher's experiment   shows, currently available open-source models and datasets can be used to   create [37]surprisingly effective language models with relative ease."
    },
    {
      "type": "paragraph",
      "id": "7ebc9f87b483f80c",
      "text": "  30. [https://www.youtube.com/c/YannicKilcher/videos https://www.youtube.com/c/YannicKilcher/videos]   31. [https://huggingface.co/EleutherAI/gpt-j-6B https://huggingface.co/EleutherAI/gpt-j-6B]   32. [https://zenodo.org/record/3606810#.YpjGgexByDU https://zenodo.org/record/3606810#.YpjGgexByDU]   33. [https://nymag.com/intelligencer/2015/11/inside-pol-4chans-racist-heart.html https://nymag.com/intelligencer/2015/11/inside-pol-4chans-racist-heart.html]   34. [https://youtu.be/efPrtcLdcdM https://youtu.be/efPrtcLdcdM]   35. [https://fortune.com/2022/06/10/ai-chatbot-trained-on-4chan-by-yannic-kilcher-draw-ethics-questions/ https://fortune.com/2022/06/10/ai-chatbot-trained-on-4chan-by-yannic-kilcher-draw-ethics-questions/]   36. [https://huggingface.co/ykilcher/gpt-4chan https://huggingface.co/ykilcher/gpt-4chan]   37. [https://thegradient.pub/gpt-4chan-lessons/#:~:text=An evaluation of the model on the Language Model Evaluation Harness. Kilcher emphasized the result that GPT-4chan slightly outperformed other existing language models on the TruthfulQA Benchmark, which involves picking the most truthful answer to a multiple choice question https://thegradient.pub/gpt-4chan-lessons/#:~:text=An evaluation of the model on the Language Model Evaluation Harness. Kilcher emphasized the result that GPT-4chan slightly outperformed other existing language models on the TruthfulQA Benchmark, which involves picking the most truthful answer to a multiple choice question]"
    },
    {
      "type": "markdown",
      "id": "2fc6b1acfe9eaa43",
      "text": "Source: Georgetown CSET) via [https://catless.ncl.ac.uk/Risks/33/30/#subj12.1 The Risks Digest]"
    }
  ],
  "journal": [
    {
      "type": "create",
      "date": 1655769663000,
      "item": {
        "title": "A Language Model Trained to Mimic 4chan Might Portend AI's Grim Future",
        "story": [
          {
            "type": "paragraph",
            "id": "13b4f5e985985668",
            "text": "A harbinger of the AI future?   [Excerpted from a note by Dan Geer.  PGN]"
          },
          {
            "type": "paragraph",
            "id": "2a10fe38ed30da6e",
            "text": "A Language Model Trained to Mimic 4chan Might Portend AI's Grim Future [https://cset.georgetown.edu/newsletter/june-16-2022/ https://cset.georgetown.edu/newsletter/june-16-2022/]"
          },
          {
            "type": "markdown",
            "id": "6ac53f396df24a34",
            "text": "  A machine learning researcher trained a language model on three and half   years' worth of 4chan posts to create what he dubbed &quot;the most horrible   model on the Internet,&quot; raising concerns about the public availability of   language models and sparking debate about their ethical use. Yannic   Kilcher, a Swiss ML expert who covers AI and ML advances on his popular   [30]YouTube channel, fine-tuned an existing open-source language model --   [31]EleutherAI's GPT-J-6B&#8212;using [32]a dataset of more than 130 million   posts from 4chan's &quot;Politically Incorrect&quot; board, an online forum with   [33]a longstanding reputation for toxicity and offensiveness. As Kilcher   described in [34]a video documenting the process, he then programmed a   team of bots to post on the board as often as they could. According to   Kilcher, the bots posted approximately 30,000 times during two separate   24-hour periods. While 4chan users were able to identify some of the bots   for what they were, this appeared to be due less to the model's   shortcomings and more to the bots' superhuman indefatigability&#8212;they   posted round-the-clock, as frequently as the site allowed. Kilcher's   experiment was criticized by a number of experts and observers, who   [35]called it irresponsible and unethical. While Kilcher made it possible   for anyone to use his [36]&quot;GPT-4chan&quot; by uploading it to Hugging Face, an   online repository for AI and ML code, the site quickly restricted   access. But the cat could be out of the bag: as Kilcher's experiment   shows, currently available open-source models and datasets can be used to   create [37]surprisingly effective language models with relative ease."
          },
          {
            "type": "paragraph",
            "id": "7ebc9f87b483f80c",
            "text": "  30. [https://www.youtube.com/c/YannicKilcher/videos https://www.youtube.com/c/YannicKilcher/videos]   31. [https://huggingface.co/EleutherAI/gpt-j-6B https://huggingface.co/EleutherAI/gpt-j-6B]   32. [https://zenodo.org/record/3606810#.YpjGgexByDU https://zenodo.org/record/3606810#.YpjGgexByDU]   33. [https://nymag.com/intelligencer/2015/11/inside-pol-4chans-racist-heart.html https://nymag.com/intelligencer/2015/11/inside-pol-4chans-racist-heart.html]   34. [https://youtu.be/efPrtcLdcdM https://youtu.be/efPrtcLdcdM]   35. [https://fortune.com/2022/06/10/ai-chatbot-trained-on-4chan-by-yannic-kilcher-draw-ethics-questions/ https://fortune.com/2022/06/10/ai-chatbot-trained-on-4chan-by-yannic-kilcher-draw-ethics-questions/]   36. [https://huggingface.co/ykilcher/gpt-4chan https://huggingface.co/ykilcher/gpt-4chan]   37. [https://thegradient.pub/gpt-4chan-lessons/#:~:text=An evaluation of the model on the Language Model Evaluation Harness. Kilcher emphasized the result that GPT-4chan slightly outperformed other existing language models on the TruthfulQA Benchmark, which involves picking the most truthful answer to a multiple choice question https://thegradient.pub/gpt-4chan-lessons/#:~:text=An evaluation of the model on the Language Model Evaluation Harness. Kilcher emphasized the result that GPT-4chan slightly outperformed other existing language models on the TruthfulQA Benchmark, which involves picking the most truthful answer to a multiple choice question]"
          },
          {
            "type": "markdown",
            "id": "2fc6b1acfe9eaa43",
            "text": "Source: Georgetown CSET) via [https://catless.ncl.ac.uk/Risks/33/30/#subj12.1 The Risks Digest]"
          }
        ]
      }
    },
    {
      "type": "fork",
      "site": "risks.rodwell.me",
      "date": 1655879362313
    }
  ]
}