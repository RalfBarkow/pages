{
  "title": "Shared Forest",
  "story": [
    {
      "type": "paragraph",
      "id": "be4edc6aaa996fc3",
      "text": "Is there a favoured data structure for storing ambiguous parse trees in Natural Language Processing? [https://linguistics.stackexchange.com/questions/4619/is-there-a-favoured-data-structure-for-storing-ambiguous-parse-trees-in-natural stackexchange]"
    },
    {
      "type": "paragraph",
      "id": "43d21a343563cd68",
      "text": "Short answer\n\nThere is a favoured structure for storing ambiguous parse trees. It is usually called a shared forest, and it is simply a grammar that generates only the sentence parsed with exactly the same parse trees as the grammar of the language (up to a renaming homomorphisme for the non-terminal symbols). This applies to Context-Free grammars, but also to several other formalisms such as Tree-Adjoining Grammars. It can be used as a generator to enumerate the individual parse-trees.\n\nShared forests are often presented as a graphs, with various qualification, but these graphs are only representations of grammars. They appear in all general context-free parsers in the literature."
    },
    {
      "type": "paragraph",
      "id": "1e8b550680bd7e3e",
      "text": "Longer answer\n\nYour question is a good question. However, the sentence you emphasize in boldface is, in my opinion, the wrong way to worry about representing ambiguity, even though it is the usual way to state it.\n\nWhen you ask for a data structure, you are asking for a device to do processing, but you forget to worry about the intrinsic nature of that device, about the meaning it may have in your model of language processing. In some sense you emphasize the doing over the understanding.\n\nThere is actually an abstract answer that applies to numerous cases, numerous formalisms, independently of the parsing algorithm used, such as the CKY algorithm, Earley's algorithm, and many others.\n\nThe relevant concept is that of a shared forest. It is a condensed form of all the correct parse trees for the sentence, However, though the concept of shared forest was widely used in the parsing literature, it did take some time to understand what it was, other than a convenient data structure. The understanding opened it to generalizations.\n\nHere I am skipping several fine points, see my answer to another question, for more details.\n\nThe basic idea (described in a 1995 paper by Lang and in the Grune-Jacobs book) relies on the fact that context-free languages, and many other syntactic formalisms are closed under intersection with regular languages (Type-3 grammars in Chomsky hierarchy). Furthermore, this closure property is constructive, which means that given a grammar G (in some syntactic formalism, such as CF grammar, or tree adjoining grammar, or many others) generating all syntactically correct sentences of the language, and a formal specification R of the regular language, it is possible to exhibit another grammar F, that generates only the syntactically correct sentences that belong to the regular set, with exactly the same ambiguities as with the original grammar G. This grammar F is a shared forest (there are many equivalent ways of building such a grammar - see Billot & Lang, The structure of shared forests in ambiguous parsing). Basically, the relevant rules of the original grammar are homomorphique images of the rules of the shared forest, through a renaming homomorphism of the non terminals. The shared forest uses \"specialized copies\" of the non-terminals of the original grammar so as to control more tightly the generative power of its rules.\n\nA set of one sentence is a regular set, and the construction applies. Then, the shared forest F can be used a a generative grammar that generates only a single sentence, but with differents parse-trees corresponding to all the parses with the original grammar G. So, for example, it can be used to enumerate all the correct parse-trees for the sentence.\n\nThis can generalize to many situations. For example, when there is phonological ambiguity, as in the question Phonological ambiguity that changes the syntactic structure, this ambiguity regarding the words actually uttered can be represented by a word lattice, which actually defines formally a regular set of (not necessarily syntactically correct) sentences. The same construction intersecting the regular set with the grammar G can be used, accounting at the same time for lexical/phonological ambiguity and for syntactic ambiguity.\n\nNow, what about this construction of the intersection. For CF grammars, there is an old construction that was published some 50 years ago (Bar-Hillel, Perles, Shamir 1961). All later algorithms, such as CKY, Earley, chart parsing, etc, that produce a shared forest are actually only variants of that construction that may optimize some steps so as to avoid some useless construction steps while producing the shared forest F. Similar constructions exist for many other classes of grammar than the CF grammars.\n\nThe next issue is to develop techniques to choose the right tree in the forest. This can be achieved in various ways but remains a very open topic. For example it is possible to associate features or data with specific algebraic characteristics (semi-ring) to the lexicon and parts of speech, together with composition rules associated to the grammar rules, to identify the \"better\" parse-tree. The Viterbi techniques to chose a most-likely parse-tree according to some probabilities fall in this category. Alternatively, the choice of correct parse-trees may be postponed to later stages of analysis.\n\nThis is (the skeleton of) the whole story, afaik, regarding shared forest. Much is still being developped on that basis.\n\nIt may seem too abstract, but it gives a good and actually simple mathematical understanding for organizing the technology. But that does not mean that all is simple when you get into actual details, for example with sophisticated feature structures.\n\nAnother advantage of the approach is that it gives a cleaner view of issues by separating the operational from the denotational. What this means is that the relevant entities you may be interested in, such as trees or forests, are specified by abstract mathematical definitions, on the basis of desirable properties, without specifying any actual method to effectively compute them. The operational algorithms that will compute them (the parsing algorithms) are elaborated separately, and have to be proved correct with respect to the denotational definition. This separates the issues of conceptual perspicuity and computational correctness and effectiveness.\n\nAnother point is that the complexity of the relevant structures can be analyzed from the mathematical definitions, independently of the algorithms that computes them.\n\nFinally, to come back to your question, shared forest have gained wide acceptance among NLP practitioners. The abstract view of it as the grammar of an intersection is less well known by those who are not mathematically oriented, though it is nearly 20 years old. This ignorance/rejection of mathematics is unfortunately the source of much waste of time and energy.\n\nOf course, the grammar view of the shared forest is an abstraction, which may be implemented in various ways, some being more easily computed with than others. Hence the grammar is sometimes a bit harder to see when described an an implemented structure in some algorithm descriptions. It may also happen, as in the case of Earley's algorithm, that the parse forest grammar is derived from a binarized version of the original grammar.\n\nBibliography: search the web with the keywords: parsing intersection forest - many papers are open access somewhere.\n\nSome references on stackexchange:\n\n    answer to Algorithms or data structures for dealing with ambiguity\n\n    Recovering a parse forest from an Earley parser? and my answer\n\n    Complexity of a GLR parser on an ambiguous grammar [https://cstheory.stackexchange.com/questions/22621/complexity-of-a-glr-parser-on-an-ambiguous-grammar stackexchange]"
    },
    {
      "type": "pagefold",
      "id": "7fb3e51bd418d08c",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "d236a5c393f0a77a",
      "text": "How do I reconstruct the forest of syntax trees from the Earley vector? [https://cs.stackexchange.com/questions/27937/how-do-i-reconstruct-the-forest-of-syntax-trees-from-the-earley-vector stackexchange]"
    },
    {
      "type": "paragraph",
      "id": "e38b43d355be67ff",
      "text": "\n\nUsing the Earley vector as a recognizer is quite straightforward: when the end of the string is reached, you just have to check for a completed axiomatic production started at position 0. If you have at least one, then the string is accepted.\n\nUsing the Earley vector to reconstruct the parsing tree(s) is less obvious. Actually, I cannot figure out how an algorithmic procedure would work, moreover the only references I found were either vague or super-technical. Could anybody shed some light on it?\n"
    },
    {
      "type": "pagefold",
      "id": "49c405079fdd1e66",
      "text": "~"
    },
    {
      "type": "reference",
      "id": "ca14119dadf7ea8d",
      "site": "wiki.ralfbarkow.ch",
      "slug": "remove-model",
      "title": "Remove Model",
      "text": "[[Creativity]] as a 3-Step Process"
    },
    {
      "type": "paragraph",
      "id": "5e6aae47e7c07abe",
      "text": "â‡’ [[The Ethical Imperative]] ([[Recover]]ing the trees)"
    },
    {
      "type": "markdown",
      "id": "c5db300328f88a99",
      "text": "> Exhibit the [[Tree]] recovered by the [[Parser]] "
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Shared Forest",
        "story": []
      },
      "date": 1702636859454
    },
    {
      "item": {
        "type": "factory",
        "id": "be4edc6aaa996fc3"
      },
      "id": "be4edc6aaa996fc3",
      "type": "add",
      "date": 1702636876045
    },
    {
      "type": "edit",
      "id": "be4edc6aaa996fc3",
      "item": {
        "type": "paragraph",
        "id": "be4edc6aaa996fc3",
        "text": "Is there a favoured data structure for storing ambiguous parse trees in Natural Language Processing?"
      },
      "date": 1702636878718
    },
    {
      "type": "edit",
      "id": "be4edc6aaa996fc3",
      "item": {
        "type": "paragraph",
        "id": "be4edc6aaa996fc3",
        "text": "Is there a favoured data structure for storing ambiguous parse trees in Natural Language Processing? [stackexchange]"
      },
      "date": 1702636886935
    },
    {
      "type": "edit",
      "id": "be4edc6aaa996fc3",
      "item": {
        "type": "paragraph",
        "id": "be4edc6aaa996fc3",
        "text": "Is there a favoured data structure for storing ambiguous parse trees in Natural Language Processing? [https://linguistics.stackexchange.com/questions/4619/is-there-a-favoured-data-structure-for-storing-ambiguous-parse-trees-in-natural stackexchange]"
      },
      "date": 1702636894888
    },
    {
      "item": {
        "type": "paragraph",
        "id": "43d21a343563cd68",
        "text": "Short answer\n\nThere is a favoured structure for storing ambiguous parse trees. It is usually called a shared forest, and it is simply a grammar that generates only the sentence parsed with exactly the same parse trees as the grammar of the language (up to a renaming homomorphisme for the non-terminal symbols). This applies to Context-Free grammars, but also to several other formalisms such as Tree-Adjoining Grammars. It can be used as a generator to enumerate the individual parse-trees.\n\nShared forests are often presented as a graphs, with various qualification, but these graphs are only representations of grammars. They appear in all general context-free parsers in the literature."
      },
      "id": "43d21a343563cd68",
      "type": "add",
      "after": "be4edc6aaa996fc3",
      "date": 1702652857691
    },
    {
      "type": "edit",
      "id": "43d21a343563cd68",
      "item": {
        "type": "paragraph",
        "id": "43d21a343563cd68",
        "text": "Short answer\n\nThere is a favoured structure for storing ambiguous parse trees. It is usually called a shared forest, and it is simply a grammar that generates only the sentence parsed with exactly the same parse trees as the grammar of the language (up to a renaming homomorphisme for the non-terminal symbols). This applies to Context-Free grammars, but also to several other formalisms such as Tree-Adjoining Grammars. It can be used as a generator to enumerate the individual parse-trees.\n\nShared forests are often presented as a graphs, with various qualification, but these graphs are only representations of grammars. They appear in all general context-free parsers in the literature."
      },
      "date": 1702652859387
    },
    {
      "item": {
        "type": "paragraph",
        "id": "1e8b550680bd7e3e",
        "text": "Longer answer\n\nYour question is a good question. However, the sentence you emphasize in boldface is, in my opinion, the wrong way to worry about representing ambiguity, even though it is the usual way to state it.\n\nWhen you ask for a data structure, you are asking for a device to do processing, but you forget to worry about the intrinsic nature of that device, about the meaning it may have in your model of language processing. In some sense you emphasize the doing over the understanding.\n\nThere is actually an abstract answer that applies to numerous cases, numerous formalisms, independently of the parsing algorithm used, such as the CKY algorithm, Earley's algorithm, and many others.\n\nThe relevant concept is that of a shared forest. It is a condensed form of all the correct parse trees for the sentence, However, though the concept of shared forest was widely used in the parsing literature, it did take some time to understand what it was, other than a convenient data structure. The understanding opened it to generalizations.\n\nHere I am skipping several fine points, see my answer to another question, for more details.\n\nThe basic idea (described in a 1995 paper by Lang and in the Grune-Jacobs book) relies on the fact that context-free languages, and many other syntactic formalisms are closed under intersection with regular languages (Type-3 grammars in Chomsky hierarchy). Furthermore, this closure property is constructive, which means that given a grammar G (in some syntactic formalism, such as CF grammar, or tree adjoining grammar, or many others) generating all syntactically correct sentences of the language, and a formal specification R of the regular language, it is possible to exhibit another grammar F, that generates only the syntactically correct sentences that belong to the regular set, with exactly the same ambiguities as with the original grammar G. This grammar F is a shared forest (there are many equivalent ways of building such a grammar - see Billot & Lang, The structure of shared forests in ambiguous parsing). Basically, the relevant rules of the original grammar are homomorphique images of the rules of the shared forest, through a renaming homomorphism of the non terminals. The shared forest uses \"specialized copies\" of the non-terminals of the original grammar so as to control more tightly the generative power of its rules.\n\nA set of one sentence is a regular set, and the construction applies. Then, the shared forest F can be used a a generative grammar that generates only a single sentence, but with differents parse-trees corresponding to all the parses with the original grammar G. So, for example, it can be used to enumerate all the correct parse-trees for the sentence.\n\nThis can generalize to many situations. For example, when there is phonological ambiguity, as in the question Phonological ambiguity that changes the syntactic structure, this ambiguity regarding the words actually uttered can be represented by a word lattice, which actually defines formally a regular set of (not necessarily syntactically correct) sentences. The same construction intersecting the regular set with the grammar G can be used, accounting at the same time for lexical/phonological ambiguity and for syntactic ambiguity.\n\nNow, what about this construction of the intersection. For CF grammars, there is an old construction that was published some 50 years ago (Bar-Hillel, Perles, Shamir 1961). All later algorithms, such as CKY, Earley, chart parsing, etc, that produce a shared forest are actually only variants of that construction that may optimize some steps so as to avoid some useless construction steps while producing the shared forest F. Similar constructions exist for many other classes of grammar than the CF grammars.\n\nThe next issue is to develop techniques to choose the right tree in the forest. This can be achieved in various ways but remains a very open topic. For example it is possible to associate features or data with specific algebraic characteristics (semi-ring) to the lexicon and parts of speech, together with composition rules associated to the grammar rules, to identify the \"better\" parse-tree. The Viterbi techniques to chose a most-likely parse-tree according to some probabilities fall in this category. Alternatively, the choice of correct parse-trees may be postponed to later stages of analysis.\n\nThis is (the skeleton of) the whole story, afaik, regarding shared forest. Much is still being developped on that basis.\n\nIt may seem too abstract, but it gives a good and actually simple mathematical understanding for organizing the technology. But that does not mean that all is simple when you get into actual details, for example with sophisticated feature structures.\n\nAnother advantage of the approach is that it gives a cleaner view of issues by separating the operational from the denotational. What this means is that the relevant entities you may be interested in, such as trees or forests, are specified by abstract mathematical definitions, on the basis of desirable properties, without specifying any actual method to effectively compute them. The operational algorithms that will compute them (the parsing algorithms) are elaborated separately, and have to be proved correct with respect to the denotational definition. This separates the issues of conceptual perspicuity and computational correctness and effectiveness.\n\nAnother point is that the complexity of the relevant structures can be analyzed from the mathematical definitions, independently of the algorithms that computes them.\n\nFinally, to come back to your question, shared forest have gained wide acceptance among NLP practitioners. The abstract view of it as the grammar of an intersection is less well known by those who are not mathematically oriented, though it is nearly 20 years old. This ignorance/rejection of mathematics is unfortunately the source of much waste of time and energy.\n\nOf course, the grammar view of the shared forest is an abstraction, which may be implemented in various ways, some being more easily computed with than others. Hence the grammar is sometimes a bit harder to see when described an an implemented structure in some algorithm descriptions. It may also happen, as in the case of Earley's algorithm, that the parse forest grammar is derived from a binarized version of the original grammar.\n\nBibliography: search the web with the keywords: parsing intersection forest - many papers are open access somewhere.\n\nSome references on stackexchange:\n\n    answer to Algorithms or data structures for dealing with ambiguity\n\n    Recovering a parse forest from an Earley parser? and my answer\n\n    Complexity of a GLR parser on an ambiguous grammar [https://cstheory.stackexchange.com/questions/22621/complexity-of-a-glr-parser-on-an-ambiguous-grammar stackexchange]"
      },
      "id": "1e8b550680bd7e3e",
      "type": "add",
      "after": "43d21a343563cd68",
      "date": 1702652878998
    },
    {
      "type": "edit",
      "id": "1e8b550680bd7e3e",
      "item": {
        "type": "paragraph",
        "id": "1e8b550680bd7e3e",
        "text": "Longer answer\n\nYour question is a good question. However, the sentence you emphasize in boldface is, in my opinion, the wrong way to worry about representing ambiguity, even though it is the usual way to state it.\n\nWhen you ask for a data structure, you are asking for a device to do processing, but you forget to worry about the intrinsic nature of that device, about the meaning it may have in your model of language processing. In some sense you emphasize the doing over the understanding.\n\nThere is actually an abstract answer that applies to numerous cases, numerous formalisms, independently of the parsing algorithm used, such as the CKY algorithm, Earley's algorithm, and many others.\n\nThe relevant concept is that of a shared forest. It is a condensed form of all the correct parse trees for the sentence, However, though the concept of shared forest was widely used in the parsing literature, it did take some time to understand what it was, other than a convenient data structure. The understanding opened it to generalizations.\n\nHere I am skipping several fine points, see my answer to another question, for more details.\n\nThe basic idea (described in a 1995 paper by Lang and in the Grune-Jacobs book) relies on the fact that context-free languages, and many other syntactic formalisms are closed under intersection with regular languages (Type-3 grammars in Chomsky hierarchy). Furthermore, this closure property is constructive, which means that given a grammar G (in some syntactic formalism, such as CF grammar, or tree adjoining grammar, or many others) generating all syntactically correct sentences of the language, and a formal specification R of the regular language, it is possible to exhibit another grammar F, that generates only the syntactically correct sentences that belong to the regular set, with exactly the same ambiguities as with the original grammar G. This grammar F is a shared forest (there are many equivalent ways of building such a grammar - see Billot & Lang, The structure of shared forests in ambiguous parsing). Basically, the relevant rules of the original grammar are homomorphique images of the rules of the shared forest, through a renaming homomorphism of the non terminals. The shared forest uses \"specialized copies\" of the non-terminals of the original grammar so as to control more tightly the generative power of its rules.\n\nA set of one sentence is a regular set, and the construction applies. Then, the shared forest F can be used a a generative grammar that generates only a single sentence, but with differents parse-trees corresponding to all the parses with the original grammar G. So, for example, it can be used to enumerate all the correct parse-trees for the sentence.\n\nThis can generalize to many situations. For example, when there is phonological ambiguity, as in the question Phonological ambiguity that changes the syntactic structure, this ambiguity regarding the words actually uttered can be represented by a word lattice, which actually defines formally a regular set of (not necessarily syntactically correct) sentences. The same construction intersecting the regular set with the grammar G can be used, accounting at the same time for lexical/phonological ambiguity and for syntactic ambiguity.\n\nNow, what about this construction of the intersection. For CF grammars, there is an old construction that was published some 50 years ago (Bar-Hillel, Perles, Shamir 1961). All later algorithms, such as CKY, Earley, chart parsing, etc, that produce a shared forest are actually only variants of that construction that may optimize some steps so as to avoid some useless construction steps while producing the shared forest F. Similar constructions exist for many other classes of grammar than the CF grammars.\n\nThe next issue is to develop techniques to choose the right tree in the forest. This can be achieved in various ways but remains a very open topic. For example it is possible to associate features or data with specific algebraic characteristics (semi-ring) to the lexicon and parts of speech, together with composition rules associated to the grammar rules, to identify the \"better\" parse-tree. The Viterbi techniques to chose a most-likely parse-tree according to some probabilities fall in this category. Alternatively, the choice of correct parse-trees may be postponed to later stages of analysis.\n\nThis is (the skeleton of) the whole story, afaik, regarding shared forest. Much is still being developped on that basis.\n\nIt may seem too abstract, but it gives a good and actually simple mathematical understanding for organizing the technology. But that does not mean that all is simple when you get into actual details, for example with sophisticated feature structures.\n\nAnother advantage of the approach is that it gives a cleaner view of issues by separating the operational from the denotational. What this means is that the relevant entities you may be interested in, such as trees or forests, are specified by abstract mathematical definitions, on the basis of desirable properties, without specifying any actual method to effectively compute them. The operational algorithms that will compute them (the parsing algorithms) are elaborated separately, and have to be proved correct with respect to the denotational definition. This separates the issues of conceptual perspicuity and computational correctness and effectiveness.\n\nAnother point is that the complexity of the relevant structures can be analyzed from the mathematical definitions, independently of the algorithms that computes them.\n\nFinally, to come back to your question, shared forest have gained wide acceptance among NLP practitioners. The abstract view of it as the grammar of an intersection is less well known by those who are not mathematically oriented, though it is nearly 20 years old. This ignorance/rejection of mathematics is unfortunately the source of much waste of time and energy.\n\nOf course, the grammar view of the shared forest is an abstraction, which may be implemented in various ways, some being more easily computed with than others. Hence the grammar is sometimes a bit harder to see when described an an implemented structure in some algorithm descriptions. It may also happen, as in the case of Earley's algorithm, that the parse forest grammar is derived from a binarized version of the original grammar.\n\nBibliography: search the web with the keywords: parsing intersection forest - many papers are open access somewhere.\n\nSome references on stackexchange:\n\n    answer to Algorithms or data structures for dealing with ambiguity\n\n    Recovering a parse forest from an Earley parser? and my answer\n\n    Complexity of a GLR parser on an ambiguous grammar [https://cstheory.stackexchange.com/questions/22621/complexity-of-a-glr-parser-on-an-ambiguous-grammar stackexchange]"
      },
      "date": 1702652880988
    },
    {
      "type": "edit",
      "id": "1e8b550680bd7e3e",
      "item": {
        "type": "paragraph",
        "id": "1e8b550680bd7e3e",
        "text": "Longer answer\n\nYour question is a good question. However, the sentence you emphasize in boldface is, in my opinion, the wrong way to worry about representing ambiguity, even though it is the usual way to state it.\n\nWhen you ask for a data structure, you are asking for a device to do processing, but you forget to worry about the intrinsic nature of that device, about the meaning it may have in your model of language processing. In some sense you emphasize the doing over the understanding.\n\nThere is actually an abstract answer that applies to numerous cases, numerous formalisms, independently of the parsing algorithm used, such as the CKY algorithm, Earley's algorithm, and many others.\n\nThe relevant concept is that of a shared forest. It is a condensed form of all the correct parse trees for the sentence, However, though the concept of shared forest was widely used in the parsing literature, it did take some time to understand what it was, other than a convenient data structure. The understanding opened it to generalizations.\n\nHere I am skipping several fine points, see my answer to another question, for more details.\n\nThe basic idea (described in a 1995 paper by Lang and in the Grune-Jacobs book) relies on the fact that context-free languages, and many other syntactic formalisms are closed under intersection with regular languages (Type-3 grammars in Chomsky hierarchy). Furthermore, this closure property is constructive, which means that given a grammar G (in some syntactic formalism, such as CF grammar, or tree adjoining grammar, or many others) generating all syntactically correct sentences of the language, and a formal specification R of the regular language, it is possible to exhibit another grammar F, that generates only the syntactically correct sentences that belong to the regular set, with exactly the same ambiguities as with the original grammar G. This grammar F is a shared forest (there are many equivalent ways of building such a grammar - see Billot & Lang, The structure of shared forests in ambiguous parsing). Basically, the relevant rules of the original grammar are homomorphique images of the rules of the shared forest, through a renaming homomorphism of the non terminals. The shared forest uses \"specialized copies\" of the non-terminals of the original grammar so as to control more tightly the generative power of its rules.\n\nA set of one sentence is a regular set, and the construction applies. Then, the shared forest F can be used a a generative grammar that generates only a single sentence, but with differents parse-trees corresponding to all the parses with the original grammar G. So, for example, it can be used to enumerate all the correct parse-trees for the sentence.\n\nThis can generalize to many situations. For example, when there is phonological ambiguity, as in the question Phonological ambiguity that changes the syntactic structure, this ambiguity regarding the words actually uttered can be represented by a word lattice, which actually defines formally a regular set of (not necessarily syntactically correct) sentences. The same construction intersecting the regular set with the grammar G can be used, accounting at the same time for lexical/phonological ambiguity and for syntactic ambiguity.\n\nNow, what about this construction of the intersection. For CF grammars, there is an old construction that was published some 50 years ago (Bar-Hillel, Perles, Shamir 1961). All later algorithms, such as CKY, Earley, chart parsing, etc, that produce a shared forest are actually only variants of that construction that may optimize some steps so as to avoid some useless construction steps while producing the shared forest F. Similar constructions exist for many other classes of grammar than the CF grammars.\n\nThe next issue is to develop techniques to choose the right tree in the forest. This can be achieved in various ways but remains a very open topic. For example it is possible to associate features or data with specific algebraic characteristics (semi-ring) to the lexicon and parts of speech, together with composition rules associated to the grammar rules, to identify the \"better\" parse-tree. The Viterbi techniques to chose a most-likely parse-tree according to some probabilities fall in this category. Alternatively, the choice of correct parse-trees may be postponed to later stages of analysis.\n\nThis is (the skeleton of) the whole story, afaik, regarding shared forest. Much is still being developped on that basis.\n\nIt may seem too abstract, but it gives a good and actually simple mathematical understanding for organizing the technology. But that does not mean that all is simple when you get into actual details, for example with sophisticated feature structures.\n\nAnother advantage of the approach is that it gives a cleaner view of issues by separating the operational from the denotational. What this means is that the relevant entities you may be interested in, such as trees or forests, are specified by abstract mathematical definitions, on the basis of desirable properties, without specifying any actual method to effectively compute them. The operational algorithms that will compute them (the parsing algorithms) are elaborated separately, and have to be proved correct with respect to the denotational definition. This separates the issues of conceptual perspicuity and computational correctness and effectiveness.\n\nAnother point is that the complexity of the relevant structures can be analyzed from the mathematical definitions, independently of the algorithms that computes them.\n\nFinally, to come back to your question, shared forest have gained wide acceptance among NLP practitioners. The abstract view of it as the grammar of an intersection is less well known by those who are not mathematically oriented, though it is nearly 20 years old. This ignorance/rejection of mathematics is unfortunately the source of much waste of time and energy.\n\nOf course, the grammar view of the shared forest is an abstraction, which may be implemented in various ways, some being more easily computed with than others. Hence the grammar is sometimes a bit harder to see when described an an implemented structure in some algorithm descriptions. It may also happen, as in the case of Earley's algorithm, that the parse forest grammar is derived from a binarized version of the original grammar.\n\nBibliography: search the web with the keywords: parsing intersection forest - many papers are open access somewhere.\n\nSome references on stackexchange:\n\n    answer to Algorithms or data structures for dealing with ambiguity\n\n    Recovering a parse forest from an Earley parser? and my answer\n\n    Complexity of a GLR parser on an ambiguous grammar [https://cstheory.stackexchange.com/questions/22621/complexity-of-a-glr-parser-on-an-ambiguous-grammar stackexchange]"
      },
      "date": 1702652915106
    },
    {
      "type": "edit",
      "id": "1e8b550680bd7e3e",
      "item": {
        "type": "paragraph",
        "id": "1e8b550680bd7e3e",
        "text": "Longer answer\n\nYour question is a good question. However, the sentence you emphasize in boldface is, in my opinion, the wrong way to worry about representing ambiguity, even though it is the usual way to state it.\n\nWhen you ask for a data structure, you are asking for a device to do processing, but you forget to worry about the intrinsic nature of that device, about the meaning it may have in your model of language processing. In some sense you emphasize the doing over the understanding.\n\nThere is actually an abstract answer that applies to numerous cases, numerous formalisms, independently of the parsing algorithm used, such as the CKY algorithm, Earley's algorithm, and many others.\n\nThe relevant concept is that of a shared forest. It is a condensed form of all the correct parse trees for the sentence, However, though the concept of shared forest was widely used in the parsing literature, it did take some time to understand what it was, other than a convenient data structure. The understanding opened it to generalizations.\n\nHere I am skipping several fine points, see my answer to another question, for more details.\n\nThe basic idea (described in a 1995 paper by Lang and in the Grune-Jacobs book) relies on the fact that context-free languages, and many other syntactic formalisms are closed under intersection with regular languages (Type-3 grammars in Chomsky hierarchy). Furthermore, this closure property is constructive, which means that given a grammar G (in some syntactic formalism, such as CF grammar, or tree adjoining grammar, or many others) generating all syntactically correct sentences of the language, and a formal specification R of the regular language, it is possible to exhibit another grammar F, that generates only the syntactically correct sentences that belong to the regular set, with exactly the same ambiguities as with the original grammar G. This grammar F is a shared forest (there are many equivalent ways of building such a grammar - see Billot & Lang, The structure of shared forests in ambiguous parsing). Basically, the relevant rules of the original grammar are homomorphique images of the rules of the shared forest, through a renaming homomorphism of the non terminals. The shared forest uses \"specialized copies\" of the non-terminals of the original grammar so as to control more tightly the generative power of its rules.\n\nA set of one sentence is a regular set, and the construction applies. Then, the shared forest F can be used a a generative grammar that generates only a single sentence, but with differents parse-trees corresponding to all the parses with the original grammar G. So, for example, it can be used to enumerate all the correct parse-trees for the sentence.\n\nThis can generalize to many situations. For example, when there is phonological ambiguity, as in the question Phonological ambiguity that changes the syntactic structure, this ambiguity regarding the words actually uttered can be represented by a word lattice, which actually defines formally a regular set of (not necessarily syntactically correct) sentences. The same construction intersecting the regular set with the grammar G can be used, accounting at the same time for lexical/phonological ambiguity and for syntactic ambiguity.\n\nNow, what about this construction of the intersection. For CF grammars, there is an old construction that was published some 50 years ago (Bar-Hillel, Perles, Shamir 1961). All later algorithms, such as CKY, Earley, chart parsing, etc, that produce a shared forest are actually only variants of that construction that may optimize some steps so as to avoid some useless construction steps while producing the shared forest F. Similar constructions exist for many other classes of grammar than the CF grammars.\n\nThe next issue is to develop techniques to choose the right tree in the forest. This can be achieved in various ways but remains a very open topic. For example it is possible to associate features or data with specific algebraic characteristics (semi-ring) to the lexicon and parts of speech, together with composition rules associated to the grammar rules, to identify the \"better\" parse-tree. The Viterbi techniques to chose a most-likely parse-tree according to some probabilities fall in this category. Alternatively, the choice of correct parse-trees may be postponed to later stages of analysis.\n\nThis is (the skeleton of) the whole story, afaik, regarding shared forest. Much is still being developped on that basis.\n\nIt may seem too abstract, but it gives a good and actually simple mathematical understanding for organizing the technology. But that does not mean that all is simple when you get into actual details, for example with sophisticated feature structures.\n\nAnother advantage of the approach is that it gives a cleaner view of issues by separating the operational from the denotational. What this means is that the relevant entities you may be interested in, such as trees or forests, are specified by abstract mathematical definitions, on the basis of desirable properties, without specifying any actual method to effectively compute them. The operational algorithms that will compute them (the parsing algorithms) are elaborated separately, and have to be proved correct with respect to the denotational definition. This separates the issues of conceptual perspicuity and computational correctness and effectiveness.\n\nAnother point is that the complexity of the relevant structures can be analyzed from the mathematical definitions, independently of the algorithms that computes them.\n\nFinally, to come back to your question, shared forest have gained wide acceptance among NLP practitioners. The abstract view of it as the grammar of an intersection is less well known by those who are not mathematically oriented, though it is nearly 20 years old. This ignorance/rejection of mathematics is unfortunately the source of much waste of time and energy.\n\nOf course, the grammar view of the shared forest is an abstraction, which may be implemented in various ways, some being more easily computed with than others. Hence the grammar is sometimes a bit harder to see when described an an implemented structure in some algorithm descriptions. It may also happen, as in the case of Earley's algorithm, that the parse forest grammar is derived from a binarized version of the original grammar.\n\nBibliography: search the web with the keywords: parsing intersection forest - many papers are open access somewhere.\n\nSome references on stackexchange:\n\n    answer to Algorithms or data structures for dealing with ambiguity\n\n    Recovering a parse forest from an Earley parser? and my answer\n\n    Complexity of a GLR parser on an ambiguous grammar [https://cstheory.stackexchange.com/questions/22621/complexity-of-a-glr-parser-on-an-ambiguous-grammar stackexchange]"
      },
      "date": 1702652967880
    },
    {
      "type": "edit",
      "id": "1e8b550680bd7e3e",
      "item": {
        "type": "paragraph",
        "id": "1e8b550680bd7e3e",
        "text": "Longer answer\n\nYour question is a good question. However, the sentence you emphasize in boldface is, in my opinion, the wrong way to worry about representing ambiguity, even though it is the usual way to state it.\n\nWhen you ask for a data structure, you are asking for a device to do processing, but you forget to worry about the intrinsic nature of that device, about the meaning it may have in your model of language processing. In some sense you emphasize the doing over the understanding.\n\nThere is actually an abstract answer that applies to numerous cases, numerous formalisms, independently of the parsing algorithm used, such as the CKY algorithm, Earley's algorithm, and many others.\n\nThe relevant concept is that of a shared forest. It is a condensed form of all the correct parse trees for the sentence, However, though the concept of shared forest was widely used in the parsing literature, it did take some time to understand what it was, other than a convenient data structure. The understanding opened it to generalizations.\n\nHere I am skipping several fine points, see my answer to another question, for more details.\n\nThe basic idea (described in a 1995 paper by Lang and in the Grune-Jacobs book) relies on the fact that context-free languages, and many other syntactic formalisms are closed under intersection with regular languages (Type-3 grammars in Chomsky hierarchy). Furthermore, this closure property is constructive, which means that given a grammar G (in some syntactic formalism, such as CF grammar, or tree adjoining grammar, or many others) generating all syntactically correct sentences of the language, and a formal specification R of the regular language, it is possible to exhibit another grammar F, that generates only the syntactically correct sentences that belong to the regular set, with exactly the same ambiguities as with the original grammar G. This grammar F is a shared forest (there are many equivalent ways of building such a grammar - see Billot & Lang, The structure of shared forests in ambiguous parsing). Basically, the relevant rules of the original grammar are homomorphique images of the rules of the shared forest, through a renaming homomorphism of the non terminals. The shared forest uses \"specialized copies\" of the non-terminals of the original grammar so as to control more tightly the generative power of its rules.\n\nA set of one sentence is a regular set, and the construction applies. Then, the shared forest F can be used a a generative grammar that generates only a single sentence, but with differents parse-trees corresponding to all the parses with the original grammar G. So, for example, it can be used to enumerate all the correct parse-trees for the sentence.\n\nThis can generalize to many situations. For example, when there is phonological ambiguity, as in the question Phonological ambiguity that changes the syntactic structure, this ambiguity regarding the words actually uttered can be represented by a word lattice, which actually defines formally a regular set of (not necessarily syntactically correct) sentences. The same construction intersecting the regular set with the grammar G can be used, accounting at the same time for lexical/phonological ambiguity and for syntactic ambiguity.\n\nNow, what about this construction of the intersection. For CF grammars, there is an old construction that was published some 50 years ago (Bar-Hillel, Perles, Shamir 1961). All later algorithms, such as CKY, Earley, chart parsing, etc, that produce a shared forest are actually only variants of that construction that may optimize some steps so as to avoid some useless construction steps while producing the shared forest F. Similar constructions exist for many other classes of grammar than the CF grammars.\n\nThe next issue is to develop techniques to choose the right tree in the forest. This can be achieved in various ways but remains a very open topic. For example it is possible to associate features or data with specific algebraic characteristics (semi-ring) to the lexicon and parts of speech, together with composition rules associated to the grammar rules, to identify the \"better\" parse-tree. The Viterbi techniques to chose a most-likely parse-tree according to some probabilities fall in this category. Alternatively, the choice of correct parse-trees may be postponed to later stages of analysis.\n\nThis is (the skeleton of) the whole story, afaik, regarding shared forest. Much is still being developped on that basis.\n\nIt may seem too abstract, but it gives a good and actually simple mathematical understanding for organizing the technology. But that does not mean that all is simple when you get into actual details, for example with sophisticated feature structures.\n\nAnother advantage of the approach is that it gives a cleaner view of issues by separating the operational from the denotational. What this means is that the relevant entities you may be interested in, such as trees or forests, are specified by abstract mathematical definitions, on the basis of desirable properties, without specifying any actual method to effectively compute them. The operational algorithms that will compute them (the parsing algorithms) are elaborated separately, and have to be proved correct with respect to the denotational definition. This separates the issues of conceptual perspicuity and computational correctness and effectiveness.\n\nAnother point is that the complexity of the relevant structures can be analyzed from the mathematical definitions, independently of the algorithms that computes them.\n\nFinally, to come back to your question, shared forest have gained wide acceptance among NLP practitioners. The abstract view of it as the grammar of an intersection is less well known by those who are not mathematically oriented, though it is nearly 20 years old. This ignorance/rejection of mathematics is unfortunately the source of much waste of time and energy.\n\nOf course, the grammar view of the shared forest is an abstraction, which may be implemented in various ways, some being more easily computed with than others. Hence the grammar is sometimes a bit harder to see when described an an implemented structure in some algorithm descriptions. It may also happen, as in the case of Earley's algorithm, that the parse forest grammar is derived from a binarized version of the original grammar.\n\nBibliography: search the web with the keywords: parsing intersection forest - many papers are open access somewhere.\n\nSome references on stackexchange:\n\n    answer to Algorithms or data structures for dealing with ambiguity\n\n    Recovering a parse forest from an Earley parser? and my answer\n\n    Complexity of a GLR parser on an ambiguous grammar [https://cstheory.stackexchange.com/questions/22621/complexity-of-a-glr-parser-on-an-ambiguous-grammar stackexchange]"
      },
      "date": 1702653004518
    },
    {
      "type": "add",
      "id": "d236a5c393f0a77a",
      "item": {
        "type": "paragraph",
        "id": "d236a5c393f0a77a",
        "text": "How do I reconstruct the forest of syntax trees from the Earley vector? [https://cs.stackexchange.com/questions/27937/how-do-i-reconstruct-the-forest-of-syntax-trees-from-the-earley-vector stackexchange]"
      },
      "after": "1e8b550680bd7e3e",
      "date": 1702653008045
    },
    {
      "item": {
        "type": "pagefold",
        "id": "7fb3e51bd418d08c",
        "text": "~"
      },
      "id": "7fb3e51bd418d08c",
      "type": "add",
      "after": "d236a5c393f0a77a",
      "date": 1702653009640
    },
    {
      "type": "edit",
      "id": "7fb3e51bd418d08c",
      "item": {
        "type": "pagefold",
        "id": "7fb3e51bd418d08c",
        "text": "~"
      },
      "date": 1702653013560
    },
    {
      "id": "7fb3e51bd418d08c",
      "type": "move",
      "order": [
        "be4edc6aaa996fc3",
        "43d21a343563cd68",
        "1e8b550680bd7e3e",
        "7fb3e51bd418d08c",
        "d236a5c393f0a77a"
      ],
      "date": 1702653021657,
      "error": {
        "type": "error",
        "msg": "Internal Server Error",
        "response": "Server Ignoring move. Try reload."
      }
    },
    {
      "type": "fork",
      "date": 1702653026912
    },
    {
      "item": {
        "type": "factory",
        "id": "e38b43d355be67ff"
      },
      "id": "e38b43d355be67ff",
      "type": "add",
      "after": "d236a5c393f0a77a",
      "date": 1702653072769
    },
    {
      "type": "edit",
      "id": "e38b43d355be67ff",
      "item": {
        "type": "paragraph",
        "id": "e38b43d355be67ff",
        "text": "\n\nUsing the Earley vector as a recognizer is quite straightforward: when the end of the string is reached, you just have to check for a completed axiomatic production started at position 0. If you have at least one, then the string is accepted.\n\nUsing the Earley vector to reconstruct the parsing tree(s) is less obvious. Actually, I cannot figure out how an algorithmic procedure would work, moreover the only references I found were either vague or super-technical. Could anybody shed some light on it?\n"
      },
      "date": 1702653075921
    },
    {
      "item": {
        "type": "factory",
        "id": "49c405079fdd1e66"
      },
      "id": "49c405079fdd1e66",
      "type": "add",
      "after": "e38b43d355be67ff",
      "date": 1702653752842
    },
    {
      "type": "edit",
      "id": "49c405079fdd1e66",
      "item": {
        "type": "pagefold",
        "id": "49c405079fdd1e66",
        "text": "~"
      },
      "date": 1702653756111
    },
    {
      "item": {
        "type": "factory",
        "id": "ca14119dadf7ea8d"
      },
      "id": "ca14119dadf7ea8d",
      "type": "add",
      "after": "49c405079fdd1e66",
      "date": 1702653760678
    },
    {
      "type": "edit",
      "id": "ca14119dadf7ea8d",
      "item": {
        "type": "reference",
        "id": "ca14119dadf7ea8d",
        "site": "wiki.ralfbarkow.ch",
        "slug": "remove-model",
        "title": "Remove Model",
        "text": "# [[Creativity]] as a 3-Step Process"
      },
      "date": 1702653766795
    },
    {
      "type": "edit",
      "id": "ca14119dadf7ea8d",
      "item": {
        "type": "reference",
        "id": "ca14119dadf7ea8d",
        "site": "wiki.ralfbarkow.ch",
        "slug": "remove-model",
        "title": "Remove Model",
        "text": "[[Creativity]] as a 3-Step Process"
      },
      "date": 1702653775598
    },
    {
      "id": "5e6aae47e7c07abe",
      "type": "add",
      "item": {
        "type": "paragraph",
        "id": "5e6aae47e7c07abe",
        "text": "â‡’ [[The Ethical Imperative]] ([[Recover]]ing the trees)"
      },
      "after": "ca14119dadf7ea8d",
      "attribution": {
        "page": "Remove Model"
      },
      "date": 1702653781197
    },
    {
      "id": "c5db300328f88a99",
      "type": "add",
      "item": {
        "type": "markdown",
        "id": "c5db300328f88a99",
        "text": "> Exhibit the [[Tree]] recovered by the [[Parser]] "
      },
      "after": "5e6aae47e7c07abe",
      "attribution": {
        "page": "Remove Model"
      },
      "date": 1702653784766
    }
  ]
}