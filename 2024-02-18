{
  "title": "2024-02-18",
  "story": [
    {
      "type": "paragraph",
      "id": "a1d6ef1489af8d3a",
      "text": "In diesem Fall muß der Punkt eine größere freie Umgebung um sich herum haben, damit sein Klang eine Resonanz erhält. Trotzdem bleibt aber dieser Klang zart, bescheiden und wird von der ihn umgebenden Schrift übertönt."
    },
    {
      "type": "paragraph",
      "id": "68205422afe41113",
      "text": "\"[[retrieval]] according to the matching paradigm\" ⇒ [[Path]]"
    },
    {
      "type": "paragraph",
      "id": "a2f5aa16115eade7",
      "text": "LEVY, Benjamin and ANDERSON, Michael, 2002. Inhibitory processes and the control of memory retrieval. Trends in cognitive sciences. 1 August 2002. Vol. 6, p. 299–305. DOI 10.1016/S1364-6613(02)01923-X. \nPeople are often confronted with reminders of things they would prefer not to think about. When this happens, they often attempt to put the unwanted memories out of awareness. Recent research shows that the capacity to [[suppress]] distracting traces is mediated by executive-control processes that are analogous to those involved in overriding prepotent motor responses, and it is these processes that cause persisting memory failures for the suppressed items. There is evidence that memory retrieval and motor tasks that are likely to demand executive control recruit overlapping neural mechanisms, suggesting that a common process mediates control in these domains. Together, these findings indicate that memory failures often arise from the mechanisms that lie at the heart of our capacity to influence the focus of thought.\n"
    },
    {
      "type": "paragraph",
      "id": "2f4b33ad3abe5eab",
      "text": "MCKNIGHT, Cliff, DILLON, Andrew and RICHARDSON, John, 1990. A comparison of linear and hypertext formats in information retrieval. In: Oxford: Intellect. [https://www.academia.edu/download/55072183/CmAdJr90.pdf pdf] [Accessed 18 February 2024]. An exploratory study is described in which the same text was presented to subjects in one of four formats, of which two were hypertext (TIES and Hypercard) and two were linear (Word Processor and paper). Subjects were required to use the text to answer 12 questions. Measurement was made of their time and accuracy and their movement through the document was recorded, in addition to a variety of subjective data being collected. Although there was no significant difference between conditions for task completion time, subjects performed more accurately with linear formats. The implications of these findings and the other data collected are discussed.\n"
    },
    {
      "type": "paragraph",
      "id": "0364248249d1788e",
      "text": "Unter vielen Möglichkeiten sollen zwei typische Fälle erwähnt werden:"
    },
    {
      "type": "image",
      "id": "096bf5c004006eba",
      "text": "Punkt",
      "size": "wide",
      "width": 418,
      "height": 298,
      "url": "/assets/plugins/image/db2835a5d9cc778f18fb7b52b9975046.jpg"
    },
    {
      "type": "paragraph",
      "id": "90f9e1388f86a7f5",
      "text": "Erster Fall I. Der [[Punkt]] wird aus dem praktisch zweckmäßigen Zustand in einen unzweckmäßigen, also in einen alogischen versetzt."
    },
    {
      "type": "paragraph",
      "id": "b545c49196143046",
      "text": "Heute gehe ich ins Kino. Heute gehe ich. Ins Kino Heute gehe. Ich ins Kino"
    },
    {
      "type": "paragraph",
      "id": "72e18bd4650019d4",
      "text": "Es ist klar, daß es im zweiten Satz noch möglich ist, die Versetzung des Punktes als eine zweckmäßige aufzufassen - Unterstreichen des Ziels, Nachdruck der Absicht, Posaunenklang.\nIm dritten Satz ist die reine Gestalt des Alogischen in Tätigkeit, was aber als Druckfehler erklärt werden kann - der innere Wert des Punktes blitzt einen Augenblick heraus und wird sofort gelöscht."
    },
    {
      "type": "paragraph",
      "id": "3294c9782204991e",
      "text": "Zweiter Fall 2. Der Punkt wird dadurch aus seinem praktisch zweckmäßigen Zustand versetzt, so daß er außerhalb der Reihenkette des laufenden Satzes zu stehen kommt."
    },
    {
      "type": "pagefold",
      "id": "e0321546c748556b",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "c857db6a13151ac6",
      "text": "[[Memetic Proxy]]"
    },
    {
      "type": "paragraph",
      "id": "4cdbb6c7df3a55e8",
      "text": "ALBERT, Julien, BALFROID, Martin, DOH, Miriam, BOGAERT, Jeremie, LA FISCA, Luca, DE VOS, Liesbet, RENARD, Bryan, STRAGIER, Vincent and JEAN, Emmanuel, [no date]. User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study. . Online. Available from: https://orbi.umons.ac.be/bitstream/20.500.12907/48327/1/TRAIL23___RECLLM___DBWRS2023.pdf [Accessed 18 February 2024]. \n\nBERRIOS TORRES, ANTONIO, 2022. Language models for patents: exploring prompt engineering for the patent domain. . Online. 2022. Available from: https://www.politesi.polimi.it/handle/10589/186082 [Accessed 18 February 2024]. \n\nFENG, Felicia Li, YEN, Ryan, YOU, Yuzhe, FAN, Mingming, ZHAO, Jian and LU, Zhicong, 2023. CoPrompt: Supporting Prompt Sharing and Referring in Collaborative Natural Language Programming.. Online. 26 December 2023. arXiv. arXiv:2310.09235. Available from: http://arxiv.org/abs/2310.09235 [Accessed 18 February 2024]. \nNatural language (NL) programming has become more approachable due to the powerful code-generation capability of large language models (LLMs). This shift to using NL to program enhances collaborative programming by reducing communication barriers and context-switching among programmers from varying backgrounds. However, programmers may face challenges during prompt engineering in a collaborative setting as they need to actively keep aware of their collaborators’ progress and intents. In this paper, we aim to investigate ways to assist programmers’ prompt engineering in a collaborative context. We first conducted a formative study to understand the workflows and challenges of programmers when using NL for collaborative programming. Based on our findings, we implemented a prototype, CoPrompt, to support collaborative prompt engineering by providing referring, requesting, sharing, and linking mechanisms. Our user study indicates that CoPrompt assists programmers in comprehending collaborators’ prompts and building on their collaborators’ work, reducing repetitive updates and communication costs.\narXiv:2310.09235 [cs]\n\nGRZYWINSKI, Rob, D’ARCY, Joshua, NAIDOFF, Rob, SHUKLA, Ashish, BROWNE, Alex, GIBBONS, Ren and BENT, Brinnae, 2023. Releasing the CRaQAn (Coreference Resolution in Question-Answering): An open-source dataset and dataset creation methodology using instruction-following models.. Online. 27 November 2023. arXiv. arXiv:2311.16338. Available from: http://arxiv.org/abs/2311.16338 [Accessed 18 February 2024]. \nInstruction-following language models demand robust methodologies for information retrieval to augment instructions for question-answering applications. A primary challenge is the resolution of coreferences in the context of chunking strategies for long documents. The critical barrier to experimentation of handling coreferences is a lack of open source datasets, specifically in question-answering tasks that require coreference resolution. In this work we present our Coreference Resolution in Question-Answering (CRaQAn) dataset, an open-source dataset that caters to the nuanced information retrieval requirements of coreference resolution in question-answering tasks by providing over 250 question-answer pairs containing coreferences. To develop this dataset, we developed a novel approach for creating high-quality datasets using an instruction-following model (GPT-4) and a Recursive Criticism and Improvement Loop.\narXiv:2311.16338 [cs]\n\nHÄKKINEN, Josefina and RAMADAN, Zaina, 2023. A Study on the Perception of Feedback with Varying Sentiment Generated Using a Large Language Model.. Online. 2023. Available from: https://www.diva-portal.org/smash/record.jsf?pid=diva2:1779789 [Accessed 18 February 2024]. \n\nHAN, Yuzhang, HOU, Jing and SUN, Yi, 2023. Research and Application of GPT-Based Large Language Models in Business and Economics: A Systematic Literature Review in Progress. In: 2023 IEEE International Conference on Computing (ICOCO). Online. IEEE. 2023. p. 118–123. Available from: https://ieeexplore.ieee.org/abstract/document/10397642/ [Accessed 18 February 2024]. \n\nHEWETT, Joe and LEEKE, Matthew, 2022. Developing a GPT-3-Based Automated Victim for Advance Fee Fraud Disruption. In: 2022 IEEE 27th Pacific Rim International Symposium on Dependable Computing (PRDC). Online. IEEE. 2022. p. 205–211. Available from: https://ieeexplore.ieee.org/abstract/document/10027811/ [Accessed 18 February 2024]. \n\nISSAK, Alayt and VARSHNEY, Lav R., 2023. Prompt Programming for the Visual Domain. . Online. 2023. Available from: https://openreview.net/forum?id=hBz5h3C9Sq [Accessed 18 February 2024]. \n\nLAURI ALEKSI TÖRNWALL, Mikael, 2023. Contextual short-term memory for LLM-based chatbot.. Online. 2023. Available from: https://www.diva-portal.org/smash/record.jsf?pid=diva2:1801471 [Accessed 18 February 2024]. \n\nLI, Yinheng, 2023. Apractical SURVEY ON ZERO-SHOT PROMPT DESIGN FOR IN-CONTEXT LEARNING. . Online. 2023. Available from: https://www.researchgate.net/profile/Yinheng-Li/publication/369619413_A_PRACTICAL_SURVEY_ON_ZERO-SHOT_PROMPT_DESIGN_FOR_IN-CONTEXT_LEARNING/links/6424b45c315dfb4cceb88c49/A-PRACTICAL-SURVEY-ON-ZERO-SHOT-PROMPT-DESIGN-FOR-IN-CONTEXT-LEARNING.pdf [Accessed 18 February 2024]. \n\nLUNDBLAD, Jonathan, THÖRN, Edwin and THÖRN, Linus, 2023. The impact of task specification on code generated via ChatGPT.. Online. 2023. Available from: https://www.diva-portal.org/smash/record.jsf?pid=diva2:1776870 [Accessed 18 February 2024]. \n\nPARKER, Michael J., ANDERSON, Caitlin, STONE, Claire and OH, YeaRim, 2023. A Large Language Model Approach to Educational Survey Feedback Analysis.. Online. 29 September 2023. arXiv. arXiv:2309.17447. Available from: http://arxiv.org/abs/2309.17447 [Accessed 18 February 2024]. \nThis paper assesses the potential for the large language models (LLMs) GPT-4 and GPT-3.5 to aid in deriving insight from education feedback surveys. Exploration of LLM use cases in education has focused on teaching and learning, with less exploration of capabilities in education feedback analysis. Survey analysis in education involves goals such as finding gaps in curricula or evaluating teachers, often requiring time-consuming manual processing of textual responses. LLMs have the potential to provide a flexible means of achieving these goals without specialized machine learning models or fine-tuning. We demonstrate a versatile approach to such goals by treating them as sequences of natural language processing (NLP) tasks including classification (multi-label, multi-class, and binary), extraction, thematic analysis, and sentiment analysis, each performed by LLM. We apply these workflows to a real-world dataset of 2500 end-of-course survey comments from biomedical science courses, and evaluate a zero-shot approach (i.e., requiring no examples or labeled training data) across all tasks, reflecting education settings, where labeled data is often scarce. By applying effective prompting practices, we achieve human-level performance on multiple tasks with GPT-4, enabling workflows necessary to achieve typical goals. We also show the potential of inspecting LLMs’ chain-of-thought (CoT) reasoning for providing insight that may foster confidence in practice. Moreover, this study features development of a versatile set of classification categories, suitable for various course types (online, hybrid, or in-person) and amenable to customization. Our results suggest that LLMs can be used to derive a range of insights from survey text.\narXiv:2309.17447 [cs]\n\nPHOGAT, Karmvir Singh, HARSHA, Chetan, DASARATHA, Sridhar, RAMAKRISHNA, Shashishekar and PURANAM, Sai Akhil, 2023. Zero-Shot Question Answering over Financial Documents using Large Language Models.. Online. 19 November 2023. arXiv. arXiv:2311.14722. Available from: http://arxiv.org/abs/2311.14722 [Accessed 18 February 2024]. \nWe introduce a large language model (LLM) based approach to answer complex questions requiring multi-hop numerical reasoning over financial reports. While LLMs have exhibited remarkable performance on various natural language and reasoning tasks, complex reasoning problems often rely on few-shot prompts that require carefully crafted examples. In contrast, our approach uses novel zero-shot prompts that guide the LLM to encode the required reasoning into a Python program or a domain specific language. The generated program is then executed by a program interpreter, thus mitigating the limitations of LLM in performing accurate arithmetic calculations. We evaluate the proposed approach on three financial datasets using some of the recently developed generative pretrained transformer (GPT) models and perform comparisons with various zero-shot baselines. The experimental results demonstrate that our approach significantly improves the accuracy for all the LLMs over their respective baselines. We provide a detailed analysis of the results, generating insights to support our findings. The success of our approach demonstrates the enormous potential to extract complex domain specific numerical reasoning by designing zero-shot prompts to effectively exploit the knowledge embedded in LLMs.\narXiv:2311.14722 [cs]\n\nPROCKO, Tyler and COLLINS, Steve, [no date]. Automatic Code Documentation with Syntax Trees and GPT: Alleviating Software Development’s Most Redundant Task. Available at SSRN 4571367. Online. Available from: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4571367 [Accessed 18 February 2024]. \n\nPROCKO, Tyler Thomas and COLLINS, Steve, [no date]. Automatic Code Documentation with Syntax Trees and GPT. [https://www.researchgate.net/profile/Tyler_Procko/publication/373911060_Automatic_Code_Documentation_with_Syntax_Trees_and_GPT_Alleviating_Software_Development's_Most_Redundant_Task/links/65afde756c7ad06ab42605f4/Automatic-Code-Documentation-with-Syntax-Trees-and-GPT-Alleviating-Software-Developments-Most-Redundant-Task.pdf pdf] [Accessed 18 February 2024]. \n\nREYNOLDS, Laria and MCDONELL, Kyle, 2021. Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm. In: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. Online. Yokohama Japan: ACM. 8 May 2021. p. 1–7. ISBN 978-1-4503-8095-9. DOI 10.1145/3411763.3451760. [Accessed 18 February 2024]. \n"
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "2024-02-18",
        "story": []
      },
      "date": 1708235192334
    },
    {
      "item": {
        "type": "factory",
        "id": "68205422afe41113"
      },
      "id": "68205422afe41113",
      "type": "add",
      "date": 1708235193954
    },
    {
      "type": "edit",
      "id": "68205422afe41113",
      "item": {
        "type": "paragraph",
        "id": "68205422afe41113",
        "text": "\"[[retrieval]] according to the matching paradigm\""
      },
      "date": 1708235203367
    },
    {
      "type": "fork",
      "site": "localhost:3000",
      "date": 1708235273282
    },
    {
      "type": "edit",
      "id": "68205422afe41113",
      "item": {
        "type": "paragraph",
        "id": "68205422afe41113",
        "text": "\"[[retrieval]] according to the matching paradigm\" ⇒ [[Path]]"
      },
      "date": 1708235294143
    },
    {
      "item": {
        "type": "factory",
        "id": "a2f5aa16115eade7"
      },
      "id": "a2f5aa16115eade7",
      "type": "add",
      "after": "68205422afe41113",
      "date": 1708236627021
    },
    {
      "type": "edit",
      "id": "a2f5aa16115eade7",
      "item": {
        "type": "paragraph",
        "id": "a2f5aa16115eade7",
        "text": "\nLEVY, Benjamin and ANDERSON, Michael, 2002. Inhibitory processes and the control of memory retrieval. Trends in cognitive sciences. 1 August 2002. Vol. 6, p. 299–305. DOI 10.1016/S1364-6613(02)01923-X. \nPeople are often confronted with reminders of things they would prefer not to think about. When this happens, they often attempt to put the unwanted memories out of awareness. Recent research shows that the capacity to suppress distracting traces is mediated by executive-control processes that are analogous to those involved in overriding prepotent motor responses, and it is these processes that cause persisting memory failures for the suppressed items. There is evidence that memory retrieval and motor tasks that are likely to demand executive control recruit overlapping neural mechanisms, suggesting that a common process mediates control in these domains. Together, these findings indicate that memory failures often arise from the mechanisms that lie at the heart of our capacity to influence the focus of thought.\n"
      },
      "date": 1708236629009
    },
    {
      "type": "edit",
      "id": "a2f5aa16115eade7",
      "item": {
        "type": "paragraph",
        "id": "a2f5aa16115eade7",
        "text": "LEVY, Benjamin and ANDERSON, Michael, 2002. Inhibitory processes and the control of memory retrieval. Trends in cognitive sciences. 1 August 2002. Vol. 6, p. 299–305. DOI 10.1016/S1364-6613(02)01923-X. \nPeople are often confronted with reminders of things they would prefer not to think about. When this happens, they often attempt to put the unwanted memories out of awareness. Recent research shows that the capacity to suppress distracting traces is mediated by executive-control processes that are analogous to those involved in overriding prepotent motor responses, and it is these processes that cause persisting memory failures for the suppressed items. There is evidence that memory retrieval and motor tasks that are likely to demand executive control recruit overlapping neural mechanisms, suggesting that a common process mediates control in these domains. Together, these findings indicate that memory failures often arise from the mechanisms that lie at the heart of our capacity to influence the focus of thought.\n"
      },
      "date": 1708236664243
    },
    {
      "type": "edit",
      "id": "a2f5aa16115eade7",
      "item": {
        "type": "paragraph",
        "id": "a2f5aa16115eade7",
        "text": "LEVY, Benjamin and ANDERSON, Michael, 2002. Inhibitory processes and the control of memory retrieval. Trends in cognitive sciences. 1 August 2002. Vol. 6, p. 299–305. DOI 10.1016/S1364-6613(02)01923-X. \nPeople are often confronted with reminders of things they would prefer not to think about. When this happens, they often attempt to put the unwanted memories out of awareness. Recent research shows that the capacity to [[suppress]] distracting traces is mediated by executive-control processes that are analogous to those involved in overriding prepotent motor responses, and it is these processes that cause persisting memory failures for the suppressed items. There is evidence that memory retrieval and motor tasks that are likely to demand executive control recruit overlapping neural mechanisms, suggesting that a common process mediates control in these domains. Together, these findings indicate that memory failures often arise from the mechanisms that lie at the heart of our capacity to influence the focus of thought.\n"
      },
      "date": 1708236688614
    },
    {
      "item": {
        "type": "factory",
        "id": "2f4b33ad3abe5eab"
      },
      "id": "2f4b33ad3abe5eab",
      "type": "add",
      "after": "a2f5aa16115eade7",
      "date": 1708237681476
    },
    {
      "type": "edit",
      "id": "2f4b33ad3abe5eab",
      "item": {
        "type": "paragraph",
        "id": "2f4b33ad3abe5eab",
        "text": "\nMCKNIGHT, Cliff, DILLON, Andrew and RICHARDSON, John, 1990. A comparison of linear and hypertext formats in information retrieval. In: . Online. Oxford: Intellect. Available from: https://www.academia.edu/download/55072183/CmAdJr90.pdf [Accessed 18 February 2024]. \n"
      },
      "date": 1708237684069
    },
    {
      "type": "edit",
      "id": "2f4b33ad3abe5eab",
      "item": {
        "type": "paragraph",
        "id": "2f4b33ad3abe5eab",
        "text": "MCKNIGHT, Cliff, DILLON, Andrew and RICHARDSON, John, 1990. A comparison of linear and hypertext formats in information retrieval. In: Oxford: Intellect. Available from: https://www.academia.edu/download/55072183/CmAdJr90.pdf [Accessed 18 February 2024]. \n"
      },
      "date": 1708237753663
    },
    {
      "type": "edit",
      "id": "2f4b33ad3abe5eab",
      "item": {
        "type": "paragraph",
        "id": "2f4b33ad3abe5eab",
        "text": "MCKNIGHT, Cliff, DILLON, Andrew and RICHARDSON, John, 1990. A comparison of linear and hypertext formats in information retrieval. In: Oxford: Intellect. [https://www.academia.edu/download/55072183/CmAdJr90.pdf pdf] [Accessed 18 February 2024]. \n"
      },
      "date": 1708237787580
    },
    {
      "type": "edit",
      "id": "2f4b33ad3abe5eab",
      "item": {
        "type": "paragraph",
        "id": "2f4b33ad3abe5eab",
        "text": "MCKNIGHT, Cliff, DILLON, Andrew and RICHARDSON, John, 1990. A comparison of linear and hypertext formats in information retrieval. In: Oxford: Intellect. [https://www.academia.edu/download/55072183/CmAdJr90.pdf pdf] [Accessed 18 February 2024]. An exploratory study is described in which the same text was presented to subjects in one of four formats, of which two were hypertext (TIES and Hypercard) and two were linear (Word Processor and paper). Subjects were required to use the text to answer 12 questions. Measurement was made of their time and accuracy and their movement through the document was recorded, in addition to a variety of subjective data being collected. Although there was no significant difference between conditions for task completion time, subjects performed more accurately with linear formats. The implications of these findings and the other data collected are discussed.\n"
      },
      "date": 1708237839184
    },
    {
      "type": "fork",
      "site": "wiki.ralfbarkow.ch",
      "date": 1708256362079
    },
    {
      "item": {
        "type": "factory",
        "id": "096bf5c004006eba"
      },
      "id": "096bf5c004006eba",
      "type": "add",
      "after": "2f4b33ad3abe5eab",
      "date": 1708256494295
    },
    {
      "type": "edit",
      "id": "096bf5c004006eba",
      "item": {
        "type": "image",
        "id": "096bf5c004006eba",
        "text": "Punkt",
        "size": "wide",
        "width": 418,
        "height": 298,
        "url": "/assets/plugins/image/db2835a5d9cc778f18fb7b52b9975046.jpg"
      },
      "date": 1708256653666
    },
    {
      "item": {
        "type": "factory",
        "id": "0364248249d1788e"
      },
      "id": "0364248249d1788e",
      "type": "add",
      "after": "096bf5c004006eba",
      "date": 1708256678289
    },
    {
      "type": "edit",
      "id": "0364248249d1788e",
      "item": {
        "type": "paragraph",
        "id": "0364248249d1788e",
        "text": "Unter vielen Möglichkeiten sollen zwei typische Fälle erwähnt werden:"
      },
      "date": 1708256682727
    },
    {
      "type": "add",
      "id": "90f9e1388f86a7f5",
      "item": {
        "type": "paragraph",
        "id": "90f9e1388f86a7f5",
        "text": "Erster Fall I. Der Punkt wird aus dem praktisch zweckmäßigen Zustand in einen unzweckmäßigen, also in einen alogischen versetzt.\nHeute gehe ich ins Kino. Heute gehe ich. Ins Kino Heute gehe. Ich ins Kino\nEs ist klar, daß es im zweiten Satz noch möglich ist, die Versetzung des Punktes als eine zweckmäßige aufzufassen - Unterstreichen des Ziels, Nachdruck der Absicht, Posaunenklang.\nIm dritten Satz ist die reine Gestalt des Alogischen in Tätigkeit, was aber als Druckfehler erklärt werden kann - der innere Wert des Punktes blitzt einen Augenblick heraus und wird sofort gelöscht.\nZweiter Fall 2. Der Punkt wird dadurch aus seinem praktisch zweckmäßigen Zustand versetzt, so daß er außerhalb der Reihenkette des laufenden Satzes zu stehen kommt.\nHeute gehe ich ins Kino\n•\nIn diesem Fall muß der Punkt eine größere freie Umgebung um sich herum haben, damit sein Klang eine Resonanz erhält. Trotzdem bleibt aber dieser Klang zart, bescheiden und wird von der ihn umgebenden Schrift übertönt."
      },
      "after": "0364248249d1788e",
      "date": 1708256683378
    },
    {
      "id": "0364248249d1788e",
      "type": "move",
      "order": [
        "68205422afe41113",
        "a2f5aa16115eade7",
        "2f4b33ad3abe5eab",
        "0364248249d1788e",
        "096bf5c004006eba",
        "90f9e1388f86a7f5"
      ],
      "date": 1708256712718
    },
    {
      "type": "edit",
      "id": "90f9e1388f86a7f5",
      "item": {
        "type": "paragraph",
        "id": "90f9e1388f86a7f5",
        "text": "Erster Fall I. Der Punkt wird aus dem praktisch zweckmäßigen Zustand in einen unzweckmäßigen, also in einen alogischen versetzt."
      },
      "date": 1708256734242
    },
    {
      "type": "add",
      "id": "b545c49196143046",
      "item": {
        "type": "paragraph",
        "id": "b545c49196143046",
        "text": "Heute gehe ich ins Kino. Heute gehe ich. Ins Kino Heute gehe. Ich ins Kino"
      },
      "after": "90f9e1388f86a7f5",
      "date": 1708256736635
    },
    {
      "type": "add",
      "id": "72e18bd4650019d4",
      "item": {
        "type": "paragraph",
        "id": "72e18bd4650019d4",
        "text": "Es ist klar, daß es im zweiten Satz noch möglich ist, die Versetzung des Punktes als eine zweckmäßige aufzufassen - Unterstreichen des Ziels, Nachdruck der Absicht, Posaunenklang.\nIm dritten Satz ist die reine Gestalt des Alogischen in Tätigkeit, was aber als Druckfehler erklärt werden kann - der innere Wert des Punktes blitzt einen Augenblick heraus und wird sofort gelöscht.\nZweiter Fall 2. Der Punkt wird dadurch aus seinem praktisch zweckmäßigen Zustand versetzt, so daß er außerhalb der Reihenkette des laufenden Satzes zu stehen kommt.\nHeute gehe ich ins Kino\n•\nIn diesem Fall muß der Punkt eine größere freie Umgebung um sich herum haben, damit sein Klang eine Resonanz erhält. Trotzdem bleibt aber dieser Klang zart, bescheiden und wird von der ihn umgebenden Schrift übertönt."
      },
      "after": "b545c49196143046",
      "date": 1708256739364
    },
    {
      "type": "edit",
      "id": "72e18bd4650019d4",
      "item": {
        "type": "paragraph",
        "id": "72e18bd4650019d4",
        "text": "Es ist klar, daß es im zweiten Satz noch möglich ist, die Versetzung des Punktes als eine zweckmäßige aufzufassen - Unterstreichen des Ziels, Nachdruck der Absicht, Posaunenklang.\nIm dritten Satz ist die reine Gestalt des Alogischen in Tätigkeit, was aber als Druckfehler erklärt werden kann - der innere Wert des Punktes blitzt einen Augenblick heraus und wird sofort gelöscht."
      },
      "date": 1708256796704
    },
    {
      "type": "add",
      "id": "3294c9782204991e",
      "item": {
        "type": "paragraph",
        "id": "3294c9782204991e",
        "text": "Zweiter Fall 2. Der Punkt wird dadurch aus seinem praktisch zweckmäßigen Zustand versetzt, so daß er außerhalb der Reihenkette des laufenden Satzes zu stehen kommt.\nHeute gehe ich ins Kino\n•\nIn diesem Fall muß der Punkt eine größere freie Umgebung um sich herum haben, damit sein Klang eine Resonanz erhält. Trotzdem bleibt aber dieser Klang zart, bescheiden und wird von der ihn umgebenden Schrift übertönt."
      },
      "after": "72e18bd4650019d4",
      "date": 1708256799066
    },
    {
      "type": "edit",
      "id": "3294c9782204991e",
      "item": {
        "type": "paragraph",
        "id": "3294c9782204991e",
        "text": "Zweiter Fall 2. Der Punkt wird dadurch aus seinem praktisch zweckmäßigen Zustand versetzt, so daß er außerhalb der Reihenkette des laufenden Satzes zu stehen kommt."
      },
      "date": 1708257062276
    },
    {
      "type": "add",
      "id": "a1d6ef1489af8d3a",
      "item": {
        "type": "paragraph",
        "id": "a1d6ef1489af8d3a",
        "text": "In diesem Fall muß der Punkt eine größere freie Umgebung um sich herum haben, damit sein Klang eine Resonanz erhält. Trotzdem bleibt aber dieser Klang zart, bescheiden und wird von der ihn umgebenden Schrift übertönt."
      },
      "after": "3564380c1d2421e9",
      "date": 1708257065157
    },
    {
      "type": "edit",
      "id": "90f9e1388f86a7f5",
      "item": {
        "type": "paragraph",
        "id": "90f9e1388f86a7f5",
        "text": "Erster Fall I. Der [[Punkt]] wird aus dem praktisch zweckmäßigen Zustand in einen unzweckmäßigen, also in einen alogischen versetzt."
      },
      "date": 1708257128639
    },
    {
      "item": {
        "type": "factory",
        "id": "e0321546c748556b"
      },
      "id": "e0321546c748556b",
      "type": "add",
      "after": "3294c9782204991e",
      "date": 1708278425498
    },
    {
      "type": "edit",
      "id": "e0321546c748556b",
      "item": {
        "type": "pagefold",
        "id": "e0321546c748556b",
        "text": "~"
      },
      "date": 1708278429269
    },
    {
      "item": {
        "type": "factory",
        "id": "4cdbb6c7df3a55e8"
      },
      "id": "4cdbb6c7df3a55e8",
      "type": "add",
      "after": "e0321546c748556b",
      "date": 1708278430758
    },
    {
      "type": "edit",
      "id": "4cdbb6c7df3a55e8",
      "item": {
        "type": "paragraph",
        "id": "4cdbb6c7df3a55e8",
        "text": "\nALBERT, Julien, BALFROID, Martin, DOH, Miriam, BOGAERT, Jeremie, LA FISCA, Luca, DE VOS, Liesbet, RENARD, Bryan, STRAGIER, Vincent and JEAN, Emmanuel, [no date]. User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study. . Online. Available from: https://orbi.umons.ac.be/bitstream/20.500.12907/48327/1/TRAIL23___RECLLM___DBWRS2023.pdf [Accessed 18 February 2024]. \n\nBERRIOS TORRES, ANTONIO, 2022. Language models for patents: exploring prompt engineering for the patent domain. . Online. 2022. Available from: https://www.politesi.polimi.it/handle/10589/186082 [Accessed 18 February 2024]. \n\nFENG, Felicia Li, YEN, Ryan, YOU, Yuzhe, FAN, Mingming, ZHAO, Jian and LU, Zhicong, 2023. CoPrompt: Supporting Prompt Sharing and Referring in Collaborative Natural Language Programming.. Online. 26 December 2023. arXiv. arXiv:2310.09235. Available from: http://arxiv.org/abs/2310.09235 [Accessed 18 February 2024]. \nNatural language (NL) programming has become more approachable due to the powerful code-generation capability of large language models (LLMs). This shift to using NL to program enhances collaborative programming by reducing communication barriers and context-switching among programmers from varying backgrounds. However, programmers may face challenges during prompt engineering in a collaborative setting as they need to actively keep aware of their collaborators’ progress and intents. In this paper, we aim to investigate ways to assist programmers’ prompt engineering in a collaborative context. We first conducted a formative study to understand the workflows and challenges of programmers when using NL for collaborative programming. Based on our findings, we implemented a prototype, CoPrompt, to support collaborative prompt engineering by providing referring, requesting, sharing, and linking mechanisms. Our user study indicates that CoPrompt assists programmers in comprehending collaborators’ prompts and building on their collaborators’ work, reducing repetitive updates and communication costs.\narXiv:2310.09235 [cs]\n\nGRZYWINSKI, Rob, D’ARCY, Joshua, NAIDOFF, Rob, SHUKLA, Ashish, BROWNE, Alex, GIBBONS, Ren and BENT, Brinnae, 2023. Releasing the CRaQAn (Coreference Resolution in Question-Answering): An open-source dataset and dataset creation methodology using instruction-following models.. Online. 27 November 2023. arXiv. arXiv:2311.16338. Available from: http://arxiv.org/abs/2311.16338 [Accessed 18 February 2024]. \nInstruction-following language models demand robust methodologies for information retrieval to augment instructions for question-answering applications. A primary challenge is the resolution of coreferences in the context of chunking strategies for long documents. The critical barrier to experimentation of handling coreferences is a lack of open source datasets, specifically in question-answering tasks that require coreference resolution. In this work we present our Coreference Resolution in Question-Answering (CRaQAn) dataset, an open-source dataset that caters to the nuanced information retrieval requirements of coreference resolution in question-answering tasks by providing over 250 question-answer pairs containing coreferences. To develop this dataset, we developed a novel approach for creating high-quality datasets using an instruction-following model (GPT-4) and a Recursive Criticism and Improvement Loop.\narXiv:2311.16338 [cs]\n\nHÄKKINEN, Josefina and RAMADAN, Zaina, 2023. A Study on the Perception of Feedback with Varying Sentiment Generated Using a Large Language Model.. Online. 2023. Available from: https://www.diva-portal.org/smash/record.jsf?pid=diva2:1779789 [Accessed 18 February 2024]. \n\nHAN, Yuzhang, HOU, Jing and SUN, Yi, 2023. Research and Application of GPT-Based Large Language Models in Business and Economics: A Systematic Literature Review in Progress. In: 2023 IEEE International Conference on Computing (ICOCO). Online. IEEE. 2023. p. 118–123. Available from: https://ieeexplore.ieee.org/abstract/document/10397642/ [Accessed 18 February 2024]. \n\nHEWETT, Joe and LEEKE, Matthew, 2022. Developing a GPT-3-Based Automated Victim for Advance Fee Fraud Disruption. In: 2022 IEEE 27th Pacific Rim International Symposium on Dependable Computing (PRDC). Online. IEEE. 2022. p. 205–211. Available from: https://ieeexplore.ieee.org/abstract/document/10027811/ [Accessed 18 February 2024]. \n\nISSAK, Alayt and VARSHNEY, Lav R., 2023. Prompt Programming for the Visual Domain. . Online. 2023. Available from: https://openreview.net/forum?id=hBz5h3C9Sq [Accessed 18 February 2024]. \n\nLAURI ALEKSI TÖRNWALL, Mikael, 2023. Contextual short-term memory for LLM-based chatbot.. Online. 2023. Available from: https://www.diva-portal.org/smash/record.jsf?pid=diva2:1801471 [Accessed 18 February 2024]. \n\nLI, Yinheng, 2023. Apractical SURVEY ON ZERO-SHOT PROMPT DESIGN FOR IN-CONTEXT LEARNING. . Online. 2023. Available from: https://www.researchgate.net/profile/Yinheng-Li/publication/369619413_A_PRACTICAL_SURVEY_ON_ZERO-SHOT_PROMPT_DESIGN_FOR_IN-CONTEXT_LEARNING/links/6424b45c315dfb4cceb88c49/A-PRACTICAL-SURVEY-ON-ZERO-SHOT-PROMPT-DESIGN-FOR-IN-CONTEXT-LEARNING.pdf [Accessed 18 February 2024]. \n\nLUNDBLAD, Jonathan, THÖRN, Edwin and THÖRN, Linus, 2023. The impact of task specification on code generated via ChatGPT.. Online. 2023. Available from: https://www.diva-portal.org/smash/record.jsf?pid=diva2:1776870 [Accessed 18 February 2024]. \n\nPARKER, Michael J., ANDERSON, Caitlin, STONE, Claire and OH, YeaRim, 2023. A Large Language Model Approach to Educational Survey Feedback Analysis.. Online. 29 September 2023. arXiv. arXiv:2309.17447. Available from: http://arxiv.org/abs/2309.17447 [Accessed 18 February 2024]. \nThis paper assesses the potential for the large language models (LLMs) GPT-4 and GPT-3.5 to aid in deriving insight from education feedback surveys. Exploration of LLM use cases in education has focused on teaching and learning, with less exploration of capabilities in education feedback analysis. Survey analysis in education involves goals such as finding gaps in curricula or evaluating teachers, often requiring time-consuming manual processing of textual responses. LLMs have the potential to provide a flexible means of achieving these goals without specialized machine learning models or fine-tuning. We demonstrate a versatile approach to such goals by treating them as sequences of natural language processing (NLP) tasks including classification (multi-label, multi-class, and binary), extraction, thematic analysis, and sentiment analysis, each performed by LLM. We apply these workflows to a real-world dataset of 2500 end-of-course survey comments from biomedical science courses, and evaluate a zero-shot approach (i.e., requiring no examples or labeled training data) across all tasks, reflecting education settings, where labeled data is often scarce. By applying effective prompting practices, we achieve human-level performance on multiple tasks with GPT-4, enabling workflows necessary to achieve typical goals. We also show the potential of inspecting LLMs’ chain-of-thought (CoT) reasoning for providing insight that may foster confidence in practice. Moreover, this study features development of a versatile set of classification categories, suitable for various course types (online, hybrid, or in-person) and amenable to customization. Our results suggest that LLMs can be used to derive a range of insights from survey text.\narXiv:2309.17447 [cs]\n\nPHOGAT, Karmvir Singh, HARSHA, Chetan, DASARATHA, Sridhar, RAMAKRISHNA, Shashishekar and PURANAM, Sai Akhil, 2023. Zero-Shot Question Answering over Financial Documents using Large Language Models.. Online. 19 November 2023. arXiv. arXiv:2311.14722. Available from: http://arxiv.org/abs/2311.14722 [Accessed 18 February 2024]. \nWe introduce a large language model (LLM) based approach to answer complex questions requiring multi-hop numerical reasoning over financial reports. While LLMs have exhibited remarkable performance on various natural language and reasoning tasks, complex reasoning problems often rely on few-shot prompts that require carefully crafted examples. In contrast, our approach uses novel zero-shot prompts that guide the LLM to encode the required reasoning into a Python program or a domain specific language. The generated program is then executed by a program interpreter, thus mitigating the limitations of LLM in performing accurate arithmetic calculations. We evaluate the proposed approach on three financial datasets using some of the recently developed generative pretrained transformer (GPT) models and perform comparisons with various zero-shot baselines. The experimental results demonstrate that our approach significantly improves the accuracy for all the LLMs over their respective baselines. We provide a detailed analysis of the results, generating insights to support our findings. The success of our approach demonstrates the enormous potential to extract complex domain specific numerical reasoning by designing zero-shot prompts to effectively exploit the knowledge embedded in LLMs.\narXiv:2311.14722 [cs]\n\nPROCKO, Tyler and COLLINS, Steve, [no date]. Automatic Code Documentation with Syntax Trees and GPT: Alleviating Software Development’s Most Redundant Task. Available at SSRN 4571367. Online. Available from: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4571367 [Accessed 18 February 2024]. \n\nPROCKO, Tyler Thomas and COLLINS, Steve, [no date]. Automatic Code Documentation with Syntax Trees and GPT. . Online. Available from: https://www.researchgate.net/profile/Tyler_Procko/publication/373911060_Automatic_Code_Documentation_with_Syntax_Trees_and_GPT_Alleviating_Software_Development's_Most_Redundant_Task/links/65afde756c7ad06ab42605f4/Automatic-Code-Documentation-with-Syntax-Trees-and-GPT-Alleviating-Software-Developments-Most-Redundant-Task.pdf [Accessed 18 February 2024]. \n\nREYNOLDS, Laria and MCDONELL, Kyle, 2021. Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm. In: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. Online. Yokohama Japan: ACM. 8 May 2021. p. 1–7. ISBN 978-1-4503-8095-9. DOI 10.1145/3411763.3451760. [Accessed 18 February 2024]. \n"
      },
      "date": 1708278433785
    },
    {
      "id": "c857db6a13151ac6",
      "type": "add",
      "item": {
        "type": "paragraph",
        "id": "c857db6a13151ac6",
        "text": "[[Memetic Proxy]]"
      },
      "after": "e0321546c748556b",
      "attribution": {
        "page": "scratch"
      },
      "date": 1708278465620
    },
    {
      "type": "edit",
      "id": "4cdbb6c7df3a55e8",
      "item": {
        "type": "paragraph",
        "id": "4cdbb6c7df3a55e8",
        "text": "ALBERT, Julien, BALFROID, Martin, DOH, Miriam, BOGAERT, Jeremie, LA FISCA, Luca, DE VOS, Liesbet, RENARD, Bryan, STRAGIER, Vincent and JEAN, Emmanuel, [no date]. User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study. . Online. Available from: https://orbi.umons.ac.be/bitstream/20.500.12907/48327/1/TRAIL23___RECLLM___DBWRS2023.pdf [Accessed 18 February 2024]. \n\nBERRIOS TORRES, ANTONIO, 2022. Language models for patents: exploring prompt engineering for the patent domain. . Online. 2022. Available from: https://www.politesi.polimi.it/handle/10589/186082 [Accessed 18 February 2024]. \n\nFENG, Felicia Li, YEN, Ryan, YOU, Yuzhe, FAN, Mingming, ZHAO, Jian and LU, Zhicong, 2023. CoPrompt: Supporting Prompt Sharing and Referring in Collaborative Natural Language Programming.. Online. 26 December 2023. arXiv. arXiv:2310.09235. Available from: http://arxiv.org/abs/2310.09235 [Accessed 18 February 2024]. \nNatural language (NL) programming has become more approachable due to the powerful code-generation capability of large language models (LLMs). This shift to using NL to program enhances collaborative programming by reducing communication barriers and context-switching among programmers from varying backgrounds. However, programmers may face challenges during prompt engineering in a collaborative setting as they need to actively keep aware of their collaborators’ progress and intents. In this paper, we aim to investigate ways to assist programmers’ prompt engineering in a collaborative context. We first conducted a formative study to understand the workflows and challenges of programmers when using NL for collaborative programming. Based on our findings, we implemented a prototype, CoPrompt, to support collaborative prompt engineering by providing referring, requesting, sharing, and linking mechanisms. Our user study indicates that CoPrompt assists programmers in comprehending collaborators’ prompts and building on their collaborators’ work, reducing repetitive updates and communication costs.\narXiv:2310.09235 [cs]\n\nGRZYWINSKI, Rob, D’ARCY, Joshua, NAIDOFF, Rob, SHUKLA, Ashish, BROWNE, Alex, GIBBONS, Ren and BENT, Brinnae, 2023. Releasing the CRaQAn (Coreference Resolution in Question-Answering): An open-source dataset and dataset creation methodology using instruction-following models.. Online. 27 November 2023. arXiv. arXiv:2311.16338. Available from: http://arxiv.org/abs/2311.16338 [Accessed 18 February 2024]. \nInstruction-following language models demand robust methodologies for information retrieval to augment instructions for question-answering applications. A primary challenge is the resolution of coreferences in the context of chunking strategies for long documents. The critical barrier to experimentation of handling coreferences is a lack of open source datasets, specifically in question-answering tasks that require coreference resolution. In this work we present our Coreference Resolution in Question-Answering (CRaQAn) dataset, an open-source dataset that caters to the nuanced information retrieval requirements of coreference resolution in question-answering tasks by providing over 250 question-answer pairs containing coreferences. To develop this dataset, we developed a novel approach for creating high-quality datasets using an instruction-following model (GPT-4) and a Recursive Criticism and Improvement Loop.\narXiv:2311.16338 [cs]\n\nHÄKKINEN, Josefina and RAMADAN, Zaina, 2023. A Study on the Perception of Feedback with Varying Sentiment Generated Using a Large Language Model.. Online. 2023. Available from: https://www.diva-portal.org/smash/record.jsf?pid=diva2:1779789 [Accessed 18 February 2024]. \n\nHAN, Yuzhang, HOU, Jing and SUN, Yi, 2023. Research and Application of GPT-Based Large Language Models in Business and Economics: A Systematic Literature Review in Progress. In: 2023 IEEE International Conference on Computing (ICOCO). Online. IEEE. 2023. p. 118–123. Available from: https://ieeexplore.ieee.org/abstract/document/10397642/ [Accessed 18 February 2024]. \n\nHEWETT, Joe and LEEKE, Matthew, 2022. Developing a GPT-3-Based Automated Victim for Advance Fee Fraud Disruption. In: 2022 IEEE 27th Pacific Rim International Symposium on Dependable Computing (PRDC). Online. IEEE. 2022. p. 205–211. Available from: https://ieeexplore.ieee.org/abstract/document/10027811/ [Accessed 18 February 2024]. \n\nISSAK, Alayt and VARSHNEY, Lav R., 2023. Prompt Programming for the Visual Domain. . Online. 2023. Available from: https://openreview.net/forum?id=hBz5h3C9Sq [Accessed 18 February 2024]. \n\nLAURI ALEKSI TÖRNWALL, Mikael, 2023. Contextual short-term memory for LLM-based chatbot.. Online. 2023. Available from: https://www.diva-portal.org/smash/record.jsf?pid=diva2:1801471 [Accessed 18 February 2024]. \n\nLI, Yinheng, 2023. Apractical SURVEY ON ZERO-SHOT PROMPT DESIGN FOR IN-CONTEXT LEARNING. . Online. 2023. Available from: https://www.researchgate.net/profile/Yinheng-Li/publication/369619413_A_PRACTICAL_SURVEY_ON_ZERO-SHOT_PROMPT_DESIGN_FOR_IN-CONTEXT_LEARNING/links/6424b45c315dfb4cceb88c49/A-PRACTICAL-SURVEY-ON-ZERO-SHOT-PROMPT-DESIGN-FOR-IN-CONTEXT-LEARNING.pdf [Accessed 18 February 2024]. \n\nLUNDBLAD, Jonathan, THÖRN, Edwin and THÖRN, Linus, 2023. The impact of task specification on code generated via ChatGPT.. Online. 2023. Available from: https://www.diva-portal.org/smash/record.jsf?pid=diva2:1776870 [Accessed 18 February 2024]. \n\nPARKER, Michael J., ANDERSON, Caitlin, STONE, Claire and OH, YeaRim, 2023. A Large Language Model Approach to Educational Survey Feedback Analysis.. Online. 29 September 2023. arXiv. arXiv:2309.17447. Available from: http://arxiv.org/abs/2309.17447 [Accessed 18 February 2024]. \nThis paper assesses the potential for the large language models (LLMs) GPT-4 and GPT-3.5 to aid in deriving insight from education feedback surveys. Exploration of LLM use cases in education has focused on teaching and learning, with less exploration of capabilities in education feedback analysis. Survey analysis in education involves goals such as finding gaps in curricula or evaluating teachers, often requiring time-consuming manual processing of textual responses. LLMs have the potential to provide a flexible means of achieving these goals without specialized machine learning models or fine-tuning. We demonstrate a versatile approach to such goals by treating them as sequences of natural language processing (NLP) tasks including classification (multi-label, multi-class, and binary), extraction, thematic analysis, and sentiment analysis, each performed by LLM. We apply these workflows to a real-world dataset of 2500 end-of-course survey comments from biomedical science courses, and evaluate a zero-shot approach (i.e., requiring no examples or labeled training data) across all tasks, reflecting education settings, where labeled data is often scarce. By applying effective prompting practices, we achieve human-level performance on multiple tasks with GPT-4, enabling workflows necessary to achieve typical goals. We also show the potential of inspecting LLMs’ chain-of-thought (CoT) reasoning for providing insight that may foster confidence in practice. Moreover, this study features development of a versatile set of classification categories, suitable for various course types (online, hybrid, or in-person) and amenable to customization. Our results suggest that LLMs can be used to derive a range of insights from survey text.\narXiv:2309.17447 [cs]\n\nPHOGAT, Karmvir Singh, HARSHA, Chetan, DASARATHA, Sridhar, RAMAKRISHNA, Shashishekar and PURANAM, Sai Akhil, 2023. Zero-Shot Question Answering over Financial Documents using Large Language Models.. Online. 19 November 2023. arXiv. arXiv:2311.14722. Available from: http://arxiv.org/abs/2311.14722 [Accessed 18 February 2024]. \nWe introduce a large language model (LLM) based approach to answer complex questions requiring multi-hop numerical reasoning over financial reports. While LLMs have exhibited remarkable performance on various natural language and reasoning tasks, complex reasoning problems often rely on few-shot prompts that require carefully crafted examples. In contrast, our approach uses novel zero-shot prompts that guide the LLM to encode the required reasoning into a Python program or a domain specific language. The generated program is then executed by a program interpreter, thus mitigating the limitations of LLM in performing accurate arithmetic calculations. We evaluate the proposed approach on three financial datasets using some of the recently developed generative pretrained transformer (GPT) models and perform comparisons with various zero-shot baselines. The experimental results demonstrate that our approach significantly improves the accuracy for all the LLMs over their respective baselines. We provide a detailed analysis of the results, generating insights to support our findings. The success of our approach demonstrates the enormous potential to extract complex domain specific numerical reasoning by designing zero-shot prompts to effectively exploit the knowledge embedded in LLMs.\narXiv:2311.14722 [cs]\n\nPROCKO, Tyler and COLLINS, Steve, [no date]. Automatic Code Documentation with Syntax Trees and GPT: Alleviating Software Development’s Most Redundant Task. Available at SSRN 4571367. Online. Available from: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4571367 [Accessed 18 February 2024]. \n\nPROCKO, Tyler Thomas and COLLINS, Steve, [no date]. Automatic Code Documentation with Syntax Trees and GPT. [https://www.researchgate.net/profile/Tyler_Procko/publication/373911060_Automatic_Code_Documentation_with_Syntax_Trees_and_GPT_Alleviating_Software_Development's_Most_Redundant_Task/links/65afde756c7ad06ab42605f4/Automatic-Code-Documentation-with-Syntax-Trees-and-GPT-Alleviating-Software-Developments-Most-Redundant-Task.pdf pdf] [Accessed 18 February 2024]. \n\nREYNOLDS, Laria and MCDONELL, Kyle, 2021. Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm. In: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. Online. Yokohama Japan: ACM. 8 May 2021. p. 1–7. ISBN 978-1-4503-8095-9. DOI 10.1145/3411763.3451760. [Accessed 18 February 2024]. \n"
      },
      "date": 1708278661558
    }
  ]
}