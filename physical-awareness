{
  "title": "Physical Awareness",
  "story": [
    {
      "type": "paragraph",
      "id": "200f1a2656d2cdfe",
      "text": "We present a new trainable system for physically plausible markerless 3D human motion capture, which achieves state-of-the-art results in a broad range of challenging scenarios."
    },
    {
      "type": "paragraph",
      "id": "3738ebdd0fe1410a",
      "text": "Unlike most neural methods for human motion capture, our approach, which we dub “physionical”, is aware of physical and environmental constraints. It combines in a fully-differentiable way several key innovations, i.e., 1) a proportional-derivative controller, with gains predicted by a neural network, that reduces delays even in the presence of fast motions, 2) an explicit rigid body dynamics model and 3) a novel optimisation layer that prevents physically implausible foot-floor penetration as a hard constraint. The inputs to our system are 2D joint keypoints, which are canonicalised in a novel way so as to reduce the dependency on intrinsic camera parameters---both at train and test time. This enables more accurate global translation estimation without generalisability loss. Our model can be finetuned only with 2D annotations when the 3D annotations are not available. It produces smooth and physically-principled 3D motions in an interactive frame rate in a wide variety of challenging scenes, including newly recorded ones. Its advantages are especially noticeable on in-the-wild sequences that significantly differ from common 3D pose estimation benchmarks such as Human 3.6M and MPI-INF-3DHP. Qualitative results are provided in the supplementary video."
    },
    {
      "type": "pagefold",
      "id": "2a161273c3a197b4",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "7c88d9cbbd1bb205",
      "text": "SHIMADA, Soshi, GOLYANIK, Vladislav, XU, Weipeng, PÉREZ, Patrick and THEOBALT, Christian, 2021. Neural monocular 3D human motion capture with physical awareness. ACM Transactions on Graphics. Online. 19 July 2021. Vol. 40, no. 4, p. 83:1-83:15. [Accessed 28 August 2023]. [https://doi.org/10.1145/3450626.3459825 doi]"
    },
    {
      "type": "paragraph",
      "id": "320cf154301a79ef",
      "text": "\nJABARIN, Baha, WU, James, VERTEGAAL, Roel and GRIGOROV, Lenko, 2003. Establishing remote conversations through eye contact with physical awareness proxies. In: CHI ’03 Extended Abstracts on Human Factors in Computing Systems. Online. New York, NY, USA: Association for Computing Machinery. 5 April 2003. p. 948–949. [Accessed 28 August 2023]. CHI EA ’03. ISBN 978-1-58113-637-1. DOI 10.1145/765891.766087. We present a mechanism for initiating mediated conversations through eye contact. An eyePHONE is a physical proxy of a remote individual that senses and conveys attention using an eye tracking device and a pair of actuated eyeballs. Users may initiate calls by jointly looking at each other’s eyePHONE. We discuss how this allows participants to implement some of the basic social rules of face-to-face conversations in mediated conversations.\n"
    },
    {
      "type": "paragraph",
      "id": "ce72e5acfc9c59c9",
      "text": "The negotiation of interlocutor attention through nonverbal cues is typically not supported by mediated systems [6]. Media spaces [5] address the problem of providing casual awareness of the activities and presence of remote individuals. For example, the availability of continuous virtual windows into a remote environment encourages spontaneous communication, albeit at a cost of privacy [5]. In Montage [3], such privacy issues were addressed by allowing only momentary and reciprocal video glances into remote offices. Peepholes [2] further mitigated privacy concerns by using only iconic presence indicators. Similarly, physical awareness proxies [4] convey a remote user’s availability using the rich but abstract representation of a tangible interface. The present work extends work on physical awareness proxies by allowing proxies to not just convey the availability of a remote user for communications, but sense eye contact."
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Physical Awareness",
        "story": []
      },
      "date": 1693237530155
    },
    {
      "item": {
        "type": "factory",
        "id": "7c88d9cbbd1bb205"
      },
      "id": "7c88d9cbbd1bb205",
      "type": "add",
      "date": 1693237531242
    },
    {
      "type": "edit",
      "id": "7c88d9cbbd1bb205",
      "item": {
        "type": "paragraph",
        "id": "7c88d9cbbd1bb205",
        "text": "\nSHIMADA, Soshi, GOLYANIK, Vladislav, XU, Weipeng, PÉREZ, Patrick and THEOBALT, Christian, 2021. Neural monocular 3D human motion capture with physical awareness. ACM Transactions on Graphics. Online. 19 July 2021. Vol. 40, no. 4, p. 83:1-83:15. [Accessed 28 August 2023]. DOI 10.1145/3450626.3459825. We present a new trainable system for physically plausible markerless 3D human motion capture, which achieves state-of-the-art results in a broad range of challenging scenarios. Unlike most neural methods for human motion capture, our approach, which we dub “physionical”, is aware of physical and environmental constraints. It combines in a fully-differentiable way several key innovations, i.e., 1) a proportional-derivative controller, with gains predicted by a neural network, that reduces delays even in the presence of fast motions, 2) an explicit rigid body dynamics model and 3) a novel optimisation layer that prevents physically implausible foot-floor penetration as a hard constraint. The inputs to our system are 2D joint keypoints, which are canonicalised in a novel way so as to reduce the dependency on intrinsic camera parameters---both at train and test time. This enables more accurate global translation estimation without generalisability loss. Our model can be finetuned only with 2D annotations when the 3D annotations are not available. It produces smooth and physically-principled 3D motions in an interactive frame rate in a wide variety of challenging scenes, including newly recorded ones. Its advantages are especially noticeable on in-the-wild sequences that significantly differ from common 3D pose estimation benchmarks such as Human 3.6M and MPI-INF-3DHP. Qualitative results are provided in the supplementary video.\n"
      },
      "date": 1693237532793
    },
    {
      "type": "edit",
      "id": "7c88d9cbbd1bb205",
      "item": {
        "type": "paragraph",
        "id": "7c88d9cbbd1bb205",
        "text": "SHIMADA, Soshi, GOLYANIK, Vladislav, XU, Weipeng, PÉREZ, Patrick and THEOBALT, Christian, 2021. Neural monocular 3D human motion capture with physical awareness. ACM Transactions on Graphics. Online. 19 July 2021. Vol. 40, no. 4, p. 83:1-83:15. [Accessed 28 August 2023]. DOI 10.1145/3450626.3459825."
      },
      "date": 1693237551257
    },
    {
      "type": "add",
      "id": "200f1a2656d2cdfe",
      "item": {
        "type": "paragraph",
        "id": "200f1a2656d2cdfe",
        "text": "We present a new trainable system for physically plausible markerless 3D human motion capture, which achieves state-of-the-art results in a broad range of challenging scenarios. Unlike most neural methods for human motion capture, our approach, which we dub “physionical”, is aware of physical and environmental constraints. It combines in a fully-differentiable way several key innovations, i.e., 1) a proportional-derivative controller, with gains predicted by a neural network, that reduces delays even in the presence of fast motions, 2) an explicit rigid body dynamics model and 3) a novel optimisation layer that prevents physically implausible foot-floor penetration as a hard constraint. The inputs to our system are 2D joint keypoints, which are canonicalised in a novel way so as to reduce the dependency on intrinsic camera parameters---both at train and test time. This enables more accurate global translation estimation without generalisability loss. Our model can be finetuned only with 2D annotations when the 3D annotations are not available. It produces smooth and physically-principled 3D motions in an interactive frame rate in a wide variety of challenging scenes, including newly recorded ones. Its advantages are especially noticeable on in-the-wild sequences that significantly differ from common 3D pose estimation benchmarks such as Human 3.6M and MPI-INF-3DHP. Qualitative results are provided in the supplementary video."
      },
      "after": "7c88d9cbbd1bb205",
      "date": 1693237552628
    },
    {
      "id": "200f1a2656d2cdfe",
      "type": "move",
      "order": [
        "200f1a2656d2cdfe",
        "7c88d9cbbd1bb205"
      ],
      "date": 1693237554731
    },
    {
      "item": {
        "type": "factory",
        "id": "2a161273c3a197b4"
      },
      "id": "2a161273c3a197b4",
      "type": "add",
      "after": "7c88d9cbbd1bb205",
      "date": 1693237556080
    },
    {
      "id": "2a161273c3a197b4",
      "type": "move",
      "order": [
        "200f1a2656d2cdfe",
        "2a161273c3a197b4",
        "7c88d9cbbd1bb205"
      ],
      "date": 1693237558569
    },
    {
      "type": "edit",
      "id": "2a161273c3a197b4",
      "item": {
        "type": "pagefold",
        "id": "2a161273c3a197b4",
        "text": "~"
      },
      "date": 1693237561141
    },
    {
      "type": "edit",
      "id": "7c88d9cbbd1bb205",
      "item": {
        "type": "paragraph",
        "id": "7c88d9cbbd1bb205",
        "text": "SHIMADA, Soshi, GOLYANIK, Vladislav, XU, Weipeng, PÉREZ, Patrick and THEOBALT, Christian, 2021. Neural monocular 3D human motion capture with physical awareness. ACM Transactions on Graphics. Online. 19 July 2021. Vol. 40, no. 4, p. 83:1-83:15. [Accessed 28 August 2023]. [https://doi.org/10.1145/3450626.3459825 doi]"
      },
      "date": 1693237567365
    },
    {
      "type": "edit",
      "id": "200f1a2656d2cdfe",
      "item": {
        "type": "paragraph",
        "id": "200f1a2656d2cdfe",
        "text": "We present a new trainable system for physically plausible markerless 3D human motion capture, which achieves state-of-the-art results in a broad range of challenging scenarios."
      },
      "date": 1693237584746
    },
    {
      "type": "add",
      "id": "3738ebdd0fe1410a",
      "item": {
        "type": "paragraph",
        "id": "3738ebdd0fe1410a",
        "text": "Unlike most neural methods for human motion capture, our approach, which we dub “physionical”, is aware of physical and environmental constraints. It combines in a fully-differentiable way several key innovations, i.e., 1) a proportional-derivative controller, with gains predicted by a neural network, that reduces delays even in the presence of fast motions, 2) an explicit rigid body dynamics model and 3) a novel optimisation layer that prevents physically implausible foot-floor penetration as a hard constraint. The inputs to our system are 2D joint keypoints, which are canonicalised in a novel way so as to reduce the dependency on intrinsic camera parameters---both at train and test time. This enables more accurate global translation estimation without generalisability loss. Our model can be finetuned only with 2D annotations when the 3D annotations are not available. It produces smooth and physically-principled 3D motions in an interactive frame rate in a wide variety of challenging scenes, including newly recorded ones. Its advantages are especially noticeable on in-the-wild sequences that significantly differ from common 3D pose estimation benchmarks such as Human 3.6M and MPI-INF-3DHP. Qualitative results are provided in the supplementary video."
      },
      "after": "200f1a2656d2cdfe",
      "date": 1693237585006
    },
    {
      "item": {
        "type": "factory",
        "id": "320cf154301a79ef"
      },
      "id": "320cf154301a79ef",
      "type": "add",
      "after": "7c88d9cbbd1bb205",
      "date": 1693237884913
    },
    {
      "type": "edit",
      "id": "320cf154301a79ef",
      "item": {
        "type": "paragraph",
        "id": "320cf154301a79ef",
        "text": "\nJABARIN, Baha, WU, James, VERTEGAAL, Roel and GRIGOROV, Lenko, 2003. Establishing remote conversations through eye contact with physical awareness proxies. In: CHI ’03 Extended Abstracts on Human Factors in Computing Systems. Online. New York, NY, USA: Association for Computing Machinery. 5 April 2003. p. 948–949. [Accessed 28 August 2023]. CHI EA ’03. ISBN 978-1-58113-637-1. DOI 10.1145/765891.766087. We present a mechanism for initiating mediated conversations through eye contact. An eyePHONE is a physical proxy of a remote individual that senses and conveys attention using an eye tracking device and a pair of actuated eyeballs. Users may initiate calls by jointly looking at each other’s eyePHONE. We discuss how this allows participants to implement some of the basic social rules of face-to-face conversations in mediated conversations.\n"
      },
      "date": 1693237886520
    },
    {
      "item": {
        "type": "factory",
        "id": "ce72e5acfc9c59c9"
      },
      "id": "ce72e5acfc9c59c9",
      "type": "add",
      "after": "320cf154301a79ef",
      "date": 1693237933355
    },
    {
      "type": "edit",
      "id": "ce72e5acfc9c59c9",
      "item": {
        "type": "paragraph",
        "id": "ce72e5acfc9c59c9",
        "text": "The negotiation of interlocutor attention through nonverbal cues is typically not supported by mediated systems [6]. Media spaces [5] address the problem of providing casual awareness of the activities and presence of remote individuals. For example, the availability of continuous virtual windows into a remote environment encourages spontaneous communication, albeit at a cost of privacy [5]. In Montage [3], such privacy issues were addressed by allowing only momentary and reciprocal video glances into remote offices. Peepholes [2] further mitigated privacy concerns by using only iconic presence indicators. Similarly, physical awareness proxies [4] convey a remote user’s availability using the rich but abstract representation of a tangible interface. The present work extends work on physical awareness proxies by allowing proxies to not just convey the availability of a remote user for communications, but sense eye contact."
      },
      "date": 1693237934707
    }
  ]
}