{
  "title": "Statistical Parrot",
  "story": [
    {
      "type": "paragraph",
      "id": "00fec7fc10d66c84",
      "text": "CAMPELLO DE SOUZA, Bruno, SERRANO DE ANDRADE NETO, Agostinho and ROAZZI, Antonio, 2023. The Generative AI Revolution, Cognitive Mediation Networks Theory and the Emergence of a New Mode of Mental Functioning: Introducing the Sophotechnic Mediation Scale. Cognitive Mediation Networks Theory and the Emergence of a New Mode of Mental Functioning: Introducing the Sophotechnic Mediation Scale (July 11, 2023). Online. 2023. Available from: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4506710 [Accessed 3 January 2024]."
    },
    {
      "type": "paragraph",
      "id": "3ed4c757d919010b",
      "text": "LI, Muhan, 2022. Symbolic Data Augmentation for Assisted Neural Reasoning. Digipen Institute of Technology. 2022. [https://www.mccormick.northwestern.edu/computer-science/documents/2022-06-symbolic-data-augmentation.pdf pdf] [Accessed 3 January 2024]."
    },
    {
      "type": "markdown",
      "id": "41ffb468475f5fb8",
      "text": "**Abstract**. This work proposes a novel data augmentation technique based on symbolic methods SDAR that generates annotations in the text space. The SDAR annotator is an ensemble of multiple sub-annotators, each equipped with a searcher and a symbolic knowledge retriever. We demonstrate that SDAR can boost the performance of smaller models to a comparable degree of or even surpass larger models with a magnitude more parameters and establish the STOA single model performance on OpenBookQA.\n> Even if we have the ground truth knowledge that is most related to the question and desired answer, there is still no guarantee that the language model is correctly understanding the reasoning process. May be its just a more localized ”statistical parrot” [35] that selects the answer most related to the given text.\n\n⇒ [[Step by Step Reasoning]]"
    },
    {
      "type": "paragraph",
      "id": "f3956ee5cf0131b6",
      "text": "[35] E. M. Bender, T. Gebru, A. McMillan-Major, and S. Shmitchell, “On the dangers of stochastic parrots: Can language models be too big?” In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, ser. FAccT ’21, Virtual Event, Canada: Association for Computing Machinery, 2021, pp. 610–623, ISBN: 9781450383097."
    },
    {
      "type": "paragraph",
      "id": "dd913de3ed425fc1",
      "text": "RINI, Regina, 2023. A Talking Cure for Autonomy Traps: How to share our social world with chatbots. Archived draft. Available from: [https://philpapers.org/rec/RINATC philpapers][Accessed 3 January 2024]."
    },
    {
      "type": "markdown",
      "id": "16a772cea6f44272",
      "text": "**Abstract**. Large Language Models (LLMs) like ChatGPT were trained on human conversation, but in the future they will also train us. As chatbots speak from our smartphones and customer service helplines, they will become a part of everyday life and a growing share of all the conversations we ever have. It’s hard to doubt this will have some effect on us. Here I explore a specific concern about the impact of artificial conversation on our capacity to deliberate and hold ourselves accountable to reason – that is, to be autonomous, in Kant’s sense of the term. I develop ideas from psychologist Jean Piaget to show how chatbots are [[Autonomy Trap]]s: their deference to our commands tempts us into venting authoritarian whims, ultimately weakening our own self-control. I argue that the Kantian tradition, including Piaget and sociologist Emile Durkheim, offers powerful conceptual resources for resisting this slide. But it will require us to do something that may seem bizarre: we will need to treat mindless chatbots as if they are autonomous persons too. "
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Statistical Parrot",
        "story": []
      },
      "date": 1704266393625
    },
    {
      "item": {
        "type": "factory",
        "id": "00fec7fc10d66c84"
      },
      "id": "00fec7fc10d66c84",
      "type": "add",
      "date": 1704266415285
    },
    {
      "type": "edit",
      "id": "00fec7fc10d66c84",
      "item": {
        "type": "paragraph",
        "id": "00fec7fc10d66c84",
        "text": "\nCAMPELLO DE SOUZA, Bruno, SERRANO DE ANDRADE NETO, Agostinho and ROAZZI, Antonio, 2023. The Generative AI Revolution, Cognitive Mediation Networks Theory and the Emergence of a New Mode of Mental Functioning: Introducing the Sophotechnic Mediation Scale. Cognitive Mediation Networks Theory and the Emergence of a New Mode of Mental Functioning: Introducing the Sophotechnic Mediation Scale (July 11, 2023). Online. 2023. Available from: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4506710 [Accessed 3 January 2024]. \n\nLI, Muhan, 2022. Computer Science Department. Digipen Institute of Technology. Online. 2022. Available from: https://www.mccormick.northwestern.edu/computer-science/documents/2022-06-symbolic-data-augmentation.pdf [Accessed 3 January 2024]. \n\nRINI, Regina, [no date]. A Talking Cure for Autonomy Traps: How to share our social world with chatbots. . Online. Available from: https://philpapers.org/rec/RINATC [Accessed 3 January 2024]. \n"
      },
      "date": 1704266417049
    },
    {
      "type": "edit",
      "id": "00fec7fc10d66c84",
      "item": {
        "type": "paragraph",
        "id": "00fec7fc10d66c84",
        "text": "CAMPELLO DE SOUZA, Bruno, SERRANO DE ANDRADE NETO, Agostinho and ROAZZI, Antonio, 2023. The Generative AI Revolution, Cognitive Mediation Networks Theory and the Emergence of a New Mode of Mental Functioning: Introducing the Sophotechnic Mediation Scale. Cognitive Mediation Networks Theory and the Emergence of a New Mode of Mental Functioning: Introducing the Sophotechnic Mediation Scale (July 11, 2023). Online. 2023. Available from: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4506710 [Accessed 3 January 2024]. \n\nLI, Muhan, 2022. Computer Science Department. Digipen Institute of Technology. Online. 2022. Available from: https://www.mccormick.northwestern.edu/computer-science/documents/2022-06-symbolic-data-augmentation.pdf [Accessed 3 January 2024]."
      },
      "date": 1704266534782
    },
    {
      "type": "add",
      "id": "dd913de3ed425fc1",
      "item": {
        "type": "paragraph",
        "id": "dd913de3ed425fc1",
        "text": "RINI, Regina, 2023. A Talking Cure for Autonomy Traps: How to share our social world with chatbots. Archived draft. Available from: [https://philpapers.org/rec/RINATC philpapers][Accessed 3 January 2024]."
      },
      "after": "00fec7fc10d66c84",
      "date": 1704266571867
    },
    {
      "item": {
        "type": "factory",
        "id": "16a772cea6f44272"
      },
      "id": "16a772cea6f44272",
      "type": "add",
      "after": "dd913de3ed425fc1",
      "date": 1704266700146
    },
    {
      "type": "edit",
      "id": "16a772cea6f44272",
      "item": {
        "type": "paragraph",
        "id": "16a772cea6f44272",
        "text": "**Abstract**. Large Language Models (LLMs) like ChatGPT were trained on human conversation, but in the future they will also train us. As chatbots speak from our smartphones and customer service helplines, they will become a part of everyday life and a growing share of all the conversations we ever have. It’s hard to doubt this will have some effect on us. Here I explore a specific concern about the impact of artificial conversation on our capacity to deliberate and hold ourselves accountable to reason – that is, to be autonomous, in Kant’s sense of the term. I develop ideas from psychologist Jean Piaget to show how chatbots are autonomy traps: their deference to our commands tempts us into venting authoritarian whims, ultimately weakening our own self-control. I argue that the Kantian tradition, including Piaget and sociologist Emile Durkheim, offers powerful conceptual resources for resisting this slide. But it will require us to do something that may seem bizarre: we will need to treat mindless chatbots as if they are autonomous persons too. "
      },
      "date": 1704266710870
    },
    {
      "type": "edit",
      "id": "16a772cea6f44272",
      "item": {
        "type": "markdown",
        "id": "16a772cea6f44272",
        "text": "**Abstract**. Large Language Models (LLMs) like ChatGPT were trained on human conversation, but in the future they will also train us. As chatbots speak from our smartphones and customer service helplines, they will become a part of everyday life and a growing share of all the conversations we ever have. It’s hard to doubt this will have some effect on us. Here I explore a specific concern about the impact of artificial conversation on our capacity to deliberate and hold ourselves accountable to reason – that is, to be autonomous, in Kant’s sense of the term. I develop ideas from psychologist Jean Piaget to show how chatbots are autonomy traps: their deference to our commands tempts us into venting authoritarian whims, ultimately weakening our own self-control. I argue that the Kantian tradition, including Piaget and sociologist Emile Durkheim, offers powerful conceptual resources for resisting this slide. But it will require us to do something that may seem bizarre: we will need to treat mindless chatbots as if they are autonomous persons too. "
      },
      "date": 1704266711908
    },
    {
      "type": "edit",
      "id": "16a772cea6f44272",
      "item": {
        "type": "markdown",
        "id": "16a772cea6f44272",
        "text": "**Abstract**. Large Language Models (LLMs) like ChatGPT were trained on human conversation, but in the future they will also train us. As chatbots speak from our smartphones and customer service helplines, they will become a part of everyday life and a growing share of all the conversations we ever have. It’s hard to doubt this will have some effect on us. Here I explore a specific concern about the impact of artificial conversation on our capacity to deliberate and hold ourselves accountable to reason – that is, to be autonomous, in Kant’s sense of the term. I develop ideas from psychologist Jean Piaget to show how chatbots are [[Autonomy Trap]]s: their deference to our commands tempts us into venting authoritarian whims, ultimately weakening our own self-control. I argue that the Kantian tradition, including Piaget and sociologist Emile Durkheim, offers powerful conceptual resources for resisting this slide. But it will require us to do something that may seem bizarre: we will need to treat mindless chatbots as if they are autonomous persons too. "
      },
      "date": 1704266785706
    },
    {
      "type": "edit",
      "id": "00fec7fc10d66c84",
      "item": {
        "type": "paragraph",
        "id": "00fec7fc10d66c84",
        "text": "CAMPELLO DE SOUZA, Bruno, SERRANO DE ANDRADE NETO, Agostinho and ROAZZI, Antonio, 2023. The Generative AI Revolution, Cognitive Mediation Networks Theory and the Emergence of a New Mode of Mental Functioning: Introducing the Sophotechnic Mediation Scale. Cognitive Mediation Networks Theory and the Emergence of a New Mode of Mental Functioning: Introducing the Sophotechnic Mediation Scale (July 11, 2023). Online. 2023. Available from: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4506710 [Accessed 3 January 2024]."
      },
      "date": 1704267329585
    },
    {
      "type": "add",
      "id": "3ed4c757d919010b",
      "item": {
        "type": "paragraph",
        "id": "3ed4c757d919010b",
        "text": "LI, Muhan, 2022. Symbolic Data Augmentation for Assisted Neural Reasoning. Digipen Institute of Technology. 2022. [https://www.mccormick.northwestern.edu/computer-science/documents/2022-06-symbolic-data-augmentation.pdf pdf] [Accessed 3 January 2024]."
      },
      "after": "00fec7fc10d66c84",
      "date": 1704267361357
    },
    {
      "type": "edit",
      "id": "3ed4c757d919010b",
      "item": {
        "type": "paragraph",
        "id": "3ed4c757d919010b",
        "text": "LI, Muhan, 2022. Symbolic Data Augmentation for Assisted Neural Reasoning. Digipen Institute of Technology. 2022. [https://www.mccormick.northwestern.edu/computer-science/documents/2022-06-symbolic-data-augmentation.pdf pdf] [Accessed 3 January 2024]."
      },
      "date": 1704267378871
    },
    {
      "type": "add",
      "id": "41ffb468475f5fb8",
      "item": {
        "type": "paragraph",
        "id": "41ffb468475f5fb8",
        "text": "**Abstract**. This work proposes a novel data augmentation technique based on symbolic methods SDAR that generates annotations in the text space. The SDAR annotator is an ensemble of multiple sub-annotators, each equipped with a searcher and a symbolic knowledge retriever. We demonstrate that SDAR can boost the performance of smaller models to a comparable degree of or even surpass larger models with a magnitude more parameters and establish the STOA single model performance on OpenBookQA."
      },
      "after": "3ed4c757d919010b",
      "date": 1704267420574
    },
    {
      "type": "edit",
      "id": "41ffb468475f5fb8",
      "item": {
        "type": "markdown",
        "id": "41ffb468475f5fb8",
        "text": "**Abstract**. This work proposes a novel data augmentation technique based on symbolic methods SDAR that generates annotations in the text space. The SDAR annotator is an ensemble of multiple sub-annotators, each equipped with a searcher and a symbolic knowledge retriever. We demonstrate that SDAR can boost the performance of smaller models to a comparable degree of or even surpass larger models with a magnitude more parameters and establish the STOA single model performance on OpenBookQA."
      },
      "date": 1704267422225
    },
    {
      "type": "edit",
      "id": "41ffb468475f5fb8",
      "item": {
        "type": "markdown",
        "id": "41ffb468475f5fb8",
        "text": "**Abstract**. This work proposes a novel data augmentation technique based on symbolic methods SDAR that generates annotations in the text space. The SDAR annotator is an ensemble of multiple sub-annotators, each equipped with a searcher and a symbolic knowledge retriever. We demonstrate that SDAR can boost the performance of smaller models to a comparable degree of or even surpass larger models with a magnitude more parameters and establish the STOA single model performance on OpenBookQA.\n> Even if we have the ground truth knowledge that is most related to the question and desired answer, there is still no guarantee that the language model is correctly understanding the reasoning process. May be its just a more localized ”statistical parrot” [35] that selects the answer most related to the given text."
      },
      "date": 1704267516488
    },
    {
      "type": "edit",
      "id": "41ffb468475f5fb8",
      "item": {
        "type": "markdown",
        "id": "41ffb468475f5fb8",
        "text": "**Abstract**. This work proposes a novel data augmentation technique based on symbolic methods SDAR that generates annotations in the text space. The SDAR annotator is an ensemble of multiple sub-annotators, each equipped with a searcher and a symbolic knowledge retriever. We demonstrate that SDAR can boost the performance of smaller models to a comparable degree of or even surpass larger models with a magnitude more parameters and establish the STOA single model performance on OpenBookQA.\n> Even if we have the ground truth knowledge that is most related to the question and desired answer, there is still no guarantee that the language model is correctly understanding the reasoning process. May be its just a more localized ”statistical parrot” [35] that selects the answer most related to the given text.\n\n⇒ [[Step by Step Reasoning]]"
      },
      "date": 1704267587654
    },
    {
      "item": {
        "type": "factory",
        "id": "f3956ee5cf0131b6"
      },
      "id": "f3956ee5cf0131b6",
      "type": "add",
      "after": "16a772cea6f44272",
      "date": 1704267646859
    },
    {
      "type": "edit",
      "id": "f3956ee5cf0131b6",
      "item": {
        "type": "paragraph",
        "id": "f3956ee5cf0131b6",
        "text": "[35] E. M. Bender, T. Gebru, A. McMillan-Major, and S. Shmitchell, “On the dangers of stochastic parrots: Can language models be too big?” In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, ser. FAccT ’21, Virtual Event, Canada: Association for Computing Machinery, 2021, pp. 610–623, ISBN: 9781450383097."
      },
      "date": 1704267648836
    },
    {
      "id": "f3956ee5cf0131b6",
      "type": "move",
      "order": [
        "00fec7fc10d66c84",
        "3ed4c757d919010b",
        "41ffb468475f5fb8",
        "f3956ee5cf0131b6",
        "dd913de3ed425fc1",
        "16a772cea6f44272"
      ],
      "date": 1704267656438
    },
    {
      "type": "fork",
      "site": "localhost:3000",
      "date": 1704269232016
    }
  ]
}