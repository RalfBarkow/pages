{
  "title": "Programmer Test",
  "story": [
    {
      "type": "html",
      "text": "XP terminology, not quite synonymous with [[Unit Test]]. (See Also [[Developer Test]])",
      "id": "2f33b877825237bfe11aadf38c849a65"
    },
    {
      "type": "html",
      "text": "\nFailure of a [[Unit Test]] shall implicate one (1) and only one (1) unit. (A method, class, module, or package.)",
      "id": "48abbd4a50e7d6a17475d0d0940c91e0"
    },
    {
      "type": "html",
      "text": "\nFailure of a [[Programmer Test]], under [[Test Driven Development]], implicates only the most recent edit.",
      "id": "ff2bd3c67b8f8b6adbf7dfe284552587"
    },
    {
      "type": "html",
      "text": "\n[http://www.XProgramming.com/xpmag/whatisXP.htm#test www.XProgramming.com]  ",
      "id": "543576a4e441cdde3b7fed070724c6c0"
    },
    {
      "type": "html",
      "text": "\nOften a [[Programmer Test]] is better than a comment, to help us understand why a particular function is needed, to demonstrate how a function is called and what are the expected results are, and to document bugs in previous versions of the program that we want to make sure don't come back.",
      "id": "32e24888def07e6f2c1d30695287712f"
    },
    {
      "type": "html",
      "text": "\n[[Programmer Test]]s give us confidence that after we improve one facet of the program (adding a feature, or making it load faster, ...), we haven't made some other facet worse.",
      "id": "ba068d7fd6d4641ff2a95b4d99eaeff7"
    },
    {
      "type": "html",
      "text": "\nIf it's worth doing, it's worth testing to make sure it was done right.",
      "id": "08725bfa2480225a5a7c9b9dce309cca"
    },
    {
      "type": "html",
      "text": "<hr>",
      "id": "4e4b5dc485db215e062e165087125fa8"
    },
    {
      "type": "html",
      "text": "\nI'm starting to understand why [[Programmer Test]]s are so important. When there's a couple of useless-looking lines in the code, with some cryptic comment about how we \"need to do this or else it doesn't work\" ( [[Voodoo Chicken Coding]] ), but I take them out and it still <i>seems</i> to work - the [[Unit Test]]s help explain <i>why</i> we need it, they show that while it may work in some cases, but fails other cases. However, I still find it difficult to write [[Unit Test]]s for my own code. Let's take the example in the [[Things You Should Never Do]] article - a bunch of crufty-looking code to handle 60 kinds of FTP servers. How in the world do I [[Unit Test]] that code? I suppose I could write unit tests that download a short file from 60 different servers -- but those unit tests would give a false error if one of those servers went off-line. Or worse, server number 60 could upgrade to the same software used by server number 33, then when I remove the code that was absolutely necessary to get my software working with the software that <i>used</i> to be running on server number 60, those unit tests would give a false pass.",
      "id": "500705f7e1bc509056c6d244485cb499"
    },
    {
      "type": "html",
      "text": "<i>Of course, the right way to do it would be to write a simulator for each of the FTP servers, or for each of the distinctive characteristics they have. This is the yin and yang of coding, the same way every server security hole has a corresponding exploit. (See [[Never Writea Line Of Code Withouta Failing Test]])</i>",
      "id": "8f235a466266f92a85676a1df8106c1e"
    },
    {
      "type": "html",
      "text": "\nWhat you would do is put together a very trivial simulator, which might run as a separate process or simply as a replacement for the function that reads a line from the FTP server. You would put together sixty simple \"scripts\", one for each type of FTP server: client says A, server says B, client says C, ... If the client says anything other than its next line, it fails the test; otherwise the simulator replies with the next line for the server.",
      "id": "39f9a854c5d40c38f4cc0256b096501f"
    },
    {
      "type": "html",
      "text": "\nThat's what unit testing is all about: you test each unit IN ISOLATION.",
      "id": "fcbf6320f3f2ac4634f5723a8242a697"
    },
    {
      "type": "html",
      "text": "\nAnother possibility would be to perceive the whole network as the system to work on. Then the test actually connects to the FTP servers, and it can be made succeeding by fixing either client or server.",
      "id": "4d74c797eaae4e41d1a03d883eff1073"
    },
    {
      "type": "html",
      "text": "<hr>",
      "id": "4e4b5dc485db215e062e165087125fa8"
    },
    {
      "type": "html",
      "text": "\nSee [[History Of Programmer Test]]",
      "id": "fca7222b0d4603318f09782602129bbd"
    },
    {
      "type": "html",
      "text": "<hr>",
      "id": "4e4b5dc485db215e062e165087125fa8"
    },
    {
      "type": "html",
      "text": "\nWhat process should I follow if all my [[Programmer Test]]s pass, but my code does not work? Obviously, once I find the error I should write a test that exposes it, but how do I get to that point? Should I fire up a debugger? Start logging? Write random tests? --[[Wayne Miller]]",
      "id": "a158e2ad3392252ccbb13c1c40bf1e08"
    },
    {
      "type": "html",
      "text": "\nYou should inspect the process by which you wrote those tests. [[Test Driven Development]]'s outer cycle is frequent review and manual program massaging. That was the discovery process to write more tests. If you do Big<b></b>[[Test Driven Development]]Up<b></b>Front, you will merrily TDD many bugs and dead-spots into your code. [[Pair Programming]] also helps defeat the [[Dark Side]].",
      "id": "a448efa8dec9ef5bba3fcba7703c9a89"
    },
    {
      "type": "html",
      "text": "\nIf, however, your code still doesn't work, and a small amount of debugging can't find the problem, throw the code away and start again. --[[Phl Ip]]",
      "id": "b9c600991c50b77d4ec140b128a4d55d"
    },
    {
      "type": "html",
      "text": "<i>How does one know his code does not work short of it failing to provide an expected result based on a specified input?  Known input and expected output is the definition of a test in a nutshell, whether one chooses to automate the test or run it manually is a separate issue.</i>",
      "id": "136fd16019205a0cf18af06687e70266"
    },
    {
      "type": "html",
      "text": "''When one's code provides an unexpected result, one should use all the tools at one's disposal to determine why the unexpected result occurred.  Review the tests written for the calling code, why do they pass?  ",
      "id": "036fd0d238ef8d40af9b8b29cea73462"
    },
    {
      "type": "html",
      "text": "\nReview the calling code, is it doing something not tested?  Use a debugger, if that is one's preference.  Put in message boxes or log files or flash lights on a front panel.  One piece of advice, though, once one identifies the condition causing an anomalous result, add an automated test for that condition before fixing the problem.''",
      "id": "2d9403b44118a3208c67e9101e9ee87a"
    },
    {
      "type": "html",
      "text": "\nMy thought here would be in the case of a customer-discovered bug, where the bug is reproducible but the user IO is not practical as a developer test (user input is much too large, and the job takes far too long). Throwing the code away is not really an option, because it is not yet evident what code is wrong. Sounds like the opinion is to solve with traditional techniques and mark afterward with a test? -[[Wayne Miller]]",
      "id": "898e892526c80ecedee59626d85d5d01"
    },
    {
      "type": "html",
      "text": "<i>Close. The consensus seems to be to discover the location of the bug in the code with traditional techniques, then write a failing test, then fix the code, and finally make sure the test passes. [[Never Writea Line Of Code Withouta Failing Test]]</i>",
      "id": "1688bd9cd2cb8db8947d713ac5510744"
    },
    {
      "type": "html",
      "text": "<i>Usually, after you find the bug, you can figure out a small [[Programmer Test]] which will make the code fail.  Yes, some long sequence of user input is needed to trigger the bug.  But generally the bug is small and easily triggered with a defined set of conditions.  You can create those conditions and call the offending code much more easily than re-creating the full sequence of user input.  That's your test.</i> --[[Eric Hopper]]",
      "id": "0f1463ee288cde2717ae318d1a9dd9e9"
    },
    {
      "type": "html",
      "text": "<hr>",
      "id": "4e4b5dc485db215e062e165087125fa8"
    },
    {
      "type": "html",
      "text": "<i>Don't test through the user interface.  The common approach is to have a separate test executable that has the production code files linked into it.  An alternative is to add the test code to the production code and have the test mode launched through a special command or a command line switch.  You may choose to expose this to the end user or not.  Typically programmer tests will be written at a lower level of access than exposed to the end user.  This avoids many of the issues of large amounts of set up and job run time, and with an automated program, well computers are real good at doing the repetitive grunt work to set up a test condition.  The advice within programmer tests is always to write a test, individuals, however, are always free to ignore this advice.</i>",
      "id": "2b7092caa0a5a7cb031d138b0c100985"
    },
    {
      "type": "html",
      "text": "<hr>",
      "id": "4e4b5dc485db215e062e165087125fa8"
    },
    {
      "type": "html",
      "text": "---\n1/14/05  If I know that those tests pass, I should use the tested code exactly as written, to provide only the functionality I tested them for.  I should then think of the new criteria that my code generates, knowing that if those other tests pass, then it must be the thing I added that doesn't deal with what those other tests are testing.   For example, suppose tests for \"add user\" and \"remove user\" pass within the same app scope, but if I \"add user, remove user\" made up of identical code, that fails.  My very first thought should be that they work separately when I click one and then the other, but not when executed in immediate succession in code.  My tests were flawed because they implied some time delay by user actions.  If I am using code for extended purposes besides what the tests that code pass on, no matter how minor that extension, then I need new tests, or the functionality is not guaranteed to provide the expected results.  One should strive to have numerous failing tests, to demonstrate the precise limits of a function, versus one passing test, demonstrating a special case where the functionality does work.",
      "id": "5e0b491bedb0c241e75ba7be157e3894"
    },
    {
      "type": "html",
      "text": "<hr>",
      "id": "4e4b5dc485db215e062e165087125fa8"
    },
    {
      "type": "html",
      "text": "<i>If, however, your code still doesn't work, and a small amount of debugging can't find the problem, throw the code away and start again...</i> \nThis reminds me of a phrase seen often in [[Plan Nine]] discussions: <b>Build</b><b>Two</b><b>You'llThrowOneAway</b> -- the Temporal<b></b>[[Prime Directive]] doesn't seem to care about the order of the <b>builds</b> and the <b>throws</b>. -- [[Chris Garrod]]",
      "id": "33778231bf2f292cb2c98fb8076860b6"
    },
    {
      "type": "html",
      "text": "<hr>",
      "id": "4e4b5dc485db215e062e165087125fa8"
    },
    {
      "type": "html",
      "text": "[[Category Testing]]",
      "id": "0f15ec36a0fd3c08d7d5265320180a96"
    },
    {
      "type": "html",
      "text": "See original on  [http://c2.com/cgi/wiki?ProgrammerTest c2.com]",
      "id": "0dcea89332103faa0bf89ecde7923a38"
    }
  ],
  "journal": [
    {
      "date": 1378707231000,
      "id": "e584c9d3221c682d03095cd2f34cb1ba",
      "type": "create",
      "item": {
        "title": "Programmer Test",
        "story": [
          {
            "type": "html",
            "text": "XP terminology, not quite synonymous with [[Unit Test]]. (See Also [[Developer Test]])",
            "id": "2f33b877825237bfe11aadf38c849a65"
          },
          {
            "type": "html",
            "text": "\nFailure of a [[Unit Test]] shall implicate one (1) and only one (1) unit. (A method, class, module, or package.)",
            "id": "48abbd4a50e7d6a17475d0d0940c91e0"
          },
          {
            "type": "html",
            "text": "\nFailure of a [[Programmer Test]], under [[Test Driven Development]], implicates only the most recent edit.",
            "id": "ff2bd3c67b8f8b6adbf7dfe284552587"
          },
          {
            "type": "html",
            "text": "\n[http://www.XProgramming.com/xpmag/whatisXP.htm#test www.XProgramming.com]  ",
            "id": "543576a4e441cdde3b7fed070724c6c0"
          },
          {
            "type": "html",
            "text": "\nOften a [[Programmer Test]] is better than a comment, to help us understand why a particular function is needed, to demonstrate how a function is called and what are the expected results are, and to document bugs in previous versions of the program that we want to make sure don't come back.",
            "id": "32e24888def07e6f2c1d30695287712f"
          },
          {
            "type": "html",
            "text": "\n[[Programmer Test]]s give us confidence that after we improve one facet of the program (adding a feature, or making it load faster, ...), we haven't made some other facet worse.",
            "id": "ba068d7fd6d4641ff2a95b4d99eaeff7"
          },
          {
            "type": "html",
            "text": "\nIf it's worth doing, it's worth testing to make sure it was done right.",
            "id": "08725bfa2480225a5a7c9b9dce309cca"
          },
          {
            "type": "html",
            "text": "<hr>",
            "id": "4e4b5dc485db215e062e165087125fa8"
          },
          {
            "type": "html",
            "text": "\nI'm starting to understand why [[Programmer Test]]s are so important. When there's a couple of useless-looking lines in the code, with some cryptic comment about how we \"need to do this or else it doesn't work\" ( [[Voodoo Chicken Coding]] ), but I take them out and it still <i>seems</i> to work - the [[Unit Test]]s help explain <i>why</i> we need it, they show that while it may work in some cases, but fails other cases. However, I still find it difficult to write [[Unit Test]]s for my own code. Let's take the example in the [[Things You Should Never Do]] article - a bunch of crufty-looking code to handle 60 kinds of FTP servers. How in the world do I [[Unit Test]] that code? I suppose I could write unit tests that download a short file from 60 different servers -- but those unit tests would give a false error if one of those servers went off-line. Or worse, server number 60 could upgrade to the same software used by server number 33, then when I remove the code that was absolutely necessary to get my software working with the software that <i>used</i> to be running on server number 60, those unit tests would give a false pass.",
            "id": "500705f7e1bc509056c6d244485cb499"
          },
          {
            "type": "html",
            "text": "<i>Of course, the right way to do it would be to write a simulator for each of the FTP servers, or for each of the distinctive characteristics they have. This is the yin and yang of coding, the same way every server security hole has a corresponding exploit. (See [[Never Writea Line Of Code Withouta Failing Test]])</i>",
            "id": "8f235a466266f92a85676a1df8106c1e"
          },
          {
            "type": "html",
            "text": "\nWhat you would do is put together a very trivial simulator, which might run as a separate process or simply as a replacement for the function that reads a line from the FTP server. You would put together sixty simple \"scripts\", one for each type of FTP server: client says A, server says B, client says C, ... If the client says anything other than its next line, it fails the test; otherwise the simulator replies with the next line for the server.",
            "id": "39f9a854c5d40c38f4cc0256b096501f"
          },
          {
            "type": "html",
            "text": "\nThat's what unit testing is all about: you test each unit IN ISOLATION.",
            "id": "fcbf6320f3f2ac4634f5723a8242a697"
          },
          {
            "type": "html",
            "text": "\nAnother possibility would be to perceive the whole network as the system to work on. Then the test actually connects to the FTP servers, and it can be made succeeding by fixing either client or server.",
            "id": "4d74c797eaae4e41d1a03d883eff1073"
          },
          {
            "type": "html",
            "text": "<hr>",
            "id": "4e4b5dc485db215e062e165087125fa8"
          },
          {
            "type": "html",
            "text": "\nSee [[History Of Programmer Test]]",
            "id": "fca7222b0d4603318f09782602129bbd"
          },
          {
            "type": "html",
            "text": "<hr>",
            "id": "4e4b5dc485db215e062e165087125fa8"
          },
          {
            "type": "html",
            "text": "\nWhat process should I follow if all my [[Programmer Test]]s pass, but my code does not work? Obviously, once I find the error I should write a test that exposes it, but how do I get to that point? Should I fire up a debugger? Start logging? Write random tests? --[[Wayne Miller]]",
            "id": "a158e2ad3392252ccbb13c1c40bf1e08"
          },
          {
            "type": "html",
            "text": "\nYou should inspect the process by which you wrote those tests. [[Test Driven Development]]'s outer cycle is frequent review and manual program massaging. That was the discovery process to write more tests. If you do Big<b></b>[[Test Driven Development]]Up<b></b>Front, you will merrily TDD many bugs and dead-spots into your code. [[Pair Programming]] also helps defeat the [[Dark Side]].",
            "id": "a448efa8dec9ef5bba3fcba7703c9a89"
          },
          {
            "type": "html",
            "text": "\nIf, however, your code still doesn't work, and a small amount of debugging can't find the problem, throw the code away and start again. --[[Phl Ip]]",
            "id": "b9c600991c50b77d4ec140b128a4d55d"
          },
          {
            "type": "html",
            "text": "<i>How does one know his code does not work short of it failing to provide an expected result based on a specified input?  Known input and expected output is the definition of a test in a nutshell, whether one chooses to automate the test or run it manually is a separate issue.</i>",
            "id": "136fd16019205a0cf18af06687e70266"
          },
          {
            "type": "html",
            "text": "''When one's code provides an unexpected result, one should use all the tools at one's disposal to determine why the unexpected result occurred.  Review the tests written for the calling code, why do they pass?  ",
            "id": "036fd0d238ef8d40af9b8b29cea73462"
          },
          {
            "type": "html",
            "text": "\nReview the calling code, is it doing something not tested?  Use a debugger, if that is one's preference.  Put in message boxes or log files or flash lights on a front panel.  One piece of advice, though, once one identifies the condition causing an anomalous result, add an automated test for that condition before fixing the problem.''",
            "id": "2d9403b44118a3208c67e9101e9ee87a"
          },
          {
            "type": "html",
            "text": "\nMy thought here would be in the case of a customer-discovered bug, where the bug is reproducible but the user IO is not practical as a developer test (user input is much too large, and the job takes far too long). Throwing the code away is not really an option, because it is not yet evident what code is wrong. Sounds like the opinion is to solve with traditional techniques and mark afterward with a test? -[[Wayne Miller]]",
            "id": "898e892526c80ecedee59626d85d5d01"
          },
          {
            "type": "html",
            "text": "<i>Close. The consensus seems to be to discover the location of the bug in the code with traditional techniques, then write a failing test, then fix the code, and finally make sure the test passes. [[Never Writea Line Of Code Withouta Failing Test]]</i>",
            "id": "1688bd9cd2cb8db8947d713ac5510744"
          },
          {
            "type": "html",
            "text": "<i>Usually, after you find the bug, you can figure out a small [[Programmer Test]] which will make the code fail.  Yes, some long sequence of user input is needed to trigger the bug.  But generally the bug is small and easily triggered with a defined set of conditions.  You can create those conditions and call the offending code much more easily than re-creating the full sequence of user input.  That's your test.</i> --[[Eric Hopper]]",
            "id": "0f1463ee288cde2717ae318d1a9dd9e9"
          },
          {
            "type": "html",
            "text": "<hr>",
            "id": "4e4b5dc485db215e062e165087125fa8"
          },
          {
            "type": "html",
            "text": "<i>Don't test through the user interface.  The common approach is to have a separate test executable that has the production code files linked into it.  An alternative is to add the test code to the production code and have the test mode launched through a special command or a command line switch.  You may choose to expose this to the end user or not.  Typically programmer tests will be written at a lower level of access than exposed to the end user.  This avoids many of the issues of large amounts of set up and job run time, and with an automated program, well computers are real good at doing the repetitive grunt work to set up a test condition.  The advice within programmer tests is always to write a test, individuals, however, are always free to ignore this advice.</i>",
            "id": "2b7092caa0a5a7cb031d138b0c100985"
          },
          {
            "type": "html",
            "text": "<hr>",
            "id": "4e4b5dc485db215e062e165087125fa8"
          },
          {
            "type": "html",
            "text": "---\n1/14/05  If I know that those tests pass, I should use the tested code exactly as written, to provide only the functionality I tested them for.  I should then think of the new criteria that my code generates, knowing that if those other tests pass, then it must be the thing I added that doesn't deal with what those other tests are testing.   For example, suppose tests for \"add user\" and \"remove user\" pass within the same app scope, but if I \"add user, remove user\" made up of identical code, that fails.  My very first thought should be that they work separately when I click one and then the other, but not when executed in immediate succession in code.  My tests were flawed because they implied some time delay by user actions.  If I am using code for extended purposes besides what the tests that code pass on, no matter how minor that extension, then I need new tests, or the functionality is not guaranteed to provide the expected results.  One should strive to have numerous failing tests, to demonstrate the precise limits of a function, versus one passing test, demonstrating a special case where the functionality does work.",
            "id": "5e0b491bedb0c241e75ba7be157e3894"
          },
          {
            "type": "html",
            "text": "<hr>",
            "id": "4e4b5dc485db215e062e165087125fa8"
          },
          {
            "type": "html",
            "text": "<i>If, however, your code still doesn't work, and a small amount of debugging can't find the problem, throw the code away and start again...</i> \nThis reminds me of a phrase seen often in [[Plan Nine]] discussions: <b>Build</b><b>Two</b><b>You'llThrowOneAway</b> -- the Temporal<b></b>[[Prime Directive]] doesn't seem to care about the order of the <b>builds</b> and the <b>throws</b>. -- [[Chris Garrod]]",
            "id": "33778231bf2f292cb2c98fb8076860b6"
          },
          {
            "type": "html",
            "text": "<hr>",
            "id": "4e4b5dc485db215e062e165087125fa8"
          },
          {
            "type": "html",
            "text": "[[Category Testing]]",
            "id": "0f15ec36a0fd3c08d7d5265320180a96"
          },
          {
            "type": "html",
            "text": "See original on  [http://c2.com/cgi/wiki?ProgrammerTest c2.com]",
            "id": "0dcea89332103faa0bf89ecde7923a38"
          }
        ]
      }
    },
    {
      "type": "fork",
      "site": "sfw.c2.com",
      "date": 1628111440323
    }
  ]
}