{
  "title": "Essentials of the Self-Organizing Map",
  "story": [
    {
      "type": "paragraph",
      "id": "23e4d0b8a25dd11f",
      "text": "The self-organizing map (SOM) is an automatic data-analysis method. It is widely applied to clustering problems and data exploration in industry, finance, natural sciences, and linguistics. "
    },
    {
      "type": "paragraph",
      "id": "536710e77d048f30",
      "text": "The most extensive applications, exemplified in this paper, can be found in the management of massive textual databases and in bioinformatics. "
    },
    {
      "type": "paragraph",
      "id": "fcba124a5aeabcfa",
      "text": "The SOM is related to the classical vector quantization (VQ), which is used extensively in digital signal processing and transmission. Like in VQ, the SOM represents a distribution of input data items using a finite set of models. "
    },
    {
      "type": "paragraph",
      "id": "1796a9be45293046",
      "text": "In the SOM, however, these models are automatically associated with the nodes of a regular (usually two-dimensional) grid in an orderly fashion such that more similar models become automatically associated with nodes that are adjacent in the grid, whereas less similar models are situated farther away from each other in the grid. "
    },
    {
      "type": "paragraph",
      "id": "594a3b8da8483b20",
      "text": "This organization, a kind of similarity diagram of the models, makes it possible to obtain an insight into the topographic relationships of data, especially of high-dimensional data items. If the data items belong to certain predetermined classes, the models (and the nodes) can be calibrated according to these classes. An unknown input item is then classified according to that node, the model of which is most similar with it in some metric used in the construction of the SOM. "
    },
    {
      "type": "paragraph",
      "id": "92dd7c9879d449a0",
      "text": "A new finding introduced in this paper is that an input item can even more accurately be represented by a linear mixture of a few best-matching models. This becomes possible by a least-squares fitting procedure where the coefficients in the linear mixture of models are constrained to nonnegative values."
    },
    {
      "type": "pagefold",
      "id": "a958e3c8505bac56",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "da074000b4e3a859",
      "text": "KOHONEN, Teuvo, 2013. Essentials of the self-organizing map. Neural Networks. 1 January 2013. Vol. 37, p. 52–65. DOI 10.1016/j.neunet.2012.09.018. \n"
    },
    {
      "type": "paragraph",
      "id": "f95e6a6375b301e8",
      "text": "[…]"
    },
    {
      "type": "paragraph",
      "id": "871cdbed39c7090a",
      "text": "It is not possible to give a full account of the theory and different versions of the SOM, or applications of the SOM in this article. We can only refer to the above lists of 7768 SOM publications (today, their number is over 10,000), and to more than ten textbooks, monographs, or edited books, e.g. Allinson, Yin, Allinson and Slack (2001), Kohonen (1989, 2001), Miikkulainen (1993), Obermayer and Sejnowski (2001), Oja and Kaski (1999), Ritter et al. (1992), Seiffert and Jain (2002), Tokutaka, Kishida, and Fujimura (1999), Tokutaka, Ookita, and Fujimura (2007) and Van Hulle (2000), and a great number of Ph.D. Theses."
    },
    {
      "type": "paragraph",
      "id": "e43da6d583eb6a16",
      "text": "⇒ [[Levels of Abstraction in Modeling]]"
    },
    {
      "type": "pagefold",
      "id": "de965c10d0268f68",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "ffd499dcdd593457",
      "text": "Miikkulainen, R. (1993). [[Subsymbolic Natural Language Processing]]: an integrated model of scripts, lexicon, and memory. Cambridge, MA: MIT Press."
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Essentials of the Self-Organizing Map",
        "story": []
      },
      "date": 1673888859520
    },
    {
      "item": {
        "type": "factory",
        "id": "da074000b4e3a859"
      },
      "id": "da074000b4e3a859",
      "type": "add",
      "date": 1673888877471
    },
    {
      "type": "edit",
      "id": "da074000b4e3a859",
      "item": {
        "type": "paragraph",
        "id": "da074000b4e3a859",
        "text": "\nKOHONEN, Teuvo, 2013. Essentials of the self-organizing map. Neural Networks. 1 January 2013. Vol. 37, p. 52–65. DOI 10.1016/j.neunet.2012.09.018. The self-organizing map (SOM) is an automatic data-analysis method. It is widely applied to clustering problems and data exploration in industry, finance, natural sciences, and linguistics. The most extensive applications, exemplified in this paper, can be found in the management of massive textual databases and in bioinformatics. The SOM is related to the classical vector quantization (VQ), which is used extensively in digital signal processing and transmission. Like in VQ, the SOM represents a distribution of input data items using a finite set of models. In the SOM, however, these models are automatically associated with the nodes of a regular (usually two-dimensional) grid in an orderly fashion such that more similar models become automatically associated with nodes that are adjacent in the grid, whereas less similar models are situated farther away from each other in the grid. This organization, a kind of similarity diagram of the models, makes it possible to obtain an insight into the topographic relationships of data, especially of high-dimensional data items. If the data items belong to certain predetermined classes, the models (and the nodes) can be calibrated according to these classes. An unknown input item is then classified according to that node, the model of which is most similar with it in some metric used in the construction of the SOM. A new finding introduced in this paper is that an input item can even more accurately be represented by a linear mixture of a few best-matching models. This becomes possible by a least-squares fitting procedure where the coefficients in the linear mixture of models are constrained to nonnegative values.\n"
      },
      "date": 1673888879226
    },
    {
      "item": {
        "type": "factory",
        "id": "23e4d0b8a25dd11f"
      },
      "id": "23e4d0b8a25dd11f",
      "type": "add",
      "after": "da074000b4e3a859",
      "date": 1673888888912
    },
    {
      "type": "edit",
      "id": "da074000b4e3a859",
      "item": {
        "type": "paragraph",
        "id": "da074000b4e3a859",
        "text": "KOHONEN, Teuvo, 2013. Essentials of the self-organizing map. Neural Networks. 1 January 2013. Vol. 37, p. 52–65. DOI 10.1016/j.neunet.2012.09.018. \n"
      },
      "date": 1673888889909
    },
    {
      "type": "edit",
      "id": "23e4d0b8a25dd11f",
      "item": {
        "type": "paragraph",
        "id": "23e4d0b8a25dd11f",
        "text": "The self-organizing map (SOM) is an automatic data-analysis method. It is widely applied to clustering problems and data exploration in industry, finance, natural sciences, and linguistics. The most extensive applications, exemplified in this paper, can be found in the management of massive textual databases and in bioinformatics. The SOM is related to the classical vector quantization (VQ), which is used extensively in digital signal processing and transmission. Like in VQ, the SOM represents a distribution of input data items using a finite set of models. In the SOM, however, these models are automatically associated with the nodes of a regular (usually two-dimensional) grid in an orderly fashion such that more similar models become automatically associated with nodes that are adjacent in the grid, whereas less similar models are situated farther away from each other in the grid. This organization, a kind of similarity diagram of the models, makes it possible to obtain an insight into the topographic relationships of data, especially of high-dimensional data items. If the data items belong to certain predetermined classes, the models (and the nodes) can be calibrated according to these classes. An unknown input item is then classified according to that node, the model of which is most similar with it in some metric used in the construction of the SOM. A new finding introduced in this paper is that an input item can even more accurately be represented by a linear mixture of a few best-matching models. This becomes possible by a least-squares fitting procedure where the coefficients in the linear mixture of models are constrained to nonnegative values."
      },
      "date": 1673888890385
    },
    {
      "id": "23e4d0b8a25dd11f",
      "type": "move",
      "order": [
        "23e4d0b8a25dd11f",
        "da074000b4e3a859"
      ],
      "date": 1673888891749
    },
    {
      "item": {
        "type": "factory",
        "id": "a958e3c8505bac56"
      },
      "id": "a958e3c8505bac56",
      "type": "add",
      "after": "da074000b4e3a859",
      "date": 1673888894428
    },
    {
      "type": "edit",
      "id": "a958e3c8505bac56",
      "item": {
        "type": "pagefold",
        "id": "a958e3c8505bac56",
        "text": "~"
      },
      "date": 1673888898438
    },
    {
      "id": "a958e3c8505bac56",
      "type": "move",
      "order": [
        "23e4d0b8a25dd11f",
        "a958e3c8505bac56",
        "da074000b4e3a859"
      ],
      "date": 1673888900839
    },
    {
      "type": "edit",
      "id": "23e4d0b8a25dd11f",
      "item": {
        "type": "paragraph",
        "id": "23e4d0b8a25dd11f",
        "text": "The self-organizing map (SOM) is an automatic data-analysis method. It is widely applied to clustering problems and data exploration in industry, finance, natural sciences, and linguistics. "
      },
      "date": 1673888913817
    },
    {
      "type": "add",
      "id": "536710e77d048f30",
      "item": {
        "type": "paragraph",
        "id": "536710e77d048f30",
        "text": "The most extensive applications, exemplified in this paper, can be found in the management of massive textual databases and in bioinformatics. "
      },
      "after": "23e4d0b8a25dd11f",
      "date": 1673888924855
    },
    {
      "type": "add",
      "id": "fcba124a5aeabcfa",
      "item": {
        "type": "paragraph",
        "id": "fcba124a5aeabcfa",
        "text": "The SOM is related to the classical vector quantization (VQ), which is used extensively in digital signal processing and transmission. Like in VQ, the SOM represents a distribution of input data items using a finite set of models. In the SOM, however, these models are automatically associated with the nodes of a regular (usually two-dimensional) grid in an orderly fashion such that more similar models become automatically associated with nodes that are adjacent in the grid, whereas less similar models are situated farther away from each other in the grid. This organization, a kind of similarity diagram of the models, makes it possible to obtain an insight into the topographic relationships of data, especially of high-dimensional data items. If the data items belong to certain predetermined classes, the models (and the nodes) can be calibrated according to these classes. An unknown input item is then classified according to that node, the model of which is most similar with it in some metric used in the construction of the SOM. A new finding introduced in this paper is that an input item can even more accurately be represented by a linear mixture of a few best-matching models. This becomes possible by a least-squares fitting procedure where the coefficients in the linear mixture of models are constrained to nonnegative values."
      },
      "after": "536710e77d048f30",
      "date": 1673888925278
    },
    {
      "type": "edit",
      "id": "fcba124a5aeabcfa",
      "item": {
        "type": "paragraph",
        "id": "fcba124a5aeabcfa",
        "text": "The SOM is related to the classical vector quantization (VQ), which is used extensively in digital signal processing and transmission. Like in VQ, the SOM represents a distribution of input data items using a finite set of models. "
      },
      "date": 1673888946701
    },
    {
      "type": "add",
      "id": "1796a9be45293046",
      "item": {
        "type": "paragraph",
        "id": "1796a9be45293046",
        "text": "In the SOM, however, these models are automatically associated with the nodes of a regular (usually two-dimensional) grid in an orderly fashion such that more similar models become automatically associated with nodes that are adjacent in the grid, whereas less similar models are situated farther away from each other in the grid. This organization, a kind of similarity diagram of the models, makes it possible to obtain an insight into the topographic relationships of data, especially of high-dimensional data items. If the data items belong to certain predetermined classes, the models (and the nodes) can be calibrated according to these classes. An unknown input item is then classified according to that node, the model of which is most similar with it in some metric used in the construction of the SOM. A new finding introduced in this paper is that an input item can even more accurately be represented by a linear mixture of a few best-matching models. This becomes possible by a least-squares fitting procedure where the coefficients in the linear mixture of models are constrained to nonnegative values."
      },
      "after": "fcba124a5aeabcfa",
      "date": 1673888947210
    },
    {
      "type": "edit",
      "id": "1796a9be45293046",
      "item": {
        "type": "paragraph",
        "id": "1796a9be45293046",
        "text": "In the SOM, however, these models are automatically associated with the nodes of a regular (usually two-dimensional) grid in an orderly fashion such that more similar models become automatically associated with nodes that are adjacent in the grid, whereas less similar models are situated farther away from each other in the grid. "
      },
      "date": 1673888972562
    },
    {
      "type": "add",
      "id": "594a3b8da8483b20",
      "item": {
        "type": "paragraph",
        "id": "594a3b8da8483b20",
        "text": "This organization, a kind of similarity diagram of the models, makes it possible to obtain an insight into the topographic relationships of data, especially of high-dimensional data items. If the data items belong to certain predetermined classes, the models (and the nodes) can be calibrated according to these classes. An unknown input item is then classified according to that node, the model of which is most similar with it in some metric used in the construction of the SOM. A new finding introduced in this paper is that an input item can even more accurately be represented by a linear mixture of a few best-matching models. This becomes possible by a least-squares fitting procedure where the coefficients in the linear mixture of models are constrained to nonnegative values."
      },
      "after": "1796a9be45293046",
      "date": 1673888973512
    },
    {
      "type": "edit",
      "id": "594a3b8da8483b20",
      "item": {
        "type": "paragraph",
        "id": "594a3b8da8483b20",
        "text": "This organization, a kind of similarity diagram of the models, makes it possible to obtain an insight into the topographic relationships of data, especially of high-dimensional data items. If the data items belong to certain predetermined classes, the models (and the nodes) can be calibrated according to these classes. An unknown input item is then classified according to that node, the model of which is most similar with it in some metric used in the construction of the SOM. "
      },
      "date": 1673888999396
    },
    {
      "type": "add",
      "id": "92dd7c9879d449a0",
      "item": {
        "type": "paragraph",
        "id": "92dd7c9879d449a0",
        "text": "A new finding introduced in this paper is that an input item can even more accurately be represented by a linear mixture of a few best-matching models. This becomes possible by a least-squares fitting procedure where the coefficients in the linear mixture of models are constrained to nonnegative values."
      },
      "after": "594a3b8da8483b20",
      "date": 1673889000311
    },
    {
      "item": {
        "type": "factory",
        "id": "f95e6a6375b301e8"
      },
      "id": "f95e6a6375b301e8",
      "type": "add",
      "after": "da074000b4e3a859",
      "date": 1673889120860
    },
    {
      "type": "edit",
      "id": "f95e6a6375b301e8",
      "item": {
        "type": "paragraph",
        "id": "f95e6a6375b301e8",
        "text": "[…]"
      },
      "date": 1673889124527
    },
    {
      "type": "add",
      "id": "871cdbed39c7090a",
      "item": {
        "type": "paragraph",
        "id": "871cdbed39c7090a",
        "text": "It is not possible to give a full account of the theory and different versions of the SOM, or applications of the SOM in this article. We can only refer to the above lists of 7768 SOM publications (today, their number is over 10,000), and to more than ten textbooks, monographs, or edited books, e.g. Allinson, Yin, Allinson and Slack (2001), Kohonen (1989, 2001), Miikkulainen (1993), Obermayer and Sejnowski (2001), Oja and Kaski (1999), Ritter et al. (1992), Seiffert and Jain (2002), Tokutaka, Kishida, and Fujimura (1999), Tokutaka, Ookita, and Fujimura (2007) and Van Hulle (2000), and a great number of Ph.D. Theses."
      },
      "after": "f95e6a6375b301e8",
      "date": 1673889125263
    },
    {
      "item": {
        "type": "factory",
        "id": "de965c10d0268f68"
      },
      "id": "de965c10d0268f68",
      "type": "add",
      "after": "871cdbed39c7090a",
      "date": 1673889163620
    },
    {
      "type": "edit",
      "id": "de965c10d0268f68",
      "item": {
        "type": "pagefold",
        "id": "de965c10d0268f68",
        "text": "~"
      },
      "date": 1673889166333
    },
    {
      "item": {
        "type": "factory",
        "id": "ffd499dcdd593457"
      },
      "id": "ffd499dcdd593457",
      "type": "add",
      "after": "de965c10d0268f68",
      "date": 1673889167658
    },
    {
      "type": "edit",
      "id": "ffd499dcdd593457",
      "item": {
        "type": "paragraph",
        "id": "ffd499dcdd593457",
        "text": "Miikkulainen, R. (1993). Subsymbolic natural language processing: an integrated model of scripts, lexicon, and memory. Cambridge, MA: MIT Press."
      },
      "date": 1673889169287
    },
    {
      "type": "edit",
      "id": "ffd499dcdd593457",
      "item": {
        "type": "paragraph",
        "id": "ffd499dcdd593457",
        "text": "Miikkulainen, R. (1993). [[Subsymbolic natural language processing]]: an integrated model of scripts, lexicon, and memory. Cambridge, MA: MIT Press."
      },
      "date": 1673889178631
    },
    {
      "type": "edit",
      "id": "ffd499dcdd593457",
      "item": {
        "type": "paragraph",
        "id": "ffd499dcdd593457",
        "text": "Miikkulainen, R. (1993). [[Subsymbolic Natural Language Processing]]: an integrated model of scripts, lexicon, and memory. Cambridge, MA: MIT Press."
      },
      "date": 1673889202692
    },
    {
      "type": "add",
      "id": "e43da6d583eb6a16",
      "item": {
        "type": "paragraph",
        "id": "e43da6d583eb6a16",
        "text": "⇒ [[Levels of Abstraction in Modeling]]"
      },
      "after": "871cdbed39c7090a",
      "date": 1673889267758
    }
  ]
}