{
  "title": "Markov Chains",
  "story": [
    {
      "type": "paragraph",
      "id": "0e4c2feedfd49d17",
      "text": " A visual explanation by Victor Powell\n/w text by Lewis Lehe "
    },
    {
      "type": "paragraph",
      "id": "89e32b38828a4f2d",
      "text": "https://setosa.io/blog/2014/07/26/markov-chains/"
    },
    {
      "type": "paragraph",
      "id": "897ee14749fcdc04",
      "text": "Markov chains, named after Andrey Markov, are mathematical systems that hop from one \"state\" (a situation or set of values) to another. For example, if you made a Markov chain model of a baby's behavior, you might include \"playing,\" \"eating\", \"sleeping,\" and \"crying\" as states, which together with other behaviors could form a 'state space': a list of all possible states. In addition, on top of the state space, a Markov chain tells you the probabilitiy of hopping, or \"transitioning,\" from one state to any other state---e.g., the chance that a baby currently playing will fall asleep in the next five minutes without crying first."
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Markov Chains",
        "story": []
      },
      "date": 1638706022540
    },
    {
      "item": {
        "type": "factory",
        "id": "89e32b38828a4f2d"
      },
      "id": "89e32b38828a4f2d",
      "type": "add",
      "date": 1638706030235
    },
    {
      "type": "edit",
      "id": "89e32b38828a4f2d",
      "item": {
        "type": "paragraph",
        "id": "89e32b38828a4f2d",
        "text": "https://setosa.io/blog/2014/07/26/markov-chains/"
      },
      "date": 1638706032113
    },
    {
      "item": {
        "type": "factory",
        "id": "897ee14749fcdc04"
      },
      "id": "897ee14749fcdc04",
      "type": "add",
      "after": "89e32b38828a4f2d",
      "date": 1638706041126
    },
    {
      "type": "edit",
      "id": "897ee14749fcdc04",
      "item": {
        "type": "paragraph",
        "id": "897ee14749fcdc04",
        "text": "Markov chains, named after Andrey Markov, are mathematical systems that hop from one \"state\" (a situation or set of values) to another. For example, if you made a Markov chain model of a baby's behavior, you might include \"playing,\" \"eating\", \"sleeping,\" and \"crying\" as states, which together with other behaviors could form a 'state space': a list of all possible states. In addition, on top of the state space, a Markov chain tells you the probabilitiy of hopping, or \"transitioning,\" from one state to any other state---e.g., the chance that a baby currently playing will fall asleep in the next five minutes without crying first."
      },
      "date": 1638706042597
    },
    {
      "item": {
        "type": "factory",
        "id": "0e4c2feedfd49d17"
      },
      "id": "0e4c2feedfd49d17",
      "type": "add",
      "after": "897ee14749fcdc04",
      "date": 1638706052684
    },
    {
      "type": "edit",
      "id": "0e4c2feedfd49d17",
      "item": {
        "type": "paragraph",
        "id": "0e4c2feedfd49d17",
        "text": " A visual explanation by Victor Powell\n/w text by Lewis Lehe "
      },
      "date": 1638706054063
    },
    {
      "id": "0e4c2feedfd49d17",
      "type": "move",
      "order": [
        "0e4c2feedfd49d17",
        "89e32b38828a4f2d",
        "897ee14749fcdc04"
      ],
      "date": 1638706055963
    }
  ]
}