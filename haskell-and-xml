{
  "title": "Haskell and XML",
  "story": [
    {
      "type": "markdown",
      "id": "bde9f870ebbd768a",
      "text": "Haskell and XML: Generic Combinators or Type-Based Translation?\n"
    },
    {
      "type": "markdown",
      "id": "07ad4cedeb66315c",
      "text": "Malcolm Wallace and Colin Runciman\n"
    },
    {
      "type": "markdown",
      "id": "2e8be84f15deb853",
      "text": "Abstract: We present two complementary approaches to writing XML document-processing applications in a functional language.\n\n\n"
    },
    {
      "type": "markdown",
      "id": "07ae5fd45ef5f330",
      "text": "In the first approach, the generic tree structure of XML documents is used as the basis for the design of a library of combinators for generic processing: selection, generation, and transformation of XML trees.\n\nThe second approach is to use a type-translation framework for treating XML document type definitions (DTDs) as declarations of algebraic data types, and a derivation of the corresponding functions for reading and writing documents as typed values in Haskell.\n\nPublished in the Proceedings of the International Conference on Functional Programming, Paris, Sept 1999. ACM Copyright.\n\n1  Introduction\n1.1  Document markup languages\nXML (Extensible Markup Language) [1] is a recent simplification of the older SGML (Standardised Generalised Markup Language) standard that is widely used in the publishing industry. It is a markup language, meaning that it adds structural information around the text of a document. It is extensible, meaning that the vocabulary of the markup is not fixed -- each document can contain or reference a meta-document, called a DTD (Document Type Definition), which describes the particular markup capabilities used.\n\nThe use of XML is not however restricted to the traditional idea of a document. Many organisations are proposing to use XML as an interchange format for pure data produced by applications like graph-plotters, spreadsheets, and relational databases.\n\nHTML (Hyper-Text Markup Language) is one well-known example of an instance of SGML -- every HTML document is an SGML document conforming to a particular DTD. Where XML improves over SGML is in removing shorthand forms that require an application to have knowledge of a document's DTD. For instance, in HTML some markup (such as a numbered list) requires an end marker; other forms (such as paragraphs) have implicit end markers understood when the next similar form starts; and yet other markup (such as in-line images) is self-contained and needs no end marker. An HTML application needs to be aware of the specific kind of markup in order to do the right thing.\n\n1.2  XML document structure\nXML is more regular. All markup has an explicit end marker without exception: every document is well-formed; its nesting structure is syntactically clear. One important consequence is that an XML application does not need to know the meaning or interpretation of all markup expressions -- parts of the document can be selected, re-arranged, transformed, by structure alone rather than by meaning.\n\nAn XML document is essentially a tree structure. There are two basic `types' of content in a document: tagged elements, and plain text. A tagged element consists of a start tag and an end tag, which may enclose any sequence of other content (elements or text fragments). Tagged elements can be nested to any depth, and the document is well-formed if it consists of a single top-level element containing other properly nested elements. Start tags have the syntax <tag>, and end tags </tag>, where tag is an arbitrary name. There is special syntax for an empty element: <tag/> is exactly equivalent to <tag></tag>. The start and end tags for each element contain a tag name, which identifies semantic information about the structure, indicating how the enclosed content should be interpreted. The start tag may also contain attributes, which are simple name/value bindings, providing further information about the element. Figure 1 shows an example XML document, illustrating all these components.\n\n    <?xml version='1.0'?>\n    <!DOCTYPE album SYSTEM \"album.dtd\">\n    <album>\n      <title>Time Out</title>\n      <artist>Dave Brubeck Quartet</artist>\n      <coverart style='abstract'>\n        <location thumbnail='pix/small/timeout.jpg'\n                  fullsize='pix/covers/timeout.jpg'/>\n      </coverart>\n\n      <catalogno label='Columbia' number='CL 1397'\n                 format='LP'/>\n      <catalogno label='Columbia' number='CS 8192'\n                 format='LP'/>\n      <catalogno label='Columbia' number='CPK 1181'\n                 format='LP' country='Korea'/>\n      <catalogno label='Sony/CBS' number='Legacy CK 40585'\n                 format='CD'/>\n\n      <personnel>\n        <player name='Dave Brubeck' instrument='piano'/>\n        <player name='Paul Desmond' instrument='alto sax'/>\n        <player name='Eugene Wright' instrument='bass'/>\n        <player name='Joe Morello' instrument='drums'/>\n      </personnel>\n\n      <tracks>\n        <track title='Blue Rondo &agrave; la Turk'\n               credit='Brubeck' timing='6m42s'/>\n        <track title='Strange Meadow Lark'\n               credit='Brubeck'  timing='7m20s' />\n        <track title='Take Five'\n               credit='Desmond'  timing='5m24s' />\n        <track title='Three To Get Ready'\n               credit='Brubeck'  timing='5m21s' />\n        <track title=\"Kathy's Waltz\"\n               credit='Brubeck'  timing='4m48s' />\n        <track title=\"Everybody's Jumpin'\"\n               credit='Brubeck'  timing='4m22s' />\n        <track title='Pick Up Sticks'\n               credit='Brubeck'  timing='4m16s' />\n      </tracks>\n\n      <notes author=\"unknown\">\n        Possibly the DBQ's most famous album,\n        this contains\n        <trackref link='#3'>Take Five</trackref>,\n        the most famous jazz track of that period.\n        These experiments in different time\n        signatures are what Dave Brubeck is most\n        remembered for.  Recorded Jun-Aug 1959\n        in NYC.  See also the sequel,\n          <albumref link='cbs-timefurthout'>\n            Time Further Out</albumref>.\n      </notes>\n    </album>\n\n    Figure 1: An example XML document.\n\n1.3  Representing XML in Haskell\nThis paper is about processing XML using the functional language Haskell.1 Modern functional languages are well-equipped to deal with tree-structured data, so one expects the language to be a good fit for the application. Even so, a key issue is just how to represent documents, and in particular how to reconcile the DTD datatype definitions included in XML documents with the data types that can be defined in Haskell. We have investigated two complementary approaches:\n\n    (1) Define an internal data structure that represents contents of any XML document, independent of all DTDs.\n    (2) Given the DTD for some XML documents of interest, systematically derive definitions for internal Haskell data types to represent them. These definitions are closely based on the specific DTD. \n\nAdvantages of (1) include genericity and function-level scripting. Generic applications handle a wide class of XML documents, not just those sharing a specific DTD. One example of a completely generic application is searching documents to extract contents matching some pattern. Our Xtract2 is an interpreter for a regular XML query language.\n\nThe term `generic' also applies to applications that make some assumptions about a document's structure but need not know the full DTD,3 for example, a small script to add a ``total'' column to the end of every table (recognised by a particular markup tag) without altering any of the surrounding structure.\n\nBy function-level scripting we mean that the programmer does not have to be concerned with details of programming over data structures. All details of data structure manipulation can be hidden in a library of high-level combinators. In effect, combinatory expressions serve as an extensible domain-specific language.\n\nAdvantages of (2) include stronger typing and fuller control. A well-formed XML document is further said to be valid if it conforms to a stated DTD. By establishing a correspondence between DTDs and Haskell types, the concept of validity can be extended to include applications that process documents. Not only is there a static guarantee that applications cannot fail in respect of document structure if the input XML conforms to the stated DTD; any XML output produced via a DTD-derived type is guaranteed to be valid. With direct access to the DTD-specific data structure, the programmer has fuller control over how computation is done. They can use a full repertoire of programming techniques with the safeguard that type-checked Haskell will automatically produce XML that is valid in respect of a specified DTD.\n\nBoth approaches rely on a toolkit of more basic components for processing XML documents in Haskell: for instance, a parser and pretty-printer. These supporting components are implemented using existing combinator libraries [7, 8].\n\n1.4  Sections following\n§2 develops the approach using a generic representation and a combinator library, including an illustrative application. §3 develops the alternative based on translation between DTDs and Haskell data types. §4 discusses some pros and cons of the two approaches based on our experience implementing and using both. §5 discusses related work; §6 offers some conclusions and suggestions for further work.\n2  Generic combinators\nIn this section, we begin with a generic representation for the contents of XML documents, excluding any DTD. We introduce content filters as a suitable basic type for functions processing this representation, and combinators for putting such filters together. A complete table of basic filters is given in Figure 2, and of combinators and their definitions in Figure 3. An example program is shown in Figure 4. One expected property of a fitting set of combinators is that they satisfy algebraic laws; a table of laws satisfied by our combinators is given in Figure 6.\n\n2.1  Documents and transformations\nData modelling\n\n    data Element = Elem Name [Attribute] [Content]\n    data Content = CElem Element\n                 | CText String\n\nBecause functional languages are good at processing tree-structured data, there is a natural fit between the XML document domain and Haskell tree datatypes. In simplified form, the main datatypes which model an XML document are Element and Content, whose definitions are mutually recursive, together forming a multi-branch tree structure.\n\nThe filter type\n\n    type CFilter = Content -> [Content]\n\nOur basic type for all document processing functions is the content filter, which takes a fragment of the content of an XML document (whether that be some text, or a complete tagged element), and returns some sequence of content. The result list might be empty, it might contain a single item, or it could contain a large collection of items.\n\nSome filters are used to select parts of the input document, and others are used to construct parts of the output document. They all share the same basic type, because when building a new document, the intention is to re-use or extract information from parts of the old document. Where the result of a filter is either empty or a singleton, the filter can sometimes be thought of as a predicate, deciding whether or not to keep its input.\n\nProgram wrapper\n\n    processXmlWith :: CFilter -> IO ()\n\nWe assume a top-level wrapper function, which gets command-line arguments, parses an XML file into the Content type, applies a filter, and pretty-prints the output document. The given filter is applied to the top-level enclosing element of the document.\n\nBasic filters\nA complete list of predefined filters is shown in Figure 2. The simplest possible filters: none takes any content and returns nothing; keep takes any content and returns just that item. Algebraically, these are the zero and unit filters.\n\n    Predicates\n      \tnone, \t  \tzero/failure\n      \tkeep, \t  \tidentity/success\n      \telm, \t  \ttagged element?\n      \ttxt \t  \tplain text?\n      \t  \t:: CFilter\n      \ttag, \t  \tnamed element?\n      \tattr \t  \telement has attribute?\n      \t  \t:: String -> CFilter\n      \tattrval \t  \telement has attribute/value?\n      \t  \t:: (String,String) -> CFilter\n     \n    Selection\n      \tchildren \t  \tchildren of element\n      \t  \t:: CFilter\n      \tshowAttr, \t  \tvalue of attribute\n      \t(?) \t  \tsynonym for showAttr\n      \t  \t:: String -> CFilter\n     \n    Construction\n      \tliteral, \t  \tbuild plain text\n      \t(!) \t  \tsynonym for literal\n      \t  \t:: String -> CFilter\n      \tmkElem \t  \tbuild element\n      \t  \t:: String -> [CFilter] -> CFilter\n      \tmkElemAttrs \t  \tbuild element with attributes\n      \t  \t:: String -> [(String,CFilter)]\n      \t  \t-> [CFilter] -> CFilter\n      \treplaceTag \t  \treplace element's tag\n      \t  \t:: String -> CFilter\n      \treplaceAttrs \t  \treplace element's attributes\n      \t  \t:: [(String,CFilter)] -> CFilter\n\n    Figure 2: Basic content filters.\n\n    Predicate and selection filters. The filter elm is a predicate, returning just this item if it is an element, or nothing otherwise.4 Conversely, txt returns this item only if is plain text,5 and nothing otherwise. The filter children returns the immediate children of an element if it has any, or nothing if this content-item is not an element. The filter tag t returns this item only if it is an element whose tag name is the string t. The filter attr a returns this item only if it is an element containing the attribute name a. The filter attrval (a,v) returns this item only if is an element containing the attribute a with the value v.\n\n    Construction filters. The function literal s makes a text content containing just the string s. The function mkElem t fs builds a content element with the tag t; the argument fs is a list of filters, each of which is applied to the current item, and all their results are collected to become the children of the new element. The function mkElemAttrs t avs fs is just like mkElem except that its extra parameter avs is a list of attribute values6 to be attached to the tag.\n\nA useful filter which involves both selection and construction is showAttr a, which extracts the value of the attribute a from the current element and returns just that string as a piece of content.\n\nWhen constructing a new document (e.g. the script in Figure 4 which generates HTML), the mkElem function occurs repeatedly. We define and use a small library of functions such as htable, hrow, and hcol which are just synonyms for particular applications of mkElem and mkElemAttrs to different tagnames, reducing verbosity and making the syntax rather more readable.\n\nAlso for convenience, we define the new operators ? and ! as synonyms for showAttr and literal respectively: they are used in a bracketed postfix notation,7 a style some programmers prefer.\n\n2.2  Combinators\nThe combinators used as intermediate code in compilers can render programs `totally unfit for human consumption' [11]! However, the idea of a combinator library for a specific class of applications is to achieve a form of expression that is natural for the problem. A combinator library should be like a language extension tailored to the problem domain [4]. In this sense, functional languages are extensible, just as XML itself is extensible. The combinators are higher-order operators serving as `glue'[6] to assemble functions into more powerful combinations. We aim to keep the types of component functions as uniform as possible so that any function can be composed with any other. Within the lexical limits of the host language, choice of notation should follow application conventions: in Haskell we can, where appropriate, define new infix operator symbols for combinators.\n\nSo, having defined some basic filters already, in what ways can these usefully be combined into more interesting and complex filters? (See Figure 3.)\n\n      \to, \t  \tIrish composition\n      \t(|||), \t  \tappend results\n      \twith, \t  \tguard\n      \twithout,\t\t  \tnegative guard\n      \t(/>), \t  \tinterior search\n      \t(</), \t  \texterior search\n      \t(|>|) \t  \tdirected choice\n      \t  \t:: CFilter -> CFilter -> CFilter\n     \n      \tf `o` g = concat . map f . g\n      \tf ||| g = \\c-> f c ++ g c\n      \tf `with` g = filter (not.null.g) . f\n      \tf `without` g = filter (null.g) . f\n      \tf /> g = g `o` children `o` f\n      \tf </ g = f `with` (g `o` children)\n      \tf |>| g = f ?> f :> g\n     \n      \tcat \t  \tconcatenate results\n      \t  \t:: [CFilter] -> CFilter\n     \n      \tcat fs = \\c-> concat. map (\\f->f c) fs\n     \n      \tet \t  \tdisjoint union\n      \t  \t:: (String->CFilter) -> CFilter -> CFilter\n     \n      \tf `et` g = (f `oo` tagged elm)\n      \t|>| (g `o` txt)\n     \n      \t(?>) \t  \tif-then-else choice\n      \t  \t:: CFilter -> ThenElse CFilter -> CFilter\n     \n      \tdata ThenElse a = a :> a\n      \tp ?> f :> g = \\c-> if (not.null.p) c\n      \tthen f c else g c\n     \n      \tchip, \t  \t``in-place'' application to children\n      \tdeep, \t  \trecursive search (topmost)\n      \tdeepest,\t\t  \trecursive search (deepest)\n      \tmulti, \t  \trecursive search (all)\n      \tfoldXml \t  \trecursive application\n      \t  \t:: CFilter -> CFilter\n     \n      \tdeep f = f |>| (deep f `o` children)\n      \tdeepest f = (deepest f `o` children) |>| f\n      \tmulti f = f ||| (multi f `o` children)\n      \tfoldXml f = f `o` (chip (foldXml f))\n\n    Figure 3: Filter combinators and their definitions.\n\nThe most important and useful filter combinator is `o`. We call this operator Irish composition, for reasons which should be obvious. It plugs two filters together: the left filter is applied to the results of the right filter. So, for instance, the expression\n\n    text `o` children `o` tag \"title\"\n\nmeans ``only the plain-text children of the current element, provided the current element has the title tag name''.\n\nSome other combinators are as follows. f ||| g is an append operator: it joins the results of f and g sequentially. cat fs is the list generalisation of |||; it concatenates the results of each of the filters from the fs list. f `with` g acts as a guard on the results of f, pruning to include only those which are productive under g. The dual, f `without` g, excludes those results of f which are productive under g. The expression p ?> f :> g is a functional choice operator; if the (predicate) filter p is productive, then the filter f is applied, otherwise g is applied. From this is derived a directed choice operator: f |>| g gives either the results of f, or those of g only if f is unproductive.\n\nGeneralised Path Selectors\nSelection of subtrees by path patterns is familiar to users of the Unix file-system, where such patterns are used to access directory structure, using a / notation to indicate the `containing' relation. Similar patterns are used in XSLT, an XML transformation language [3]. In this connection, we define two path selection combinators /> and </. Both combinators choose subtrees to return based on whether the results of the left filter contain the results of the right filter as children: /> is an `interior' selector, returning the inner structure; </ is an `exterior' selector, returning the outer structure.\n\nAn editing combinator\nAside from predicates, selectors, choice, and constructive filters, there is one very useful combinator which stands in its own category -- an editing combinator. chip f processes the children of an element in-place: the filter f is applied to its children; the results are rebuilt as the new children of that same element.\n\nRecursion\nIt is often useful to express recursive transformations on XML documents: transformations which can be applied at many different levels of the document tree.\n\nOne family of such expressions is useful primarily in selecting a subtree from an arbitrarily deep location, although they can of course be used for editing and filtering as well as selection. The recursive combinator deep f potentially pushes the action of filter f deep inside the document sub-tree. It first tries the given filter on the current item: if it is productive then it stops here, but if no results are returned, then it moves to the children and tries again recursively. When used with a predicate, this strategy searches for the topmost matching elements in the tree. There are variations: deepest searches for the bottommost matching elements; multi returns all matches, even those which are sub-trees of other matches. However, as already noted, the action of these combinators is not restricted to predicates or selectors.\n\nAnother powerful recursion combinator is foldXml: the expression foldXml f applies the filter f to every level of the tree, from the leaves upwards to the root (at least conceptually -- of course lazy evaluation makes this more efficient).\n\n2.3  Example\nThe use of these filters and combinators is illustrated in an example script in Figure 4. This program transforms an <album> element into an HTML document that provides a formatted summary. The HTML output, rendered by the Netscape browser, is illustrated in Figure 5. Such a task might be fairly common in e-commerce applications.\n\nWe now describe some of the salient features of the example.\n\n    (albumf `o` deep (tag \"album\"))\n\nThe script first searches recursively for the topmost element tagged <album>, before applying the filter albumf to it. Thus, it works equally well with any XML source document that contains an <album> element anywhere within it, and (correctly) produces no output for documents which do not contain album data.\n\nThe output document's <HEAD> section contains the artist name and album title separated by a colon. We note that the expression,\n\n    txt `o` children `o` tag \"artist\"\n        `o` children `o` tag \"album\"\n\nwhich grabs the textual content of the <artist> element within the <album> element, is somewhat unwieldy. Moreover its trailing test for the <album> tag is redundant, since the calling filter has already performed that match. The expression can be simplified by using path selectors to:\n\n    keep /> tag \"artist\" /> txt\n\nand this style is used elsewhere in the example. (The algebraic laws in Section 2.5 guarantee that this rewriting is safe.)\n\nSuch expressions make some assumptions about the structure of the data within the <album> element. In this instance, the assumption is that an <artist> element is an immediate child, and that its immediate children include text. If such assumptions prove incorrect for a particular document, the filter is simply unproductive; no error is flagged.\n\nWith a suitable definition, hbody = mkElemAttr \"BODY\" the expression\n\n    hbody  [(\"bgcolor\",(\"white\"!))]   [...]\n\ncan be understood to set the background colour attribute of the <BODY> tag to the literal value white. Notice how the attribute value is itself described by a filter. In this case, the filter is not very exciting, but the later definition of mkLink illustrates the generation of an HTML reference by looking up the value of a supplied link attribute (using the ? filter).\n\nWhen the script is used on the particular document from Figure 1, the output is a re-ordering of the internal components of the input: in the <BODY> part of the output, the <notes> section is selected and transformed by notesf before the <catalogno> elements are processed by the summaryf filter. Although in the absence of a DTD it is impossible to be sure of any input ordering, the script here ensures that the output ordering is consistent.\n\nThe definition of the notesf filter is interesting because it makes fewer assumptions about the content of a <notes> structure, and in addition it preserves the input ordering. The chained if-then-else choice within the recursive foldXml combinator causes all internal structure of the <notes> element to be retained except for the replacement of <trackref>s by emphasised text, and <albumref>s by HTML links.\n\nOne of the most striking features of the example as a whole is how selection and testing of old content and construction of new content are uniform, and can be combined almost interchangeably.\n\nWe will return to the treatment of <catalogno> elements in Section 2.4 after introducing some extra labelling combinators.\n\n    module Main where\n    import Xml\n    main =\n      processXmlWith (albumf `o` deep (tag \"album\"))\n    albumf =\n      html\n        [ hhead\n          [ htitle\n            [ txt `o` children `o` tag \"artist\"\n                  `o` children `o` tag \"album\"\n            , literal \": \"\n            , keep /> tag \"title\" /> txt\n            ]\n          ]\n        , hbody [(\"bgcolor\",(\"white\"!))]\n          [ hcenter\n              [ h1 [ keep /> tag \"title\" /> txt ] ]\n          , h2 [ (\"Notes\"!) ]\n          , hpara [ notesf `o` (keep /> tag \"notes\") ]\n          , summaryf\n          ]\n        ]\n    notesf =\n      foldXml (txt            ?> keep            :>\n               tag \"trackref\" ?> replaceTag \"EM\" :>\n               tag \"albumref\" ?> mkLink          :>\n               children)\n    summaryf =\n      htable [(\"BORDER\",(\"1\"!))]\n        [ hrow [ hcol [ (\"Album title\"!) ]\n               , hcol [ keep /> tag \"title\" /> txt ]\n               ]\n        , hrow [ hcol [ (\"Artist\"!) ]\n               , hcol [ keep /> tag \"artist\" /> txt ]\n               ]\n        , hrow [ hcol [ (\"Recording date\"!) ]\n               , hcol [ keep />\n                           tag \"recordingdate\" /> txt ]\n               ]\n        , hrow [ hcola [ (\"VALIGN\",(\"top\"!)) ]\n                       [ (\"Catalog numbers\"!) ]\n               , hcol\n                 [ hlist\n                   [ catno `oo`\n                      numbered (deep (tag \"catalogno\"))\n                   ]\n                 ]\n               ]\n        ]\n    catno n =\n      mkElem \"LI\"\n        [ ((show n++\". \")!),  (\"label\"?),  (\"number\"?)\n        , (\" (\"!),  (\"format\"?),  (\")\"!) ]\n    mkLink =\n      mkElemAttr \"A\" [ (\"HREF\",(\"link\"?)) ]\n        [ children ]\n\n    Figure 4: An example document-processing script using the generic filter combinators.\n\n    picture of browser\n\n    Figure 5: The HTML results of the example script, rendered by a browser.\n\n2.4  Labellings\nOne feature that is occasionally useful is the ability to attach labels to items in a sequence, for instance, to number a list of items, or to treat the first/last item of a list differently from the other items. For this purpose, the library provides special labelling combinators. We choose to introduce a new type:\n\n  type LabelFilter a = Content -> [ (a,Content) ]\n\nA LabelFilter is like a CFilter except it attaches a label to each of its results. We might have chosen to fold label values inside the Content type, to yield a uniform CFilter type, but keeping the labels separate allows them to be of completely polymorphic type: a label could even be another filter for example.\n\nThere are several common labelling functions:\n\n  numbered     :: CFilter -> LabelFilter Int\n  interspersed :: a -> CFilter -> a\n                                 -> LabelFilter a\n  tagged       :: CFilter -> LabelFilter String\n  attributed   :: CFilter ->\n                    LabelFilter [(String,String)]\n\nThese labelling functions lift a CFilter to the LabelFilter type: numbered f transforms the ordinary filter f into a new filter that attaches integers (from 1 upwards) to the results of f; interspersed a f z attaches the label a to all of the results of f except the last, which gets the label z; tagged f labels every tagged element with its tag name (and non-elements with the empty string); attributed f labels every tagged element with its attribute/value pairs (and non-elements with the empty list).\n\n  `oo` :: (a->CFilter) -> LabelFilter a -> CFilter\n\nThe combinator `oo` is a new form of composition which drops a LabelFilter back to the CFilter type by application of another filter that consumes the label.\n\nThe use of this form of labelling is illustrated by the treatment of <catalogno>s in the example of Figure 4:\n\n  catno `oo` numbered (deep (tag \"catalogno\"))\n\nFirst, the desired elements are extracted from their topmost positions in the tree, then they are given numeric labels, and finally the catno filter incorporates the label into some generated text. Another example can be seen in the definition of the `et` combinator in Figure 3. (`et` combines a filter f on elements with a filter g on text. f pattern-matches against tagnames -- the tagnames are extracted by the labelling function tagged.)\n\nFurthermore, it is possible to combine labellings. The `x` combinator glues two labelling functions together, pairing the labels they produce.\n\n  `x` :: (CFilter->LabelFilter a)\n           -> (CFilter->LabelFilter b)\n           -> (CFilter->LabelFilter (a,b))\n\n2.5  Algebraic laws of combinators\nWe briefly show how combinators are defined in such a way that various algebraic laws hold. The complete set of laws is given in Figure 6.\n\n      \tIrish composition\n    f `o` (g `o` h) = (f `o` g) `o` h\t\t  \tassociativity\n    none `o` f = f `o` none = none\t\t  \tzero\n    keep `o` f = f `o` keep = f\t\t  \tidentity\n     \n      \tGuards\n    f `with` keep = f \t  \tidentity\n    f `with` none = none `with` f = none\t\t  \tzero\n    (f `with` g) `with` g = f `with` g\t\t  \tidempotence\n    (f `with` g) `with` h\n    = (f `with` h) `with` g\t\t  \tpromotion\n    (f `o` g) `with` h\n    = (f `with` h) `o` g\t\t  \tpromotion\n     \n    f `without` keep = none `without` f\n    = none\t\t  \tzero\n    f `without` none = keep\t\t  \tidentity\n    (f `without` g) `without` g\n    = f `without` g\t\t  \tidempotence\n    (f `without` g) `without` h\n    = (f `without` h) `without` g\t\t  \tpromotion\n    (f `o` g) `without` h\n    = (f `without` h) `o` g\t\t  \tpromotion\n     \n      \tPath selectors\n    f /> (g /> h) = (f /> g) /> h\t\t  \tassociativity\n    none /> f = f /> none = none\t\t  \tzero\n    keep /> f = f `o` children\t\t  \t \n    f /> keep = children `o` f\t\t  \t \n    keep /> keep = children\t\t  \t \n    none </ f = f </ none = none\t\t  \tzero\n    f </ keep = f `with` children\t\t  \t \n    (f </ g) </ g = f </ g\t\t  \tidempotence\n    (f </ g) /> g = f /> g\t\t  \tidempotence\n     \n    (f /> g) </ h = f /> (g </ h)\t\t  \tpromotion\n    (f </ g) </ h = (f </ h) </ g \t  \tpromotion\n    f `o` (g /> h) = g /> (f `o` h)\t\t  \tpromotion\n    (f /> g) `o` h = (f `o` h) /> g\t\t  \tpromotion\n    (f /> g) `with` h = f /> (g `with` h) \t  \tpromotion\n    (f </ g) `with` h = (f `with` h) </ g \t  \tpromotion\n     \n      \tDirected choice\n    (f |>| g) |>| h = f |>| (g |>| h)\t\t  \tassociativity\n    keep |>| f = keep\t\t  \t \n    none |>| f = f |>| none = f\t\t  \tidentity\n    f |>| f = f\t\t  \tidempotence\n     \n      \tRecursion\n    deep keep = keep\t\t  \tsimplification\n    deep none = none\t\t  \tsimplification\n    deep children = children\t\t  \tsimplification\n    deep (deep f) = deep f\t\t  \tdepth law\n     \n      \tMisc\n    elm |>| txt = txt |>| elm = keep\t\t  \tcompleteness\n    elm `o` txt = txt `o` elm = none\t\t  \texcl. middle\n    children `o` elm = children\t\t  \t \n    children `o` txt = none\t\t  \t\n\n    Figure 6: Algebraic laws of combinators.\n\nGiving all content filters the same type maximises the usefulness of combinators for plugging together functions of this type. However, it is still helpful to identify subclasses of content filters that offer extra guarantees. Two examples of such classes are:\n\n    A predicate p has the property that p c always gives as result either [c] or [].\n    A selector s has the property that s c always gives as result a sequence of contents taken from c. Resulting items do not overlap, and the result sequence respects the order in which the contents were found in c. \n\nSo a predicate is a selector, but a selector is not necessarily a predicate.\n\nThe `o` form of filter composition could be defined using a Haskell list comprehension\n\n    (f `o` g) c = [c'' | c' <- g c, c'' <- f c']\n\nHowever, we prefer the equivalent higher-order definition f `o` g = concat . map f . g because it is more convenient in algebraic calculation.8 Composition is associative, with none as zero, and keep as identity.\n\nThe `with` form of guarded composition is not associative, but we do have some laws, particularly idempotence. We also have a promotion law about combined uses of `with` and `o`. The dual operator, `without` has parallel laws.\n\nThe /> path selector is associative but </ is not, and there are some idempotence laws for both. Most important however, are the various promotion laws for changing the order of application of />, </, and with.\n\nThe directed choice operator |>| viewed by itself appears to be algebraically sensible, but it does not seem to have useful algebraic properties in connection with other combinators because of its bias towards the left operand. The simpler result-appending combinator ||| could be an alternative to the directed choice operator, and would probably lead to more laws, but it has less `application bite'. A potentially serious problem is that the |||-combination of two selectors is not necessarily a selector.\n\nThe recursion operator deep has some minor laws, one of which, the depth law, is more profound. We have not yet fully investigated the properties of deepest, multi, and foldXml.\n\n\n\n3  Translation of DTDs to Types\n3.1  DTDs\nSo far we have considered document-processing by generic tree transformations, where markup is matched textually at runtime, and no account is taken of any deeper meaning of tags.\n\nHowever, when the DTD for a document is available, the meaning it defines for markup tags can be used to powerful effect. The most basic use is to confirm semantic validity: a stronger notion than mere syntactic well-formedness. A DTD defines a grammar for document content: it specifies a vocabulary of markup tags, and the allowed content and attributes for each tag. Document validation is therefore a straightforward check that the document's structure conforms to the vocabulary and grammar given in the DTD.\n\nXML document validators are readily available. However, we go further and define the idea of valid document processing. A valid processing script is one which produces a valid document as output, given a valid document as input. We achieve this by demonstrating a correspondence between the DTD of a document and the definition of a set of algebraic types in Haskell, and the consequent correspondence between the document's content and a structured Haskell value. Hence, by writing document processing scripts to manipulate the typed Haskell value, the script validation problem is just an instance of normal Haskell type inference.9\n\n    <?xml version='1.0'?>\n    <!DOCTYPE album SYSTEM \"album.dtd\" [\n    <!ELEMENT album (title, artist, recordingdate?,\n                     coverart, (catalogno)+,\n                     personnel, tracks, notes) >\n    <!ELEMENT title #PCDATA>\n    <!ELEMENT artist #PCDATA>\n    <!ELEMENT recordingdate EMPTY>\n        <!ATTLIST recordingdate date CDATA #IMPLIED\n                                place CDATA #IMPLIED>\n    <!ELEMENT coverart (location)? >\n        <!ATTLIST coverart style CDATA #REQUIRED>\n    <!ELEMENT location EMPTY >\n        <!ATTLIST location thumbnail CDATA #IMPLIED\n                           fullsize CDATA #IMPLIED>\n    <!ELEMENT catalogno EMPTY >\n        <!ATTLIST\n              catalogno\n                  label CDATA #REQUIRED\n                  number CDATA #REQUIRED\n                  format (CD | LP | MiniDisc) #IMPLIED\n                  releasedate CDATA #IMPLIED\n                  country CDATA #IMPLIED>\n    <!ELEMENT personnel (player)+ >\n    <!ELEMENT player EMPTY >\n        <!ATTLIST player name CDATA #REQUIRED\n                          instrument CDATA #REQUIRED>\n    <!ELEMENT tracks (track)* >\n    <!ELEMENT track EMPTY>\n        <!ATTLIST track title CDATA #REQUIRED\n                        credit CDATA #IMPLIED\n                        timing CDATA #IMPLIED>\n    <!ELEMENT notes (#PCDATA | albumref | trackref)* >\n        <!ATTLIST notes author CDATA #IMPLIED>\n    <!ELEMENT albumref #PCDATA>\n        <!ATTLIST albumref link CDATA #REQUIRED>\n    <!ELEMENT trackref #PCDATA>\n        <!ATTLIST trackref link CDATA #IMPLIED>\n    ]>\n\n    Figure 7: An example DTD.\n\n    module AlbumDTD where\n\n    data Album = \n        Album Title Artist (Maybe Recordingdate)\n              Coverart [Catalogno] Personnel\n              Tracks Notes\n    newtype Title = Title String\n    newtype Artist = Artist String\n    newtype Recordingdate =\n                    Recordingdate Recordingdate_Attrs\n    data Recordingdate_Attrs = Recordingdate_Attrs {\n        date :: Maybe String,\n        place :: Maybe String }\n    newtype Coverart = Coverart (String, Maybe Location)\n    newtype Location = Location Location_Attrs\n    data Location_Attrs = Location_Attrs {\n        thumbnail :: Maybe String,\n        fullsize  :: Maybe String }\n    newtype Catalogno = Catalogno Catalogno_Attrs\n    data Catalogno_Attrs = Catalogno_Attrs {\n        label :: String,\n        number :: String,\n        format :: Maybe Format,\n        releasedate :: Maybe String,\n        country :: Maybe String }\n    data Format = CD | LP | MiniDisc\n    newtype Personnel = Personnel [Player]\n    newtype Player = Player Player_Attrs\n    data Player_Attrs = Player_Attrs {\n        name :: String,\n        instrument :: String }\n    newtype Tracks = Tracks [Track]\n    newtype Track = Track Track_Attrs\n    data Track_Attrs = Track_Attrs {\n        title :: String,\n        credit :: Maybe String,\n        timing :: Maybe String }\n    newtype Notes = Notes (Maybe String, [Notes_])\n    data Notes_ = \n        Notes_Str String\n      | Notes_Albumref Albumref\n      | Notes_Trackref Trackref\n    newtype Albumref = Albumref (String,String)\n    newtype Trackref = Trackref (Maybe String,String)\n\n    Figure 8: The example DTD translated to Haskell types.\n\n3.2  DTD translations.\nAn example DTD for the document shown earlier is given in Figure 7. The immediate features to note are: (1) For every element, there is a specification of allowed inner elements (ELEMENT declaration), and possibly also a specification of allowed attribute values (ATTLIST declaration). (2) For inner content, the grammar allows sequence (commas), choice (vertical bar), optionality (question mark), and repetition (star or plus). (3) Where the inner content declaration allows free text (#PCDATA), choice between text and other elements is permitted, but sequencing of those elements is not permitted. (4) In attribute lists, some values are mandatory (#REQUIRED) and some are optional (#IMPLIED); attribute values can either be unconstrained strings (CDATA) or a member of some pre-defined set of string values.\n\nThere seem to be some obvious correspondences between this very restricted form of type language and the richer type language of Haskell. Each element declaration is roughly speaking a new datatype declaration. Sequence is like product types (i.e. single-constructor values). Choice is like sum types (i.e. multi-constructor values). Optionality is just a Maybe type. Repetition is lists.\n\nAttribute lists also have a translation: because they are unordered and accessed by name, Haskell named-fields look like a good representation. Optionality can again be expressed as Maybe types. Attribute values that are constrained to a particular value-set can be modelled by defining a new enumeration type encompassing the permitted strings.\n\n3.3  Implementation\nThese rules are formalised in the appendix (Figure 9). An implementation of these rules (with some additional rules to eliminate redundancy) translated the DTD in Figure 7 into the Haskell type declarations shown in Figure 8.\n\nAlso needed, along with the type declarations, are functions which read and write values of these types to and from actual XML documents. These are generated automatically from the type declarations alone. Using an appropriate set of pre-defined type classes, we derive a new instance for each generated type using a tool like DrIFT [16].\n\n3.4  Discussion\nAlthough this type-based translation looks straightforward, it turns out that there are several tricky issues.\n\nFirst, the type translation may only use datatypes and newtypes, never type synonyms. This is a result of needing to write values out as XML -- a type synonym in Haskell is indistinguishable from the type it abbreviates, but the generated types must be distinct in order to be able to re-introduce enclosing start and end tags with the correct markup.\n\nA separate type is introduced for each collection of attributes. Hence, an element is represented by a pairing of the attributes and the content. Where a tagged element directly contains an optional type or a sequence of types which are themselves sum-types, it is necessary to interpose a separate Haskell type, e.g. Notes contains a [Notes_] where the auxiliary type Notes_ has three alternatives.\n\nNaming is a big issue. Case matters in XML, so a <tag> differs from a <TAG> and attribute attr differs from Attr. In Haskell however, types must begin with upper-case, and field-names must begin with lower-case. Where auxiliary types are necessary, we have chosen to append an underscore character to the name. All of these factors impose restrictions on the use of this translation, due to the potential name conflicts.\n\nFurthermore, there is a mismatch between Haskell's named fields and the attribute naming/scoping rules in XML. In XML, different elements may have attributes of the same name and type, whereas Haskell's named fields are restricted to use within a single type. A system of typed extensible records [5] would be a much better fit.\n\nDespite these problems in expressing DTDs within the Haskell typesystem, the latter is very much more powerful than DTDs -- for instance, DTDs have no notion of polymorphism. Indeed, there are frequent occasions when DTD writers resort to textual macros10 to indicate more detailed structuring than DTDs permit (including polymorphism and qualified typing), even though such implicit structuring cannot be validated by XML tools. It is significant to note the XML community's recognition of these limitations of DTDs -- recent proposals for schemas11 address the question of richer typing in a more disciplined manner.\n\nOne area in which the type system of Haskell in particular (as opposed to other functional languages) is exploited is type classes. This systematic overloading mechanism is very useful for codifying the I/O conversions.\n\n4  Pros and cons of the two schemes\n4.1  Combinators\nCompared with the mainstream solution for XML processing, namely new domain-specific languages for expressing and scripting transformations, the combinator approach has several advantages:\n\nEase of extension and variation\nScripting languages sometimes lack useful facilities, or provide them in convoluted ways. Extending the language is difficult. A combinator library, however, can be enlarged comparatively straightforwardly -- the definitions are accessible, and most are short and simple.\n\nComputational power\nScripting languages tend to offer either a very limited expression language, or a hook into a programming system at a completely different level of abstraction. But if XML scripts are programs in a language such as Haskell, the full power of the native language is immediately available.\n\nAbstraction, generality and reuse\nAlmost any pattern occurring in a combinator program can be isolated and defined as a separate re-usable idea [6]. This also applies at the application level, where common ideas from similar applications might easily be defined in a higher-level library. This form of re-use makes program development much quicker and less error-prone.\n\nLaws for reasoning about scripts\nThe semantics of a scripting language are often defined by illustration. So it is hard to reason with confidence about the meanings of scripts. Is A just a stylistic variation of B or are there inputs for which the two could give different results? But when the semantics of scripts can be defined in terms of the equations for the combinators, properties such as associativity and distribution can often be demonstrated simply.\n\nImplementation for free\nDoes a scripting language have an interactive interpreter? A compiler? A type-checker? A profiler? All these things are immediately available to XML scripts directly expressed as Haskell programs.\n\nOf course, there are disadvantages too.\n\nDistance from target language\nXSLT [3] has the property that a script is an expression in the target language: it uses exactly the XML syntax for building new content. Combinator-based scripts must use a different syntax due to the underlying language. The linguistic gap might cause confusion and increase learning costs.\n\nLiving in an unfamiliar world\nCombinator programs look like scripts in a small domain-specific language. Writers may be beguiled by this apparent simplicity, make a small error, and drop into an unknown corner of Haskell. Error messages may be incomprehensible, or worse, the script might work but do something utterly strange.\n\n4.2  Type-based translation\nSome of the advantages of the fully-typed representation of XML documents have already been mentioned.\n\nValidity\nThe ability for the system to spot errors automatically, not just in the data, but in the program, and also to prevent the generation of incorrect document markup.\n\nDirect programming style\nFunctional languages encourage the use of pattern-matching (binding values to variables) on the left-hand-side of equations. However, using higher-order combinators, data structures tend not to be mentioned in equations at all. The DTD translation approach is much more in keeping with the pattern-binding style, which sometimes leads to shorter programs! Whereas with combinators, it is sometimes necessary to re-traverse the same selection path with slight variations, the pattern-binding gives direct access for free.\n\n\nDisadvantages are:\n\nHigh startup cost\nBefore scripting document transformations, it is necessary to acquire, check, and process the DTD. Although the generation of Haskell types is automated, few people are familiar enough with DTDs to be able to start using them immediately. They require careful study and understanding before correct scripts can be written and the initial investment of effort pays off.\n\nIncomplete type model\nThe grammar of DTDs is small and restrictive compared to the sophisticated type systems available in functional languages. Better means of type-specification in XML are still under development. In the meantime, there is little scope for using the full power of features like polymorphism.\n\n5  Related Work\nXML Processing\nThere are infant processing languages surrounding XML. Of most interest here are:\n\n    XSLT [3] (eXtensible Style Language for Transformation) is a W3C-proposed declarative language for expressing a limited form of transformations on XML documents, originally intended for rendering to a layout-based format, e.g. HTML, PostScript, etc., but now widely used for XML->XML transformations.\n    DSSSL [12] (Document Style Semantics and Specification Language) is a mature ISO standard with no complete implementations. It is similar in essence to XSLT, but deals with full SGML input, and is based on Scheme. \n\nNot many functional language researchers are visibly engaged in XML-related work, but two other toolkits for XML-processing are Christian Lindig's XML parser in O'Caml12 and Andreas Neumann's validating XML parser in SML13 . To our knowledge, neither of these provides transformation capabilities in either a combinator style or a type-translation style. Philip Wadler has written a short formal semantics of XSL selection patterns [15].\n\nApplication-based combinators\nParsing is the most extensively studied application for combinator libraries. Since the original treatment by Burge [2], there have been many variations on the theme. Swierstra and Duponcheel's method incorporating on-the-fly grammar analysis and error-correction is a notable recent example [10]. We hope it may be possible to incorporate DTD-analysis in our combinators in a similar style.\n\nAlthough many other libraries of application combinators have been devised, the general design principles for such libraries are scarcely referred to in the literature. Hughes' exposition of a design for pretty-printing combinators [7] is a unique resource in this respect, and we have yet to exploit it fully.\n\nTree-processing operators\nAn earlier version of this paper prompted more than one pointer to the work of Eelco Visser and colleagues [13]. Their motivating application is specification of strategies for program optimisation, treated as rewriting over expression trees. The result of applying a strategy is either a single term or failure: non-determinism is achieved by backtracking but only the first success is computed, whereas we deal in `lists of successes' [14]. Their operators for combining strategies include composition, directed choice, and an explicit ľ operator for recursion. They have several operators for specifying transformation of child subterms: some are not so relevant to XML where subtree position and arity are less often fixed than in program syntax; however, one of the most frequently applied operators is close to our foldXml. Most significantly, Visser et. al. achieve great expressive power by decomposing the match/re-build stages of rewriting, and introducing explicit environments by which these stages communicate. This makes it possible to deal with subtleties such as variable bindings in the program terms under transformation. Although the structure of XML is simpler than the structure of a programming language, our library could benefit from the addition of support for binding variables when matching subtrees.\n\nProgramming functions explicitly over the XML data-structure, without the abstraction of combinators, Haskell pattern matching provides bindings for subtrees. But only at a fixed (small) depth from the root, beneath an explicitly stated pattern of constructors. Mohnen [9] defines an extension of the pattern language for deep matching: variables in a pattern can be bound to subterms at arbitrary depth inside the original term. The result of the match includes a context function representing the original subject term with `holes' at the sites of matching; subterms for these holes are supplied by arguments to the function. So contexts are the complements of environments. Mohnen shows how his matching extension simplifies various tree-processing tasks, and also how it can be translated into standard Haskell. This work could provide one component of a hybrid solution, with DTD-specific representation and generic forms of traversal and matching.\n\nVisser et. al. [13] also discuss several other approaches to the tree transformation problem.\n\n6  Conclusions and Future Work\nIn our experience, Haskell is a very suitable language for XML processing. For generic applications, a small set of combinators designed with algebraic properties in mind can be powerful enough and flexible enough to describe a full range of selection, testing, and construction operations in a uniform framework. For applications where the DTD is fixed, a tool deriving corresponding types and associated I/O routines turns XML processing into Haskell programming over typed data structures, and the Haskell typechecker validates scripts.\n\nHowever, there is plenty of scope for further work, in several directions:\n\nGenerality of combinators\nThough we have had generality as a design aim for our present combinator library there is scope for generalising it further.\n\n    Wider functionality. Most content filters in our current library are either pure selectors (with results that are sequences of sub-trees from the full document tree) or pure constructors (creating document content from values of other types). The design could usefully be extended to include a more general class of deletion operations in which sub-trees can be thinned and pruned in various ways. More general still are combinators for editing and transforming, where some of the ideas in Visser's work could usefully be transferred.\n    Multiple inputs and outputs. An interesting extension of single-document scripting is the handling of multiple documents. Producing more than one output document is no great problem. But it is far more challenging to design appropriate combinators for dealing with several inputs.\n    More general types. The labelling scheme has proved useful for some applications, but the need for a separate LabelFilter type is a blemish. We hope to generalise the CFilter type to incorporate LabelFilter as a special case. By making the CFilter type parametric it might even be possible to incorporate the type-translation of DTDs within the combinator framework. \n\nEfficiency of combinators\nThe current combinator library is quite usable, but here are some possible routes to greater efficiency.\n\n    Algebraic normalisation So far we have merely established that laws hold, and occasionally appealed to them when writing scripts. The implementation simply defines the combinators by their specifying equations. Instead, laws could be exploited at the implementation level. Following Hughes [7], we have in mind an implementation that automatically reduces all combinations to a normal form, that is the least expensive equivalent computationally.\n    Space-efficient formulation Some lazy functional programs that process trees in pre-order left-to-right fashion can be formulated to run in log(N) space. The part of the tree that is held in memory corresponds to a path from the root to some node that is currently the focus of computation: to the left are `garbage' subtrees already processed, to the right are subtrees not yet evaluated. However, our current combinators have not been formulated to guarantee this sort of space behaviour, even in favourable cases. This problem might be tackled by the normalisation approach.\n    DTD-aware combinators The current combinator library just ignores DTDs. Combinators that maintain DTD information might, for example, achieve far more efficient search in some cases by pruning branches bound to fail. They could also be used to produce first-class XML documents as the results of queries, not just raw extracts of unknown type. As we have already noted, DTDs could perhaps be attached as labels in the sense of §2.4: either as explicit values or implicitly in type information. \n\nRelations between DTDs\nAs we have seen, in the DTD-directed approach with known fixed DTDs for input and output, validation translates to static type-checking; whereas generic combinators could in principle acquire and compute DTDs dynamically. These represent extremes with disadvantages of inflexibility on the one hand and some insecurity on the other. There are many other ways of handling relations between DTDs. For example:\n\n    Polymorphic and higher-order scripts. The generic approach would gain security if one could infer a DTD->DTD function. By analogy with functional programs it is then natural to assign scripts polymorphic and higher-order DTDs, making explicit their degree of genericity.\n\n    Inclusion between DTDs. This has been implicitly assumed already, but has practical importance in its own right. As stock DTDs are refined, XML documents will inhabit a hierarchy of specialisation. Given several similar DTDs, one would like to derive a DTD for a virtual common root (intersection) or common descendent (union). This goes well beyond the abilities of current type-inference systems, but would make a useful addition to our functional toolkit for XML processing. \n\nAcknowledgements\nCanon Research Centre (Europe) Ltd. suggested this line of work and funded it. Philip Wadler, Christian Lindig, and Joe English gave very helpful comments on an earlier draft of this paper and software. Several anonymous referees also gave useful advice.\n\nReferences\n\n[1]\n    Tim Bray, Jean Paoli, and C.M. Sperberg-Macqueen. Extensible Markup Language (XML) 1.0 (W3C Recommendation). http://www.w3.org/TR/REC-xml, WWW Consortium, February 1998.\n\n[2]\n    W H Burge. Recursive Programming Techniques. Addison-Wesley, 1975.\n\n[3]\n    James Clark (ed). XSL Transformations (Working Draft). http://www.w3.org/TR/WD-xslt, WWW Consortium, April 1999.\n\n[4]\n    Jon Fairbairn. Making form follow function: An exercise in functional programming style. Software -- Practice and Experience, 17(6):379--386, June 1987.\n\n[5]\n    Benedict R Gaster. Records, Variants, and Qualified Types. Dept of Computer Science, University of Nottingham, PhD Thesis, 1998.\n\n[6]\n    John Hughes. Why functional programming matters. Computer Journal, 32(2), April 1989.\n\n[7]\n    John Hughes. The design of a pretty-printing library. In 1st Intl. School on Advanced Functional Programming, pages 53--96. Springer LNCS Vol. 925, 1995.\n\n[8]\n    Graham Hutton and Erik Meijer. Monadic parsing in Haskell. Journal of Functional Programming, 8(4), July 1998.\n\n[9]\n    Markus Mohnen. Context patterns in Haskell. In Workshop on Implementation of Functional Languages, pages 41--57. Springer LNCS Vol 1268, September 1996.\n\n[10]\n    Doaitse Swierstra and Luc Duponcheel. Deterministic error-correcting combinator parsers. In 2nd Intl. School on Advanced Functional Programming, pages 184--207. Springer LNCS Vol 1129, August 1996.\n\n[11]\n    David A Turner. A new implementation technique for applicative languages. Software -- Practice and Experience, 9(1):31--50, January 1979.\n\n[12]\n    Unknown. Document Style Semantics and Specification Language (DSSSL) (Final Draft). http://occam.sjf.novell.com/dsssl/dsssl96/, Novell Publications, 1996.\n\n[13]\n    Eelco Visser, Zine el Abidine Benaissa, and Andrew Tolmach. Building program optimisers with rewrite strategies. In International Conference on Functional Programming, pages 13--26. ACM Press, September 1998.\n\n[14]\n    Philip Wadler. How to replace failure by a list of successes. In Functional Programming Languages and Computer Architecture, pages 113--128. Springer LNCS Vol 201, September 1985.\n\n[15]\n    Philip Wadler. A formal model of pattern matching in XSL. Technical Report http://www.cs.bell-labs.com/~wadler/xsl/, Bell Labs, January 1999.\n\n[16]\n    Noel Winstanley. Reflections on instance derivation. In 1997 Glasgow Functional Programming Workshop. BCS Workshops in Computer Science, September 1997.\n\n    Appendix: DTD translation rules\n    Type declarations\n    T[[<ELEMENT n spec>]] \t= \tnewtype m =\n      \t  \tm (m_Attrs, m_)\n      \t  \tnewtype m_ = D[[spec]] m\n      \t  \twhere m = M[[n]]\n    T[[<ATTLIST n\n    decl0 ... declk>]] \t= \tdata m_Attrs =\n      \t  \tm_Attrs {F[[decl0]]\n      \t  \t, ...\n      \t  \t,F[[ declk]] }\n      \t  \twhere m = M[[n]]\n      \t  \tA[[decl0]]\n      \t  \t...\n      \t  \tA[[ declk]]\n     \n    RHS of type declarations\n    D[[ ( x0, x1, ..., xk ) ]] m \t= \tC[[ m x0 ... xk ]]\n      \t  \tD'[[ x0 ]] D'[[ x1 ]] ... D'[[ xk ]]\n    D[[ ( x0 | x1 | ... | xk ) ]] m \t= \tC[[ m x0 ]] D'[[ x0 ]]\n      \t  \t| C[[ m x1 ]] D'[[ x1 ]]\n      \t  \t| ...\n      \t  \t| C[[ m xk ]] D'[[ xk ]]\n    D[[ (x)? ]] m \t= \tMaybe D'[[ x ]]\n    D[[ (x)+ ]] m \t= \tList1 D'[[ x ]]\n    D[[ (x)* ]] m \t= \t[ D'[[ x ]] ]\n    D[[ x ]] m \t= \tC[[ m x ]]\n     \n    Inner type expressions\n    D'[[ ( x0, x1, ..., xk ) ]] \t= \t( D'[[ x0 ]] , D'[[ x1 ]]\n      \t  \t, ... D'[[ xk ]] )\n    D'[[ ( x0 | x1 | ... | xk ) ]] \t= \t(OneOfn D'[[ x0 ]] D'[[ x1 ]]\n      \t  \t... D'[[ xk ]] )\n    D'[[ (x)? ]] \t= \t(Maybe D'[[ x ]] )\n    D'[[ (x)+ ]] \t= \t(List1 D'[[ x ]] )\n    D'[[ (x)* ]] \t= \t[ D'[[ x ]] ]\n    D'[[ x ]] \t= \tC[[ x ]]\n     \n    Name mangling\n    C[[ m x0 x1 ... xk ]] \t= \t... unique constructor name\n      \t  \tbased on m\n    M[[ n ]] \t= \t... ensure initial upper-case\n    M'[[ n ]] \t= \t... ensure initial lower-case\n     \n    Named fields\n    F[[ n CDATA #REQUIRED ]]\n      \t= \tM'[[ n ]] :: String\n    F[[ n CDATA #IMPLIED ]]\n      \t= \tM'[[ n ]] :: Maybe String\n    F[[ n (s0|s1|...|sk) #REQUIRED ]]\n      \t= \tM'[[ n ]] :: M[[ n ]]\n    F[[ n (s0|s1|...|sk) #IMPLIED ]]\n      \t= \tM'[[ n ]] :: Maybe M[[ n ]]\n     \n    Constrained attributes\n    A[[ n CDATA ... ]] \t= \t0\n    A[[ n (s0|s1|...|sk) ... ]]\n      \t= \tdata M[[ n ]] =\n      \t  \tM[[ s0 ]] | M[[ s1 ]]\n      \t  \t| ... | M[[ sk ]]\n\n    Figure 9: DTD translation rules.\n\n1\n    The XML toolkit from this paper is available on the WWW at http://www.cs.york.ac.uk/fp/HaXml/ \n2\n    Xtract: a `grep'-like tool for XML documents. http://www.cs.york.ac.uk/fp/Xtract/ \n3\n    In light of the ``XML Namespaces'' recommendation, in effect a mechanism for permitting multiple DTDs, such facilities could be particularly useful. See http://www.w3.org/TR/REC-xml-names \n4\n    The shortened name elm was chosen to avoid a clash with the Standard Prelude function elem. \n5\n    For those familiar with the detail of XML, entity references within the document are treated as plain text. \n6\n    Actually, a list of attribute/filter pairs. Each filter is applied to the current element and the resultant content is flattened to a string value which is assigned to the named attribute. \n7\n    Actually a left-section of the infix operator. Because filters are higher-order, their use is eta-reduced and the rightmost argument disappears from view. \n8\n    Irish composition is in fact just the flipped-argument version of the Kleisi composition operator in the list monad. \n9\n    Well, nearly! Validity also encompasses some other minor checks, for instance that IDREF attributes must be globally unique. \n10\n    That is, parameter entity references. \n11\n    http://www.w3.org/TR/xmlschema-1 for structures, and http://www.w3.org/TR/xmlschema-2 for datatypes. \n12\n    http://www.cs.tu-bs.de/softech/people/lindig/tony.html \n13\n    http://www.informatik.uni-trier.de/ neumann/Fxp/ \n\n    This document was translated from LATEX by HEVEA. \n\n"
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Haskell and XML",
        "story": []
      },
      "date": 1665381021928
    },
    {
      "item": {
        "type": "factory",
        "id": "bde9f870ebbd768a"
      },
      "id": "bde9f870ebbd768a",
      "type": "add",
      "date": 1665381032912
    },
    {
      "type": "edit",
      "id": "bde9f870ebbd768a",
      "item": {
        "type": "markdown",
        "id": "bde9f870ebbd768a",
        "text": "\nHaskell and XML: Generic Combinators or Type-Based Translation?\nMalcolm Wallace and Colin Runciman\n\n\n\n\n\n\n    Abstract: We present two complementary approaches to writing XML document-processing applications in a functional language.\n\n    In the first approach, the generic tree structure of XML documents is used as the basis for the design of a library of combinators for generic processing: selection, generation, and transformation of XML trees.\n\n    The second approach is to use a type-translation framework for treating XML document type definitions (DTDs) as declarations of algebraic data types, and a derivation of the corresponding functions for reading and writing documents as typed values in Haskell.\n\n    Published in the Proceedings of the International Conference on Functional Programming, Paris, Sept 1999. ACM Copyright.\n\n1  Introduction\n1.1  Document markup languages\nXML (Extensible Markup Language) [1] is a recent simplification of the older SGML (Standardised Generalised Markup Language) standard that is widely used in the publishing industry. It is a markup language, meaning that it adds structural information around the text of a document. It is extensible, meaning that the vocabulary of the markup is not fixed -- each document can contain or reference a meta-document, called a DTD (Document Type Definition), which describes the particular markup capabilities used.\n\nThe use of XML is not however restricted to the traditional idea of a document. Many organisations are proposing to use XML as an interchange format for pure data produced by applications like graph-plotters, spreadsheets, and relational databases.\n\nHTML (Hyper-Text Markup Language) is one well-known example of an instance of SGML -- every HTML document is an SGML document conforming to a particular DTD. Where XML improves over SGML is in removing shorthand forms that require an application to have knowledge of a document's DTD. For instance, in HTML some markup (such as a numbered list) requires an end marker; other forms (such as paragraphs) have implicit end markers understood when the next similar form starts; and yet other markup (such as in-line images) is self-contained and needs no end marker. An HTML application needs to be aware of the specific kind of markup in order to do the right thing.\n\n1.2  XML document structure\nXML is more regular. All markup has an explicit end marker without exception: every document is well-formed; its nesting structure is syntactically clear. One important consequence is that an XML application does not need to know the meaning or interpretation of all markup expressions -- parts of the document can be selected, re-arranged, transformed, by structure alone rather than by meaning.\n\nAn XML document is essentially a tree structure. There are two basic `types' of content in a document: tagged elements, and plain text. A tagged element consists of a start tag and an end tag, which may enclose any sequence of other content (elements or text fragments). Tagged elements can be nested to any depth, and the document is well-formed if it consists of a single top-level element containing other properly nested elements. Start tags have the syntax <tag>, and end tags </tag>, where tag is an arbitrary name. There is special syntax for an empty element: <tag/> is exactly equivalent to <tag></tag>. The start and end tags for each element contain a tag name, which identifies semantic information about the structure, indicating how the enclosed content should be interpreted. The start tag may also contain attributes, which are simple name/value bindings, providing further information about the element. Figure 1 shows an example XML document, illustrating all these components.\n\n    <?xml version='1.0'?>\n    <!DOCTYPE album SYSTEM \"album.dtd\">\n    <album>\n      <title>Time Out</title>\n      <artist>Dave Brubeck Quartet</artist>\n      <coverart style='abstract'>\n        <location thumbnail='pix/small/timeout.jpg'\n                  fullsize='pix/covers/timeout.jpg'/>\n      </coverart>\n\n      <catalogno label='Columbia' number='CL 1397'\n                 format='LP'/>\n      <catalogno label='Columbia' number='CS 8192'\n                 format='LP'/>\n      <catalogno label='Columbia' number='CPK 1181'\n                 format='LP' country='Korea'/>\n      <catalogno label='Sony/CBS' number='Legacy CK 40585'\n                 format='CD'/>\n\n      <personnel>\n        <player name='Dave Brubeck' instrument='piano'/>\n        <player name='Paul Desmond' instrument='alto sax'/>\n        <player name='Eugene Wright' instrument='bass'/>\n        <player name='Joe Morello' instrument='drums'/>\n      </personnel>\n\n      <tracks>\n        <track title='Blue Rondo &agrave; la Turk'\n               credit='Brubeck' timing='6m42s'/>\n        <track title='Strange Meadow Lark'\n               credit='Brubeck'  timing='7m20s' />\n        <track title='Take Five'\n               credit='Desmond'  timing='5m24s' />\n        <track title='Three To Get Ready'\n               credit='Brubeck'  timing='5m21s' />\n        <track title=\"Kathy's Waltz\"\n               credit='Brubeck'  timing='4m48s' />\n        <track title=\"Everybody's Jumpin'\"\n               credit='Brubeck'  timing='4m22s' />\n        <track title='Pick Up Sticks'\n               credit='Brubeck'  timing='4m16s' />\n      </tracks>\n\n      <notes author=\"unknown\">\n        Possibly the DBQ's most famous album,\n        this contains\n        <trackref link='#3'>Take Five</trackref>,\n        the most famous jazz track of that period.\n        These experiments in different time\n        signatures are what Dave Brubeck is most\n        remembered for.  Recorded Jun-Aug 1959\n        in NYC.  See also the sequel,\n          <albumref link='cbs-timefurthout'>\n            Time Further Out</albumref>.\n      </notes>\n    </album>\n\n    Figure 1: An example XML document.\n\n1.3  Representing XML in Haskell\nThis paper is about processing XML using the functional language Haskell.1 Modern functional languages are well-equipped to deal with tree-structured data, so one expects the language to be a good fit for the application. Even so, a key issue is just how to represent documents, and in particular how to reconcile the DTD datatype definitions included in XML documents with the data types that can be defined in Haskell. We have investigated two complementary approaches:\n\n    (1) Define an internal data structure that represents contents of any XML document, independent of all DTDs.\n    (2) Given the DTD for some XML documents of interest, systematically derive definitions for internal Haskell data types to represent them. These definitions are closely based on the specific DTD. \n\nAdvantages of (1) include genericity and function-level scripting. Generic applications handle a wide class of XML documents, not just those sharing a specific DTD. One example of a completely generic application is searching documents to extract contents matching some pattern. Our Xtract2 is an interpreter for a regular XML query language.\n\nThe term `generic' also applies to applications that make some assumptions about a document's structure but need not know the full DTD,3 for example, a small script to add a ``total'' column to the end of every table (recognised by a particular markup tag) without altering any of the surrounding structure.\n\nBy function-level scripting we mean that the programmer does not have to be concerned with details of programming over data structures. All details of data structure manipulation can be hidden in a library of high-level combinators. In effect, combinatory expressions serve as an extensible domain-specific language.\n\nAdvantages of (2) include stronger typing and fuller control. A well-formed XML document is further said to be valid if it conforms to a stated DTD. By establishing a correspondence between DTDs and Haskell types, the concept of validity can be extended to include applications that process documents. Not only is there a static guarantee that applications cannot fail in respect of document structure if the input XML conforms to the stated DTD; any XML output produced via a DTD-derived type is guaranteed to be valid. With direct access to the DTD-specific data structure, the programmer has fuller control over how computation is done. They can use a full repertoire of programming techniques with the safeguard that type-checked Haskell will automatically produce XML that is valid in respect of a specified DTD.\n\nBoth approaches rely on a toolkit of more basic components for processing XML documents in Haskell: for instance, a parser and pretty-printer. These supporting components are implemented using existing combinator libraries [7, 8].\n\n1.4  Sections following\n§2 develops the approach using a generic representation and a combinator library, including an illustrative application. §3 develops the alternative based on translation between DTDs and Haskell data types. §4 discusses some pros and cons of the two approaches based on our experience implementing and using both. §5 discusses related work; §6 offers some conclusions and suggestions for further work.\n2  Generic combinators\nIn this section, we begin with a generic representation for the contents of XML documents, excluding any DTD. We introduce content filters as a suitable basic type for functions processing this representation, and combinators for putting such filters together. A complete table of basic filters is given in Figure 2, and of combinators and their definitions in Figure 3. An example program is shown in Figure 4. One expected property of a fitting set of combinators is that they satisfy algebraic laws; a table of laws satisfied by our combinators is given in Figure 6.\n\n2.1  Documents and transformations\nData modelling\n\n    data Element = Elem Name [Attribute] [Content]\n    data Content = CElem Element\n                 | CText String\n\nBecause functional languages are good at processing tree-structured data, there is a natural fit between the XML document domain and Haskell tree datatypes. In simplified form, the main datatypes which model an XML document are Element and Content, whose definitions are mutually recursive, together forming a multi-branch tree structure.\n\nThe filter type\n\n    type CFilter = Content -> [Content]\n\nOur basic type for all document processing functions is the content filter, which takes a fragment of the content of an XML document (whether that be some text, or a complete tagged element), and returns some sequence of content. The result list might be empty, it might contain a single item, or it could contain a large collection of items.\n\nSome filters are used to select parts of the input document, and others are used to construct parts of the output document. They all share the same basic type, because when building a new document, the intention is to re-use or extract information from parts of the old document. Where the result of a filter is either empty or a singleton, the filter can sometimes be thought of as a predicate, deciding whether or not to keep its input.\n\nProgram wrapper\n\n    processXmlWith :: CFilter -> IO ()\n\nWe assume a top-level wrapper function, which gets command-line arguments, parses an XML file into the Content type, applies a filter, and pretty-prints the output document. The given filter is applied to the top-level enclosing element of the document.\n\nBasic filters\nA complete list of predefined filters is shown in Figure 2. The simplest possible filters: none takes any content and returns nothing; keep takes any content and returns just that item. Algebraically, these are the zero and unit filters.\n\n    Predicates\n      \tnone, \t  \tzero/failure\n      \tkeep, \t  \tidentity/success\n      \telm, \t  \ttagged element?\n      \ttxt \t  \tplain text?\n      \t  \t:: CFilter\n      \ttag, \t  \tnamed element?\n      \tattr \t  \telement has attribute?\n      \t  \t:: String -> CFilter\n      \tattrval \t  \telement has attribute/value?\n      \t  \t:: (String,String) -> CFilter\n     \n    Selection\n      \tchildren \t  \tchildren of element\n      \t  \t:: CFilter\n      \tshowAttr, \t  \tvalue of attribute\n      \t(?) \t  \tsynonym for showAttr\n      \t  \t:: String -> CFilter\n     \n    Construction\n      \tliteral, \t  \tbuild plain text\n      \t(!) \t  \tsynonym for literal\n      \t  \t:: String -> CFilter\n      \tmkElem \t  \tbuild element\n      \t  \t:: String -> [CFilter] -> CFilter\n      \tmkElemAttrs \t  \tbuild element with attributes\n      \t  \t:: String -> [(String,CFilter)]\n      \t  \t-> [CFilter] -> CFilter\n      \treplaceTag \t  \treplace element's tag\n      \t  \t:: String -> CFilter\n      \treplaceAttrs \t  \treplace element's attributes\n      \t  \t:: [(String,CFilter)] -> CFilter\n\n    Figure 2: Basic content filters.\n\n    Predicate and selection filters. The filter elm is a predicate, returning just this item if it is an element, or nothing otherwise.4 Conversely, txt returns this item only if is plain text,5 and nothing otherwise. The filter children returns the immediate children of an element if it has any, or nothing if this content-item is not an element. The filter tag t returns this item only if it is an element whose tag name is the string t. The filter attr a returns this item only if it is an element containing the attribute name a. The filter attrval (a,v) returns this item only if is an element containing the attribute a with the value v.\n\n    Construction filters. The function literal s makes a text content containing just the string s. The function mkElem t fs builds a content element with the tag t; the argument fs is a list of filters, each of which is applied to the current item, and all their results are collected to become the children of the new element. The function mkElemAttrs t avs fs is just like mkElem except that its extra parameter avs is a list of attribute values6 to be attached to the tag.\n\nA useful filter which involves both selection and construction is showAttr a, which extracts the value of the attribute a from the current element and returns just that string as a piece of content.\n\nWhen constructing a new document (e.g. the script in Figure 4 which generates HTML), the mkElem function occurs repeatedly. We define and use a small library of functions such as htable, hrow, and hcol which are just synonyms for particular applications of mkElem and mkElemAttrs to different tagnames, reducing verbosity and making the syntax rather more readable.\n\nAlso for convenience, we define the new operators ? and ! as synonyms for showAttr and literal respectively: they are used in a bracketed postfix notation,7 a style some programmers prefer.\n\n2.2  Combinators\nThe combinators used as intermediate code in compilers can render programs `totally unfit for human consumption' [11]! However, the idea of a combinator library for a specific class of applications is to achieve a form of expression that is natural for the problem. A combinator library should be like a language extension tailored to the problem domain [4]. In this sense, functional languages are extensible, just as XML itself is extensible. The combinators are higher-order operators serving as `glue'[6] to assemble functions into more powerful combinations. We aim to keep the types of component functions as uniform as possible so that any function can be composed with any other. Within the lexical limits of the host language, choice of notation should follow application conventions: in Haskell we can, where appropriate, define new infix operator symbols for combinators.\n\nSo, having defined some basic filters already, in what ways can these usefully be combined into more interesting and complex filters? (See Figure 3.)\n\n      \to, \t  \tIrish composition\n      \t(|||), \t  \tappend results\n      \twith, \t  \tguard\n      \twithout,\t\t  \tnegative guard\n      \t(/>), \t  \tinterior search\n      \t(</), \t  \texterior search\n      \t(|>|) \t  \tdirected choice\n      \t  \t:: CFilter -> CFilter -> CFilter\n     \n      \tf `o` g = concat . map f . g\n      \tf ||| g = \\c-> f c ++ g c\n      \tf `with` g = filter (not.null.g) . f\n      \tf `without` g = filter (null.g) . f\n      \tf /> g = g `o` children `o` f\n      \tf </ g = f `with` (g `o` children)\n      \tf |>| g = f ?> f :> g\n     \n      \tcat \t  \tconcatenate results\n      \t  \t:: [CFilter] -> CFilter\n     \n      \tcat fs = \\c-> concat. map (\\f->f c) fs\n     \n      \tet \t  \tdisjoint union\n      \t  \t:: (String->CFilter) -> CFilter -> CFilter\n     \n      \tf `et` g = (f `oo` tagged elm)\n      \t|>| (g `o` txt)\n     \n      \t(?>) \t  \tif-then-else choice\n      \t  \t:: CFilter -> ThenElse CFilter -> CFilter\n     \n      \tdata ThenElse a = a :> a\n      \tp ?> f :> g = \\c-> if (not.null.p) c\n      \tthen f c else g c\n     \n      \tchip, \t  \t``in-place'' application to children\n      \tdeep, \t  \trecursive search (topmost)\n      \tdeepest,\t\t  \trecursive search (deepest)\n      \tmulti, \t  \trecursive search (all)\n      \tfoldXml \t  \trecursive application\n      \t  \t:: CFilter -> CFilter\n     \n      \tdeep f = f |>| (deep f `o` children)\n      \tdeepest f = (deepest f `o` children) |>| f\n      \tmulti f = f ||| (multi f `o` children)\n      \tfoldXml f = f `o` (chip (foldXml f))\n\n    Figure 3: Filter combinators and their definitions.\n\nThe most important and useful filter combinator is `o`. We call this operator Irish composition, for reasons which should be obvious. It plugs two filters together: the left filter is applied to the results of the right filter. So, for instance, the expression\n\n    text `o` children `o` tag \"title\"\n\nmeans ``only the plain-text children of the current element, provided the current element has the title tag name''.\n\nSome other combinators are as follows. f ||| g is an append operator: it joins the results of f and g sequentially. cat fs is the list generalisation of |||; it concatenates the results of each of the filters from the fs list. f `with` g acts as a guard on the results of f, pruning to include only those which are productive under g. The dual, f `without` g, excludes those results of f which are productive under g. The expression p ?> f :> g is a functional choice operator; if the (predicate) filter p is productive, then the filter f is applied, otherwise g is applied. From this is derived a directed choice operator: f |>| g gives either the results of f, or those of g only if f is unproductive.\n\nGeneralised Path Selectors\nSelection of subtrees by path patterns is familiar to users of the Unix file-system, where such patterns are used to access directory structure, using a / notation to indicate the `containing' relation. Similar patterns are used in XSLT, an XML transformation language [3]. In this connection, we define two path selection combinators /> and </. Both combinators choose subtrees to return based on whether the results of the left filter contain the results of the right filter as children: /> is an `interior' selector, returning the inner structure; </ is an `exterior' selector, returning the outer structure.\n\nAn editing combinator\nAside from predicates, selectors, choice, and constructive filters, there is one very useful combinator which stands in its own category -- an editing combinator. chip f processes the children of an element in-place: the filter f is applied to its children; the results are rebuilt as the new children of that same element.\n\nRecursion\nIt is often useful to express recursive transformations on XML documents: transformations which can be applied at many different levels of the document tree.\n\nOne family of such expressions is useful primarily in selecting a subtree from an arbitrarily deep location, although they can of course be used for editing and filtering as well as selection. The recursive combinator deep f potentially pushes the action of filter f deep inside the document sub-tree. It first tries the given filter on the current item: if it is productive then it stops here, but if no results are returned, then it moves to the children and tries again recursively. When used with a predicate, this strategy searches for the topmost matching elements in the tree. There are variations: deepest searches for the bottommost matching elements; multi returns all matches, even those which are sub-trees of other matches. However, as already noted, the action of these combinators is not restricted to predicates or selectors.\n\nAnother powerful recursion combinator is foldXml: the expression foldXml f applies the filter f to every level of the tree, from the leaves upwards to the root (at least conceptually -- of course lazy evaluation makes this more efficient).\n\n2.3  Example\nThe use of these filters and combinators is illustrated in an example script in Figure 4. This program transforms an <album> element into an HTML document that provides a formatted summary. The HTML output, rendered by the Netscape browser, is illustrated in Figure 5. Such a task might be fairly common in e-commerce applications.\n\nWe now describe some of the salient features of the example.\n\n    (albumf `o` deep (tag \"album\"))\n\nThe script first searches recursively for the topmost element tagged <album>, before applying the filter albumf to it. Thus, it works equally well with any XML source document that contains an <album> element anywhere within it, and (correctly) produces no output for documents which do not contain album data.\n\nThe output document's <HEAD> section contains the artist name and album title separated by a colon. We note that the expression,\n\n    txt `o` children `o` tag \"artist\"\n        `o` children `o` tag \"album\"\n\nwhich grabs the textual content of the <artist> element within the <album> element, is somewhat unwieldy. Moreover its trailing test for the <album> tag is redundant, since the calling filter has already performed that match. The expression can be simplified by using path selectors to:\n\n    keep /> tag \"artist\" /> txt\n\nand this style is used elsewhere in the example. (The algebraic laws in Section 2.5 guarantee that this rewriting is safe.)\n\nSuch expressions make some assumptions about the structure of the data within the <album> element. In this instance, the assumption is that an <artist> element is an immediate child, and that its immediate children include text. If such assumptions prove incorrect for a particular document, the filter is simply unproductive; no error is flagged.\n\nWith a suitable definition, hbody = mkElemAttr \"BODY\" the expression\n\n    hbody  [(\"bgcolor\",(\"white\"!))]   [...]\n\ncan be understood to set the background colour attribute of the <BODY> tag to the literal value white. Notice how the attribute value is itself described by a filter. In this case, the filter is not very exciting, but the later definition of mkLink illustrates the generation of an HTML reference by looking up the value of a supplied link attribute (using the ? filter).\n\nWhen the script is used on the particular document from Figure 1, the output is a re-ordering of the internal components of the input: in the <BODY> part of the output, the <notes> section is selected and transformed by notesf before the <catalogno> elements are processed by the summaryf filter. Although in the absence of a DTD it is impossible to be sure of any input ordering, the script here ensures that the output ordering is consistent.\n\nThe definition of the notesf filter is interesting because it makes fewer assumptions about the content of a <notes> structure, and in addition it preserves the input ordering. The chained if-then-else choice within the recursive foldXml combinator causes all internal structure of the <notes> element to be retained except for the replacement of <trackref>s by emphasised text, and <albumref>s by HTML links.\n\nOne of the most striking features of the example as a whole is how selection and testing of old content and construction of new content are uniform, and can be combined almost interchangeably.\n\nWe will return to the treatment of <catalogno> elements in Section 2.4 after introducing some extra labelling combinators.\n\n    module Main where\n    import Xml\n    main =\n      processXmlWith (albumf `o` deep (tag \"album\"))\n    albumf =\n      html\n        [ hhead\n          [ htitle\n            [ txt `o` children `o` tag \"artist\"\n                  `o` children `o` tag \"album\"\n            , literal \": \"\n            , keep /> tag \"title\" /> txt\n            ]\n          ]\n        , hbody [(\"bgcolor\",(\"white\"!))]\n          [ hcenter\n              [ h1 [ keep /> tag \"title\" /> txt ] ]\n          , h2 [ (\"Notes\"!) ]\n          , hpara [ notesf `o` (keep /> tag \"notes\") ]\n          , summaryf\n          ]\n        ]\n    notesf =\n      foldXml (txt            ?> keep            :>\n               tag \"trackref\" ?> replaceTag \"EM\" :>\n               tag \"albumref\" ?> mkLink          :>\n               children)\n    summaryf =\n      htable [(\"BORDER\",(\"1\"!))]\n        [ hrow [ hcol [ (\"Album title\"!) ]\n               , hcol [ keep /> tag \"title\" /> txt ]\n               ]\n        , hrow [ hcol [ (\"Artist\"!) ]\n               , hcol [ keep /> tag \"artist\" /> txt ]\n               ]\n        , hrow [ hcol [ (\"Recording date\"!) ]\n               , hcol [ keep />\n                           tag \"recordingdate\" /> txt ]\n               ]\n        , hrow [ hcola [ (\"VALIGN\",(\"top\"!)) ]\n                       [ (\"Catalog numbers\"!) ]\n               , hcol\n                 [ hlist\n                   [ catno `oo`\n                      numbered (deep (tag \"catalogno\"))\n                   ]\n                 ]\n               ]\n        ]\n    catno n =\n      mkElem \"LI\"\n        [ ((show n++\". \")!),  (\"label\"?),  (\"number\"?)\n        , (\" (\"!),  (\"format\"?),  (\")\"!) ]\n    mkLink =\n      mkElemAttr \"A\" [ (\"HREF\",(\"link\"?)) ]\n        [ children ]\n\n    Figure 4: An example document-processing script using the generic filter combinators.\n\n    picture of browser\n\n    Figure 5: The HTML results of the example script, rendered by a browser.\n\n2.4  Labellings\nOne feature that is occasionally useful is the ability to attach labels to items in a sequence, for instance, to number a list of items, or to treat the first/last item of a list differently from the other items. For this purpose, the library provides special labelling combinators. We choose to introduce a new type:\n\n  type LabelFilter a = Content -> [ (a,Content) ]\n\nA LabelFilter is like a CFilter except it attaches a label to each of its results. We might have chosen to fold label values inside the Content type, to yield a uniform CFilter type, but keeping the labels separate allows them to be of completely polymorphic type: a label could even be another filter for example.\n\nThere are several common labelling functions:\n\n  numbered     :: CFilter -> LabelFilter Int\n  interspersed :: a -> CFilter -> a\n                                 -> LabelFilter a\n  tagged       :: CFilter -> LabelFilter String\n  attributed   :: CFilter ->\n                    LabelFilter [(String,String)]\n\nThese labelling functions lift a CFilter to the LabelFilter type: numbered f transforms the ordinary filter f into a new filter that attaches integers (from 1 upwards) to the results of f; interspersed a f z attaches the label a to all of the results of f except the last, which gets the label z; tagged f labels every tagged element with its tag name (and non-elements with the empty string); attributed f labels every tagged element with its attribute/value pairs (and non-elements with the empty list).\n\n  `oo` :: (a->CFilter) -> LabelFilter a -> CFilter\n\nThe combinator `oo` is a new form of composition which drops a LabelFilter back to the CFilter type by application of another filter that consumes the label.\n\nThe use of this form of labelling is illustrated by the treatment of <catalogno>s in the example of Figure 4:\n\n  catno `oo` numbered (deep (tag \"catalogno\"))\n\nFirst, the desired elements are extracted from their topmost positions in the tree, then they are given numeric labels, and finally the catno filter incorporates the label into some generated text. Another example can be seen in the definition of the `et` combinator in Figure 3. (`et` combines a filter f on elements with a filter g on text. f pattern-matches against tagnames -- the tagnames are extracted by the labelling function tagged.)\n\nFurthermore, it is possible to combine labellings. The `x` combinator glues two labelling functions together, pairing the labels they produce.\n\n  `x` :: (CFilter->LabelFilter a)\n           -> (CFilter->LabelFilter b)\n           -> (CFilter->LabelFilter (a,b))\n\n2.5  Algebraic laws of combinators\nWe briefly show how combinators are defined in such a way that various algebraic laws hold. The complete set of laws is given in Figure 6.\n\n      \tIrish composition\n    f `o` (g `o` h) = (f `o` g) `o` h\t\t  \tassociativity\n    none `o` f = f `o` none = none\t\t  \tzero\n    keep `o` f = f `o` keep = f\t\t  \tidentity\n     \n      \tGuards\n    f `with` keep = f \t  \tidentity\n    f `with` none = none `with` f = none\t\t  \tzero\n    (f `with` g) `with` g = f `with` g\t\t  \tidempotence\n    (f `with` g) `with` h\n    = (f `with` h) `with` g\t\t  \tpromotion\n    (f `o` g) `with` h\n    = (f `with` h) `o` g\t\t  \tpromotion\n     \n    f `without` keep = none `without` f\n    = none\t\t  \tzero\n    f `without` none = keep\t\t  \tidentity\n    (f `without` g) `without` g\n    = f `without` g\t\t  \tidempotence\n    (f `without` g) `without` h\n    = (f `without` h) `without` g\t\t  \tpromotion\n    (f `o` g) `without` h\n    = (f `without` h) `o` g\t\t  \tpromotion\n     \n      \tPath selectors\n    f /> (g /> h) = (f /> g) /> h\t\t  \tassociativity\n    none /> f = f /> none = none\t\t  \tzero\n    keep /> f = f `o` children\t\t  \t \n    f /> keep = children `o` f\t\t  \t \n    keep /> keep = children\t\t  \t \n    none </ f = f </ none = none\t\t  \tzero\n    f </ keep = f `with` children\t\t  \t \n    (f </ g) </ g = f </ g\t\t  \tidempotence\n    (f </ g) /> g = f /> g\t\t  \tidempotence\n     \n    (f /> g) </ h = f /> (g </ h)\t\t  \tpromotion\n    (f </ g) </ h = (f </ h) </ g \t  \tpromotion\n    f `o` (g /> h) = g /> (f `o` h)\t\t  \tpromotion\n    (f /> g) `o` h = (f `o` h) /> g\t\t  \tpromotion\n    (f /> g) `with` h = f /> (g `with` h) \t  \tpromotion\n    (f </ g) `with` h = (f `with` h) </ g \t  \tpromotion\n     \n      \tDirected choice\n    (f |>| g) |>| h = f |>| (g |>| h)\t\t  \tassociativity\n    keep |>| f = keep\t\t  \t \n    none |>| f = f |>| none = f\t\t  \tidentity\n    f |>| f = f\t\t  \tidempotence\n     \n      \tRecursion\n    deep keep = keep\t\t  \tsimplification\n    deep none = none\t\t  \tsimplification\n    deep children = children\t\t  \tsimplification\n    deep (deep f) = deep f\t\t  \tdepth law\n     \n      \tMisc\n    elm |>| txt = txt |>| elm = keep\t\t  \tcompleteness\n    elm `o` txt = txt `o` elm = none\t\t  \texcl. middle\n    children `o` elm = children\t\t  \t \n    children `o` txt = none\t\t  \t\n\n    Figure 6: Algebraic laws of combinators.\n\nGiving all content filters the same type maximises the usefulness of combinators for plugging together functions of this type. However, it is still helpful to identify subclasses of content filters that offer extra guarantees. Two examples of such classes are:\n\n    A predicate p has the property that p c always gives as result either [c] or [].\n    A selector s has the property that s c always gives as result a sequence of contents taken from c. Resulting items do not overlap, and the result sequence respects the order in which the contents were found in c. \n\nSo a predicate is a selector, but a selector is not necessarily a predicate.\n\nThe `o` form of filter composition could be defined using a Haskell list comprehension\n\n    (f `o` g) c = [c'' | c' <- g c, c'' <- f c']\n\nHowever, we prefer the equivalent higher-order definition f `o` g = concat . map f . g because it is more convenient in algebraic calculation.8 Composition is associative, with none as zero, and keep as identity.\n\nThe `with` form of guarded composition is not associative, but we do have some laws, particularly idempotence. We also have a promotion law about combined uses of `with` and `o`. The dual operator, `without` has parallel laws.\n\nThe /> path selector is associative but </ is not, and there are some idempotence laws for both. Most important however, are the various promotion laws for changing the order of application of />, </, and with.\n\nThe directed choice operator |>| viewed by itself appears to be algebraically sensible, but it does not seem to have useful algebraic properties in connection with other combinators because of its bias towards the left operand. The simpler result-appending combinator ||| could be an alternative to the directed choice operator, and would probably lead to more laws, but it has less `application bite'. A potentially serious problem is that the |||-combination of two selectors is not necessarily a selector.\n\nThe recursion operator deep has some minor laws, one of which, the depth law, is more profound. We have not yet fully investigated the properties of deepest, multi, and foldXml.\n\n\n\n3  Translation of DTDs to Types\n3.1  DTDs\nSo far we have considered document-processing by generic tree transformations, where markup is matched textually at runtime, and no account is taken of any deeper meaning of tags.\n\nHowever, when the DTD for a document is available, the meaning it defines for markup tags can be used to powerful effect. The most basic use is to confirm semantic validity: a stronger notion than mere syntactic well-formedness. A DTD defines a grammar for document content: it specifies a vocabulary of markup tags, and the allowed content and attributes for each tag. Document validation is therefore a straightforward check that the document's structure conforms to the vocabulary and grammar given in the DTD.\n\nXML document validators are readily available. However, we go further and define the idea of valid document processing. A valid processing script is one which produces a valid document as output, given a valid document as input. We achieve this by demonstrating a correspondence between the DTD of a document and the definition of a set of algebraic types in Haskell, and the consequent correspondence between the document's content and a structured Haskell value. Hence, by writing document processing scripts to manipulate the typed Haskell value, the script validation problem is just an instance of normal Haskell type inference.9\n\n    <?xml version='1.0'?>\n    <!DOCTYPE album SYSTEM \"album.dtd\" [\n    <!ELEMENT album (title, artist, recordingdate?,\n                     coverart, (catalogno)+,\n                     personnel, tracks, notes) >\n    <!ELEMENT title #PCDATA>\n    <!ELEMENT artist #PCDATA>\n    <!ELEMENT recordingdate EMPTY>\n        <!ATTLIST recordingdate date CDATA #IMPLIED\n                                place CDATA #IMPLIED>\n    <!ELEMENT coverart (location)? >\n        <!ATTLIST coverart style CDATA #REQUIRED>\n    <!ELEMENT location EMPTY >\n        <!ATTLIST location thumbnail CDATA #IMPLIED\n                           fullsize CDATA #IMPLIED>\n    <!ELEMENT catalogno EMPTY >\n        <!ATTLIST\n              catalogno\n                  label CDATA #REQUIRED\n                  number CDATA #REQUIRED\n                  format (CD | LP | MiniDisc) #IMPLIED\n                  releasedate CDATA #IMPLIED\n                  country CDATA #IMPLIED>\n    <!ELEMENT personnel (player)+ >\n    <!ELEMENT player EMPTY >\n        <!ATTLIST player name CDATA #REQUIRED\n                          instrument CDATA #REQUIRED>\n    <!ELEMENT tracks (track)* >\n    <!ELEMENT track EMPTY>\n        <!ATTLIST track title CDATA #REQUIRED\n                        credit CDATA #IMPLIED\n                        timing CDATA #IMPLIED>\n    <!ELEMENT notes (#PCDATA | albumref | trackref)* >\n        <!ATTLIST notes author CDATA #IMPLIED>\n    <!ELEMENT albumref #PCDATA>\n        <!ATTLIST albumref link CDATA #REQUIRED>\n    <!ELEMENT trackref #PCDATA>\n        <!ATTLIST trackref link CDATA #IMPLIED>\n    ]>\n\n    Figure 7: An example DTD.\n\n    module AlbumDTD where\n\n    data Album = \n        Album Title Artist (Maybe Recordingdate)\n              Coverart [Catalogno] Personnel\n              Tracks Notes\n    newtype Title = Title String\n    newtype Artist = Artist String\n    newtype Recordingdate =\n                    Recordingdate Recordingdate_Attrs\n    data Recordingdate_Attrs = Recordingdate_Attrs {\n        date :: Maybe String,\n        place :: Maybe String }\n    newtype Coverart = Coverart (String, Maybe Location)\n    newtype Location = Location Location_Attrs\n    data Location_Attrs = Location_Attrs {\n        thumbnail :: Maybe String,\n        fullsize  :: Maybe String }\n    newtype Catalogno = Catalogno Catalogno_Attrs\n    data Catalogno_Attrs = Catalogno_Attrs {\n        label :: String,\n        number :: String,\n        format :: Maybe Format,\n        releasedate :: Maybe String,\n        country :: Maybe String }\n    data Format = CD | LP | MiniDisc\n    newtype Personnel = Personnel [Player]\n    newtype Player = Player Player_Attrs\n    data Player_Attrs = Player_Attrs {\n        name :: String,\n        instrument :: String }\n    newtype Tracks = Tracks [Track]\n    newtype Track = Track Track_Attrs\n    data Track_Attrs = Track_Attrs {\n        title :: String,\n        credit :: Maybe String,\n        timing :: Maybe String }\n    newtype Notes = Notes (Maybe String, [Notes_])\n    data Notes_ = \n        Notes_Str String\n      | Notes_Albumref Albumref\n      | Notes_Trackref Trackref\n    newtype Albumref = Albumref (String,String)\n    newtype Trackref = Trackref (Maybe String,String)\n\n    Figure 8: The example DTD translated to Haskell types.\n\n3.2  DTD translations.\nAn example DTD for the document shown earlier is given in Figure 7. The immediate features to note are: (1) For every element, there is a specification of allowed inner elements (ELEMENT declaration), and possibly also a specification of allowed attribute values (ATTLIST declaration). (2) For inner content, the grammar allows sequence (commas), choice (vertical bar), optionality (question mark), and repetition (star or plus). (3) Where the inner content declaration allows free text (#PCDATA), choice between text and other elements is permitted, but sequencing of those elements is not permitted. (4) In attribute lists, some values are mandatory (#REQUIRED) and some are optional (#IMPLIED); attribute values can either be unconstrained strings (CDATA) or a member of some pre-defined set of string values.\n\nThere seem to be some obvious correspondences between this very restricted form of type language and the richer type language of Haskell. Each element declaration is roughly speaking a new datatype declaration. Sequence is like product types (i.e. single-constructor values). Choice is like sum types (i.e. multi-constructor values). Optionality is just a Maybe type. Repetition is lists.\n\nAttribute lists also have a translation: because they are unordered and accessed by name, Haskell named-fields look like a good representation. Optionality can again be expressed as Maybe types. Attribute values that are constrained to a particular value-set can be modelled by defining a new enumeration type encompassing the permitted strings.\n\n3.3  Implementation\nThese rules are formalised in the appendix (Figure 9). An implementation of these rules (with some additional rules to eliminate redundancy) translated the DTD in Figure 7 into the Haskell type declarations shown in Figure 8.\n\nAlso needed, along with the type declarations, are functions which read and write values of these types to and from actual XML documents. These are generated automatically from the type declarations alone. Using an appropriate set of pre-defined type classes, we derive a new instance for each generated type using a tool like DrIFT [16].\n\n3.4  Discussion\nAlthough this type-based translation looks straightforward, it turns out that there are several tricky issues.\n\nFirst, the type translation may only use datatypes and newtypes, never type synonyms. This is a result of needing to write values out as XML -- a type synonym in Haskell is indistinguishable from the type it abbreviates, but the generated types must be distinct in order to be able to re-introduce enclosing start and end tags with the correct markup.\n\nA separate type is introduced for each collection of attributes. Hence, an element is represented by a pairing of the attributes and the content. Where a tagged element directly contains an optional type or a sequence of types which are themselves sum-types, it is necessary to interpose a separate Haskell type, e.g. Notes contains a [Notes_] where the auxiliary type Notes_ has three alternatives.\n\nNaming is a big issue. Case matters in XML, so a <tag> differs from a <TAG> and attribute attr differs from Attr. In Haskell however, types must begin with upper-case, and field-names must begin with lower-case. Where auxiliary types are necessary, we have chosen to append an underscore character to the name. All of these factors impose restrictions on the use of this translation, due to the potential name conflicts.\n\nFurthermore, there is a mismatch between Haskell's named fields and the attribute naming/scoping rules in XML. In XML, different elements may have attributes of the same name and type, whereas Haskell's named fields are restricted to use within a single type. A system of typed extensible records [5] would be a much better fit.\n\nDespite these problems in expressing DTDs within the Haskell typesystem, the latter is very much more powerful than DTDs -- for instance, DTDs have no notion of polymorphism. Indeed, there are frequent occasions when DTD writers resort to textual macros10 to indicate more detailed structuring than DTDs permit (including polymorphism and qualified typing), even though such implicit structuring cannot be validated by XML tools. It is significant to note the XML community's recognition of these limitations of DTDs -- recent proposals for schemas11 address the question of richer typing in a more disciplined manner.\n\nOne area in which the type system of Haskell in particular (as opposed to other functional languages) is exploited is type classes. This systematic overloading mechanism is very useful for codifying the I/O conversions.\n\n4  Pros and cons of the two schemes\n4.1  Combinators\nCompared with the mainstream solution for XML processing, namely new domain-specific languages for expressing and scripting transformations, the combinator approach has several advantages:\n\nEase of extension and variation\nScripting languages sometimes lack useful facilities, or provide them in convoluted ways. Extending the language is difficult. A combinator library, however, can be enlarged comparatively straightforwardly -- the definitions are accessible, and most are short and simple.\n\nComputational power\nScripting languages tend to offer either a very limited expression language, or a hook into a programming system at a completely different level of abstraction. But if XML scripts are programs in a language such as Haskell, the full power of the native language is immediately available.\n\nAbstraction, generality and reuse\nAlmost any pattern occurring in a combinator program can be isolated and defined as a separate re-usable idea [6]. This also applies at the application level, where common ideas from similar applications might easily be defined in a higher-level library. This form of re-use makes program development much quicker and less error-prone.\n\nLaws for reasoning about scripts\nThe semantics of a scripting language are often defined by illustration. So it is hard to reason with confidence about the meanings of scripts. Is A just a stylistic variation of B or are there inputs for which the two could give different results? But when the semantics of scripts can be defined in terms of the equations for the combinators, properties such as associativity and distribution can often be demonstrated simply.\n\nImplementation for free\nDoes a scripting language have an interactive interpreter? A compiler? A type-checker? A profiler? All these things are immediately available to XML scripts directly expressed as Haskell programs.\n\nOf course, there are disadvantages too.\n\nDistance from target language\nXSLT [3] has the property that a script is an expression in the target language: it uses exactly the XML syntax for building new content. Combinator-based scripts must use a different syntax due to the underlying language. The linguistic gap might cause confusion and increase learning costs.\n\nLiving in an unfamiliar world\nCombinator programs look like scripts in a small domain-specific language. Writers may be beguiled by this apparent simplicity, make a small error, and drop into an unknown corner of Haskell. Error messages may be incomprehensible, or worse, the script might work but do something utterly strange.\n\n4.2  Type-based translation\nSome of the advantages of the fully-typed representation of XML documents have already been mentioned.\n\nValidity\nThe ability for the system to spot errors automatically, not just in the data, but in the program, and also to prevent the generation of incorrect document markup.\n\nDirect programming style\nFunctional languages encourage the use of pattern-matching (binding values to variables) on the left-hand-side of equations. However, using higher-order combinators, data structures tend not to be mentioned in equations at all. The DTD translation approach is much more in keeping with the pattern-binding style, which sometimes leads to shorter programs! Whereas with combinators, it is sometimes necessary to re-traverse the same selection path with slight variations, the pattern-binding gives direct access for free.\n\n\nDisadvantages are:\n\nHigh startup cost\nBefore scripting document transformations, it is necessary to acquire, check, and process the DTD. Although the generation of Haskell types is automated, few people are familiar enough with DTDs to be able to start using them immediately. They require careful study and understanding before correct scripts can be written and the initial investment of effort pays off.\n\nIncomplete type model\nThe grammar of DTDs is small and restrictive compared to the sophisticated type systems available in functional languages. Better means of type-specification in XML are still under development. In the meantime, there is little scope for using the full power of features like polymorphism.\n\n5  Related Work\nXML Processing\nThere are infant processing languages surrounding XML. Of most interest here are:\n\n    XSLT [3] (eXtensible Style Language for Transformation) is a W3C-proposed declarative language for expressing a limited form of transformations on XML documents, originally intended for rendering to a layout-based format, e.g. HTML, PostScript, etc., but now widely used for XML->XML transformations.\n    DSSSL [12] (Document Style Semantics and Specification Language) is a mature ISO standard with no complete implementations. It is similar in essence to XSLT, but deals with full SGML input, and is based on Scheme. \n\nNot many functional language researchers are visibly engaged in XML-related work, but two other toolkits for XML-processing are Christian Lindig's XML parser in O'Caml12 and Andreas Neumann's validating XML parser in SML13 . To our knowledge, neither of these provides transformation capabilities in either a combinator style or a type-translation style. Philip Wadler has written a short formal semantics of XSL selection patterns [15].\n\nApplication-based combinators\nParsing is the most extensively studied application for combinator libraries. Since the original treatment by Burge [2], there have been many variations on the theme. Swierstra and Duponcheel's method incorporating on-the-fly grammar analysis and error-correction is a notable recent example [10]. We hope it may be possible to incorporate DTD-analysis in our combinators in a similar style.\n\nAlthough many other libraries of application combinators have been devised, the general design principles for such libraries are scarcely referred to in the literature. Hughes' exposition of a design for pretty-printing combinators [7] is a unique resource in this respect, and we have yet to exploit it fully.\n\nTree-processing operators\nAn earlier version of this paper prompted more than one pointer to the work of Eelco Visser and colleagues [13]. Their motivating application is specification of strategies for program optimisation, treated as rewriting over expression trees. The result of applying a strategy is either a single term or failure: non-determinism is achieved by backtracking but only the first success is computed, whereas we deal in `lists of successes' [14]. Their operators for combining strategies include composition, directed choice, and an explicit ľ operator for recursion. They have several operators for specifying transformation of child subterms: some are not so relevant to XML where subtree position and arity are less often fixed than in program syntax; however, one of the most frequently applied operators is close to our foldXml. Most significantly, Visser et. al. achieve great expressive power by decomposing the match/re-build stages of rewriting, and introducing explicit environments by which these stages communicate. This makes it possible to deal with subtleties such as variable bindings in the program terms under transformation. Although the structure of XML is simpler than the structure of a programming language, our library could benefit from the addition of support for binding variables when matching subtrees.\n\nProgramming functions explicitly over the XML data-structure, without the abstraction of combinators, Haskell pattern matching provides bindings for subtrees. But only at a fixed (small) depth from the root, beneath an explicitly stated pattern of constructors. Mohnen [9] defines an extension of the pattern language for deep matching: variables in a pattern can be bound to subterms at arbitrary depth inside the original term. The result of the match includes a context function representing the original subject term with `holes' at the sites of matching; subterms for these holes are supplied by arguments to the function. So contexts are the complements of environments. Mohnen shows how his matching extension simplifies various tree-processing tasks, and also how it can be translated into standard Haskell. This work could provide one component of a hybrid solution, with DTD-specific representation and generic forms of traversal and matching.\n\nVisser et. al. [13] also discuss several other approaches to the tree transformation problem.\n\n6  Conclusions and Future Work\nIn our experience, Haskell is a very suitable language for XML processing. For generic applications, a small set of combinators designed with algebraic properties in mind can be powerful enough and flexible enough to describe a full range of selection, testing, and construction operations in a uniform framework. For applications where the DTD is fixed, a tool deriving corresponding types and associated I/O routines turns XML processing into Haskell programming over typed data structures, and the Haskell typechecker validates scripts.\n\nHowever, there is plenty of scope for further work, in several directions:\n\nGenerality of combinators\nThough we have had generality as a design aim for our present combinator library there is scope for generalising it further.\n\n    Wider functionality. Most content filters in our current library are either pure selectors (with results that are sequences of sub-trees from the full document tree) or pure constructors (creating document content from values of other types). The design could usefully be extended to include a more general class of deletion operations in which sub-trees can be thinned and pruned in various ways. More general still are combinators for editing and transforming, where some of the ideas in Visser's work could usefully be transferred.\n    Multiple inputs and outputs. An interesting extension of single-document scripting is the handling of multiple documents. Producing more than one output document is no great problem. But it is far more challenging to design appropriate combinators for dealing with several inputs.\n    More general types. The labelling scheme has proved useful for some applications, but the need for a separate LabelFilter type is a blemish. We hope to generalise the CFilter type to incorporate LabelFilter as a special case. By making the CFilter type parametric it might even be possible to incorporate the type-translation of DTDs within the combinator framework. \n\nEfficiency of combinators\nThe current combinator library is quite usable, but here are some possible routes to greater efficiency.\n\n    Algebraic normalisation So far we have merely established that laws hold, and occasionally appealed to them when writing scripts. The implementation simply defines the combinators by their specifying equations. Instead, laws could be exploited at the implementation level. Following Hughes [7], we have in mind an implementation that automatically reduces all combinations to a normal form, that is the least expensive equivalent computationally.\n    Space-efficient formulation Some lazy functional programs that process trees in pre-order left-to-right fashion can be formulated to run in log(N) space. The part of the tree that is held in memory corresponds to a path from the root to some node that is currently the focus of computation: to the left are `garbage' subtrees already processed, to the right are subtrees not yet evaluated. However, our current combinators have not been formulated to guarantee this sort of space behaviour, even in favourable cases. This problem might be tackled by the normalisation approach.\n    DTD-aware combinators The current combinator library just ignores DTDs. Combinators that maintain DTD information might, for example, achieve far more efficient search in some cases by pruning branches bound to fail. They could also be used to produce first-class XML documents as the results of queries, not just raw extracts of unknown type. As we have already noted, DTDs could perhaps be attached as labels in the sense of §2.4: either as explicit values or implicitly in type information. \n\nRelations between DTDs\nAs we have seen, in the DTD-directed approach with known fixed DTDs for input and output, validation translates to static type-checking; whereas generic combinators could in principle acquire and compute DTDs dynamically. These represent extremes with disadvantages of inflexibility on the one hand and some insecurity on the other. There are many other ways of handling relations between DTDs. For example:\n\n    Polymorphic and higher-order scripts. The generic approach would gain security if one could infer a DTD->DTD function. By analogy with functional programs it is then natural to assign scripts polymorphic and higher-order DTDs, making explicit their degree of genericity.\n\n    Inclusion between DTDs. This has been implicitly assumed already, but has practical importance in its own right. As stock DTDs are refined, XML documents will inhabit a hierarchy of specialisation. Given several similar DTDs, one would like to derive a DTD for a virtual common root (intersection) or common descendent (union). This goes well beyond the abilities of current type-inference systems, but would make a useful addition to our functional toolkit for XML processing. \n\nAcknowledgements\nCanon Research Centre (Europe) Ltd. suggested this line of work and funded it. Philip Wadler, Christian Lindig, and Joe English gave very helpful comments on an earlier draft of this paper and software. Several anonymous referees also gave useful advice.\n\nReferences\n\n[1]\n    Tim Bray, Jean Paoli, and C.M. Sperberg-Macqueen. Extensible Markup Language (XML) 1.0 (W3C Recommendation). http://www.w3.org/TR/REC-xml, WWW Consortium, February 1998.\n\n[2]\n    W H Burge. Recursive Programming Techniques. Addison-Wesley, 1975.\n\n[3]\n    James Clark (ed). XSL Transformations (Working Draft). http://www.w3.org/TR/WD-xslt, WWW Consortium, April 1999.\n\n[4]\n    Jon Fairbairn. Making form follow function: An exercise in functional programming style. Software -- Practice and Experience, 17(6):379--386, June 1987.\n\n[5]\n    Benedict R Gaster. Records, Variants, and Qualified Types. Dept of Computer Science, University of Nottingham, PhD Thesis, 1998.\n\n[6]\n    John Hughes. Why functional programming matters. Computer Journal, 32(2), April 1989.\n\n[7]\n    John Hughes. The design of a pretty-printing library. In 1st Intl. School on Advanced Functional Programming, pages 53--96. Springer LNCS Vol. 925, 1995.\n\n[8]\n    Graham Hutton and Erik Meijer. Monadic parsing in Haskell. Journal of Functional Programming, 8(4), July 1998.\n\n[9]\n    Markus Mohnen. Context patterns in Haskell. In Workshop on Implementation of Functional Languages, pages 41--57. Springer LNCS Vol 1268, September 1996.\n\n[10]\n    Doaitse Swierstra and Luc Duponcheel. Deterministic error-correcting combinator parsers. In 2nd Intl. School on Advanced Functional Programming, pages 184--207. Springer LNCS Vol 1129, August 1996.\n\n[11]\n    David A Turner. A new implementation technique for applicative languages. Software -- Practice and Experience, 9(1):31--50, January 1979.\n\n[12]\n    Unknown. Document Style Semantics and Specification Language (DSSSL) (Final Draft). http://occam.sjf.novell.com/dsssl/dsssl96/, Novell Publications, 1996.\n\n[13]\n    Eelco Visser, Zine el Abidine Benaissa, and Andrew Tolmach. Building program optimisers with rewrite strategies. In International Conference on Functional Programming, pages 13--26. ACM Press, September 1998.\n\n[14]\n    Philip Wadler. How to replace failure by a list of successes. In Functional Programming Languages and Computer Architecture, pages 113--128. Springer LNCS Vol 201, September 1985.\n\n[15]\n    Philip Wadler. A formal model of pattern matching in XSL. Technical Report http://www.cs.bell-labs.com/~wadler/xsl/, Bell Labs, January 1999.\n\n[16]\n    Noel Winstanley. Reflections on instance derivation. In 1997 Glasgow Functional Programming Workshop. BCS Workshops in Computer Science, September 1997.\n\n    Appendix: DTD translation rules\n    Type declarations\n    T[[<ELEMENT n spec>]] \t= \tnewtype m =\n      \t  \tm (m_Attrs, m_)\n      \t  \tnewtype m_ = D[[spec]] m\n      \t  \twhere m = M[[n]]\n    T[[<ATTLIST n\n    decl0 ... declk>]] \t= \tdata m_Attrs =\n      \t  \tm_Attrs {F[[decl0]]\n      \t  \t, ...\n      \t  \t,F[[ declk]] }\n      \t  \twhere m = M[[n]]\n      \t  \tA[[decl0]]\n      \t  \t...\n      \t  \tA[[ declk]]\n     \n    RHS of type declarations\n    D[[ ( x0, x1, ..., xk ) ]] m \t= \tC[[ m x0 ... xk ]]\n      \t  \tD'[[ x0 ]] D'[[ x1 ]] ... D'[[ xk ]]\n    D[[ ( x0 | x1 | ... | xk ) ]] m \t= \tC[[ m x0 ]] D'[[ x0 ]]\n      \t  \t| C[[ m x1 ]] D'[[ x1 ]]\n      \t  \t| ...\n      \t  \t| C[[ m xk ]] D'[[ xk ]]\n    D[[ (x)? ]] m \t= \tMaybe D'[[ x ]]\n    D[[ (x)+ ]] m \t= \tList1 D'[[ x ]]\n    D[[ (x)* ]] m \t= \t[ D'[[ x ]] ]\n    D[[ x ]] m \t= \tC[[ m x ]]\n     \n    Inner type expressions\n    D'[[ ( x0, x1, ..., xk ) ]] \t= \t( D'[[ x0 ]] , D'[[ x1 ]]\n      \t  \t, ... D'[[ xk ]] )\n    D'[[ ( x0 | x1 | ... | xk ) ]] \t= \t(OneOfn D'[[ x0 ]] D'[[ x1 ]]\n      \t  \t... D'[[ xk ]] )\n    D'[[ (x)? ]] \t= \t(Maybe D'[[ x ]] )\n    D'[[ (x)+ ]] \t= \t(List1 D'[[ x ]] )\n    D'[[ (x)* ]] \t= \t[ D'[[ x ]] ]\n    D'[[ x ]] \t= \tC[[ x ]]\n     \n    Name mangling\n    C[[ m x0 x1 ... xk ]] \t= \t... unique constructor name\n      \t  \tbased on m\n    M[[ n ]] \t= \t... ensure initial upper-case\n    M'[[ n ]] \t= \t... ensure initial lower-case\n     \n    Named fields\n    F[[ n CDATA #REQUIRED ]]\n      \t= \tM'[[ n ]] :: String\n    F[[ n CDATA #IMPLIED ]]\n      \t= \tM'[[ n ]] :: Maybe String\n    F[[ n (s0|s1|...|sk) #REQUIRED ]]\n      \t= \tM'[[ n ]] :: M[[ n ]]\n    F[[ n (s0|s1|...|sk) #IMPLIED ]]\n      \t= \tM'[[ n ]] :: Maybe M[[ n ]]\n     \n    Constrained attributes\n    A[[ n CDATA ... ]] \t= \t0\n    A[[ n (s0|s1|...|sk) ... ]]\n      \t= \tdata M[[ n ]] =\n      \t  \tM[[ s0 ]] | M[[ s1 ]]\n      \t  \t| ... | M[[ sk ]]\n\n    Figure 9: DTD translation rules.\n\n1\n    The XML toolkit from this paper is available on the WWW at http://www.cs.york.ac.uk/fp/HaXml/ \n2\n    Xtract: a `grep'-like tool for XML documents. http://www.cs.york.ac.uk/fp/Xtract/ \n3\n    In light of the ``XML Namespaces'' recommendation, in effect a mechanism for permitting multiple DTDs, such facilities could be particularly useful. See http://www.w3.org/TR/REC-xml-names \n4\n    The shortened name elm was chosen to avoid a clash with the Standard Prelude function elem. \n5\n    For those familiar with the detail of XML, entity references within the document are treated as plain text. \n6\n    Actually, a list of attribute/filter pairs. Each filter is applied to the current element and the resultant content is flattened to a string value which is assigned to the named attribute. \n7\n    Actually a left-section of the infix operator. Because filters are higher-order, their use is eta-reduced and the rightmost argument disappears from view. \n8\n    Irish composition is in fact just the flipped-argument version of the Kleisi composition operator in the list monad. \n9\n    Well, nearly! Validity also encompasses some other minor checks, for instance that IDREF attributes must be globally unique. \n10\n    That is, parameter entity references. \n11\n    http://www.w3.org/TR/xmlschema-1 for structures, and http://www.w3.org/TR/xmlschema-2 for datatypes. \n12\n    http://www.cs.tu-bs.de/softech/people/lindig/tony.html \n13\n    http://www.informatik.uni-trier.de/ neumann/Fxp/ \n\n    This document was translated from LATEX by HEVEA. \n\n"
      },
      "date": 1665381035193
    },
    {
      "type": "edit",
      "id": "bde9f870ebbd768a",
      "item": {
        "type": "markdown",
        "id": "bde9f870ebbd768a",
        "text": "Haskell and XML: Generic Combinators or Type-Based Translation?\n"
      },
      "date": 1665381043130
    },
    {
      "type": "add",
      "id": "07ad4cedeb66315c",
      "item": {
        "type": "markdown",
        "id": "07ad4cedeb66315c",
        "text": "Malcolm Wallace and Colin Runciman\n"
      },
      "after": "bde9f870ebbd768a",
      "date": 1665381047243
    },
    {
      "type": "add",
      "id": "2e8be84f15deb853",
      "item": {
        "type": "markdown",
        "id": "2e8be84f15deb853",
        "text": "Abstract: We present two complementary approaches to writing XML document-processing applications in a functional language.\n\n\n"
      },
      "after": "07ad4cedeb66315c",
      "date": 1665381056823
    },
    {
      "type": "add",
      "id": "07ae5fd45ef5f330",
      "item": {
        "type": "markdown",
        "id": "07ae5fd45ef5f330",
        "text": "In the first approach, the generic tree structure of XML documents is used as the basis for the design of a library of combinators for generic processing: selection, generation, and transformation of XML trees.\n\nThe second approach is to use a type-translation framework for treating XML document type definitions (DTDs) as declarations of algebraic data types, and a derivation of the corresponding functions for reading and writing documents as typed values in Haskell.\n\nPublished in the Proceedings of the International Conference on Functional Programming, Paris, Sept 1999. ACM Copyright.\n\n1  Introduction\n1.1  Document markup languages\nXML (Extensible Markup Language) [1] is a recent simplification of the older SGML (Standardised Generalised Markup Language) standard that is widely used in the publishing industry. It is a markup language, meaning that it adds structural information around the text of a document. It is extensible, meaning that the vocabulary of the markup is not fixed -- each document can contain or reference a meta-document, called a DTD (Document Type Definition), which describes the particular markup capabilities used.\n\nThe use of XML is not however restricted to the traditional idea of a document. Many organisations are proposing to use XML as an interchange format for pure data produced by applications like graph-plotters, spreadsheets, and relational databases.\n\nHTML (Hyper-Text Markup Language) is one well-known example of an instance of SGML -- every HTML document is an SGML document conforming to a particular DTD. Where XML improves over SGML is in removing shorthand forms that require an application to have knowledge of a document's DTD. For instance, in HTML some markup (such as a numbered list) requires an end marker; other forms (such as paragraphs) have implicit end markers understood when the next similar form starts; and yet other markup (such as in-line images) is self-contained and needs no end marker. An HTML application needs to be aware of the specific kind of markup in order to do the right thing.\n\n1.2  XML document structure\nXML is more regular. All markup has an explicit end marker without exception: every document is well-formed; its nesting structure is syntactically clear. One important consequence is that an XML application does not need to know the meaning or interpretation of all markup expressions -- parts of the document can be selected, re-arranged, transformed, by structure alone rather than by meaning.\n\nAn XML document is essentially a tree structure. There are two basic `types' of content in a document: tagged elements, and plain text. A tagged element consists of a start tag and an end tag, which may enclose any sequence of other content (elements or text fragments). Tagged elements can be nested to any depth, and the document is well-formed if it consists of a single top-level element containing other properly nested elements. Start tags have the syntax <tag>, and end tags </tag>, where tag is an arbitrary name. There is special syntax for an empty element: <tag/> is exactly equivalent to <tag></tag>. The start and end tags for each element contain a tag name, which identifies semantic information about the structure, indicating how the enclosed content should be interpreted. The start tag may also contain attributes, which are simple name/value bindings, providing further information about the element. Figure 1 shows an example XML document, illustrating all these components.\n\n    <?xml version='1.0'?>\n    <!DOCTYPE album SYSTEM \"album.dtd\">\n    <album>\n      <title>Time Out</title>\n      <artist>Dave Brubeck Quartet</artist>\n      <coverart style='abstract'>\n        <location thumbnail='pix/small/timeout.jpg'\n                  fullsize='pix/covers/timeout.jpg'/>\n      </coverart>\n\n      <catalogno label='Columbia' number='CL 1397'\n                 format='LP'/>\n      <catalogno label='Columbia' number='CS 8192'\n                 format='LP'/>\n      <catalogno label='Columbia' number='CPK 1181'\n                 format='LP' country='Korea'/>\n      <catalogno label='Sony/CBS' number='Legacy CK 40585'\n                 format='CD'/>\n\n      <personnel>\n        <player name='Dave Brubeck' instrument='piano'/>\n        <player name='Paul Desmond' instrument='alto sax'/>\n        <player name='Eugene Wright' instrument='bass'/>\n        <player name='Joe Morello' instrument='drums'/>\n      </personnel>\n\n      <tracks>\n        <track title='Blue Rondo &agrave; la Turk'\n               credit='Brubeck' timing='6m42s'/>\n        <track title='Strange Meadow Lark'\n               credit='Brubeck'  timing='7m20s' />\n        <track title='Take Five'\n               credit='Desmond'  timing='5m24s' />\n        <track title='Three To Get Ready'\n               credit='Brubeck'  timing='5m21s' />\n        <track title=\"Kathy's Waltz\"\n               credit='Brubeck'  timing='4m48s' />\n        <track title=\"Everybody's Jumpin'\"\n               credit='Brubeck'  timing='4m22s' />\n        <track title='Pick Up Sticks'\n               credit='Brubeck'  timing='4m16s' />\n      </tracks>\n\n      <notes author=\"unknown\">\n        Possibly the DBQ's most famous album,\n        this contains\n        <trackref link='#3'>Take Five</trackref>,\n        the most famous jazz track of that period.\n        These experiments in different time\n        signatures are what Dave Brubeck is most\n        remembered for.  Recorded Jun-Aug 1959\n        in NYC.  See also the sequel,\n          <albumref link='cbs-timefurthout'>\n            Time Further Out</albumref>.\n      </notes>\n    </album>\n\n    Figure 1: An example XML document.\n\n1.3  Representing XML in Haskell\nThis paper is about processing XML using the functional language Haskell.1 Modern functional languages are well-equipped to deal with tree-structured data, so one expects the language to be a good fit for the application. Even so, a key issue is just how to represent documents, and in particular how to reconcile the DTD datatype definitions included in XML documents with the data types that can be defined in Haskell. We have investigated two complementary approaches:\n\n    (1) Define an internal data structure that represents contents of any XML document, independent of all DTDs.\n    (2) Given the DTD for some XML documents of interest, systematically derive definitions for internal Haskell data types to represent them. These definitions are closely based on the specific DTD. \n\nAdvantages of (1) include genericity and function-level scripting. Generic applications handle a wide class of XML documents, not just those sharing a specific DTD. One example of a completely generic application is searching documents to extract contents matching some pattern. Our Xtract2 is an interpreter for a regular XML query language.\n\nThe term `generic' also applies to applications that make some assumptions about a document's structure but need not know the full DTD,3 for example, a small script to add a ``total'' column to the end of every table (recognised by a particular markup tag) without altering any of the surrounding structure.\n\nBy function-level scripting we mean that the programmer does not have to be concerned with details of programming over data structures. All details of data structure manipulation can be hidden in a library of high-level combinators. In effect, combinatory expressions serve as an extensible domain-specific language.\n\nAdvantages of (2) include stronger typing and fuller control. A well-formed XML document is further said to be valid if it conforms to a stated DTD. By establishing a correspondence between DTDs and Haskell types, the concept of validity can be extended to include applications that process documents. Not only is there a static guarantee that applications cannot fail in respect of document structure if the input XML conforms to the stated DTD; any XML output produced via a DTD-derived type is guaranteed to be valid. With direct access to the DTD-specific data structure, the programmer has fuller control over how computation is done. They can use a full repertoire of programming techniques with the safeguard that type-checked Haskell will automatically produce XML that is valid in respect of a specified DTD.\n\nBoth approaches rely on a toolkit of more basic components for processing XML documents in Haskell: for instance, a parser and pretty-printer. These supporting components are implemented using existing combinator libraries [7, 8].\n\n1.4  Sections following\n§2 develops the approach using a generic representation and a combinator library, including an illustrative application. §3 develops the alternative based on translation between DTDs and Haskell data types. §4 discusses some pros and cons of the two approaches based on our experience implementing and using both. §5 discusses related work; §6 offers some conclusions and suggestions for further work.\n2  Generic combinators\nIn this section, we begin with a generic representation for the contents of XML documents, excluding any DTD. We introduce content filters as a suitable basic type for functions processing this representation, and combinators for putting such filters together. A complete table of basic filters is given in Figure 2, and of combinators and their definitions in Figure 3. An example program is shown in Figure 4. One expected property of a fitting set of combinators is that they satisfy algebraic laws; a table of laws satisfied by our combinators is given in Figure 6.\n\n2.1  Documents and transformations\nData modelling\n\n    data Element = Elem Name [Attribute] [Content]\n    data Content = CElem Element\n                 | CText String\n\nBecause functional languages are good at processing tree-structured data, there is a natural fit between the XML document domain and Haskell tree datatypes. In simplified form, the main datatypes which model an XML document are Element and Content, whose definitions are mutually recursive, together forming a multi-branch tree structure.\n\nThe filter type\n\n    type CFilter = Content -> [Content]\n\nOur basic type for all document processing functions is the content filter, which takes a fragment of the content of an XML document (whether that be some text, or a complete tagged element), and returns some sequence of content. The result list might be empty, it might contain a single item, or it could contain a large collection of items.\n\nSome filters are used to select parts of the input document, and others are used to construct parts of the output document. They all share the same basic type, because when building a new document, the intention is to re-use or extract information from parts of the old document. Where the result of a filter is either empty or a singleton, the filter can sometimes be thought of as a predicate, deciding whether or not to keep its input.\n\nProgram wrapper\n\n    processXmlWith :: CFilter -> IO ()\n\nWe assume a top-level wrapper function, which gets command-line arguments, parses an XML file into the Content type, applies a filter, and pretty-prints the output document. The given filter is applied to the top-level enclosing element of the document.\n\nBasic filters\nA complete list of predefined filters is shown in Figure 2. The simplest possible filters: none takes any content and returns nothing; keep takes any content and returns just that item. Algebraically, these are the zero and unit filters.\n\n    Predicates\n      \tnone, \t  \tzero/failure\n      \tkeep, \t  \tidentity/success\n      \telm, \t  \ttagged element?\n      \ttxt \t  \tplain text?\n      \t  \t:: CFilter\n      \ttag, \t  \tnamed element?\n      \tattr \t  \telement has attribute?\n      \t  \t:: String -> CFilter\n      \tattrval \t  \telement has attribute/value?\n      \t  \t:: (String,String) -> CFilter\n     \n    Selection\n      \tchildren \t  \tchildren of element\n      \t  \t:: CFilter\n      \tshowAttr, \t  \tvalue of attribute\n      \t(?) \t  \tsynonym for showAttr\n      \t  \t:: String -> CFilter\n     \n    Construction\n      \tliteral, \t  \tbuild plain text\n      \t(!) \t  \tsynonym for literal\n      \t  \t:: String -> CFilter\n      \tmkElem \t  \tbuild element\n      \t  \t:: String -> [CFilter] -> CFilter\n      \tmkElemAttrs \t  \tbuild element with attributes\n      \t  \t:: String -> [(String,CFilter)]\n      \t  \t-> [CFilter] -> CFilter\n      \treplaceTag \t  \treplace element's tag\n      \t  \t:: String -> CFilter\n      \treplaceAttrs \t  \treplace element's attributes\n      \t  \t:: [(String,CFilter)] -> CFilter\n\n    Figure 2: Basic content filters.\n\n    Predicate and selection filters. The filter elm is a predicate, returning just this item if it is an element, or nothing otherwise.4 Conversely, txt returns this item only if is plain text,5 and nothing otherwise. The filter children returns the immediate children of an element if it has any, or nothing if this content-item is not an element. The filter tag t returns this item only if it is an element whose tag name is the string t. The filter attr a returns this item only if it is an element containing the attribute name a. The filter attrval (a,v) returns this item only if is an element containing the attribute a with the value v.\n\n    Construction filters. The function literal s makes a text content containing just the string s. The function mkElem t fs builds a content element with the tag t; the argument fs is a list of filters, each of which is applied to the current item, and all their results are collected to become the children of the new element. The function mkElemAttrs t avs fs is just like mkElem except that its extra parameter avs is a list of attribute values6 to be attached to the tag.\n\nA useful filter which involves both selection and construction is showAttr a, which extracts the value of the attribute a from the current element and returns just that string as a piece of content.\n\nWhen constructing a new document (e.g. the script in Figure 4 which generates HTML), the mkElem function occurs repeatedly. We define and use a small library of functions such as htable, hrow, and hcol which are just synonyms for particular applications of mkElem and mkElemAttrs to different tagnames, reducing verbosity and making the syntax rather more readable.\n\nAlso for convenience, we define the new operators ? and ! as synonyms for showAttr and literal respectively: they are used in a bracketed postfix notation,7 a style some programmers prefer.\n\n2.2  Combinators\nThe combinators used as intermediate code in compilers can render programs `totally unfit for human consumption' [11]! However, the idea of a combinator library for a specific class of applications is to achieve a form of expression that is natural for the problem. A combinator library should be like a language extension tailored to the problem domain [4]. In this sense, functional languages are extensible, just as XML itself is extensible. The combinators are higher-order operators serving as `glue'[6] to assemble functions into more powerful combinations. We aim to keep the types of component functions as uniform as possible so that any function can be composed with any other. Within the lexical limits of the host language, choice of notation should follow application conventions: in Haskell we can, where appropriate, define new infix operator symbols for combinators.\n\nSo, having defined some basic filters already, in what ways can these usefully be combined into more interesting and complex filters? (See Figure 3.)\n\n      \to, \t  \tIrish composition\n      \t(|||), \t  \tappend results\n      \twith, \t  \tguard\n      \twithout,\t\t  \tnegative guard\n      \t(/>), \t  \tinterior search\n      \t(</), \t  \texterior search\n      \t(|>|) \t  \tdirected choice\n      \t  \t:: CFilter -> CFilter -> CFilter\n     \n      \tf `o` g = concat . map f . g\n      \tf ||| g = \\c-> f c ++ g c\n      \tf `with` g = filter (not.null.g) . f\n      \tf `without` g = filter (null.g) . f\n      \tf /> g = g `o` children `o` f\n      \tf </ g = f `with` (g `o` children)\n      \tf |>| g = f ?> f :> g\n     \n      \tcat \t  \tconcatenate results\n      \t  \t:: [CFilter] -> CFilter\n     \n      \tcat fs = \\c-> concat. map (\\f->f c) fs\n     \n      \tet \t  \tdisjoint union\n      \t  \t:: (String->CFilter) -> CFilter -> CFilter\n     \n      \tf `et` g = (f `oo` tagged elm)\n      \t|>| (g `o` txt)\n     \n      \t(?>) \t  \tif-then-else choice\n      \t  \t:: CFilter -> ThenElse CFilter -> CFilter\n     \n      \tdata ThenElse a = a :> a\n      \tp ?> f :> g = \\c-> if (not.null.p) c\n      \tthen f c else g c\n     \n      \tchip, \t  \t``in-place'' application to children\n      \tdeep, \t  \trecursive search (topmost)\n      \tdeepest,\t\t  \trecursive search (deepest)\n      \tmulti, \t  \trecursive search (all)\n      \tfoldXml \t  \trecursive application\n      \t  \t:: CFilter -> CFilter\n     \n      \tdeep f = f |>| (deep f `o` children)\n      \tdeepest f = (deepest f `o` children) |>| f\n      \tmulti f = f ||| (multi f `o` children)\n      \tfoldXml f = f `o` (chip (foldXml f))\n\n    Figure 3: Filter combinators and their definitions.\n\nThe most important and useful filter combinator is `o`. We call this operator Irish composition, for reasons which should be obvious. It plugs two filters together: the left filter is applied to the results of the right filter. So, for instance, the expression\n\n    text `o` children `o` tag \"title\"\n\nmeans ``only the plain-text children of the current element, provided the current element has the title tag name''.\n\nSome other combinators are as follows. f ||| g is an append operator: it joins the results of f and g sequentially. cat fs is the list generalisation of |||; it concatenates the results of each of the filters from the fs list. f `with` g acts as a guard on the results of f, pruning to include only those which are productive under g. The dual, f `without` g, excludes those results of f which are productive under g. The expression p ?> f :> g is a functional choice operator; if the (predicate) filter p is productive, then the filter f is applied, otherwise g is applied. From this is derived a directed choice operator: f |>| g gives either the results of f, or those of g only if f is unproductive.\n\nGeneralised Path Selectors\nSelection of subtrees by path patterns is familiar to users of the Unix file-system, where such patterns are used to access directory structure, using a / notation to indicate the `containing' relation. Similar patterns are used in XSLT, an XML transformation language [3]. In this connection, we define two path selection combinators /> and </. Both combinators choose subtrees to return based on whether the results of the left filter contain the results of the right filter as children: /> is an `interior' selector, returning the inner structure; </ is an `exterior' selector, returning the outer structure.\n\nAn editing combinator\nAside from predicates, selectors, choice, and constructive filters, there is one very useful combinator which stands in its own category -- an editing combinator. chip f processes the children of an element in-place: the filter f is applied to its children; the results are rebuilt as the new children of that same element.\n\nRecursion\nIt is often useful to express recursive transformations on XML documents: transformations which can be applied at many different levels of the document tree.\n\nOne family of such expressions is useful primarily in selecting a subtree from an arbitrarily deep location, although they can of course be used for editing and filtering as well as selection. The recursive combinator deep f potentially pushes the action of filter f deep inside the document sub-tree. It first tries the given filter on the current item: if it is productive then it stops here, but if no results are returned, then it moves to the children and tries again recursively. When used with a predicate, this strategy searches for the topmost matching elements in the tree. There are variations: deepest searches for the bottommost matching elements; multi returns all matches, even those which are sub-trees of other matches. However, as already noted, the action of these combinators is not restricted to predicates or selectors.\n\nAnother powerful recursion combinator is foldXml: the expression foldXml f applies the filter f to every level of the tree, from the leaves upwards to the root (at least conceptually -- of course lazy evaluation makes this more efficient).\n\n2.3  Example\nThe use of these filters and combinators is illustrated in an example script in Figure 4. This program transforms an <album> element into an HTML document that provides a formatted summary. The HTML output, rendered by the Netscape browser, is illustrated in Figure 5. Such a task might be fairly common in e-commerce applications.\n\nWe now describe some of the salient features of the example.\n\n    (albumf `o` deep (tag \"album\"))\n\nThe script first searches recursively for the topmost element tagged <album>, before applying the filter albumf to it. Thus, it works equally well with any XML source document that contains an <album> element anywhere within it, and (correctly) produces no output for documents which do not contain album data.\n\nThe output document's <HEAD> section contains the artist name and album title separated by a colon. We note that the expression,\n\n    txt `o` children `o` tag \"artist\"\n        `o` children `o` tag \"album\"\n\nwhich grabs the textual content of the <artist> element within the <album> element, is somewhat unwieldy. Moreover its trailing test for the <album> tag is redundant, since the calling filter has already performed that match. The expression can be simplified by using path selectors to:\n\n    keep /> tag \"artist\" /> txt\n\nand this style is used elsewhere in the example. (The algebraic laws in Section 2.5 guarantee that this rewriting is safe.)\n\nSuch expressions make some assumptions about the structure of the data within the <album> element. In this instance, the assumption is that an <artist> element is an immediate child, and that its immediate children include text. If such assumptions prove incorrect for a particular document, the filter is simply unproductive; no error is flagged.\n\nWith a suitable definition, hbody = mkElemAttr \"BODY\" the expression\n\n    hbody  [(\"bgcolor\",(\"white\"!))]   [...]\n\ncan be understood to set the background colour attribute of the <BODY> tag to the literal value white. Notice how the attribute value is itself described by a filter. In this case, the filter is not very exciting, but the later definition of mkLink illustrates the generation of an HTML reference by looking up the value of a supplied link attribute (using the ? filter).\n\nWhen the script is used on the particular document from Figure 1, the output is a re-ordering of the internal components of the input: in the <BODY> part of the output, the <notes> section is selected and transformed by notesf before the <catalogno> elements are processed by the summaryf filter. Although in the absence of a DTD it is impossible to be sure of any input ordering, the script here ensures that the output ordering is consistent.\n\nThe definition of the notesf filter is interesting because it makes fewer assumptions about the content of a <notes> structure, and in addition it preserves the input ordering. The chained if-then-else choice within the recursive foldXml combinator causes all internal structure of the <notes> element to be retained except for the replacement of <trackref>s by emphasised text, and <albumref>s by HTML links.\n\nOne of the most striking features of the example as a whole is how selection and testing of old content and construction of new content are uniform, and can be combined almost interchangeably.\n\nWe will return to the treatment of <catalogno> elements in Section 2.4 after introducing some extra labelling combinators.\n\n    module Main where\n    import Xml\n    main =\n      processXmlWith (albumf `o` deep (tag \"album\"))\n    albumf =\n      html\n        [ hhead\n          [ htitle\n            [ txt `o` children `o` tag \"artist\"\n                  `o` children `o` tag \"album\"\n            , literal \": \"\n            , keep /> tag \"title\" /> txt\n            ]\n          ]\n        , hbody [(\"bgcolor\",(\"white\"!))]\n          [ hcenter\n              [ h1 [ keep /> tag \"title\" /> txt ] ]\n          , h2 [ (\"Notes\"!) ]\n          , hpara [ notesf `o` (keep /> tag \"notes\") ]\n          , summaryf\n          ]\n        ]\n    notesf =\n      foldXml (txt            ?> keep            :>\n               tag \"trackref\" ?> replaceTag \"EM\" :>\n               tag \"albumref\" ?> mkLink          :>\n               children)\n    summaryf =\n      htable [(\"BORDER\",(\"1\"!))]\n        [ hrow [ hcol [ (\"Album title\"!) ]\n               , hcol [ keep /> tag \"title\" /> txt ]\n               ]\n        , hrow [ hcol [ (\"Artist\"!) ]\n               , hcol [ keep /> tag \"artist\" /> txt ]\n               ]\n        , hrow [ hcol [ (\"Recording date\"!) ]\n               , hcol [ keep />\n                           tag \"recordingdate\" /> txt ]\n               ]\n        , hrow [ hcola [ (\"VALIGN\",(\"top\"!)) ]\n                       [ (\"Catalog numbers\"!) ]\n               , hcol\n                 [ hlist\n                   [ catno `oo`\n                      numbered (deep (tag \"catalogno\"))\n                   ]\n                 ]\n               ]\n        ]\n    catno n =\n      mkElem \"LI\"\n        [ ((show n++\". \")!),  (\"label\"?),  (\"number\"?)\n        , (\" (\"!),  (\"format\"?),  (\")\"!) ]\n    mkLink =\n      mkElemAttr \"A\" [ (\"HREF\",(\"link\"?)) ]\n        [ children ]\n\n    Figure 4: An example document-processing script using the generic filter combinators.\n\n    picture of browser\n\n    Figure 5: The HTML results of the example script, rendered by a browser.\n\n2.4  Labellings\nOne feature that is occasionally useful is the ability to attach labels to items in a sequence, for instance, to number a list of items, or to treat the first/last item of a list differently from the other items. For this purpose, the library provides special labelling combinators. We choose to introduce a new type:\n\n  type LabelFilter a = Content -> [ (a,Content) ]\n\nA LabelFilter is like a CFilter except it attaches a label to each of its results. We might have chosen to fold label values inside the Content type, to yield a uniform CFilter type, but keeping the labels separate allows them to be of completely polymorphic type: a label could even be another filter for example.\n\nThere are several common labelling functions:\n\n  numbered     :: CFilter -> LabelFilter Int\n  interspersed :: a -> CFilter -> a\n                                 -> LabelFilter a\n  tagged       :: CFilter -> LabelFilter String\n  attributed   :: CFilter ->\n                    LabelFilter [(String,String)]\n\nThese labelling functions lift a CFilter to the LabelFilter type: numbered f transforms the ordinary filter f into a new filter that attaches integers (from 1 upwards) to the results of f; interspersed a f z attaches the label a to all of the results of f except the last, which gets the label z; tagged f labels every tagged element with its tag name (and non-elements with the empty string); attributed f labels every tagged element with its attribute/value pairs (and non-elements with the empty list).\n\n  `oo` :: (a->CFilter) -> LabelFilter a -> CFilter\n\nThe combinator `oo` is a new form of composition which drops a LabelFilter back to the CFilter type by application of another filter that consumes the label.\n\nThe use of this form of labelling is illustrated by the treatment of <catalogno>s in the example of Figure 4:\n\n  catno `oo` numbered (deep (tag \"catalogno\"))\n\nFirst, the desired elements are extracted from their topmost positions in the tree, then they are given numeric labels, and finally the catno filter incorporates the label into some generated text. Another example can be seen in the definition of the `et` combinator in Figure 3. (`et` combines a filter f on elements with a filter g on text. f pattern-matches against tagnames -- the tagnames are extracted by the labelling function tagged.)\n\nFurthermore, it is possible to combine labellings. The `x` combinator glues two labelling functions together, pairing the labels they produce.\n\n  `x` :: (CFilter->LabelFilter a)\n           -> (CFilter->LabelFilter b)\n           -> (CFilter->LabelFilter (a,b))\n\n2.5  Algebraic laws of combinators\nWe briefly show how combinators are defined in such a way that various algebraic laws hold. The complete set of laws is given in Figure 6.\n\n      \tIrish composition\n    f `o` (g `o` h) = (f `o` g) `o` h\t\t  \tassociativity\n    none `o` f = f `o` none = none\t\t  \tzero\n    keep `o` f = f `o` keep = f\t\t  \tidentity\n     \n      \tGuards\n    f `with` keep = f \t  \tidentity\n    f `with` none = none `with` f = none\t\t  \tzero\n    (f `with` g) `with` g = f `with` g\t\t  \tidempotence\n    (f `with` g) `with` h\n    = (f `with` h) `with` g\t\t  \tpromotion\n    (f `o` g) `with` h\n    = (f `with` h) `o` g\t\t  \tpromotion\n     \n    f `without` keep = none `without` f\n    = none\t\t  \tzero\n    f `without` none = keep\t\t  \tidentity\n    (f `without` g) `without` g\n    = f `without` g\t\t  \tidempotence\n    (f `without` g) `without` h\n    = (f `without` h) `without` g\t\t  \tpromotion\n    (f `o` g) `without` h\n    = (f `without` h) `o` g\t\t  \tpromotion\n     \n      \tPath selectors\n    f /> (g /> h) = (f /> g) /> h\t\t  \tassociativity\n    none /> f = f /> none = none\t\t  \tzero\n    keep /> f = f `o` children\t\t  \t \n    f /> keep = children `o` f\t\t  \t \n    keep /> keep = children\t\t  \t \n    none </ f = f </ none = none\t\t  \tzero\n    f </ keep = f `with` children\t\t  \t \n    (f </ g) </ g = f </ g\t\t  \tidempotence\n    (f </ g) /> g = f /> g\t\t  \tidempotence\n     \n    (f /> g) </ h = f /> (g </ h)\t\t  \tpromotion\n    (f </ g) </ h = (f </ h) </ g \t  \tpromotion\n    f `o` (g /> h) = g /> (f `o` h)\t\t  \tpromotion\n    (f /> g) `o` h = (f `o` h) /> g\t\t  \tpromotion\n    (f /> g) `with` h = f /> (g `with` h) \t  \tpromotion\n    (f </ g) `with` h = (f `with` h) </ g \t  \tpromotion\n     \n      \tDirected choice\n    (f |>| g) |>| h = f |>| (g |>| h)\t\t  \tassociativity\n    keep |>| f = keep\t\t  \t \n    none |>| f = f |>| none = f\t\t  \tidentity\n    f |>| f = f\t\t  \tidempotence\n     \n      \tRecursion\n    deep keep = keep\t\t  \tsimplification\n    deep none = none\t\t  \tsimplification\n    deep children = children\t\t  \tsimplification\n    deep (deep f) = deep f\t\t  \tdepth law\n     \n      \tMisc\n    elm |>| txt = txt |>| elm = keep\t\t  \tcompleteness\n    elm `o` txt = txt `o` elm = none\t\t  \texcl. middle\n    children `o` elm = children\t\t  \t \n    children `o` txt = none\t\t  \t\n\n    Figure 6: Algebraic laws of combinators.\n\nGiving all content filters the same type maximises the usefulness of combinators for plugging together functions of this type. However, it is still helpful to identify subclasses of content filters that offer extra guarantees. Two examples of such classes are:\n\n    A predicate p has the property that p c always gives as result either [c] or [].\n    A selector s has the property that s c always gives as result a sequence of contents taken from c. Resulting items do not overlap, and the result sequence respects the order in which the contents were found in c. \n\nSo a predicate is a selector, but a selector is not necessarily a predicate.\n\nThe `o` form of filter composition could be defined using a Haskell list comprehension\n\n    (f `o` g) c = [c'' | c' <- g c, c'' <- f c']\n\nHowever, we prefer the equivalent higher-order definition f `o` g = concat . map f . g because it is more convenient in algebraic calculation.8 Composition is associative, with none as zero, and keep as identity.\n\nThe `with` form of guarded composition is not associative, but we do have some laws, particularly idempotence. We also have a promotion law about combined uses of `with` and `o`. The dual operator, `without` has parallel laws.\n\nThe /> path selector is associative but </ is not, and there are some idempotence laws for both. Most important however, are the various promotion laws for changing the order of application of />, </, and with.\n\nThe directed choice operator |>| viewed by itself appears to be algebraically sensible, but it does not seem to have useful algebraic properties in connection with other combinators because of its bias towards the left operand. The simpler result-appending combinator ||| could be an alternative to the directed choice operator, and would probably lead to more laws, but it has less `application bite'. A potentially serious problem is that the |||-combination of two selectors is not necessarily a selector.\n\nThe recursion operator deep has some minor laws, one of which, the depth law, is more profound. We have not yet fully investigated the properties of deepest, multi, and foldXml.\n\n\n\n3  Translation of DTDs to Types\n3.1  DTDs\nSo far we have considered document-processing by generic tree transformations, where markup is matched textually at runtime, and no account is taken of any deeper meaning of tags.\n\nHowever, when the DTD for a document is available, the meaning it defines for markup tags can be used to powerful effect. The most basic use is to confirm semantic validity: a stronger notion than mere syntactic well-formedness. A DTD defines a grammar for document content: it specifies a vocabulary of markup tags, and the allowed content and attributes for each tag. Document validation is therefore a straightforward check that the document's structure conforms to the vocabulary and grammar given in the DTD.\n\nXML document validators are readily available. However, we go further and define the idea of valid document processing. A valid processing script is one which produces a valid document as output, given a valid document as input. We achieve this by demonstrating a correspondence between the DTD of a document and the definition of a set of algebraic types in Haskell, and the consequent correspondence between the document's content and a structured Haskell value. Hence, by writing document processing scripts to manipulate the typed Haskell value, the script validation problem is just an instance of normal Haskell type inference.9\n\n    <?xml version='1.0'?>\n    <!DOCTYPE album SYSTEM \"album.dtd\" [\n    <!ELEMENT album (title, artist, recordingdate?,\n                     coverart, (catalogno)+,\n                     personnel, tracks, notes) >\n    <!ELEMENT title #PCDATA>\n    <!ELEMENT artist #PCDATA>\n    <!ELEMENT recordingdate EMPTY>\n        <!ATTLIST recordingdate date CDATA #IMPLIED\n                                place CDATA #IMPLIED>\n    <!ELEMENT coverart (location)? >\n        <!ATTLIST coverart style CDATA #REQUIRED>\n    <!ELEMENT location EMPTY >\n        <!ATTLIST location thumbnail CDATA #IMPLIED\n                           fullsize CDATA #IMPLIED>\n    <!ELEMENT catalogno EMPTY >\n        <!ATTLIST\n              catalogno\n                  label CDATA #REQUIRED\n                  number CDATA #REQUIRED\n                  format (CD | LP | MiniDisc) #IMPLIED\n                  releasedate CDATA #IMPLIED\n                  country CDATA #IMPLIED>\n    <!ELEMENT personnel (player)+ >\n    <!ELEMENT player EMPTY >\n        <!ATTLIST player name CDATA #REQUIRED\n                          instrument CDATA #REQUIRED>\n    <!ELEMENT tracks (track)* >\n    <!ELEMENT track EMPTY>\n        <!ATTLIST track title CDATA #REQUIRED\n                        credit CDATA #IMPLIED\n                        timing CDATA #IMPLIED>\n    <!ELEMENT notes (#PCDATA | albumref | trackref)* >\n        <!ATTLIST notes author CDATA #IMPLIED>\n    <!ELEMENT albumref #PCDATA>\n        <!ATTLIST albumref link CDATA #REQUIRED>\n    <!ELEMENT trackref #PCDATA>\n        <!ATTLIST trackref link CDATA #IMPLIED>\n    ]>\n\n    Figure 7: An example DTD.\n\n    module AlbumDTD where\n\n    data Album = \n        Album Title Artist (Maybe Recordingdate)\n              Coverart [Catalogno] Personnel\n              Tracks Notes\n    newtype Title = Title String\n    newtype Artist = Artist String\n    newtype Recordingdate =\n                    Recordingdate Recordingdate_Attrs\n    data Recordingdate_Attrs = Recordingdate_Attrs {\n        date :: Maybe String,\n        place :: Maybe String }\n    newtype Coverart = Coverart (String, Maybe Location)\n    newtype Location = Location Location_Attrs\n    data Location_Attrs = Location_Attrs {\n        thumbnail :: Maybe String,\n        fullsize  :: Maybe String }\n    newtype Catalogno = Catalogno Catalogno_Attrs\n    data Catalogno_Attrs = Catalogno_Attrs {\n        label :: String,\n        number :: String,\n        format :: Maybe Format,\n        releasedate :: Maybe String,\n        country :: Maybe String }\n    data Format = CD | LP | MiniDisc\n    newtype Personnel = Personnel [Player]\n    newtype Player = Player Player_Attrs\n    data Player_Attrs = Player_Attrs {\n        name :: String,\n        instrument :: String }\n    newtype Tracks = Tracks [Track]\n    newtype Track = Track Track_Attrs\n    data Track_Attrs = Track_Attrs {\n        title :: String,\n        credit :: Maybe String,\n        timing :: Maybe String }\n    newtype Notes = Notes (Maybe String, [Notes_])\n    data Notes_ = \n        Notes_Str String\n      | Notes_Albumref Albumref\n      | Notes_Trackref Trackref\n    newtype Albumref = Albumref (String,String)\n    newtype Trackref = Trackref (Maybe String,String)\n\n    Figure 8: The example DTD translated to Haskell types.\n\n3.2  DTD translations.\nAn example DTD for the document shown earlier is given in Figure 7. The immediate features to note are: (1) For every element, there is a specification of allowed inner elements (ELEMENT declaration), and possibly also a specification of allowed attribute values (ATTLIST declaration). (2) For inner content, the grammar allows sequence (commas), choice (vertical bar), optionality (question mark), and repetition (star or plus). (3) Where the inner content declaration allows free text (#PCDATA), choice between text and other elements is permitted, but sequencing of those elements is not permitted. (4) In attribute lists, some values are mandatory (#REQUIRED) and some are optional (#IMPLIED); attribute values can either be unconstrained strings (CDATA) or a member of some pre-defined set of string values.\n\nThere seem to be some obvious correspondences between this very restricted form of type language and the richer type language of Haskell. Each element declaration is roughly speaking a new datatype declaration. Sequence is like product types (i.e. single-constructor values). Choice is like sum types (i.e. multi-constructor values). Optionality is just a Maybe type. Repetition is lists.\n\nAttribute lists also have a translation: because they are unordered and accessed by name, Haskell named-fields look like a good representation. Optionality can again be expressed as Maybe types. Attribute values that are constrained to a particular value-set can be modelled by defining a new enumeration type encompassing the permitted strings.\n\n3.3  Implementation\nThese rules are formalised in the appendix (Figure 9). An implementation of these rules (with some additional rules to eliminate redundancy) translated the DTD in Figure 7 into the Haskell type declarations shown in Figure 8.\n\nAlso needed, along with the type declarations, are functions which read and write values of these types to and from actual XML documents. These are generated automatically from the type declarations alone. Using an appropriate set of pre-defined type classes, we derive a new instance for each generated type using a tool like DrIFT [16].\n\n3.4  Discussion\nAlthough this type-based translation looks straightforward, it turns out that there are several tricky issues.\n\nFirst, the type translation may only use datatypes and newtypes, never type synonyms. This is a result of needing to write values out as XML -- a type synonym in Haskell is indistinguishable from the type it abbreviates, but the generated types must be distinct in order to be able to re-introduce enclosing start and end tags with the correct markup.\n\nA separate type is introduced for each collection of attributes. Hence, an element is represented by a pairing of the attributes and the content. Where a tagged element directly contains an optional type or a sequence of types which are themselves sum-types, it is necessary to interpose a separate Haskell type, e.g. Notes contains a [Notes_] where the auxiliary type Notes_ has three alternatives.\n\nNaming is a big issue. Case matters in XML, so a <tag> differs from a <TAG> and attribute attr differs from Attr. In Haskell however, types must begin with upper-case, and field-names must begin with lower-case. Where auxiliary types are necessary, we have chosen to append an underscore character to the name. All of these factors impose restrictions on the use of this translation, due to the potential name conflicts.\n\nFurthermore, there is a mismatch between Haskell's named fields and the attribute naming/scoping rules in XML. In XML, different elements may have attributes of the same name and type, whereas Haskell's named fields are restricted to use within a single type. A system of typed extensible records [5] would be a much better fit.\n\nDespite these problems in expressing DTDs within the Haskell typesystem, the latter is very much more powerful than DTDs -- for instance, DTDs have no notion of polymorphism. Indeed, there are frequent occasions when DTD writers resort to textual macros10 to indicate more detailed structuring than DTDs permit (including polymorphism and qualified typing), even though such implicit structuring cannot be validated by XML tools. It is significant to note the XML community's recognition of these limitations of DTDs -- recent proposals for schemas11 address the question of richer typing in a more disciplined manner.\n\nOne area in which the type system of Haskell in particular (as opposed to other functional languages) is exploited is type classes. This systematic overloading mechanism is very useful for codifying the I/O conversions.\n\n4  Pros and cons of the two schemes\n4.1  Combinators\nCompared with the mainstream solution for XML processing, namely new domain-specific languages for expressing and scripting transformations, the combinator approach has several advantages:\n\nEase of extension and variation\nScripting languages sometimes lack useful facilities, or provide them in convoluted ways. Extending the language is difficult. A combinator library, however, can be enlarged comparatively straightforwardly -- the definitions are accessible, and most are short and simple.\n\nComputational power\nScripting languages tend to offer either a very limited expression language, or a hook into a programming system at a completely different level of abstraction. But if XML scripts are programs in a language such as Haskell, the full power of the native language is immediately available.\n\nAbstraction, generality and reuse\nAlmost any pattern occurring in a combinator program can be isolated and defined as a separate re-usable idea [6]. This also applies at the application level, where common ideas from similar applications might easily be defined in a higher-level library. This form of re-use makes program development much quicker and less error-prone.\n\nLaws for reasoning about scripts\nThe semantics of a scripting language are often defined by illustration. So it is hard to reason with confidence about the meanings of scripts. Is A just a stylistic variation of B or are there inputs for which the two could give different results? But when the semantics of scripts can be defined in terms of the equations for the combinators, properties such as associativity and distribution can often be demonstrated simply.\n\nImplementation for free\nDoes a scripting language have an interactive interpreter? A compiler? A type-checker? A profiler? All these things are immediately available to XML scripts directly expressed as Haskell programs.\n\nOf course, there are disadvantages too.\n\nDistance from target language\nXSLT [3] has the property that a script is an expression in the target language: it uses exactly the XML syntax for building new content. Combinator-based scripts must use a different syntax due to the underlying language. The linguistic gap might cause confusion and increase learning costs.\n\nLiving in an unfamiliar world\nCombinator programs look like scripts in a small domain-specific language. Writers may be beguiled by this apparent simplicity, make a small error, and drop into an unknown corner of Haskell. Error messages may be incomprehensible, or worse, the script might work but do something utterly strange.\n\n4.2  Type-based translation\nSome of the advantages of the fully-typed representation of XML documents have already been mentioned.\n\nValidity\nThe ability for the system to spot errors automatically, not just in the data, but in the program, and also to prevent the generation of incorrect document markup.\n\nDirect programming style\nFunctional languages encourage the use of pattern-matching (binding values to variables) on the left-hand-side of equations. However, using higher-order combinators, data structures tend not to be mentioned in equations at all. The DTD translation approach is much more in keeping with the pattern-binding style, which sometimes leads to shorter programs! Whereas with combinators, it is sometimes necessary to re-traverse the same selection path with slight variations, the pattern-binding gives direct access for free.\n\n\nDisadvantages are:\n\nHigh startup cost\nBefore scripting document transformations, it is necessary to acquire, check, and process the DTD. Although the generation of Haskell types is automated, few people are familiar enough with DTDs to be able to start using them immediately. They require careful study and understanding before correct scripts can be written and the initial investment of effort pays off.\n\nIncomplete type model\nThe grammar of DTDs is small and restrictive compared to the sophisticated type systems available in functional languages. Better means of type-specification in XML are still under development. In the meantime, there is little scope for using the full power of features like polymorphism.\n\n5  Related Work\nXML Processing\nThere are infant processing languages surrounding XML. Of most interest here are:\n\n    XSLT [3] (eXtensible Style Language for Transformation) is a W3C-proposed declarative language for expressing a limited form of transformations on XML documents, originally intended for rendering to a layout-based format, e.g. HTML, PostScript, etc., but now widely used for XML->XML transformations.\n    DSSSL [12] (Document Style Semantics and Specification Language) is a mature ISO standard with no complete implementations. It is similar in essence to XSLT, but deals with full SGML input, and is based on Scheme. \n\nNot many functional language researchers are visibly engaged in XML-related work, but two other toolkits for XML-processing are Christian Lindig's XML parser in O'Caml12 and Andreas Neumann's validating XML parser in SML13 . To our knowledge, neither of these provides transformation capabilities in either a combinator style or a type-translation style. Philip Wadler has written a short formal semantics of XSL selection patterns [15].\n\nApplication-based combinators\nParsing is the most extensively studied application for combinator libraries. Since the original treatment by Burge [2], there have been many variations on the theme. Swierstra and Duponcheel's method incorporating on-the-fly grammar analysis and error-correction is a notable recent example [10]. We hope it may be possible to incorporate DTD-analysis in our combinators in a similar style.\n\nAlthough many other libraries of application combinators have been devised, the general design principles for such libraries are scarcely referred to in the literature. Hughes' exposition of a design for pretty-printing combinators [7] is a unique resource in this respect, and we have yet to exploit it fully.\n\nTree-processing operators\nAn earlier version of this paper prompted more than one pointer to the work of Eelco Visser and colleagues [13]. Their motivating application is specification of strategies for program optimisation, treated as rewriting over expression trees. The result of applying a strategy is either a single term or failure: non-determinism is achieved by backtracking but only the first success is computed, whereas we deal in `lists of successes' [14]. Their operators for combining strategies include composition, directed choice, and an explicit ľ operator for recursion. They have several operators for specifying transformation of child subterms: some are not so relevant to XML where subtree position and arity are less often fixed than in program syntax; however, one of the most frequently applied operators is close to our foldXml. Most significantly, Visser et. al. achieve great expressive power by decomposing the match/re-build stages of rewriting, and introducing explicit environments by which these stages communicate. This makes it possible to deal with subtleties such as variable bindings in the program terms under transformation. Although the structure of XML is simpler than the structure of a programming language, our library could benefit from the addition of support for binding variables when matching subtrees.\n\nProgramming functions explicitly over the XML data-structure, without the abstraction of combinators, Haskell pattern matching provides bindings for subtrees. But only at a fixed (small) depth from the root, beneath an explicitly stated pattern of constructors. Mohnen [9] defines an extension of the pattern language for deep matching: variables in a pattern can be bound to subterms at arbitrary depth inside the original term. The result of the match includes a context function representing the original subject term with `holes' at the sites of matching; subterms for these holes are supplied by arguments to the function. So contexts are the complements of environments. Mohnen shows how his matching extension simplifies various tree-processing tasks, and also how it can be translated into standard Haskell. This work could provide one component of a hybrid solution, with DTD-specific representation and generic forms of traversal and matching.\n\nVisser et. al. [13] also discuss several other approaches to the tree transformation problem.\n\n6  Conclusions and Future Work\nIn our experience, Haskell is a very suitable language for XML processing. For generic applications, a small set of combinators designed with algebraic properties in mind can be powerful enough and flexible enough to describe a full range of selection, testing, and construction operations in a uniform framework. For applications where the DTD is fixed, a tool deriving corresponding types and associated I/O routines turns XML processing into Haskell programming over typed data structures, and the Haskell typechecker validates scripts.\n\nHowever, there is plenty of scope for further work, in several directions:\n\nGenerality of combinators\nThough we have had generality as a design aim for our present combinator library there is scope for generalising it further.\n\n    Wider functionality. Most content filters in our current library are either pure selectors (with results that are sequences of sub-trees from the full document tree) or pure constructors (creating document content from values of other types). The design could usefully be extended to include a more general class of deletion operations in which sub-trees can be thinned and pruned in various ways. More general still are combinators for editing and transforming, where some of the ideas in Visser's work could usefully be transferred.\n    Multiple inputs and outputs. An interesting extension of single-document scripting is the handling of multiple documents. Producing more than one output document is no great problem. But it is far more challenging to design appropriate combinators for dealing with several inputs.\n    More general types. The labelling scheme has proved useful for some applications, but the need for a separate LabelFilter type is a blemish. We hope to generalise the CFilter type to incorporate LabelFilter as a special case. By making the CFilter type parametric it might even be possible to incorporate the type-translation of DTDs within the combinator framework. \n\nEfficiency of combinators\nThe current combinator library is quite usable, but here are some possible routes to greater efficiency.\n\n    Algebraic normalisation So far we have merely established that laws hold, and occasionally appealed to them when writing scripts. The implementation simply defines the combinators by their specifying equations. Instead, laws could be exploited at the implementation level. Following Hughes [7], we have in mind an implementation that automatically reduces all combinations to a normal form, that is the least expensive equivalent computationally.\n    Space-efficient formulation Some lazy functional programs that process trees in pre-order left-to-right fashion can be formulated to run in log(N) space. The part of the tree that is held in memory corresponds to a path from the root to some node that is currently the focus of computation: to the left are `garbage' subtrees already processed, to the right are subtrees not yet evaluated. However, our current combinators have not been formulated to guarantee this sort of space behaviour, even in favourable cases. This problem might be tackled by the normalisation approach.\n    DTD-aware combinators The current combinator library just ignores DTDs. Combinators that maintain DTD information might, for example, achieve far more efficient search in some cases by pruning branches bound to fail. They could also be used to produce first-class XML documents as the results of queries, not just raw extracts of unknown type. As we have already noted, DTDs could perhaps be attached as labels in the sense of §2.4: either as explicit values or implicitly in type information. \n\nRelations between DTDs\nAs we have seen, in the DTD-directed approach with known fixed DTDs for input and output, validation translates to static type-checking; whereas generic combinators could in principle acquire and compute DTDs dynamically. These represent extremes with disadvantages of inflexibility on the one hand and some insecurity on the other. There are many other ways of handling relations between DTDs. For example:\n\n    Polymorphic and higher-order scripts. The generic approach would gain security if one could infer a DTD->DTD function. By analogy with functional programs it is then natural to assign scripts polymorphic and higher-order DTDs, making explicit their degree of genericity.\n\n    Inclusion between DTDs. This has been implicitly assumed already, but has practical importance in its own right. As stock DTDs are refined, XML documents will inhabit a hierarchy of specialisation. Given several similar DTDs, one would like to derive a DTD for a virtual common root (intersection) or common descendent (union). This goes well beyond the abilities of current type-inference systems, but would make a useful addition to our functional toolkit for XML processing. \n\nAcknowledgements\nCanon Research Centre (Europe) Ltd. suggested this line of work and funded it. Philip Wadler, Christian Lindig, and Joe English gave very helpful comments on an earlier draft of this paper and software. Several anonymous referees also gave useful advice.\n\nReferences\n\n[1]\n    Tim Bray, Jean Paoli, and C.M. Sperberg-Macqueen. Extensible Markup Language (XML) 1.0 (W3C Recommendation). http://www.w3.org/TR/REC-xml, WWW Consortium, February 1998.\n\n[2]\n    W H Burge. Recursive Programming Techniques. Addison-Wesley, 1975.\n\n[3]\n    James Clark (ed). XSL Transformations (Working Draft). http://www.w3.org/TR/WD-xslt, WWW Consortium, April 1999.\n\n[4]\n    Jon Fairbairn. Making form follow function: An exercise in functional programming style. Software -- Practice and Experience, 17(6):379--386, June 1987.\n\n[5]\n    Benedict R Gaster. Records, Variants, and Qualified Types. Dept of Computer Science, University of Nottingham, PhD Thesis, 1998.\n\n[6]\n    John Hughes. Why functional programming matters. Computer Journal, 32(2), April 1989.\n\n[7]\n    John Hughes. The design of a pretty-printing library. In 1st Intl. School on Advanced Functional Programming, pages 53--96. Springer LNCS Vol. 925, 1995.\n\n[8]\n    Graham Hutton and Erik Meijer. Monadic parsing in Haskell. Journal of Functional Programming, 8(4), July 1998.\n\n[9]\n    Markus Mohnen. Context patterns in Haskell. In Workshop on Implementation of Functional Languages, pages 41--57. Springer LNCS Vol 1268, September 1996.\n\n[10]\n    Doaitse Swierstra and Luc Duponcheel. Deterministic error-correcting combinator parsers. In 2nd Intl. School on Advanced Functional Programming, pages 184--207. Springer LNCS Vol 1129, August 1996.\n\n[11]\n    David A Turner. A new implementation technique for applicative languages. Software -- Practice and Experience, 9(1):31--50, January 1979.\n\n[12]\n    Unknown. Document Style Semantics and Specification Language (DSSSL) (Final Draft). http://occam.sjf.novell.com/dsssl/dsssl96/, Novell Publications, 1996.\n\n[13]\n    Eelco Visser, Zine el Abidine Benaissa, and Andrew Tolmach. Building program optimisers with rewrite strategies. In International Conference on Functional Programming, pages 13--26. ACM Press, September 1998.\n\n[14]\n    Philip Wadler. How to replace failure by a list of successes. In Functional Programming Languages and Computer Architecture, pages 113--128. Springer LNCS Vol 201, September 1985.\n\n[15]\n    Philip Wadler. A formal model of pattern matching in XSL. Technical Report http://www.cs.bell-labs.com/~wadler/xsl/, Bell Labs, January 1999.\n\n[16]\n    Noel Winstanley. Reflections on instance derivation. In 1997 Glasgow Functional Programming Workshop. BCS Workshops in Computer Science, September 1997.\n\n    Appendix: DTD translation rules\n    Type declarations\n    T[[<ELEMENT n spec>]] \t= \tnewtype m =\n      \t  \tm (m_Attrs, m_)\n      \t  \tnewtype m_ = D[[spec]] m\n      \t  \twhere m = M[[n]]\n    T[[<ATTLIST n\n    decl0 ... declk>]] \t= \tdata m_Attrs =\n      \t  \tm_Attrs {F[[decl0]]\n      \t  \t, ...\n      \t  \t,F[[ declk]] }\n      \t  \twhere m = M[[n]]\n      \t  \tA[[decl0]]\n      \t  \t...\n      \t  \tA[[ declk]]\n     \n    RHS of type declarations\n    D[[ ( x0, x1, ..., xk ) ]] m \t= \tC[[ m x0 ... xk ]]\n      \t  \tD'[[ x0 ]] D'[[ x1 ]] ... D'[[ xk ]]\n    D[[ ( x0 | x1 | ... | xk ) ]] m \t= \tC[[ m x0 ]] D'[[ x0 ]]\n      \t  \t| C[[ m x1 ]] D'[[ x1 ]]\n      \t  \t| ...\n      \t  \t| C[[ m xk ]] D'[[ xk ]]\n    D[[ (x)? ]] m \t= \tMaybe D'[[ x ]]\n    D[[ (x)+ ]] m \t= \tList1 D'[[ x ]]\n    D[[ (x)* ]] m \t= \t[ D'[[ x ]] ]\n    D[[ x ]] m \t= \tC[[ m x ]]\n     \n    Inner type expressions\n    D'[[ ( x0, x1, ..., xk ) ]] \t= \t( D'[[ x0 ]] , D'[[ x1 ]]\n      \t  \t, ... D'[[ xk ]] )\n    D'[[ ( x0 | x1 | ... | xk ) ]] \t= \t(OneOfn D'[[ x0 ]] D'[[ x1 ]]\n      \t  \t... D'[[ xk ]] )\n    D'[[ (x)? ]] \t= \t(Maybe D'[[ x ]] )\n    D'[[ (x)+ ]] \t= \t(List1 D'[[ x ]] )\n    D'[[ (x)* ]] \t= \t[ D'[[ x ]] ]\n    D'[[ x ]] \t= \tC[[ x ]]\n     \n    Name mangling\n    C[[ m x0 x1 ... xk ]] \t= \t... unique constructor name\n      \t  \tbased on m\n    M[[ n ]] \t= \t... ensure initial upper-case\n    M'[[ n ]] \t= \t... ensure initial lower-case\n     \n    Named fields\n    F[[ n CDATA #REQUIRED ]]\n      \t= \tM'[[ n ]] :: String\n    F[[ n CDATA #IMPLIED ]]\n      \t= \tM'[[ n ]] :: Maybe String\n    F[[ n (s0|s1|...|sk) #REQUIRED ]]\n      \t= \tM'[[ n ]] :: M[[ n ]]\n    F[[ n (s0|s1|...|sk) #IMPLIED ]]\n      \t= \tM'[[ n ]] :: Maybe M[[ n ]]\n     \n    Constrained attributes\n    A[[ n CDATA ... ]] \t= \t0\n    A[[ n (s0|s1|...|sk) ... ]]\n      \t= \tdata M[[ n ]] =\n      \t  \tM[[ s0 ]] | M[[ s1 ]]\n      \t  \t| ... | M[[ sk ]]\n\n    Figure 9: DTD translation rules.\n\n1\n    The XML toolkit from this paper is available on the WWW at http://www.cs.york.ac.uk/fp/HaXml/ \n2\n    Xtract: a `grep'-like tool for XML documents. http://www.cs.york.ac.uk/fp/Xtract/ \n3\n    In light of the ``XML Namespaces'' recommendation, in effect a mechanism for permitting multiple DTDs, such facilities could be particularly useful. See http://www.w3.org/TR/REC-xml-names \n4\n    The shortened name elm was chosen to avoid a clash with the Standard Prelude function elem. \n5\n    For those familiar with the detail of XML, entity references within the document are treated as plain text. \n6\n    Actually, a list of attribute/filter pairs. Each filter is applied to the current element and the resultant content is flattened to a string value which is assigned to the named attribute. \n7\n    Actually a left-section of the infix operator. Because filters are higher-order, their use is eta-reduced and the rightmost argument disappears from view. \n8\n    Irish composition is in fact just the flipped-argument version of the Kleisi composition operator in the list monad. \n9\n    Well, nearly! Validity also encompasses some other minor checks, for instance that IDREF attributes must be globally unique. \n10\n    That is, parameter entity references. \n11\n    http://www.w3.org/TR/xmlschema-1 for structures, and http://www.w3.org/TR/xmlschema-2 for datatypes. \n12\n    http://www.cs.tu-bs.de/softech/people/lindig/tony.html \n13\n    http://www.informatik.uni-trier.de/ neumann/Fxp/ \n\n    This document was translated from LATEX by HEVEA. \n\n"
      },
      "after": "2e8be84f15deb853",
      "date": 1665381071752
    }
  ]
}