{
  "title": "SDM Read Operation",
  "story": [
    {
      "type": "paragraph",
      "id": "1c22f6446905bb12",
      "text": "For the connection to [[Attention]] we focus on the SDM read operation and briefly summarize the write operation: all patterns write their pointers pp in a distributed fashion to all neuron addresses located within [[Hamming Distance]] d. This means that each neuron will store a [[Superposition]] of pattern pointers from those pattern addresses within d: x⌧v = P {p:d(paμ,x⌧a)d,8μ} pp. Having stored patterns in a distributed fashion across nearby neurons, SDM’s read operation retrieves stored pattern pointers from all neurons within distance d of the query and averages them. This average is effectively weighted because the same patterns have distributed storage across multiple neurons being read from. The pattern weighting will be higher for those patterns with addresses nearer the query because they have written their pointers to more neurons the query reads from. Geometrically, this weighting of each pattern can be interpreted as the intersection of radius d circles2 that are centered on the query and each pattern address paμ for all μ. A high level overview of the SDM read and write operations is shown in Fig. 1."
    },
    {
      "type": "html",
      "id": "8bdb71ca79057c42",
      "text": "<img\n  width=\"100%\"\n  src=\"https://wiki.ralfbarkow.ch/assets/pages/2023-01-17/Summarizing%20the%20SDM%20read%20and%20write%20operations.jpg\"\n>"
    },
    {
      "type": "paragraph",
      "id": "d9bdfcf4ef6664c3",
      "text": "[…]"
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "SDM Read Operation",
        "story": []
      },
      "date": 1673855863631
    },
    {
      "item": {
        "type": "factory",
        "id": "1c22f6446905bb12"
      },
      "id": "1c22f6446905bb12",
      "type": "add",
      "date": 1673855865630
    },
    {
      "type": "edit",
      "id": "1c22f6446905bb12",
      "item": {
        "type": "paragraph",
        "id": "1c22f6446905bb12",
        "text": "For the connection to Attention we focus on the SDM read operation and briefly summarize the write operation: all patterns write their pointers pp in a distributed fashion to all neuron addresses located within Hamming distance d. This means that each neuron will store a superposition of pattern pointers from those pattern addresses within d: x⌧v = P {p:d(paμ,x⌧a)d,8μ} pp. Having stored patterns in a distributed fashion across nearby neurons, SDM’s read operation retrieves stored pattern pointers from all neurons within distance d of the query and averages them. This average is effectively weighted because the same patterns have distributed storage across multiple neurons being read from. The pattern weighting will be higher for those patterns with addresses nearer the query because they have written their pointers to more neurons the query reads from. Geometrically, this weighting of each pattern can be interpreted as the intersection of radius d circles2 that are centered on the query and each pattern address paμ for all μ. A high level overview of the SDM read and write operations is shown in Fig. 1."
      },
      "date": 1673855867222
    },
    {
      "type": "edit",
      "id": "1c22f6446905bb12",
      "item": {
        "type": "paragraph",
        "id": "1c22f6446905bb12",
        "text": "For the connection to [[Attention]] we focus on the SDM read operation and briefly summarize the write operation: all patterns write their pointers pp in a distributed fashion to all neuron addresses located within Hamming distance d. This means that each neuron will store a superposition of pattern pointers from those pattern addresses within d: x⌧v = P {p:d(paμ,x⌧a)d,8μ} pp. Having stored patterns in a distributed fashion across nearby neurons, SDM’s read operation retrieves stored pattern pointers from all neurons within distance d of the query and averages them. This average is effectively weighted because the same patterns have distributed storage across multiple neurons being read from. The pattern weighting will be higher for those patterns with addresses nearer the query because they have written their pointers to more neurons the query reads from. Geometrically, this weighting of each pattern can be interpreted as the intersection of radius d circles2 that are centered on the query and each pattern address paμ for all μ. A high level overview of the SDM read and write operations is shown in Fig. 1."
      },
      "date": 1673855881305
    },
    {
      "type": "edit",
      "id": "1c22f6446905bb12",
      "item": {
        "type": "paragraph",
        "id": "1c22f6446905bb12",
        "text": "For the connection to [[Attention]] we focus on the SDM read operation and briefly summarize the write operation: all patterns write their pointers pp in a distributed fashion to all neuron addresses located within [[Hamming Distance]] d. This means that each neuron will store a superposition of pattern pointers from those pattern addresses within d: x⌧v = P {p:d(paμ,x⌧a)d,8μ} pp. Having stored patterns in a distributed fashion across nearby neurons, SDM’s read operation retrieves stored pattern pointers from all neurons within distance d of the query and averages them. This average is effectively weighted because the same patterns have distributed storage across multiple neurons being read from. The pattern weighting will be higher for those patterns with addresses nearer the query because they have written their pointers to more neurons the query reads from. Geometrically, this weighting of each pattern can be interpreted as the intersection of radius d circles2 that are centered on the query and each pattern address paμ for all μ. A high level overview of the SDM read and write operations is shown in Fig. 1."
      },
      "date": 1673855904410
    },
    {
      "type": "add",
      "id": "d9bdfcf4ef6664c3",
      "item": {
        "type": "paragraph",
        "id": "d9bdfcf4ef6664c3",
        "text": "[…]"
      },
      "after": "1c22f6446905bb12",
      "date": 1673855948620
    },
    {
      "id": "8bdb71ca79057c42",
      "type": "add",
      "item": {
        "type": "html",
        "id": "8bdb71ca79057c42",
        "text": "<img\n  width=\"100%\"\n  src=\"https://wiki.ralfbarkow.ch/assets/pages/2023-01-17/Summarizing%20the%20SDM%20read%20and%20write%20operations.jpg\"\n>"
      },
      "after": "1c22f6446905bb12",
      "date": 1673944832971
    },
    {
      "type": "edit",
      "id": "1c22f6446905bb12",
      "item": {
        "type": "paragraph",
        "id": "1c22f6446905bb12",
        "text": "For the connection to [[Attention]] we focus on the SDM read operation and briefly summarize the write operation: all patterns write their pointers pp in a distributed fashion to all neuron addresses located within [[Hamming Distance]] d. This means that each neuron will store a [[superposition]] of pattern pointers from those pattern addresses within d: x⌧v = P {p:d(paμ,x⌧a)d,8μ} pp. Having stored patterns in a distributed fashion across nearby neurons, SDM’s read operation retrieves stored pattern pointers from all neurons within distance d of the query and averages them. This average is effectively weighted because the same patterns have distributed storage across multiple neurons being read from. The pattern weighting will be higher for those patterns with addresses nearer the query because they have written their pointers to more neurons the query reads from. Geometrically, this weighting of each pattern can be interpreted as the intersection of radius d circles2 that are centered on the query and each pattern address paμ for all μ. A high level overview of the SDM read and write operations is shown in Fig. 1."
      },
      "date": 1673945116206
    },
    {
      "type": "edit",
      "id": "1c22f6446905bb12",
      "item": {
        "type": "paragraph",
        "id": "1c22f6446905bb12",
        "text": "For the connection to [[Attention]] we focus on the SDM read operation and briefly summarize the write operation: all patterns write their pointers pp in a distributed fashion to all neuron addresses located within [[Hamming Distance]] d. This means that each neuron will store a [[Superposition]] of pattern pointers from those pattern addresses within d: x⌧v = P {p:d(paμ,x⌧a)d,8μ} pp. Having stored patterns in a distributed fashion across nearby neurons, SDM’s read operation retrieves stored pattern pointers from all neurons within distance d of the query and averages them. This average is effectively weighted because the same patterns have distributed storage across multiple neurons being read from. The pattern weighting will be higher for those patterns with addresses nearer the query because they have written their pointers to more neurons the query reads from. Geometrically, this weighting of each pattern can be interpreted as the intersection of radius d circles2 that are centered on the query and each pattern address paμ for all μ. A high level overview of the SDM read and write operations is shown in Fig. 1."
      },
      "date": 1673945147278
    }
  ]
}