{
  "title": "2023-01-28",
  "story": [
    {
      "type": "paragraph",
      "id": "931db1a7eb15a85a",
      "text": "⇒ [[Generate a Rectangular Grid]]  "
    },
    {
      "type": "paragraph",
      "id": "374255e21e26bada",
      "text": "What is the function of such a rectangular grid in the context of the implementation of a self-organizing feature map (SOM)?"
    },
    {
      "type": "paragraph",
      "id": "e24195cc0d9ebcc4",
      "text": "chat.openai: A self-organizing feature map (SOM) is a type of artificial neural network that is used for unsupervised learning. It is particularly useful for visualizing high-dimensional data in a low-dimensional space. One of the key components of a SOM is the rectangular grid, also known as the \"neuron grid\" or \"feature map\". The grid is a two-dimensional array of \"neurons\", each representing a point in the low-dimensional space.\n\nThe purpose of the rectangular grid in SOM is to provide a topographic representation of the input data. Each neuron in the grid represents a prototype vector that is trained to represent a certain group of input vectors. The grid is usually initialized with random prototype vectors, and as the network learns, the prototype vectors are adjusted to better reflect the distribution of the input data.\n\nDuring the training process, the input vectors are presented to the SOM, and the best matching neuron (BMU) is determined based on the similarity between the input vector and the prototype vector of each neuron. The BMU and its neighboring neurons are then updated to better match the input vector. This process is repeated for all input vectors, and as the training progresses, the neurons in the grid become increasingly specialized to represent different parts of the input space.\n\nOnce the SOM is trained, it can be used to map new input vectors to the grid. The resulting position of the BMU can be used as a feature that can be used for further analysis or classification. The SOM can also be used to visualize the input data by plotting the position of the BMU for each input vector on the grid. This can help to identify patterns or clusters in the data that may not be immediately apparent in the original high-dimensional space."
    },
    {
      "type": "pagefold",
      "id": "6ceea1899c32f4f1",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "9b27e3ded4a84b30",
      "text": "Are there implementations in JavaScript?"
    },
    {
      "type": "paragraph",
      "id": "34f0a9ef17ba0765",
      "text": "chat.openai: Yes, there are implementations of self-organizing feature maps (SOM) in JavaScript. ⇒ [[Self-Organizing Map in Pure Javascript]]"
    },
    {
      "type": "paragraph",
      "id": "b0179cab3fc0942f",
      "text": "JavaScript is a popular programming language that is widely used for web development, and it can also be used to create standalone applications.\n\n"
    },
    {
      "type": "paragraph",
      "id": "397f14447ec57d95",
      "text": "One way to implement a SOM in JavaScript is to use a library such as Synchronous SOM ([[SOM.js]]) or Neural-SOM. These libraries provide pre-built functions and classes for creating and training SOMs, making it easier to implement the algorithm in JavaScript.\n\n"
    },
    {
      "type": "paragraph",
      "id": "9ac45ef5659e4371",
      "text": "Another way to implement a SOM in JavaScript is to write the code from scratch, using JavaScript's built-in functions and classes. This would give you more control over the implementation and allow you to customize the behavior of the SOM to suit your specific needs.\n\n"
    },
    {
      "type": "paragraph",
      "id": "2ad2d923ca5676da",
      "text": "However, keep in mind that JavaScript is not the best choice when it comes to performant machine learning algorithms and it may not be efficient for large datasets.\nIt's worth considering the usage of JavaScript for small datasets, visualization or prototyping purposes.\n\n"
    },
    {
      "type": "paragraph",
      "id": "3875efe3fcea29ef",
      "text": "In any case, it's important to have knowledge of the algorithm and the language to implement it correctly."
    },
    {
      "type": "pagefold",
      "id": "52792ac41ee1be36",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "65ab7a889a447ac6",
      "text": "Requiring external module babel-register ?"
    },
    {
      "type": "paragraph",
      "id": "85dc814fdb379d31",
      "text": "chat.openai: [[Babel]] is a JavaScript transpiler that allows developers to use modern JavaScript syntax, such as ES6 and ES7, in their code, even if the environment they are running the code in does not support it yet.\n\nThe babel-register module is a require hook that allows you to use Babel to transpile your code on-the-fly, as it is being required. This can be useful when running your code in an environment that does not support the latest JavaScript features, such as an older version of Node.js."
    },
    {
      "type": "paragraph",
      "id": "cd3fdef5ae43a20a",
      "text": "To use babel-register, you first need to install it, along with the required presets, such as @babel/preset-env, using npm:"
    },
    {
      "type": "code",
      "id": "5ddc03a4fe23dfd6",
      "text": "npm install --save-dev babel-register @babel/preset-env\n"
    },
    {
      "type": "pagefold",
      "id": "cd2989fe90c8b5bb",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "b434305a145925e4",
      "text": "There is an example on how to comsume the API which som.js offered. Please find it in ./example/64nodeSOM.js. What does it script do?"
    },
    {
      "type": "paragraph",
      "id": "6773712293a1bff3",
      "text": "chat.openai: This script is a demonstration of using the SOM (Self-Organizing Map) library to train a SOM model.\n\nThe script first imports several dependencies, including 'ndarray' and 'ndarray-ops' for working with arrays, 'cwise' for performing operations on arrays, 'ndarray-show' for displaying array values, 'underscore' for utility functions and 'som.js' for the SOM library.\n\nIt then declares and initializes several variables:\n\nmodelNumber is the number of models in the SOM.\ndimension is the dimension of the models.\nM is a 2D array of size modelNumber*dimension which is used to store the models.\nsqrootM is the square root of the number of models.\ninputNumber is the number of input vectors.\ninputVector is a 2D array of size dimension*inputNumber which is used to store the input vectors.\ntrainingTimes is the number of times the SOM will be trained.\nThen, the script fills the inputVector and M arrays with random values using the ops.random() function.\n\nIt then defines a callback function, which will be called after each training iteration and takes two arguments: currentmap, currentTime. It is not doing anything in the current code snippet.\n\nAfter that, it logs the original map array and then trains the SOM model using the som() function, passing the M array, inputVector array, trainingTimes, the callback function, a learning rate and a radius of influence.\n\nFinally, it logs the trained map array after training.\n\nIt should be noted that the script is missing some parts of the implementation like the instantiation of the SOM class, and that it is using the som.js as a function, but in most cases it should be an instance of a class."
    },
    {
      "type": "pagefold",
      "id": "24b8d2895f97b93e",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "2f5f7ec3adc4f94e",
      "text": "Is M the rectangular grid we'd talked about?"
    },
    {
      "type": "paragraph",
      "id": "66c23573f01f01ff",
      "text": "chat.openai: No, in this script, M is a 2D array that is being used to store the models of the Self-Organizing Feature Map (SOM). The rectangular grid is not explicitly created in this script, but the SOM algorithm will arrange the models in a grid-like structure. The grid structure of the SOM can be visualized by reshaping the M array into a 3D array, where the dimensions of the grid are determined by the square root of the number of models."
    },
    {
      "type": "pagefold",
      "id": "c09c38b0b99e8f6f",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "ba6e34b73a540ce9",
      "text": "Could you expand on that mapping between 2D and 3D?"
    },
    {
      "type": "paragraph",
      "id": "5746094aefc97508",
      "text": "chat.openai: Sure. In this script, the M array is a 2D array of size modelNumber * dimension, where modelNumber is the number of models in the SOM and dimension is the number of features in each model. The SOM algorithm uses this 2D array to organize the models into a grid-like structure.\n\nTo visualize this grid structure, the 2D M array can be reshaped into a 3D array. The reshaping process is done by creating a new array of size dimension * sqrootM * sqrootM and mapping the values of the M array into this new array. sqrootM is the square root of the number of models.\n\nThe first dimension of the new array represents the features of the models, the second dimension represents the rows of the grid, and the third dimension represents the columns of the grid. So, each element in the new array corresponds to a specific model in the grid, where the position of the element in the grid is determined by its row and column indices, and the values of the element correspond to the features of the model.\n\nBy reshaping the 2D M array into a 3D array, you can get a better visualization of the grid structure of the SOM.\n\n\nRegenerate response\n"
    },
    {
      "type": "pagefold",
      "id": "d2e0713956bf674a",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "d7cef40babd607fd",
      "text": "What is a SOM Model?"
    },
    {
      "type": "paragraph",
      "id": "bb3fe282c364ff41",
      "text": "chat.openai: A Self-Organizing Map (SOM) is a type of artificial neural network that is trained using unsupervised learning to produce a low-dimensional (typically two-dimensional) representation of the input space of the training samples, called a map. The map consists of a grid of neurons that represent the different regions of the input space, where each neuron is associated with a weight vector that encodes the characteristics of the inputs that the neuron represents.\n\nThe SOM algorithm begins by initializing the weight vectors of the neurons to random values. Then, it iteratively updates the weight vectors by adjusting them to be closer to the input samples that are presented to the network. The update process is done in such a way that the neurons that are closest to the input sample in the weight space are updated more than the neurons that are farther away. This process causes the neurons to \"self-organize\" into a topographic map of the input space, where similar inputs are mapped to nearby neurons, and dissimilar inputs are mapped to distant neurons.\n\nThe SOM algorithm is useful for data visualization, pattern recognition, and feature extraction, among other applications. Because it preserves the topological relationships between the inputs, it can be used to reveal the underlying structure of complex, high-dimensional data sets."
    },
    {
      "type": "pagefold",
      "id": "c8b74fd874eee54a",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "d9c2b8cf016c6772",
      "text": "How to represent a wikipedia page  as a vector of features?"
    },
    {
      "type": "paragraph",
      "id": "a611fa0889c19eb6",
      "text": "chat.openai: here are several ways to represent a Wikipedia page as a vector of features, depending on the task at hand and the resources available. Some common approaches include:\n\n"
    },
    {
      "type": "paragraph",
      "id": "e60795e30c3acb97",
      "text": "[[Bag of Words]]: This approach represents the page as a vector of the frequency of each word in the page, disregarding grammar and word order. It's a simple and widely used approach in natural language processing.\n"
    },
    {
      "type": "paragraph",
      "id": "f6f8a2183faf1db2",
      "text": "TF-IDF: This approach is a variation of the bag-of-words model that assigns a weight to each word based on its importance in the page, taking into account how often the word appears in the page compared to how often it appears in the entire Wikipedia corpus.\n"
    },
    {
      "type": "paragraph",
      "id": "94398c633f803417",
      "text": "[[Latent Semantic Analysis]] (LSA): This approach represents the page as a vector of latent concepts, or topics, that are extracted from the page through a process of dimensionality reduction. It tries to capture the underlying meaning of the page by identifying the most important concepts that the page is about.\n"
    },
    {
      "type": "paragraph",
      "id": "5b4918c44fdce6d3",
      "text": "Word Embedding: This approach represents a page as a weighted sum of word embeddings, where each word is represented as a vector of real numbers. The embeddings are typically learned by training a neural network on a large corpus of text.\n"
    },
    {
      "type": "paragraph",
      "id": "4327639bd6b83fce",
      "text": "Network based: This approach represents the page as a node in a network, where the edges represent the links between pages. The network can be analyzed using various network analysis techniques, such as centrality measures, to extract features of the page.\n"
    },
    {
      "type": "paragraph",
      "id": "c137af4fd648d0bf",
      "text": "It is important to note that these are just a few examples of the ways to represent a Wikipedia page as a vector of features and there are many other possibilities as well. The best approach would depend on the task at hand and the resources available."
    },
    {
      "type": "pagefold",
      "id": "cec3cc79bf95df1e",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "0a5088c5a9848282",
      "text": "⇒ [[Site Survey]] ⇒ [[Probe Page Preview]]"
    },
    {
      "type": "paragraph",
      "id": "453001b22accf95d",
      "text": "Ward via [https://matrix.to/#/!ORfrUEFeWFcHAMLFLr:matrix.org/$167487411948907kXEOw:matrix.org?via=matrix.org&via=matrix.allmende.io&via=chat.weho.st matrix]\nAs we approach a week of experience with Site Survey we take our first steps toward uniformity in how the parts work together and how we can support new and special purpose surveys. For example, we've created a drag and drop probe tester that will probe one page at a time. We found early that it was hard to debug with console.log when hundreds of pages are flying by at 30 per second."
    },
    {
      "type": "paragraph",
      "id": "657043fdb7229ba6",
      "text": "chat.openai: A site survey is a process of gathering information about a specific location in order to plan and design a wireless network or other type of infrastructure. This can include measuring signal strength and identifying potential sources of interference, as well as assessing the physical layout of the location and determining the best placement for network equipment. Site surveys can be conducted using specialized software and equipment, and are often performed by trained professionals with experience in network design and deployment. The goal of a site survey is to ensure that the network will perform optimally and provide reliable coverage for users."
    },
    {
      "type": "pagefold",
      "id": "2c14f2f5f43913eb",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "091054a7f9de272c",
      "text": "⇒ Recursive [[Consensual Coordination]] ⇒ [[KJ Method]]: chat.openai: The KJ method (also known as the KJ Analysis or Affinity Diagram) is a tool used in [[Brainstorming]] and problem-solving sessions to organize and categorize ideas. It is named after its creator, Jiro Kawakita, who developed the method in the 1970s. The KJ method is used to help groups of people identify and prioritize key issues or ideas by grouping similar ideas together and then identifying relationships among them. It is often used in business, education, and other fields to help teams generate, organize, and evaluate ideas."
    },
    {
      "type": "paragraph",
      "id": "a3dcbb89cde187a9",
      "text": "chat.openai: Self-organizing Maps (SOM) can be used to create a visual representation of the clusters and relationships among a set of data points, similar to how Affinity Mapping is used to organize and visualize a set of ideas. SOM is an unsupervised machine learning technique that is used for data visualization and dimensionality reduction. It works by training a neural network on a set of input data, and then using the network to create a two-dimensional map of the data. The map is organized so that similar data points are grouped together, and the relationships between the data points are represented by the topology of the map.\n\nFor example, SOM can be used to create a map of customer data, where each customer is represented by a data point. The map will group customers with similar characteristics (like age, income, location, etc.) together, and the topology of the map will show how the customers are related to one another. This makes it easy to see patterns and relationships among the customers and to make decisions based on that information.\n\nIn a similar way, SOM algorithm can be applied in Affinity Mapping to create a visual representation of the clusters and relationships among a set of ideas, concepts or data points."
    },
    {
      "type": "pagefold",
      "id": "b8fa37a8f931b5aa",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "1ce05f97264a47b3",
      "text": "Takashi explores this practice in a paper entitled [https://drive.google.com/open?id=1JP-RIPvD5LXdb85pZ5ah-nb3ffC_nsqj Philosophy and Methodology of Clustering in Pattern Mining]"
    },
    {
      "type": "paragraph",
      "id": "7bc7d02210c09e8d",
      "text": "chat.openai: [[I]]'m sorry, I'm unable to access external links as I'm a text-based model, but I can tell you that Takashi Iba's paper is discussing the use of the clustering technique in [[Pattern Mining]], which is the process of discovering patterns and relationships in a dataset. Clustering is a key aspect of this process, as it helps to group similar data points together and identify patterns among them. The paper likely explores the use of clustering techniques, such as the KJ Method and Affinity Mapping, and how they can be used to identify patterns and relationships in a dataset. Additionally, the paper probably describes the philosophy and methodology behind the use of clustering in pattern mining, and how it can be used to gain insights from data."
    },
    {
      "type": "paragraph",
      "id": "70b3ffef2110735f",
      "text": "[…] chat.openai: Pattern mining is a technique used to identify patterns and relationships within a dataset. One of the most well-known applications of pattern mining is [[Market-Basket Analysis]], which is used to identify items that are often purchased together in a retail setting. This can help retailers optimize their inventory and product placement, and also identify new sales opportunities.\n\nData mining allows for the discovery of unexpected associations in large datasets, which can open new avenues for research or marketing. Another important use of pattern mining is the discovery of sequential patterns, such as sequences of errors or warnings that precede equipment failure. This information can be used to schedule preventative maintenance or provide insight into a design flaw.\n\nIt's also worth noting that pattern mining is used in many other domains, such as financial analysis, medical research, bioinformatics, natural language processing and image and text recognition.\n\n\n⇒ [[Regenerate Response]]"
    },
    {
      "type": "video",
      "id": "2f55f42e194e7df7",
      "text": "YOUTUBE tkZqPMzgvzg\nHip hop, grit, and academic success: Bettina Love at TEDxUGA\n"
    },
    {
      "type": "pagefold",
      "id": "e32951b801832d1c",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "b022105a10192836",
      "text": "Talking About ⇒ [[Large Language Model]]s [https://fedi.simonwillison.net/@simon/109738632902770815 post], [https://www.arxiv-vanity.com/papers/2212.03551/ page] ⇒ [[Sentient Being]]"
    },
    {
      "type": "assets",
      "id": "48bee69709b621a2",
      "text": "pages/2023-01-28"
    },
    {
      "type": "paragraph",
      "id": "e9978202e6d6215c",
      "text": "Three Triangles in a Hexagon [https://www.puzzleprime.com/lessons/three-triangles-in-a-hexagon/ page], [https://www.puzzleprime.com/wp-content/uploads/2020/07/Three-Triangles-in-a-Hexagon-1-600x601.jpg jpg] ⇒ [[Dreyeck]]"
    },
    {
      "type": "html",
      "id": "da6fabb1d72e7ab7",
      "text": "<img\n  src=\"https://wiki.ralfbarkow.ch/assets/pages/2023-01-28/Three%20Triangles%20in%20a%20Hexagon.jpg\"\n  width=\"100%\"\n>"
    },
    {
      "type": "html",
      "id": "db056b2dbf91a394",
      "text": "    <iframe id=\"p5.js web editor embed\"\n        title=\"p5.js web editor embed\"\n        width=\"800\"\n        height=\"600\"\n        src=\"https://editor.p5js.org/\">\n    </iframe>"
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "2023-01-28",
        "story": []
      },
      "date": 1674901898427
    },
    {
      "item": {
        "type": "factory",
        "id": "374255e21e26bada"
      },
      "id": "374255e21e26bada",
      "type": "add",
      "date": 1674901899871
    },
    {
      "type": "edit",
      "id": "374255e21e26bada",
      "item": {
        "type": "paragraph",
        "id": "374255e21e26bada",
        "text": "What is the function of such a rectangular grid in the context of the implementation of a self-organizing feature map (SOM)?"
      },
      "date": 1674901903298
    },
    {
      "item": {
        "type": "factory",
        "id": "931db1a7eb15a85a"
      },
      "id": "931db1a7eb15a85a",
      "type": "add",
      "after": "374255e21e26bada",
      "date": 1674901906905
    },
    {
      "type": "edit",
      "id": "931db1a7eb15a85a",
      "item": {
        "type": "paragraph",
        "id": "931db1a7eb15a85a",
        "text": "⇒ [[Generate a Rectangular Grid]]  "
      },
      "date": 1674901908684
    },
    {
      "id": "931db1a7eb15a85a",
      "type": "move",
      "order": [
        "931db1a7eb15a85a",
        "374255e21e26bada"
      ],
      "date": 1674901910266
    },
    {
      "item": {
        "type": "factory",
        "id": "e24195cc0d9ebcc4"
      },
      "id": "e24195cc0d9ebcc4",
      "type": "add",
      "after": "374255e21e26bada",
      "date": 1674901920606
    },
    {
      "type": "edit",
      "id": "e24195cc0d9ebcc4",
      "item": {
        "type": "paragraph",
        "id": "e24195cc0d9ebcc4",
        "text": "chat.openai: A self-organizing feature map (SOM) is a type of artificial neural network that is used for unsupervised learning. It is particularly useful for visualizing high-dimensional data in a low-dimensional space. One of the key components of a SOM is the rectangular grid, also known as the \"neuron grid\" or \"feature map\". The grid is a two-dimensional array of \"neurons\", each representing a point in the low-dimensional space.\n\nThe purpose of the rectangular grid in SOM is to provide a topographic representation of the input data. Each neuron in the grid represents a prototype vector that is trained to represent a certain group of input vectors. The grid is usually initialized with random prototype vectors, and as the network learns, the prototype vectors are adjusted to better reflect the distribution of the input data.\n\nDuring the training process, the input vectors are presented to the SOM, and the best matching neuron (BMU) is determined based on the similarity between the input vector and the prototype vector of each neuron. The BMU and its neighboring neurons are then updated to better match the input vector. This process is repeated for all input vectors, and as the training progresses, the neurons in the grid become increasingly specialized to represent different parts of the input space.\n\nOnce the SOM is trained, it can be used to map new input vectors to the grid. The resulting position of the BMU can be used as a feature that can be used for further analysis or classification. The SOM can also be used to visualize the input data by plotting the position of the BMU for each input vector on the grid. This can help to identify patterns or clusters in the data that may not be immediately apparent in the original high-dimensional space."
      },
      "date": 1674901930103
    },
    {
      "item": {
        "type": "factory",
        "id": "6ceea1899c32f4f1"
      },
      "id": "6ceea1899c32f4f1",
      "type": "add",
      "after": "e24195cc0d9ebcc4",
      "date": 1674902022454
    },
    {
      "type": "edit",
      "id": "6ceea1899c32f4f1",
      "item": {
        "type": "pagefold",
        "id": "6ceea1899c32f4f1",
        "text": "~"
      },
      "date": 1674902025208
    },
    {
      "item": {
        "type": "factory",
        "id": "9b27e3ded4a84b30"
      },
      "id": "9b27e3ded4a84b30",
      "type": "add",
      "after": "6ceea1899c32f4f1",
      "date": 1674902026580
    },
    {
      "type": "edit",
      "id": "9b27e3ded4a84b30",
      "item": {
        "type": "paragraph",
        "id": "9b27e3ded4a84b30",
        "text": "Are there implementations in JavaScript?"
      },
      "date": 1674902029360
    },
    {
      "type": "add",
      "id": "34f0a9ef17ba0765",
      "item": {
        "type": "paragraph",
        "id": "34f0a9ef17ba0765",
        "text": "chat.openai: Yes, there are implementations of self-organizing feature maps (SOM) in JavaScript. JavaScript is a popular programming language that is widely used for web development, and it can also be used to create standalone applications.\n\nOne way to implement a SOM in JavaScript is to use a library such as Synchronous SOM (SOM.js) or Neural-SOM. These libraries provide pre-built functions and classes for creating and training SOMs, making it easier to implement the algorithm in JavaScript.\n\nAnother way to implement a SOM in JavaScript is to write the code from scratch, using JavaScript's built-in functions and classes. This would give you more control over the implementation and allow you to customize the behavior of the SOM to suit your specific needs.\n\nHowever, keep in mind that JavaScript is not the best choice when it comes to performant machine learning algorithms and it may not be efficient for large datasets.\nIt's worth considering the usage of JavaScript for small datasets, visualization or prototyping purposes.\n\nIn any case, it's important to have knowledge of the algorithm and the language to implement it correctly."
      },
      "after": "9b27e3ded4a84b30",
      "date": 1674902045958
    },
    {
      "type": "edit",
      "id": "34f0a9ef17ba0765",
      "item": {
        "type": "paragraph",
        "id": "34f0a9ef17ba0765",
        "text": "chat.openai: Yes, there are implementations of self-organizing feature maps (SOM) in JavaScript. "
      },
      "date": 1674902092996
    },
    {
      "type": "add",
      "id": "b0179cab3fc0942f",
      "item": {
        "type": "paragraph",
        "id": "b0179cab3fc0942f",
        "text": "JavaScript is a popular programming language that is widely used for web development, and it can also be used to create standalone applications.\n\nOne way to implement a SOM in JavaScript is to use a library such as Synchronous SOM (SOM.js) or Neural-SOM. These libraries provide pre-built functions and classes for creating and training SOMs, making it easier to implement the algorithm in JavaScript.\n\nAnother way to implement a SOM in JavaScript is to write the code from scratch, using JavaScript's built-in functions and classes. This would give you more control over the implementation and allow you to customize the behavior of the SOM to suit your specific needs.\n\nHowever, keep in mind that JavaScript is not the best choice when it comes to performant machine learning algorithms and it may not be efficient for large datasets.\nIt's worth considering the usage of JavaScript for small datasets, visualization or prototyping purposes.\n\nIn any case, it's important to have knowledge of the algorithm and the language to implement it correctly."
      },
      "after": "34f0a9ef17ba0765",
      "date": 1674902095190
    },
    {
      "type": "edit",
      "id": "34f0a9ef17ba0765",
      "item": {
        "type": "paragraph",
        "id": "34f0a9ef17ba0765",
        "text": "chat.openai: Yes, there are implementations of self-organizing feature maps (SOM) in JavaScript. ⇒ [[Self-Organizing Map in Pure Javascript]]"
      },
      "date": 1674902119894
    },
    {
      "type": "edit",
      "id": "b0179cab3fc0942f",
      "item": {
        "type": "paragraph",
        "id": "b0179cab3fc0942f",
        "text": "JavaScript is a popular programming language that is widely used for web development, and it can also be used to create standalone applications.\n\n"
      },
      "date": 1674902160197
    },
    {
      "type": "add",
      "id": "397f14447ec57d95",
      "item": {
        "type": "paragraph",
        "id": "397f14447ec57d95",
        "text": "One way to implement a SOM in JavaScript is to use a library such as Synchronous SOM (SOM.js) or Neural-SOM. These libraries provide pre-built functions and classes for creating and training SOMs, making it easier to implement the algorithm in JavaScript.\n\n"
      },
      "after": "b0179cab3fc0942f",
      "date": 1674902162606
    },
    {
      "type": "add",
      "id": "9ac45ef5659e4371",
      "item": {
        "type": "paragraph",
        "id": "9ac45ef5659e4371",
        "text": "Another way to implement a SOM in JavaScript is to write the code from scratch, using JavaScript's built-in functions and classes. This would give you more control over the implementation and allow you to customize the behavior of the SOM to suit your specific needs.\n\n"
      },
      "after": "397f14447ec57d95",
      "date": 1674902165001
    },
    {
      "type": "add",
      "id": "2ad2d923ca5676da",
      "item": {
        "type": "paragraph",
        "id": "2ad2d923ca5676da",
        "text": "However, keep in mind that JavaScript is not the best choice when it comes to performant machine learning algorithms and it may not be efficient for large datasets.\nIt's worth considering the usage of JavaScript for small datasets, visualization or prototyping purposes.\n\n"
      },
      "after": "9ac45ef5659e4371",
      "date": 1674902168664
    },
    {
      "type": "add",
      "id": "3875efe3fcea29ef",
      "item": {
        "type": "paragraph",
        "id": "3875efe3fcea29ef",
        "text": "In any case, it's important to have knowledge of the algorithm and the language to implement it correctly."
      },
      "after": "2ad2d923ca5676da",
      "date": 1674902171485
    },
    {
      "type": "edit",
      "id": "397f14447ec57d95",
      "item": {
        "type": "paragraph",
        "id": "397f14447ec57d95",
        "text": "One way to implement a SOM in JavaScript is to use a library such as Synchronous SOM ([[SOM.js]]) or Neural-SOM. These libraries provide pre-built functions and classes for creating and training SOMs, making it easier to implement the algorithm in JavaScript.\n\n"
      },
      "date": 1674902181361
    },
    {
      "item": {
        "type": "factory",
        "id": "52792ac41ee1be36"
      },
      "id": "52792ac41ee1be36",
      "type": "add",
      "after": "3875efe3fcea29ef",
      "date": 1674902397567
    },
    {
      "type": "edit",
      "id": "52792ac41ee1be36",
      "item": {
        "type": "pagefold",
        "id": "52792ac41ee1be36",
        "text": "~"
      },
      "date": 1674902400844
    },
    {
      "item": {
        "type": "factory",
        "id": "65ab7a889a447ac6"
      },
      "id": "65ab7a889a447ac6",
      "type": "add",
      "after": "52792ac41ee1be36",
      "date": 1674902402020
    },
    {
      "type": "edit",
      "id": "65ab7a889a447ac6",
      "item": {
        "type": "paragraph",
        "id": "65ab7a889a447ac6",
        "text": "Requiring external module babel-register ?"
      },
      "date": 1674902404147
    },
    {
      "type": "add",
      "id": "85dc814fdb379d31",
      "item": {
        "type": "paragraph",
        "id": "85dc814fdb379d31",
        "text": "chat.openai: Babel is a JavaScript transpiler that allows developers to use modern JavaScript syntax, such as ES6 and ES7, in their code, even if the environment they are running the code in does not support it yet.\n\nThe babel-register module is a require hook that allows you to use Babel to transpile your code on-the-fly, as it is being required. This can be useful when running your code in an environment that does not support the latest JavaScript features, such as an older version of Node.js."
      },
      "after": "65ab7a889a447ac6",
      "date": 1674902481242
    },
    {
      "type": "edit",
      "id": "85dc814fdb379d31",
      "item": {
        "type": "paragraph",
        "id": "85dc814fdb379d31",
        "text": "chat.openai: [[Babel]] is a JavaScript transpiler that allows developers to use modern JavaScript syntax, such as ES6 and ES7, in their code, even if the environment they are running the code in does not support it yet.\n\nThe babel-register module is a require hook that allows you to use Babel to transpile your code on-the-fly, as it is being required. This can be useful when running your code in an environment that does not support the latest JavaScript features, such as an older version of Node.js."
      },
      "date": 1674902489902
    },
    {
      "item": {
        "type": "factory",
        "id": "cd3fdef5ae43a20a"
      },
      "id": "cd3fdef5ae43a20a",
      "type": "add",
      "after": "85dc814fdb379d31",
      "date": 1674902613852
    },
    {
      "type": "edit",
      "id": "cd3fdef5ae43a20a",
      "item": {
        "type": "paragraph",
        "id": "cd3fdef5ae43a20a",
        "text": "To use babel-register, you first need to install it, along with the required presets, such as @babel/preset-env, using npm:"
      },
      "date": 1674902615627
    },
    {
      "item": {
        "type": "factory",
        "id": "5ddc03a4fe23dfd6"
      },
      "id": "5ddc03a4fe23dfd6",
      "type": "add",
      "after": "cd3fdef5ae43a20a",
      "date": 1674902619017
    },
    {
      "type": "edit",
      "id": "5ddc03a4fe23dfd6",
      "item": {
        "type": "code",
        "id": "5ddc03a4fe23dfd6",
        "text": "npm install --save-dev babel-register @babel/preset-env\n"
      },
      "date": 1674902621099
    },
    {
      "item": {
        "type": "factory",
        "id": "cd2989fe90c8b5bb"
      },
      "id": "cd2989fe90c8b5bb",
      "type": "add",
      "after": "5ddc03a4fe23dfd6",
      "date": 1674902783962
    },
    {
      "type": "edit",
      "id": "cd2989fe90c8b5bb",
      "item": {
        "type": "pagefold",
        "id": "cd2989fe90c8b5bb",
        "text": "~"
      },
      "date": 1674902788019
    },
    {
      "item": {
        "type": "factory",
        "id": "b434305a145925e4"
      },
      "id": "b434305a145925e4",
      "type": "add",
      "after": "cd2989fe90c8b5bb",
      "date": 1674902789238
    },
    {
      "type": "edit",
      "id": "b434305a145925e4",
      "item": {
        "type": "paragraph",
        "id": "b434305a145925e4",
        "text": "There is an example on how to comsume the API which som.js offered. Please find it in ./example/64nodeSOM.js."
      },
      "date": 1674902795876
    },
    {
      "type": "edit",
      "id": "b434305a145925e4",
      "item": {
        "type": "paragraph",
        "id": "b434305a145925e4",
        "text": "There is an example on how to comsume the API which som.js offered. Please find it in ./example/64nodeSOM.js. What does it script do?"
      },
      "date": 1674902812541
    },
    {
      "type": "add",
      "id": "6773712293a1bff3",
      "item": {
        "type": "paragraph",
        "id": "6773712293a1bff3",
        "text": "chat.openai:"
      },
      "after": "b434305a145925e4",
      "date": 1674902819337
    },
    {
      "type": "edit",
      "id": "6773712293a1bff3",
      "item": {
        "type": "paragraph",
        "id": "6773712293a1bff3",
        "text": "chat.openai: This script is a demonstration of using the SOM (Self-Organizing Map) library to train a SOM model.\n\nThe script first imports several dependencies, including 'ndarray' and 'ndarray-ops' for working with arrays, 'cwise' for performing operations on arrays, 'ndarray-show' for displaying array values, 'underscore' for utility functions and 'som.js' for the SOM library.\n\nIt then declares and initializes several variables:\n\nmodelNumber is the number of models in the SOM.\ndimension is the dimension of the models.\nM is a 2D array of size modelNumber*dimension which is used to store the models.\nsqrootM is the square root of the number of models.\ninputNumber is the number of input vectors.\ninputVector is a 2D array of size dimension*inputNumber which is used to store the input vectors.\ntrainingTimes is the number of times the SOM will be trained.\nThen, the script fills the inputVector and M arrays with random values using the ops.random() function.\n\nIt then defines a callback function, which will be called after each training iteration and takes two arguments: currentmap, currentTime. It is not doing anything in the current code snippet.\n\nAfter that, it logs the original map array and then trains the SOM model using the som() function, passing the M array, inputVector array, trainingTimes, the callback function, a learning rate and a radius of influence.\n\nFinally, it logs the trained map array after training.\n\nIt should be noted that the script is missing some parts of the implementation like the instantiation of the SOM class, and that it is using the som.js as a function, but in most cases it should be an instance of a class."
      },
      "date": 1674902830534
    },
    {
      "item": {
        "type": "factory",
        "id": "24b8d2895f97b93e"
      },
      "id": "24b8d2895f97b93e",
      "type": "add",
      "after": "6773712293a1bff3",
      "date": 1674902907315
    },
    {
      "type": "edit",
      "id": "24b8d2895f97b93e",
      "item": {
        "type": "pagefold",
        "id": "24b8d2895f97b93e",
        "text": "~"
      },
      "date": 1674902911448
    },
    {
      "item": {
        "type": "factory",
        "id": "2f5f7ec3adc4f94e"
      },
      "id": "2f5f7ec3adc4f94e",
      "type": "add",
      "after": "24b8d2895f97b93e",
      "date": 1674902912467
    },
    {
      "type": "edit",
      "id": "2f5f7ec3adc4f94e",
      "item": {
        "type": "paragraph",
        "id": "2f5f7ec3adc4f94e",
        "text": "Is M the rectangular grid we'd talked about?"
      },
      "date": 1674902914723
    },
    {
      "item": {
        "type": "factory",
        "id": "66c23573f01f01ff"
      },
      "id": "66c23573f01f01ff",
      "type": "add",
      "after": "2f5f7ec3adc4f94e",
      "date": 1674902919480
    },
    {
      "type": "edit",
      "id": "66c23573f01f01ff",
      "item": {
        "type": "paragraph",
        "id": "66c23573f01f01ff",
        "text": "chat.openai: No, in this script, M is a 2D array that is being used to store the models of the Self-Organizing Feature Map (SOM). The rectangular grid is not explicitly created in this script, but the SOM algorithm will arrange the models in a grid-like structure. The grid structure of the SOM can be visualized by reshaping the M array into a 3D array, where the dimensions of the grid are determined by the square root of the number of models."
      },
      "date": 1674902925874
    },
    {
      "item": {
        "type": "factory",
        "id": "c09c38b0b99e8f6f"
      },
      "id": "c09c38b0b99e8f6f",
      "type": "add",
      "after": "66c23573f01f01ff",
      "date": 1674902983723
    },
    {
      "type": "edit",
      "id": "c09c38b0b99e8f6f",
      "item": {
        "type": "pagefold",
        "id": "c09c38b0b99e8f6f",
        "text": "~"
      },
      "date": 1674902986253
    },
    {
      "item": {
        "type": "factory",
        "id": "ba6e34b73a540ce9"
      },
      "id": "ba6e34b73a540ce9",
      "type": "add",
      "after": "c09c38b0b99e8f6f",
      "date": 1674902987414
    },
    {
      "type": "edit",
      "id": "ba6e34b73a540ce9",
      "item": {
        "type": "paragraph",
        "id": "ba6e34b73a540ce9",
        "text": "Could you expand on that mapping between 2D and 3D?"
      },
      "date": 1674902989163
    },
    {
      "item": {
        "type": "factory",
        "id": "5746094aefc97508"
      },
      "id": "5746094aefc97508",
      "type": "add",
      "after": "ba6e34b73a540ce9",
      "date": 1674903008169
    },
    {
      "type": "edit",
      "id": "5746094aefc97508",
      "item": {
        "type": "paragraph",
        "id": "5746094aefc97508",
        "text": "chat.openai: Sure. In this script, the M array is a 2D array of size modelNumber * dimension, where modelNumber is the number of models in the SOM and dimension is the number of features in each model. The SOM algorithm uses this 2D array to organize the models into a grid-like structure.\n\nTo visualize this grid structure, the 2D M array can be reshaped into a 3D array. The reshaping process is done by creating a new array of size dimension * sqrootM * sqrootM and mapping the values of the M array into this new array. sqrootM is the square root of the number of models.\n\nThe first dimension of the new array represents the features of the models, the second dimension represents the rows of the grid, and the third dimension represents the columns of the grid. So, each element in the new array corresponds to a specific model in the grid, where the position of the element in the grid is determined by its row and column indices, and the values of the element correspond to the features of the model.\n\nBy reshaping the 2D M array into a 3D array, you can get a better visualization of the grid structure of the SOM.\n\n\nRegenerate response\n"
      },
      "date": 1674903014845
    },
    {
      "item": {
        "type": "factory",
        "id": "d2e0713956bf674a"
      },
      "id": "d2e0713956bf674a",
      "type": "add",
      "after": "5746094aefc97508",
      "date": 1674903103545
    },
    {
      "type": "edit",
      "id": "d2e0713956bf674a",
      "item": {
        "type": "pagefold",
        "id": "d2e0713956bf674a",
        "text": "~"
      },
      "date": 1674903106133
    },
    {
      "item": {
        "type": "factory",
        "id": "d7cef40babd607fd"
      },
      "id": "d7cef40babd607fd",
      "type": "add",
      "after": "d2e0713956bf674a",
      "date": 1674903107449
    },
    {
      "type": "edit",
      "id": "d7cef40babd607fd",
      "item": {
        "type": "paragraph",
        "id": "d7cef40babd607fd",
        "text": "What is a SOM Model?"
      },
      "date": 1674903109153
    },
    {
      "item": {
        "type": "factory",
        "id": "bb3fe282c364ff41"
      },
      "id": "bb3fe282c364ff41",
      "type": "add",
      "after": "d7cef40babd607fd",
      "date": 1674903116764
    },
    {
      "type": "edit",
      "id": "bb3fe282c364ff41",
      "item": {
        "type": "paragraph",
        "id": "bb3fe282c364ff41",
        "text": "chat.openai: A Self-Organizing Map (SOM) is a type of artificial neural network that is trained using unsupervised learning to produce a low-dimensional (typically two-dimensional) representation of the input space of the training samples, called a map. The map consists of a grid of neurons that represent the different regions of the input space, where each neuron is associated with a weight vector that encodes the characteristics of the inputs that the neuron represents.\n\nThe SOM algorithm begins by initializing the weight vectors of the neurons to random values. Then, it iteratively updates the weight vectors by adjusting them to be closer to the input samples that are presented to the network. The update process is done in such a way that the neurons that are closest to the input sample in the weight space are updated more than the neurons that are farther away. This process causes the neurons to \"self-organize\" into a topographic map of the input space, where similar inputs are mapped to nearby neurons, and dissimilar inputs are mapped to distant neurons.\n\nThe SOM algorithm is useful for data visualization, pattern recognition, and feature extraction, among other applications. Because it preserves the topological relationships between the inputs, it can be used to reveal the underlying structure of complex, high-dimensional data sets."
      },
      "date": 1674903122505
    },
    {
      "item": {
        "type": "factory",
        "id": "c8b74fd874eee54a"
      },
      "id": "c8b74fd874eee54a",
      "type": "add",
      "after": "bb3fe282c364ff41",
      "date": 1674903324324
    },
    {
      "type": "edit",
      "id": "c8b74fd874eee54a",
      "item": {
        "type": "pagefold",
        "id": "c8b74fd874eee54a",
        "text": "~"
      },
      "date": 1674903331037
    },
    {
      "item": {
        "type": "factory",
        "id": "d9c2b8cf016c6772"
      },
      "id": "d9c2b8cf016c6772",
      "type": "add",
      "after": "c8b74fd874eee54a",
      "date": 1674903334955
    },
    {
      "type": "edit",
      "id": "d9c2b8cf016c6772",
      "item": {
        "type": "paragraph",
        "id": "d9c2b8cf016c6772",
        "text": "How to represent a wikipedia page  as a vector of features?"
      },
      "date": 1674903336765
    },
    {
      "item": {
        "type": "factory",
        "id": "a611fa0889c19eb6"
      },
      "id": "a611fa0889c19eb6",
      "type": "add",
      "after": "d9c2b8cf016c6772",
      "date": 1674903343404
    },
    {
      "type": "edit",
      "id": "a611fa0889c19eb6",
      "item": {
        "type": "paragraph",
        "id": "a611fa0889c19eb6",
        "text": "chat.openai: here are several ways to represent a Wikipedia page as a vector of features, depending on the task at hand and the resources available. Some common approaches include:\n\nBag of Words: This approach represents the page as a vector of the frequency of each word in the page, disregarding grammar and word order. It's a simple and widely used approach in natural language processing.\nTF-IDF: This approach is a variation of the bag-of-words model that assigns a weight to each word based on its importance in the page, taking into account how often the word appears in the page compared to how often it appears in the entire Wikipedia corpus.\nLatent Semantic Analysis (LSA): This approach represents the page as a vector of latent concepts, or topics, that are extracted from the page through a process of dimensionality reduction. It tries to capture the underlying meaning of the page by identifying the most important concepts that the page is about.\nWord Embedding: This approach represents a page as a weighted sum of word embeddings, where each word is represented as a vector of real numbers. The embeddings are typically learned by training a neural network on a large corpus of text.\nNetwork based: This approach represents the page as a node in a network, where the edges represent the links between pages. The network can be analyzed using various network analysis techniques, such as centrality measures, to extract features of the page.\nIt is important to note that these are just a few examples of the ways to represent a Wikipedia page as a vector of features and there are many other possibilities as well. The best approach would depend on the task at hand and the resources available."
      },
      "date": 1674903351621
    },
    {
      "type": "edit",
      "id": "a611fa0889c19eb6",
      "item": {
        "type": "paragraph",
        "id": "a611fa0889c19eb6",
        "text": "chat.openai: here are several ways to represent a Wikipedia page as a vector of features, depending on the task at hand and the resources available. Some common approaches include:\n\n"
      },
      "date": 1674903364509
    },
    {
      "type": "add",
      "id": "e60795e30c3acb97",
      "item": {
        "type": "paragraph",
        "id": "e60795e30c3acb97",
        "text": "Bag of Words: This approach represents the page as a vector of the frequency of each word in the page, disregarding grammar and word order. It's a simple and widely used approach in natural language processing.\n"
      },
      "after": "a611fa0889c19eb6",
      "date": 1674903367032
    },
    {
      "type": "add",
      "id": "f6f8a2183faf1db2",
      "item": {
        "type": "paragraph",
        "id": "f6f8a2183faf1db2",
        "text": "TF-IDF: This approach is a variation of the bag-of-words model that assigns a weight to each word based on its importance in the page, taking into account how often the word appears in the page compared to how often it appears in the entire Wikipedia corpus.\n"
      },
      "after": "e60795e30c3acb97",
      "date": 1674903368754
    },
    {
      "type": "add",
      "id": "94398c633f803417",
      "item": {
        "type": "paragraph",
        "id": "94398c633f803417",
        "text": "Latent Semantic Analysis (LSA): This approach represents the page as a vector of latent concepts, or topics, that are extracted from the page through a process of dimensionality reduction. It tries to capture the underlying meaning of the page by identifying the most important concepts that the page is about.\nWord Embedding: This approach represents a page as a weighted sum of word embeddings, where each word is represented as a vector of real numbers. The embeddings are typically learned by training a neural network on a large corpus of text.\nNetwork based: This approach represents the page as a node in a network, where the edges represent the links between pages. The network can be analyzed using various network analysis techniques, such as centrality measures, to extract features of the page.\nIt is important to note that these are just a few examples of the ways to represent a Wikipedia page as a vector of features and there are many other possibilities as well. The best approach would depend on the task at hand and the resources available."
      },
      "after": "f6f8a2183faf1db2",
      "date": 1674903374439
    },
    {
      "type": "edit",
      "id": "94398c633f803417",
      "item": {
        "type": "paragraph",
        "id": "94398c633f803417",
        "text": "Latent Semantic Analysis (LSA): This approach represents the page as a vector of latent concepts, or topics, that are extracted from the page through a process of dimensionality reduction. It tries to capture the underlying meaning of the page by identifying the most important concepts that the page is about.\n"
      },
      "date": 1674903384754
    },
    {
      "type": "add",
      "id": "5b4918c44fdce6d3",
      "item": {
        "type": "paragraph",
        "id": "5b4918c44fdce6d3",
        "text": "Word Embedding: This approach represents a page as a weighted sum of word embeddings, where each word is represented as a vector of real numbers. The embeddings are typically learned by training a neural network on a large corpus of text.\nNetwork based: This approach represents the page as a node in a network, where the edges represent the links between pages. The network can be analyzed using various network analysis techniques, such as centrality measures, to extract features of the page.\nIt is important to note that these are just a few examples of the ways to represent a Wikipedia page as a vector of features and there are many other possibilities as well. The best approach would depend on the task at hand and the resources available."
      },
      "after": "94398c633f803417",
      "date": 1674903386268
    },
    {
      "type": "edit",
      "id": "5b4918c44fdce6d3",
      "item": {
        "type": "paragraph",
        "id": "5b4918c44fdce6d3",
        "text": "Word Embedding: This approach represents a page as a weighted sum of word embeddings, where each word is represented as a vector of real numbers. The embeddings are typically learned by training a neural network on a large corpus of text.\n"
      },
      "date": 1674903394577
    },
    {
      "type": "add",
      "id": "4327639bd6b83fce",
      "item": {
        "type": "paragraph",
        "id": "4327639bd6b83fce",
        "text": "Network based: This approach represents the page as a node in a network, where the edges represent the links between pages. The network can be analyzed using various network analysis techniques, such as centrality measures, to extract features of the page.\n"
      },
      "after": "5b4918c44fdce6d3",
      "date": 1674903401127
    },
    {
      "type": "add",
      "id": "c137af4fd648d0bf",
      "item": {
        "type": "paragraph",
        "id": "c137af4fd648d0bf",
        "text": "It is important to note that these are just a few examples of the ways to represent a Wikipedia page as a vector of features and there are many other possibilities as well. The best approach would depend on the task at hand and the resources available."
      },
      "after": "4327639bd6b83fce",
      "date": 1674903401652
    },
    {
      "type": "edit",
      "id": "e60795e30c3acb97",
      "item": {
        "type": "paragraph",
        "id": "e60795e30c3acb97",
        "text": "[[Bag of Words]]: This approach represents the page as a vector of the frequency of each word in the page, disregarding grammar and word order. It's a simple and widely used approach in natural language processing.\n"
      },
      "date": 1674903457583
    },
    {
      "type": "edit",
      "id": "94398c633f803417",
      "item": {
        "type": "paragraph",
        "id": "94398c633f803417",
        "text": "[[Latent Semantic Analysis]] (LSA): This approach represents the page as a vector of latent concepts, or topics, that are extracted from the page through a process of dimensionality reduction. It tries to capture the underlying meaning of the page by identifying the most important concepts that the page is about.\n"
      },
      "date": 1674903516697
    },
    {
      "item": {
        "type": "factory",
        "id": "cec3cc79bf95df1e"
      },
      "id": "cec3cc79bf95df1e",
      "type": "add",
      "after": "c137af4fd648d0bf",
      "date": 1674905518697
    },
    {
      "type": "edit",
      "id": "cec3cc79bf95df1e",
      "item": {
        "type": "pagefold",
        "id": "cec3cc79bf95df1e",
        "text": "~"
      },
      "date": 1674905523051
    },
    {
      "item": {
        "type": "factory",
        "id": "0a5088c5a9848282"
      },
      "id": "0a5088c5a9848282",
      "type": "add",
      "after": "cec3cc79bf95df1e",
      "date": 1674905524600
    },
    {
      "type": "edit",
      "id": "0a5088c5a9848282",
      "item": {
        "type": "paragraph",
        "id": "0a5088c5a9848282",
        "text": "[[Site Survey]]"
      },
      "date": 1674905529222
    },
    {
      "type": "edit",
      "id": "0a5088c5a9848282",
      "item": {
        "type": "paragraph",
        "id": "0a5088c5a9848282",
        "text": "⇒ [[Site Survey]]"
      },
      "date": 1674905542686
    },
    {
      "item": {
        "type": "factory",
        "id": "453001b22accf95d"
      },
      "id": "453001b22accf95d",
      "type": "add",
      "after": "0a5088c5a9848282",
      "date": 1674905551845
    },
    {
      "type": "edit",
      "id": "453001b22accf95d",
      "item": {
        "type": "paragraph",
        "id": "453001b22accf95d",
        "text": "Ward via [[matrix]]\nAs we approach a week of experience with Site Survey we take our first steps toward uniformity in how the parts work together and how we can support new and special purpose surveys. For example, we've created a drag and drop probe tester that will probe one page at a time. We found early that it was hard to debug with console.log when hundreds of pages are flying by at 30 per second."
      },
      "date": 1674905565651
    },
    {
      "item": {
        "type": "factory",
        "id": "657043fdb7229ba6"
      },
      "id": "657043fdb7229ba6",
      "type": "add",
      "after": "453001b22accf95d",
      "date": 1674905597991
    },
    {
      "type": "edit",
      "id": "657043fdb7229ba6",
      "item": {
        "type": "paragraph",
        "id": "657043fdb7229ba6",
        "text": "chat.openai: A site survey is a process of gathering information about a specific location in order to plan and design a wireless network or other type of infrastructure. This can include measuring signal strength and identifying potential sources of interference, as well as assessing the physical layout of the location and determining the best placement for network equipment. Site surveys can be conducted using specialized software and equipment, and are often performed by trained professionals with experience in network design and deployment. The goal of a site survey is to ensure that the network will perform optimally and provide reliable coverage for users."
      },
      "date": 1674905608099
    },
    {
      "type": "edit",
      "id": "453001b22accf95d",
      "item": {
        "type": "paragraph",
        "id": "453001b22accf95d",
        "text": "Ward via [https://matrix.to/#/!ORfrUEFeWFcHAMLFLr:matrix.org/$167487411948907kXEOw:matrix.org?via=matrix.org&via=matrix.allmende.io&via=chat.weho.st matrix]\nAs we approach a week of experience with Site Survey we take our first steps toward uniformity in how the parts work together and how we can support new and special purpose surveys. For example, we've created a drag and drop probe tester that will probe one page at a time. We found early that it was hard to debug with console.log when hundreds of pages are flying by at 30 per second."
      },
      "date": 1674905657034
    },
    {
      "type": "edit",
      "id": "0a5088c5a9848282",
      "item": {
        "type": "paragraph",
        "id": "0a5088c5a9848282",
        "text": "⇒ [[Site Survey]] [[Page Probe"
      },
      "date": 1674905684766
    },
    {
      "type": "edit",
      "id": "0a5088c5a9848282",
      "item": {
        "type": "paragraph",
        "id": "0a5088c5a9848282",
        "text": "⇒ [[Site Survey]] ⇒ [[Probe Page Preview]]"
      },
      "date": 1674905707369
    },
    {
      "item": {
        "type": "factory",
        "id": "2c14f2f5f43913eb"
      },
      "id": "2c14f2f5f43913eb",
      "type": "add",
      "after": "657043fdb7229ba6",
      "date": 1674907750476
    },
    {
      "type": "edit",
      "id": "2c14f2f5f43913eb",
      "item": {
        "type": "pagefold",
        "id": "2c14f2f5f43913eb",
        "text": "~"
      },
      "date": 1674907753501
    },
    {
      "item": {
        "type": "factory",
        "id": "091054a7f9de272c"
      },
      "id": "091054a7f9de272c",
      "type": "add",
      "after": "2c14f2f5f43913eb",
      "date": 1674907755282
    },
    {
      "type": "edit",
      "id": "091054a7f9de272c",
      "item": {
        "type": "paragraph",
        "id": "091054a7f9de272c",
        "text": "⇒ [[KJ Method]]: chat.openai:"
      },
      "date": 1674907779989
    },
    {
      "type": "edit",
      "id": "091054a7f9de272c",
      "item": {
        "type": "paragraph",
        "id": "091054a7f9de272c",
        "text": "⇒ [[KJ Method]]: chat.openai: The KJ method (also known as the KJ Analysis or Affinity Diagram) is a tool used in brainstorming and problem-solving sessions to organize and categorize ideas. It is named after its creator, Jiro Kawakita, who developed the method in the 1970s. The KJ method is used to help groups of people identify and prioritize key issues or ideas by grouping similar ideas together and then identifying relationships among them. It is often used in business, education, and other fields to help teams generate, organize, and evaluate ideas."
      },
      "date": 1674907789675
    },
    {
      "type": "edit",
      "id": "091054a7f9de272c",
      "item": {
        "type": "paragraph",
        "id": "091054a7f9de272c",
        "text": "⇒ [[KJ Method]]: chat.openai: The KJ method (also known as the KJ Analysis or Affinity Diagram) is a tool used in [[Brainstorming]] and problem-solving sessions to organize and categorize ideas. It is named after its creator, Jiro Kawakita, who developed the method in the 1970s. The KJ method is used to help groups of people identify and prioritize key issues or ideas by grouping similar ideas together and then identifying relationships among them. It is often used in business, education, and other fields to help teams generate, organize, and evaluate ideas."
      },
      "date": 1674907835892
    },
    {
      "item": {
        "type": "factory",
        "id": "a3dcbb89cde187a9"
      },
      "id": "a3dcbb89cde187a9",
      "type": "add",
      "after": "091054a7f9de272c",
      "date": 1674908172186
    },
    {
      "type": "edit",
      "id": "a3dcbb89cde187a9",
      "item": {
        "type": "paragraph",
        "id": "a3dcbb89cde187a9",
        "text": "chat.openai: Self-organizing Maps (SOM) can be used to create a visual representation of the clusters and relationships among a set of data points, similar to how Affinity Mapping is used to organize and visualize a set of ideas. SOM is an unsupervised machine learning technique that is used for data visualization and dimensionality reduction. It works by training a neural network on a set of input data, and then using the network to create a two-dimensional map of the data. The map is organized so that similar data points are grouped together, and the relationships between the data points are represented by the topology of the map.\n\nFor example, SOM can be used to create a map of customer data, where each customer is represented by a data point. The map will group customers with similar characteristics (like age, income, location, etc.) together, and the topology of the map will show how the customers are related to one another. This makes it easy to see patterns and relationships among the customers and to make decisions based on that information.\n\nIn a similar way, SOM algorithm can be applied in Affinity Mapping to create a visual representation of the clusters and relationships among a set of ideas, concepts or data points."
      },
      "date": 1674908180171
    },
    {
      "item": {
        "type": "factory",
        "id": "b8fa37a8f931b5aa"
      },
      "id": "b8fa37a8f931b5aa",
      "type": "add",
      "after": "a3dcbb89cde187a9",
      "date": 1674908267966
    },
    {
      "type": "edit",
      "id": "b8fa37a8f931b5aa",
      "item": {
        "type": "pagefold",
        "id": "b8fa37a8f931b5aa",
        "text": "~"
      },
      "date": 1674908270984
    },
    {
      "item": {
        "type": "factory",
        "id": "1ce05f97264a47b3"
      },
      "id": "1ce05f97264a47b3",
      "type": "add",
      "after": "b8fa37a8f931b5aa",
      "date": 1674908272422
    },
    {
      "type": "edit",
      "id": "1ce05f97264a47b3",
      "item": {
        "type": "paragraph",
        "id": "1ce05f97264a47b3",
        "text": "Takashi explores this practice in a paper entitled [https://drive.google.com/open?id=1JP-RIPvD5LXdb85pZ5ah-nb3ffC_nsqj Philosophy and Methodology of Clustering in Pattern Mining]"
      },
      "date": 1674908274313
    },
    {
      "item": {
        "type": "factory",
        "id": "7bc7d02210c09e8d"
      },
      "id": "7bc7d02210c09e8d",
      "type": "add",
      "after": "1ce05f97264a47b3",
      "date": 1674908281400
    },
    {
      "type": "edit",
      "id": "7bc7d02210c09e8d",
      "item": {
        "type": "paragraph",
        "id": "7bc7d02210c09e8d",
        "text": "chat.openai: [[I]]'m sorry, I'm unable to access external links as I'm a text-based model, but I can tell you that Takashi Iba's paper is discussing the use of the clustering technique in pattern mining, which is the process of discovering patterns and relationships in a dataset. Clustering is a key aspect of this process, as it helps to group similar data points together and identify patterns among them. The paper likely explores the use of clustering techniques, such as the KJ Method and Affinity Mapping, and how they can be used to identify patterns and relationships in a dataset. Additionally, the paper probably describes the philosophy and methodology behind the use of clustering in pattern mining, and how it can be used to gain insights from data."
      },
      "date": 1674908294608
    },
    {
      "type": "edit",
      "id": "7bc7d02210c09e8d",
      "item": {
        "type": "paragraph",
        "id": "7bc7d02210c09e8d",
        "text": "chat.openai: [[I]]'m sorry, I'm unable to access external links as I'm a text-based model, but I can tell you that Takashi Iba's paper is discussing the use of the clustering technique in [[Pattern Mining]], which is the process of discovering patterns and relationships in a dataset. Clustering is a key aspect of this process, as it helps to group similar data points together and identify patterns among them. The paper likely explores the use of clustering techniques, such as the KJ Method and Affinity Mapping, and how they can be used to identify patterns and relationships in a dataset. Additionally, the paper probably describes the philosophy and methodology behind the use of clustering in pattern mining, and how it can be used to gain insights from data."
      },
      "date": 1674908412088
    },
    {
      "type": "add",
      "id": "70b3ffef2110735f",
      "item": {
        "type": "paragraph",
        "id": "70b3ffef2110735f",
        "text": "[…] chat.openai: Pattern mining is a technique used to identify patterns and relationships within a dataset. One of the most well-known applications of pattern mining is market-basket analysis, which is used to identify items that are often purchased together in a retail setting. This can help retailers optimize their inventory and product placement, and also identify new sales opportunities.\n\nData mining allows for the discovery of unexpected associations in large datasets, which can open new avenues for research or marketing. Another important use of pattern mining is the discovery of sequential patterns, such as sequences of errors or warnings that precede equipment failure. This information can be used to schedule preventative maintenance or provide insight into a design flaw.\n\nIt's also worth noting that pattern mining is used in many other domains, such as financial analysis, medical research, bioinformatics, natural language processing and image and text recognition.\n\n\nRegenerate response\n"
      },
      "after": "7bc7d02210c09e8d",
      "date": 1674908541453
    },
    {
      "type": "edit",
      "id": "70b3ffef2110735f",
      "item": {
        "type": "paragraph",
        "id": "70b3ffef2110735f",
        "text": "[…] chat.openai: Pattern mining is a technique used to identify patterns and relationships within a dataset. One of the most well-known applications of pattern mining is [[Market-Basket Analysis]], which is used to identify items that are often purchased together in a retail setting. This can help retailers optimize their inventory and product placement, and also identify new sales opportunities.\n\nData mining allows for the discovery of unexpected associations in large datasets, which can open new avenues for research or marketing. Another important use of pattern mining is the discovery of sequential patterns, such as sequences of errors or warnings that precede equipment failure. This information can be used to schedule preventative maintenance or provide insight into a design flaw.\n\nIt's also worth noting that pattern mining is used in many other domains, such as financial analysis, medical research, bioinformatics, natural language processing and image and text recognition.\n\n\nRegenerate response\n"
      },
      "date": 1674908623449
    },
    {
      "id": "2f55f42e194e7df7",
      "type": "add",
      "item": {
        "type": "video",
        "id": "2f55f42e194e7df7",
        "text": "YOUTUBE tkZqPMzgvzg\nHip hop, grit, and academic success: Bettina Love at TEDxUGA\n"
      },
      "after": "70b3ffef2110735f",
      "date": 1674908905259
    },
    {
      "type": "edit",
      "id": "70b3ffef2110735f",
      "item": {
        "type": "paragraph",
        "id": "70b3ffef2110735f",
        "text": "[…] chat.openai: Pattern mining is a technique used to identify patterns and relationships within a dataset. One of the most well-known applications of pattern mining is [[Market-Basket Analysis]], which is used to identify items that are often purchased together in a retail setting. This can help retailers optimize their inventory and product placement, and also identify new sales opportunities.\n\nData mining allows for the discovery of unexpected associations in large datasets, which can open new avenues for research or marketing. Another important use of pattern mining is the discovery of sequential patterns, such as sequences of errors or warnings that precede equipment failure. This information can be used to schedule preventative maintenance or provide insight into a design flaw.\n\nIt's also worth noting that pattern mining is used in many other domains, such as financial analysis, medical research, bioinformatics, natural language processing and image and text recognition.\n\n\n⇒ [[Regenerate Response]]"
      },
      "date": 1674908944982
    },
    {
      "type": "edit",
      "id": "091054a7f9de272c",
      "item": {
        "type": "paragraph",
        "id": "091054a7f9de272c",
        "text": "⇒ Recursive [[Consensual Coordination]] ⇒ [[KJ Method]]: chat.openai: The KJ method (also known as the KJ Analysis or Affinity Diagram) is a tool used in [[Brainstorming]] and problem-solving sessions to organize and categorize ideas. It is named after its creator, Jiro Kawakita, who developed the method in the 1970s. The KJ method is used to help groups of people identify and prioritize key issues or ideas by grouping similar ideas together and then identifying relationships among them. It is often used in business, education, and other fields to help teams generate, organize, and evaluate ideas."
      },
      "date": 1674909716585
    },
    {
      "item": {
        "type": "factory",
        "id": "e32951b801832d1c"
      },
      "id": "e32951b801832d1c",
      "type": "add",
      "after": "2f55f42e194e7df7",
      "date": 1674913754797
    },
    {
      "type": "edit",
      "id": "e32951b801832d1c",
      "item": {
        "type": "pagefold",
        "id": "e32951b801832d1c",
        "text": "~"
      },
      "date": 1674913760245
    },
    {
      "item": {
        "type": "factory",
        "id": "b022105a10192836"
      },
      "id": "b022105a10192836",
      "type": "add",
      "after": "e32951b801832d1c",
      "date": 1674913762026
    },
    {
      "type": "edit",
      "id": "b022105a10192836",
      "item": {
        "type": "paragraph",
        "id": "b022105a10192836",
        "text": "Talking About Large Language Models"
      },
      "date": 1674913777808
    },
    {
      "type": "edit",
      "id": "b022105a10192836",
      "item": {
        "type": "paragraph",
        "id": "b022105a10192836",
        "text": "Talking About Large Language Models [https://fedi.simonwillison.net/@simon/109738632902770815 post]"
      },
      "date": 1674913800128
    },
    {
      "type": "edit",
      "id": "b022105a10192836",
      "item": {
        "type": "paragraph",
        "id": "b022105a10192836",
        "text": "Talking About Large Language Models [https://fedi.simonwillison.net/@simon/109738632902770815 post], [https://www.arxiv-vanity.com/papers/2212.03551/ page]"
      },
      "date": 1674913814595
    },
    {
      "item": {
        "type": "factory",
        "id": "46b35d893db7771b"
      },
      "id": "46b35d893db7771b",
      "type": "add",
      "after": "b022105a10192836",
      "date": 1674913834664
    },
    {
      "type": "edit",
      "id": "46b35d893db7771b",
      "item": {
        "type": "paragraph",
        "id": "46b35d893db7771b",
        "text": "Thanks to rapid progress in artificial intelligence, we have entered an era when technology and philosophy intersect in interesting ways. Sitting squarely at the centre of this intersection are large language models (LLMs). The more adept LLMs become at mimicking human language, the more vulnerable we become to anthropomorphism, to seeing the systems in which they are embedded as more human-like than they really are. This trend is amplified by the natural tendency to use philosophically loaded terms, such as “knows”, “believes”, and “thinks”, when describing these systems. To mitigate this trend, this paper advocates the practice of repeatedly stepping back to remind ourselves of how LLMs, and the systems of which they form a part, actually work. The hope is that increased scientific precision will encourage more philosophical nuance in the discourse around artificial intelligence, both within the field and in the public sphere."
      },
      "date": 1674913836437
    },
    {
      "type": "edit",
      "id": "46b35d893db7771b",
      "item": {
        "type": "paragraph",
        "id": "46b35d893db7771b",
        "text": "Thanks to rapid progress in artificial intelligence, we have entered an era when technology and philosophy intersect in interesting ways. Sitting squarely at the centre of this intersection are large language models (LLMs). The more adept LLMs become at mimicking human language, the more vulnerable we become to [[Anthropomorphism]], to seeing the systems in which they are embedded as more human-like than they really are. This trend is amplified by the natural tendency to use philosophically loaded terms, such as “knows”, “believes”, and “thinks”, when describing these systems. To mitigate this trend, this paper advocates the practice of repeatedly stepping back to remind ourselves of how LLMs, and the systems of which they form a part, actually work. The hope is that increased scientific precision will encourage more philosophical nuance in the discourse around artificial intelligence, both within the field and in the public sphere."
      },
      "date": 1674913863725
    },
    {
      "type": "edit",
      "id": "b022105a10192836",
      "item": {
        "type": "paragraph",
        "id": "b022105a10192836",
        "text": "Talking About [[Large Language Model]]s [https://fedi.simonwillison.net/@simon/109738632902770815 post], [https://www.arxiv-vanity.com/papers/2212.03551/ page]"
      },
      "date": 1674919632737
    },
    {
      "type": "edit",
      "id": "b022105a10192836",
      "item": {
        "type": "paragraph",
        "id": "b022105a10192836",
        "text": "Talking About ⇒ [[Large Language Model]]s [https://fedi.simonwillison.net/@simon/109738632902770815 post], [https://www.arxiv-vanity.com/papers/2212.03551/ page]"
      },
      "date": 1674919659603
    },
    {
      "id": "46b35d893db7771b",
      "type": "remove",
      "date": 1674919665073
    },
    {
      "item": {
        "type": "factory",
        "id": "48bee69709b621a2"
      },
      "id": "48bee69709b621a2",
      "type": "add",
      "after": "b022105a10192836",
      "date": 1674920234226
    },
    {
      "type": "edit",
      "id": "48bee69709b621a2",
      "item": {
        "type": "assets",
        "id": "48bee69709b621a2",
        "text": "pages/2023-01-28"
      },
      "date": 1674920246164
    },
    {
      "item": {
        "type": "factory",
        "id": "136e5f3237ba548b"
      },
      "id": "136e5f3237ba548b",
      "type": "add",
      "after": "48bee69709b621a2",
      "date": 1674920267868
    },
    {
      "type": "edit",
      "id": "136e5f3237ba548b",
      "item": {
        "type": "html",
        "id": "136e5f3237ba548b",
        "text": "<img\n  src=\"https://wiki.ralfbarkow.ch/assets/pages/2023-01-28/Three%20Triangles%20in%20a%20Hexagon.jpg\"\n  width=\"100%\"\n>"
      },
      "date": 1674920287041
    },
    {
      "item": {
        "type": "factory",
        "id": "e9978202e6d6215c"
      },
      "id": "e9978202e6d6215c",
      "type": "add",
      "after": "136e5f3237ba548b",
      "date": 1674920311553
    },
    {
      "type": "edit",
      "id": "e9978202e6d6215c",
      "item": {
        "type": "paragraph",
        "id": "e9978202e6d6215c",
        "text": "Three Triangles in a Hexagon"
      },
      "date": 1674920313390
    },
    {
      "id": "e9978202e6d6215c",
      "type": "move",
      "order": [
        "931db1a7eb15a85a",
        "374255e21e26bada",
        "e24195cc0d9ebcc4",
        "6ceea1899c32f4f1",
        "9b27e3ded4a84b30",
        "34f0a9ef17ba0765",
        "b0179cab3fc0942f",
        "397f14447ec57d95",
        "9ac45ef5659e4371",
        "2ad2d923ca5676da",
        "3875efe3fcea29ef",
        "52792ac41ee1be36",
        "65ab7a889a447ac6",
        "85dc814fdb379d31",
        "cd3fdef5ae43a20a",
        "5ddc03a4fe23dfd6",
        "cd2989fe90c8b5bb",
        "b434305a145925e4",
        "6773712293a1bff3",
        "24b8d2895f97b93e",
        "2f5f7ec3adc4f94e",
        "66c23573f01f01ff",
        "c09c38b0b99e8f6f",
        "ba6e34b73a540ce9",
        "5746094aefc97508",
        "d2e0713956bf674a",
        "d7cef40babd607fd",
        "bb3fe282c364ff41",
        "c8b74fd874eee54a",
        "d9c2b8cf016c6772",
        "a611fa0889c19eb6",
        "e60795e30c3acb97",
        "f6f8a2183faf1db2",
        "94398c633f803417",
        "5b4918c44fdce6d3",
        "4327639bd6b83fce",
        "c137af4fd648d0bf",
        "cec3cc79bf95df1e",
        "0a5088c5a9848282",
        "453001b22accf95d",
        "657043fdb7229ba6",
        "2c14f2f5f43913eb",
        "091054a7f9de272c",
        "a3dcbb89cde187a9",
        "b8fa37a8f931b5aa",
        "1ce05f97264a47b3",
        "7bc7d02210c09e8d",
        "70b3ffef2110735f",
        "2f55f42e194e7df7",
        "e32951b801832d1c",
        "b022105a10192836",
        "48bee69709b621a2",
        "e9978202e6d6215c",
        "136e5f3237ba548b"
      ],
      "date": 1674920317690
    },
    {
      "type": "edit",
      "id": "e9978202e6d6215c",
      "item": {
        "type": "paragraph",
        "id": "e9978202e6d6215c",
        "text": "Three Triangles in a Hexagon [https://www.puzzleprime.com/lessons/three-triangles-in-a-hexagon/ page]"
      },
      "date": 1674920334017
    },
    {
      "type": "edit",
      "id": "e9978202e6d6215c",
      "item": {
        "type": "paragraph",
        "id": "e9978202e6d6215c",
        "text": "Three Triangles in a Hexagon [https://www.puzzleprime.com/lessons/three-triangles-in-a-hexagon/ page], [https://www.puzzleprime.com/wp-content/uploads/2020/07/Three-Triangles-in-a-Hexagon-1-600x601.jpg jpg]"
      },
      "date": 1674920349531
    },
    {
      "type": "edit",
      "id": "e9978202e6d6215c",
      "item": {
        "type": "paragraph",
        "id": "e9978202e6d6215c",
        "text": "Three Triangles in a Hexagon [https://www.puzzleprime.com/lessons/three-triangles-in-a-hexagon/ page], [https://www.puzzleprime.com/wp-content/uploads/2020/07/Three-Triangles-in-a-Hexagon-1-600x601.jpg jpg] ⇒ [[Dreyeck]]"
      },
      "date": 1674920391961
    },
    {
      "type": "add",
      "id": "f3aaab97315f3e30",
      "item": {
        "type": "paragraph",
        "id": "f3aaab97315f3e30",
        "text": "\"You\" aren't aware of anything, right?"
      },
      "after": "b022105a10192836",
      "date": 1674920833573
    },
    {
      "type": "add",
      "id": "cc2d0258d1e21f2e",
      "item": {
        "type": "paragraph",
        "id": "cc2d0258d1e21f2e",
        "text": "chat.openai: As an AI, I am not a sentient being and do not have the ability to be aware of things in the way that humans do. I am a program that processes and generates text based on patterns and information that has been input into my database. I can provide information and answer questions to the best of my abilities based on the information that is available to me."
      },
      "after": "f3aaab97315f3e30",
      "date": 1674920853701
    },
    {
      "type": "edit",
      "id": "b022105a10192836",
      "item": {
        "type": "paragraph",
        "id": "b022105a10192836",
        "text": "Talking About ⇒ [[Large Language Model]]s [https://fedi.simonwillison.net/@simon/109738632902770815 post], [https://www.arxiv-vanity.com/papers/2212.03551/ page] ⇒ [[Sentient Being]]"
      },
      "date": 1674920908378
    },
    {
      "id": "f3aaab97315f3e30",
      "type": "remove",
      "date": 1674920918829
    },
    {
      "id": "cc2d0258d1e21f2e",
      "type": "remove",
      "date": 1674920920647
    },
    {
      "item": {
        "type": "factory",
        "id": "db056b2dbf91a394"
      },
      "id": "db056b2dbf91a394",
      "type": "add",
      "after": "136e5f3237ba548b",
      "date": 1674953897536
    },
    {
      "type": "edit",
      "id": "db056b2dbf91a394",
      "item": {
        "type": "html",
        "id": "db056b2dbf91a394",
        "text": "    <iframe id=\"p5.js web editor embed\"\n        title=\"p5.js web editor embed\"\n        width=\"800\"\n        height=\"600\"\n        src=\"https://editor.p5js.org/\">\n    </iframe>"
      },
      "date": 1674953904278
    },
    {
      "type": "remove",
      "id": "136e5f3237ba548b",
      "date": 1674953948567
    },
    {
      "item": {
        "type": "factory",
        "id": "2908e45ed5a5c4c1"
      },
      "id": "2908e45ed5a5c4c1",
      "type": "add",
      "after": "db056b2dbf91a394",
      "date": 1674953954170
    },
    {
      "type": "edit",
      "id": "2908e45ed5a5c4c1",
      "item": {
        "type": "frame",
        "id": "2908e45ed5a5c4c1",
        "text": "<img\n  src=\"https://wiki.ralfbarkow.ch/assets/pages/2023-01-28/Three%20Triangles%20in%20a%20Hexagon.jpg\"\n  width=\"100%\"\n>"
      },
      "date": 1674953956692
    },
    {
      "item": {
        "type": "factory",
        "id": "0b412a8e93cf2ac4"
      },
      "id": "0b412a8e93cf2ac4",
      "type": "add",
      "after": "2908e45ed5a5c4c1",
      "date": 1674953979473
    },
    {
      "type": "edit",
      "id": "0b412a8e93cf2ac4",
      "item": {
        "type": "frame",
        "id": "0b412a8e93cf2ac4",
        "text": "    <iframe id=\"p5.js web editor embed\"\n        title=\"p5.js web editor embed\"\n        width=\"800\"\n        height=\"600\"\n        src=\"https://editor.p5js.org/\">\n    </iframe>"
      },
      "date": 1674953985178
    },
    {
      "type": "remove",
      "id": "2908e45ed5a5c4c1",
      "date": 1674953990487
    },
    {
      "item": {
        "type": "factory",
        "id": "da6fabb1d72e7ab7"
      },
      "id": "da6fabb1d72e7ab7",
      "type": "add",
      "after": "0b412a8e93cf2ac4",
      "date": 1674953994284
    },
    {
      "type": "edit",
      "id": "da6fabb1d72e7ab7",
      "item": {
        "type": "html",
        "id": "da6fabb1d72e7ab7",
        "text": "<img\n  src=\"https://wiki.ralfbarkow.ch/assets/pages/2023-01-28/Three%20Triangles%20in%20a%20Hexagon.jpg\"\n  width=\"100%\"\n>"
      },
      "date": 1674953997558
    },
    {
      "id": "da6fabb1d72e7ab7",
      "type": "move",
      "order": [
        "931db1a7eb15a85a",
        "374255e21e26bada",
        "e24195cc0d9ebcc4",
        "6ceea1899c32f4f1",
        "9b27e3ded4a84b30",
        "34f0a9ef17ba0765",
        "b0179cab3fc0942f",
        "397f14447ec57d95",
        "9ac45ef5659e4371",
        "2ad2d923ca5676da",
        "3875efe3fcea29ef",
        "52792ac41ee1be36",
        "65ab7a889a447ac6",
        "85dc814fdb379d31",
        "cd3fdef5ae43a20a",
        "5ddc03a4fe23dfd6",
        "cd2989fe90c8b5bb",
        "b434305a145925e4",
        "6773712293a1bff3",
        "24b8d2895f97b93e",
        "2f5f7ec3adc4f94e",
        "66c23573f01f01ff",
        "c09c38b0b99e8f6f",
        "ba6e34b73a540ce9",
        "5746094aefc97508",
        "d2e0713956bf674a",
        "d7cef40babd607fd",
        "bb3fe282c364ff41",
        "c8b74fd874eee54a",
        "d9c2b8cf016c6772",
        "a611fa0889c19eb6",
        "e60795e30c3acb97",
        "f6f8a2183faf1db2",
        "94398c633f803417",
        "5b4918c44fdce6d3",
        "4327639bd6b83fce",
        "c137af4fd648d0bf",
        "cec3cc79bf95df1e",
        "0a5088c5a9848282",
        "453001b22accf95d",
        "657043fdb7229ba6",
        "2c14f2f5f43913eb",
        "091054a7f9de272c",
        "a3dcbb89cde187a9",
        "b8fa37a8f931b5aa",
        "1ce05f97264a47b3",
        "7bc7d02210c09e8d",
        "70b3ffef2110735f",
        "2f55f42e194e7df7",
        "e32951b801832d1c",
        "b022105a10192836",
        "48bee69709b621a2",
        "e9978202e6d6215c",
        "da6fabb1d72e7ab7",
        "db056b2dbf91a394",
        "0b412a8e93cf2ac4"
      ],
      "date": 1674954004261
    },
    {
      "type": "remove",
      "id": "0b412a8e93cf2ac4",
      "date": 1674954046453
    }
  ]
}