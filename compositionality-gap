{
  "title": "Compositionality Gap",
  "story": [
    {
      "type": "reference",
      "id": "31e963735f73bf64",
      "site": "wiki.ralfbarkow.ch",
      "slug": "role-playing",
      "title": "Role-Playing",
      "text": "Can we get strong guarantees from AI tools that are known to hallucinate? We discuss some strategies, and ways that [[Elm]] might be a great target for AI assistance."
    },
    {
      "type": "audio",
      "id": "0c7f5903c3db90c2",
      "text": "https://cdn.simplecast.com/audio/6a206baa-9c8e-4c25-9037-2b674204ba84/episodes/d1c5f97c-9700-48b0-ab35-a039edbfd0d5/audio/16dc506d-5aa1-42c1-8838-9ffaa3e0e1e9/default_tc.mp3\nelm radio – 080: Elm and AI [https://elm-radio.com/episode/elm-and-ai/ page]"
    },
    {
      "type": "paragraph",
      "id": "983e77dbf9d07619",
      "text": "[00:36:16]\nSo one thing that I was really amazed by, I'll share a link to this tweet, but I saw this demo where this was actually with GPT-3, but this example stuck with me where somebody was finding that GPT-3 did a poor job if you asked it questions that went through sort of several steps."
    },
    {
      "type": "paragraph",
      "id": "c4d44b0f8186c24e",
      "text": "[https://mobile.twitter.com/simonw/status/1577785656238960640 Tweet] showing intermediary questions prompt engineering technique [https://github.com/ofirpress/self-ask github], [https://arxiv.org/abs/2210.03350 arxiv]\n "
    },
    {
      "type": "video",
      "id": "9048c9f533824bd4",
      "text": "YOUTUBE A3GtlwwWDhI\nThe Compositionality Gap Explained (with GPT-3)"
    },
    {
      "type": "paragraph",
      "id": "233e71f729ae1e1e",
      "text": "[00:36:40]\nLike if you said, what is the capital of the country where the Taj Mahal is?\n[00:36:47]\nThen it would give Agra or something like the city where the Taj Mahal is instead of\n[00:36:53]\nNew Delhi, which is the capital of India.\n[00:36:55]\nSo what they did is they did some [[Prompt Engineering]]."
    },
    {
      "type": "paragraph",
      "id": "5097295a97819f24",
      "text": "[00:37:00]\nSo they gave it a starting prompt, which said, here's an example of doing this thing.\n[00:37:06]\nAnd they kind of gave an example question.\n[00:37:09]\nThey gave some intermediaries questions where it said, okay, well, in order to answer this\n[00:37:14]\nquestion, I need to answer an intermediary question first."
    },
    {
      "type": "paragraph",
      "id": "fb9ecb977614fe5f",
      "text": "[00:37:18]\nAnd so they gave an example of that as the sort of context for the prompt.\n[00:37:23]\nAnd then they said, now answer this question.\n[00:37:25]\nQuestion, what is the capital of the place where the Taj Mahal is, the country where\n[00:37:32]\nthe Taj Mahal is?"
    },
    {
      "type": "paragraph",
      "id": "6e845b55eef2613c",
      "text": "[00:37:33]\nAnd then it went ahead and followed that set of steps.\n[00:37:37]\nIntermediary question, what country is the Taj Mahal in?\n[00:37:41]\nAnswer, India."
    },
    {
      "type": "paragraph",
      "id": "fdec677959ad34bb",
      "text": "[00:37:43]\nIntermediary question, what is the capital of India?\n[00:37:47]\nNew Delhi.\n[00:37:48]\nSimple answer, New Delhi.\n[00:37:50]\nAnd it got the correct answer."
    },
    {
      "type": "paragraph",
      "id": "200b77e3d79c247d",
      "text": "[00:37:51]\nSo it got higher quality results because it was guided to break the problem down into\n[00:37:57]\nsub problems.\n[00:37:58]\nAnd pretty interesting, right?\n[00:38:01]\nYeah."
    },
    {
      "type": "paragraph",
      "id": "c9f8c46bebe9318b",
      "text": "[00:38:02]\nIt's a bit funny because I feel like everyone has this like, oh, well, you know, if I tried\n[00:38:09]\nto chat to JPT and didn't give me great results, but then I tried to prime it or I tried to\n[00:38:16]\ngive this kind of prompt or written this way, and now we get great results.\n[00:38:21]\nAnd I feel like maybe everyone will have their own ideal prompt and people will share it.\n[00:38:29]\nIt's kind of like, well, I have my set of key bindings of shortcuts for my computer."
    },
    {
      "type": "paragraph",
      "id": "cfb9e82f99b590b4",
      "text": "[00:38:35]\nOh, you don't have a shortcut for this action in your ID?\n[00:38:39]\nOh, let me share it with you.\n[00:38:41]\nOr have their own proprietary prompts.\n[00:38:44]\nMaybe yeah.\n[00:38:45]\nAnd we will start to have like our very custom experience around working with AI.\n[00:38:51]\nIt's like, hey, this is how I do it.\n[00:38:54]\nAnd this works for me.\n[00:38:55]\nAnd this might not work for you."
    },
    {
      "type": "paragraph",
      "id": "8307b8381391611a",
      "text": "[00:38:58]\nAnd then it'll be like, here's a very good prompt for generating the best prompt.\n[00:39:06]\nI kind of feel like maybe people who use Vim will have something like that.\n[00:39:13]\nThere's a real art to it."
    },
    {
      "type": "pagefold",
      "id": "34e10df97d1d54d6",
      "text": "Solving Jigsaw Puzzles"
    },
    {
      "type": "paragraph",
      "id": "f18324022d08441a",
      "text": "[00:39:18]\nAnd I mean, you're getting it to break problems.\n[00:39:21]\nSo I took this concept, and I applied this idea of breaking the problem down into sub problems.\n[00:39:28]\nI actually had written this blog post years back about like solving Elm code, like solving\n[00:39:36]\ntype puzzles in Elm, like a jigsaw puzzle frame then fill in.\n[00:39:41]\nSo like a jigsaw puzzle, you start by filling in the borders and the corner.\n[00:39:47]\nThe corner pieces are easy to find."
    },
    {
      "type": "paragraph",
      "id": "095ef4d5e8e40b18",
      "text": "[00:39:48]\nSo you find the corners, then you've got sort of a set of fixed points.\n[00:39:53]\nSo that's like one low hanging fruit.\n[00:39:56]\nIt's easy to solve those problems.\n[00:39:58]\nThen you find the edge pieces and you can fill those in.\n[00:40:00]\nAnd now that you've got the edges, it makes solving the rest of the puzzle easier, right?\n[00:40:05]\nSo that's one approach to solving jigsaw puzzles to break it down into sub problems."
    },
    {
      "type": "paragraph",
      "id": "4b182713a4ef0dfb",
      "text": "[00:40:09]\nBut like with Elm types, I kind of, I use this technique a lot when I'm writing Elm code as a human.\n[00:40:16]\nI will, I'll say like, okay, I don't know exactly what's going to fit here in this pipeline.\n[00:40:23]\nBut I know I want to like take this starting value, I want to do something to it.\n[00:40:29]\nAnd then I want it to be passed through in this pipeline to this next function."
    },
    {
      "type": "paragraph",
      "id": "dc8645262bf98c84",
      "text": "[00:40:38]\nSo sometimes I'll just like put a debug.todo there.\n[00:40:41]\nAnd then maybe I'll extract that debug.todo to a function or a let binding.\n[00:40:46]\nAnd then I'll try to get a type annotation for that value I have in my let binding.\n[00:40:52]\nThat would satisfy the compiler.\n[00:40:55]\nExactly."
    },
    {
      "type": "paragraph",
      "id": "94ac1923324b382f",
      "text": "[00:40:56]\nNow I've broken it down into a sub problem.\n[00:40:59]\nSo I took this sort of like, fill in this code, I don't know what goes here, I've turned\n[00:41:03]\nit into, okay, I know the type I need.\n[00:41:06]\nSo that's sort of like finding the edge pieces in the puzzle.\n[00:41:10]\nSo now I've created the sub problem for myself."
    },
    {
      "type": "paragraph",
      "id": "663b5589a2ed5dc3",
      "text": "[00:41:13]\nAnd now I can do things like, so I've got a debug.todo with a type annotation.\n[00:41:20]\nNow I can turn that into maybe result.map around a debug.todo or list.map with a debug.todo."
    },
    {
      "type": "paragraph",
      "id": "0e445fe6db36302e",
      "text": "[00:41:29]\nSo now I'm saying, well, I know that if I apply some function over a list, it will work.\n[00:41:38]\nAnd now I've further broken down that sub problem.\n[00:41:40]\nAnd now I can follow that step again and say, okay, we'll break out another, that debug.todo,\n[00:41:46]\ngive that a type annotation."
    },
    {
      "type": "paragraph",
      "id": "e6f7f44c459d2fed",
      "text": "[00:41:47]\nSo now it's list.map, some function, I don't know what, now follow that same process with that.\n"
    },
    {
      "type": "paragraph",
      "id": "6e073e814c99dd23",
      "text": "[00:41:53]\nSo it's breaking it down into sub problems.\n[00:41:55]\nI use this technique all the time when I'm like, often with like API design, you're doing\n[00:42:01]\nweird type puzzles, but also just with like user code, like trying to parse some markdown\n[00:42:08]\nand take the markdown blocks and find and traverse them and map them into this type and whatever."
    },
    {
      "type": "paragraph",
      "id": "d0d8a7ca18815fec",
      "text": "[00:42:16]\nNow I tried to use this sort of same prompt engineering idea to teach GPT how to follow\n[00:42:24]\nthis set of steps of breaking down a type puzzle.\n[00:42:28]\nAnd it was actually really good at it."
    },
    {
      "type": "paragraph",
      "id": "aac88cfca664167c",
      "text": "Dillon's prompt engineering type puzzle examples"
    },
    {
      "type": "markdown",
      "id": "73c28551a0944dae",
      "text": " * Decode mapping solution (correct on first try) [https://gist.github.com/dillonkearns/def823d06ef2b880bf600f0c53468e78 gist]\n\n * Markdown solution with 2 corrections from compiler feedback [https://gist.github.com/dillonkearns/46548b587d2fe3bf5e88f8214e1b3ce3 gist]\n\n * Dillon's Frame Then Fill In blog [https://incrementalelm.com/frame-then-fill-in/ post] describes a similar method to the GPT prompt"
    },
    {
      "type": "paragraph",
      "id": "411712fddaa86a48",
      "text": "[00:42:30]\nSo I'll share like a little GitHub gist of my GPT prompt and the results it got.\n[00:42:39]\nBut what I basically did is I told it, I said, your job is to solve this type puzzle.\n[00:42:46]\nAnd I gave it some guardrails.\n[00:42:48]\nSo like the guardrails I gave it were, I'm going to give you some code, which has debug.todo\n[00:42:54]\nreplace me in it.\n[00:42:56]\nYour job is to, you know, get a, satisfy the type for that debug.todo.\n[00:43:02]\nAnd your final solution cannot include debug.todo."
    },
    {
      "type": "paragraph",
      "id": "8556920e402e4a98",
      "text": "[00:43:06]\nYou can write intermediary steps, which may include debug.todo.\n[00:43:10]\nAnd you are not allowed to change any code other than the section that says debug.todo.\n[00:43:16]\nSo I gave it these guardrails.\n[00:43:17]\nAlso these are verifiable things, right?"
    },
    {
      "type": "paragraph",
      "id": "21da0cec9af67bb5",
      "text": "[00:43:19]\nSo you can test for this to see if it's given you a valid solution, given the guardrails\n[00:43:25]\nyou wanted it to honor, because it might hallucinate and not do that, but you can check that."
    },
    {
      "type": "paragraph",
      "id": "15b83cca1f6c6ff4",
      "text": "[00:43:32]\nSo one thing that I'm thinking of is, will you be able to verify things accurately?\n[00:43:39]\nMaybe I'm being too, I'm trying to play the devil's advocate here a bit, and I might be\n[00:43:44]\na bit too hard on chat.gpt.\n[00:43:47]\nBut for instance, whenever you're working in that TD style, when you do things one step\n[00:43:52]\nat a time, you discover edge cases, right?"
    },
    {
      "type": "paragraph",
      "id": "19928b006afd0a5c",
      "text": "[00:43:56]\nSo for instance, you give a list as an argument and needs to return a number.\n[00:44:01]\nAnd first you hard code that number.\n[00:44:03]\nAnd then you notice, Oh, well, what if that list is, is, is empty then?\n[00:44:08]\nOh, well then I need to write a test for if the, the, the list is empty.\n[00:44:14]\nAh, okay."
    },
    {
      "type": "paragraph",
      "id": "6311e1260bd4aaf0",
      "text": "[00:44:17]\nBut the, the AI might not do that, might not notice that.\n[00:44:20]\nSo maybe it's, it is going to fix things correctly.\n[00:44:24]\nMaybe not, but let's say it's going to do it correctly, but it's not going to have a\n[00:44:27]\ntest for that."
    },
    {
      "type": "paragraph",
      "id": "42cdfe9009b64520",
      "text": "[00:44:29]\nOr you're not going to know, or you're going to, I mean, you are not going to notice that\n[00:44:36]\nyou're going to need to write a test with an empty list.\n[00:44:39]\nSo that's the process is a bit hard to figure out if you don't do it yourself.\n[00:44:45]\nIt's kind of like, I think also one of the reasons why people say, well, you should pair\n[00:44:49]\nprogram rather than review someone else's code, because you will discover those, those\n[00:44:55]\nthings while you're working."
    },
    {
      "type": "paragraph",
      "id": "1829aaa6d808fe34",
      "text": "[00:45:04]\nI think we're going to see like a lot of junior developers using these AI tools in exactly\n[00:45:10]\nthe kind of way you're describing where maybe they trust it too much to do too many steps.\n[00:45:18]\nAnd then what happens is you're not really engaging with the problem intellectually, and\n[00:45:24]\nyou're not thinking about these test cases that come up."
    },
    {
      "type": "paragraph",
      "id": "93f7635f63d1f32f",
      "text": "[00:45:27]\nSo I think there's an art to knowing when to use it.\n[00:45:31]\nSo like the type of problem here for this sort of frame then fill in problem I'm talking about, this is this is a class of problem that I find myself spending a lot of mental effort solving on a regular basis."
    },
    {
      "type": "pagefold",
      "id": "44be41a65fe85152",
      "text": "You Know It When You See It"
    },
    {
      "type": "paragraph",
      "id": "a35befcc1b5fde38",
      "text": "[00:45:45]\nThat is kind of this, this, you know, it has this quality we talked about with a traveling\n[00:45:50]\nsalesman where you know it when you see it, if you have a good solution, you can easily\n[00:45:54]\nverify that it that it solved it."
    },
    {
      "type": "paragraph",
      "id": "04a93a2b681083d7",
      "text": "[00:45:57]\nAnd yet it's not really doing anything too creative, because it's fitting pieces together.\n[00:46:02]\nIt's not really writing too many implementation details.\n[00:46:06]\nAnd I find that often with Elm code, you arrive at these types of situations where like, if\n[00:46:11]\nyou could make the types work, you would trust that the code worked because like, there's\n[00:46:16]\nonly really one good way to fit these functions together to get the right thing.\n[00:46:20]\nLike you're not doing too much logic of like, give it this empty value and give it this now it might hallucinate these types of things."
    },
    {
      "type": "paragraph",
      "id": "d4adc29b76297f46",
      "text": "[00:46:27]\nBut you could even use prompt engineering to tell it like, you're just fitting these\n[00:46:33]\nfunctions together.\n[00:46:34]\nI don't want you to write new logic or use default values.\n[00:46:37]\nSo I think these types of things can be improved through prompt engineering and also through\n[00:46:41]\nselecting the right types of problems."
    },
    {
      "type": "paragraph",
      "id": "4c57532c5ebc2730",
      "text": "[00:46:43]\nBut like, for example, the I gave it a pretty, pretty challenging problem with this sort\n[00:46:50]\nof prompt I designed.\n[00:46:52]\nI had it fill in this, this thing in a in an Elm pages example that I have where it\n[00:46:58]\ntakes markdown blocks and it traverses these headings and it and I what I did is I primed\n[00:47:08]\nit with a list of all of the available functions that it could use.\n[00:47:15]\nAnd another thing you can do a set of guardrails is you can say only use these functions.\n[00:47:19]\nAnd you could even say you must use these functions.\n[00:47:23]\nAnd these other functions are available and you may not use any other functions.\n[00:47:27]\nAnd of course, these things are verifiable in the in the final output easily."
    },
    {
      "type": "pagefold",
      "id": "1664ab2e7bedbcd2",
      "text": "Limiting Its Creativity"
    },
    {
      "type": "paragraph",
      "id": "73adb271b044b06a",
      "text": "[00:47:32]\nBut why would you tell it you can only use these functions because you're now limiting limiting its creativity."
    },
    {
      "type": "paragraph",
      "id": "019de178e14f013d",
      "text": "[00:47:41]\nFor instance, if you forget to mention list.map, then it's not going to use that.\n[00:47:46]\nAnd it's going to use something else like list.fold instead.\n"
    },
    {
      "type": "paragraph",
      "id": "6c6ee3c1310d2799",
      "text": "[00:47:50]\nWell, so the the way basically I was doing this as a proof of concept of saying, I'm\n[00:47:58]\ngoing to give you all of the functions that are in scope in this particular code base.\n[00:48:04]\nAnd I'm going to give you like all of the functions from from the list module and from\n[00:48:09]\nthe result module."
    },
    {
      "type": "paragraph",
      "id": "2e4bb89421e4392a",
      "text": "[00:48:10]\nSo you can give it like a certain set of available functions and say, these are the types and\n[00:48:14]\nI taught it like I even taught it how partial application works."
    },
    {
      "type": "paragraph",
      "id": "f153ff121b572366",
      "text": "[00:48:18]\nSo I can take an example.\n[00:48:20]\nAnd I said, given this type, if you pass in this function, now the type annotation is this."
    },
    {
      "type": "paragraph",
      "id": "bc4bb3c69e950bcb",
      "text": "[00:48:26]\nAnd it I played around with it and tweaked it in these ways.\n[00:48:29]\nAnd it did a better job at solving these puzzles.\n[00:48:32]\nSo it's pretty interesting.\n[00:48:33]\nYou can kind of teach it in these prompts."
    },
    {
      "type": "paragraph",
      "id": "d44f089538f82eb0",
      "text": "[00:48:45]\nI wanted to solve a sort of uncreative problem of wiring things together that I don't really\n[00:48:52]\nlike if I could automate that as an atomic step, I would love to like if I could, you\n[00:48:57]\ncould even think of it this way, like, AI, give me all of the possible solutions using\n[00:49:04]\nthe functions in scope here to satisfy this type, right?"
    },
    {
      "type": "paragraph",
      "id": "88fc33915ad3d433",
      "text": "[00:49:09]\nJust like, and then you can just select, okay, these are all the valid ways to do that.\n[00:49:13]\nSo if I can teach through a GPT prompt, the AI to solve that type of puzzle, and give\n[00:49:20]\nme all the possible results, and then I can use a tool to actually verify those results.\n[00:49:25]\nSo I so I know I can 100% trust them."
    },
    {
      "type": "paragraph",
      "id": "b5f6bc296a446886",
      "text": "[00:49:28]\nThat becomes a very interesting tool in my toolkit, where now I'm more capable as a programmer.\n[00:49:34]\nAnd I'm not sort of like hallucinating weird things into my code base, or as you said,\n[00:49:39]\nlike having it write out these new cases that I'm not considering in my testing or considering\n[00:49:45]\nhow it affects the user experience."
    },
    {
      "type": "paragraph",
      "id": "952531ff933fd270",
      "text": "[00:49:47]\nAnd if that's what I want the experience to be, it's just like, how do I solve this type problem?"
    },
    {
      "type": "paragraph",
      "id": "eb9e426e16e1cd30",
      "text": "[00:49:52]\nOh, yeah, that's the only one sensible, sensible, meaningful solution, and it found it.\n[00:49:58]\nAnd I can easily look at it and say, oh, yeah, result dot map, tuple dot map first list dot map. Yes."
    },
    {
      "type": "paragraph",
      "id": "10fd20dec4d045e7",
      "text": "[00:50:06]\n[…], that it didn't use anything too crazy.\n[00:50:10]\nIt satisfies the types.\n[00:50:11]\nIt's good.\n[00:50:12]\nI can easily look at it and see it did the right thing.\n[00:50:14]\nBut it would have taken me a long time to solve it myself.\n"
    },
    {
      "type": "paragraph",
      "id": "0399d986158f1c7f",
      "text": "[00:50:18]\nAnd so in case it wasn't clear, my idea is to like, this is something I want to experiment\n[00:50:24]\na little more with the OpenAI API to fully automate this."
    },
    {
      "type": "paragraph",
      "id": "425ce9c38b354683",
      "text": "[00:50:28]\nAnd because it's a pretty easy thing to automate to just say, what are all the types of all the functions in in scope here?\n[00:50:37]\nLike that's a an automatable thing.\n[00:50:40]\nSo feed it that into the prompt and give it the ability through, you know, through writing a small script that hits the OpenAI API, tell it what the compiler error is to let it iterate on."
    },
    {
      "type": "paragraph",
      "id": "bad873b217cd8bf6",
      "text": "[00:50:53]\nSo when I gave it this problem as a proof of concept manually, I manually told it the\n[00:50:58]\ncompiler errors and it with two iterations with telling it the compiler error, it was\n[00:51:03]\nable to get the correct result, which I thought was pretty cool."
    },
    {
      "type": "paragraph",
      "id": "2065f15e0e18c4cd",
      "text": "[…]"
    },
    {
      "type": "paragraph",
      "id": "51d5e033f9545448",
      "text": "[00:52:09]\nSo a lot of our work as developers is not writing new code, it's editing existing code.\n[00:52:15]\nSo I feel like that's going to be somewhat missing now, but it's probably going to be\n[00:52:21]\nsolved pretty soon."
    },
    {
      "type": "paragraph",
      "id": "2f47b62a1a3c2e35",
      "text": "[00:52:31]\nActually, GPT-4, can't it take like 25,000 tokens as input?\n[00:52:36]\nSo you can feed it a huge input."
    },
    {
      "type": "paragraph",
      "id": "04d7fc8191f9ac8c",
      "text": "[00:52:40]\nThat's a game changer."
    },
    {
      "type": "paragraph",
      "id": "f2acf7266c98cdbb",
      "text": "[…]"
    },
    {
      "type": "paragraph",
      "id": "460f5f4914e4ce19",
      "text": "[00:52:50]\nBut until then, I'm thinking, for instance, if we had a tool that's extracted information\n[00:52:56]\nfrom your codebase, and that you can then just copy paste into the prompt, that could\n[00:53:02]\nbe pretty cool.\n[00:53:03]\nSo like having all the types for the functions.\n[00:53:06]\nAnd there is a tool that is called Elm Review, which has an extract feature."
    },
    {
      "type": "paragraph",
      "id": "b0cda91d8b906f50",
      "text": "[00:53:25]\nUnless you automate it, and why not?\n[00:53:27]\nIt gives good results."
    },
    {
      "type": "paragraph",
      "id": "d526153a5fc4a0db",
      "text": "[00:53:40]\nLike I work on a 200,000 lines of code, codebase.\n[00:53:46]\nBut how many type annotations does that represent, right?\n[00:53:51]\nLike hundreds of thousands, probably?\n[00:53:54]\nYou think so?\n[00:53:55]\nThat are in scope in a particular point in code?\n[00:53:58]\nWell, you can import anything.\n[00:54:00]\nNot everything is exposed, probably."
    },
    {
      "type": "paragraph",
      "id": "002abf10e2ec15cd",
      "text": "[00:54:03]\nAnd a lot of things are going to be values that are locally scoped to let like I would\n[00:54:08]\nI would venture to guess in a 200,000 line codebase.\n[00:54:12]\nWith code comments?\n[00:54:13]\nOr maybe there are a thousand.\n[00:54:16]\nMaybe there are like on the order of one to 10,000.\n[00:54:20]\nNo more than definitely no more than 10,000."
    },
    {
      "type": "paragraph",
      "id": "62355bbb42671424",
      "text": "[00:54:28]\nOh, there's also dependencies, but that's also not that much.\n[00:54:33]\nRight, maybe it's doable.\n[00:54:36]\nAnd you can do heuristics to filter and not even heuristics, like reliable heuristics\n[00:54:43]\nto filter out."
    },
    {
      "type": "paragraph",
      "id": "18109f9ee743be41",
      "text": "[00:54:44]\nYou know, you know that if you're trying to arrive at this type, but none of the types\n[00:54:51]\nconnect in any way."
    },
    {
      "type": "paragraph",
      "id": "ea59ad4de2a6c3fd",
      "text": "[00:54:52]\nSo if you can take a string and use it on this thing, and you can take an int and turn\n[00:54:58]\nit into a string, then those two things connect."
    },
    {
      "type": "paragraph",
      "id": "9d998f0a26d8af13",
      "text": "[00:55:01]\nBut if a if this custom type can't be turned into a string, then you know it, it's not\n[00:55:09]\ngoing to be involved in your problem at all, because your problem is dealing with strings,\n[00:55:13]\nand you can't turn that to or from a string, for example."
    },
    {
      "type": "paragraph",
      "id": "3eeb4b5495a49725",
      "text": "[00:55:17]\nYeah, you can also remove all the modules that would create an import cycle.\n[00:55:22]\nRight.\n[00:55:23]\nSo basically, you can't import anything that imports this file directly or indirectly.\n[00:55:28]\nExactly."
    },
    {
      "type": "paragraph",
      "id": "a731bcad492f7b6a",
      "text": "[00:55:30]\nSo to me, this is the really interesting intersection.\n[00:55:33]\nSo now you were mentioning earlier that you think that these tools will start to understand\n[00:55:38]\nyour code more over time, but we're not there yet.\n[00:55:41]\nI actually, I don't see it that way."
    },
    {
      "type": "paragraph",
      "id": "0f44d5af800ad63d",
      "text": "[00:55:44]\nI believe that these tools are going to continue doing what they're doing, which is that they've\n[00:55:49]\nbeen remarkably successful in being able to solve complex problems just through this crazy\n[00:55:56]\nsynthesis and predictive text sort of thing."
    },
    {
      "type": "paragraph",
      "id": "4cbe0838aa2302f1",
      "text": "[00:56:00]\nNo, I didn't mean it in the sense of understanding.\n[00:56:02]\nI meant it's just of gathering the information."
    },
    {
      "type": "paragraph",
      "id": "60969bacc744e63b",
      "text": "[00:56:07]\nLike every time you ask something to ChatGPT, you need to provide information about your\n[00:56:12]\ncode base.\n[00:56:13]\nAt the moment, it does not look at your code base."
    },
    {
      "type": "paragraph",
      "id": "c16b733883b62561",
      "text": "[00:56:19]\nBut I don't think that they will, for example, know type information about your code base,\n[00:56:25]\nexcept insofar as it's part of the predictive text because it's in there."
    },
    {
      "type": "paragraph",
      "id": "6507b979bc039c68",
      "text": "[00:56:29]\nBut I think that they're getting enough mileage solving problems through this sort of predictive\n[00:56:36]\ntext, that they're going to keep going with that.\n[00:56:39]\nBut I think the interesting intersection, especially with typed pure functional programming\n[00:56:46]\nlanguages is if you, so humans have their role, these sort of like compiler tools and\n[00:56:55]\nstatic analysis tools have their role, and these AI tools have their role."
    },
    {
      "type": "paragraph",
      "id": "e7afa56f4327711c",
      "text": "⇒ [[Role-Playing]]"
    },
    {
      "type": "pagefold",
      "id": "ce86e15a9019ab41",
      "text": "~",
      "alias": "b67786df01b86a72"
    },
    {
      "type": "paragraph",
      "id": "3a5796bfc0b50443",
      "text": "PRESS, Ofir, ZHANG, Muru, MIN, Sewon, SCHMIDT, Ludwig, SMITH, Noah A. and LEWIS, Mike, 2022. Measuring and Narrowing the Compositionality Gap in Language Models. Online. 7 October 2022. arXiv. arXiv:2210.03350. [Accessed 19 April 2023]. "
    },
    {
      "type": "paragraph",
      "id": "062f1a0ea56e4d55",
      "text": "We investigate the ability of language models to perform compositional reasoning tasks where the overall solution depends on correctly composing the answers to sub-problems. We measure how often models can correctly answer all sub-problems but not generate the overall solution, a ratio we call the compositionality gap. We evaluate this ratio by asking multi-hop questions with answers that require composing multiple facts unlikely to have been observed together during pretraining. In the GPT-3 family of models, as model size increases we show that the single-hop question answering performance improves faster than the multi-hop performance does, therefore the compositionality gap does not decrease. "
    },
    {
      "type": "paragraph",
      "id": "49d5ae7db55a996d",
      "text": "This surprising result suggests that while more powerful models memorize and recall more factual knowledge, they show no corresponding improvement in their ability to perform this kind of compositional reasoning. "
    },
    {
      "type": "paragraph",
      "id": "4bdc37e5d8d0d1e3",
      "text": "We then demonstrate how elicitive prompting (such as chain of thought) narrows the compositionality gap by reasoning explicitly instead of implicitly. We present a new method, self-ask, that further improves on chain of thought. In our method, the model explicitly asks itself (and then answers) follow-up questions before answering the initial question. We finally show that self-ask’s structured prompting lets us easily plug in a search engine to answer the follow-up questions, which additionally improves accuracy. arXiv:2210.03350 [cs]\n"
    },
    {
      "type": "paragraph",
      "id": "2a8a1b6f7d5f8d29",
      "text": "⇒ [[Self-Ask]]"
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Compositionality Gap",
        "story": []
      },
      "date": 1681969887990
    },
    {
      "item": {
        "type": "factory",
        "id": "31e963735f73bf64"
      },
      "id": "31e963735f73bf64",
      "type": "add",
      "date": 1681969889613
    },
    {
      "id": "3a5796bfc0b50443",
      "type": "add",
      "item": {
        "type": "paragraph",
        "id": "3a5796bfc0b50443",
        "text": "PRESS, Ofir, ZHANG, Muru, MIN, Sewon, SCHMIDT, Ludwig, SMITH, Noah A. and LEWIS, Mike, 2022. Measuring and Narrowing the Compositionality Gap in Language Models. Online. 7 October 2022. arXiv. arXiv:2210.03350. [Accessed 19 April 2023]. We investigate the ability of language models to perform compositional reasoning tasks where the overall solution depends on correctly composing the answers to sub-problems. We measure how often models can correctly answer all sub-problems but not generate the overall solution, a ratio we call the compositionality gap. We evaluate this ratio by asking multi-hop questions with answers that require composing multiple facts unlikely to have been observed together during pretraining. In the GPT-3 family of models, as model size increases we show that the single-hop question answering performance improves faster than the multi-hop performance does, therefore the compositionality gap does not decrease. This surprising result suggests that while more powerful models memorize and recall more factual knowledge, they show no corresponding improvement in their ability to perform this kind of compositional reasoning. We then demonstrate how elicitive prompting (such as chain of thought) narrows the compositionality gap by reasoning explicitly instead of implicitly. We present a new method, self-ask, that further improves on chain of thought. In our method, the model explicitly asks itself (and then answers) follow-up questions before answering the initial question. We finally show that self-ask’s structured prompting lets us easily plug in a search engine to answer the follow-up questions, which additionally improves accuracy.arXiv:2210.03350 [cs]\n"
      },
      "after": "31e963735f73bf64",
      "attribution": {
        "page": "Role-Playing"
      },
      "date": 1681969894502
    },
    {
      "id": "b67786df01b86a72",
      "type": "add",
      "item": {
        "type": "pagefold",
        "id": "b67786df01b86a72",
        "text": "~"
      },
      "after": "3a5796bfc0b50443",
      "attribution": {
        "page": "Role-Playing"
      },
      "date": 1681969899051
    },
    {
      "id": "ce86e15a9019ab41",
      "type": "add",
      "item": {
        "type": "pagefold",
        "id": "ce86e15a9019ab41",
        "text": "~",
        "alias": "b67786df01b86a72"
      },
      "after": "31e963735f73bf64",
      "attribution": {
        "page": "Role-Playing"
      },
      "date": 1681969902010
    },
    {
      "type": "edit",
      "id": "31e963735f73bf64",
      "item": {
        "type": "reference",
        "id": "31e963735f73bf64",
        "site": "wiki.ralfbarkow.ch",
        "slug": "role-playing",
        "title": "Role-Playing",
        "text": "Can we get strong guarantees from AI tools that are known to hallucinate? We discuss some strategies, and ways that [[Elm]] might be a great target for AI assistance."
      },
      "date": 1681969909229
    },
    {
      "id": "0c7f5903c3db90c2",
      "type": "add",
      "item": {
        "type": "audio",
        "id": "0c7f5903c3db90c2",
        "text": "https://cdn.simplecast.com/audio/6a206baa-9c8e-4c25-9037-2b674204ba84/episodes/d1c5f97c-9700-48b0-ab35-a039edbfd0d5/audio/16dc506d-5aa1-42c1-8838-9ffaa3e0e1e9/default_tc.mp3\nelm radio – 080: Elm and AI [https://elm-radio.com/episode/elm-and-ai/ page]"
      },
      "after": "31e963735f73bf64",
      "attribution": {
        "page": "Role-Playing"
      },
      "date": 1681969918180
    },
    {
      "id": "983e77dbf9d07619",
      "type": "add",
      "item": {
        "type": "paragraph",
        "id": "983e77dbf9d07619",
        "text": "[00:36:16]\nSo one thing that I was really amazed by, I'll share a link to this tweet, but I saw\n[00:36:23]\nthis demo where this was actually with GPT-3, but this example stuck with me where somebody\n[00:36:31]\nwas finding that GPT-3 did a poor job if you asked it questions that went through sort\n[00:36:38]\nof several steps."
      },
      "after": "0c7f5903c3db90c2",
      "attribution": {
        "page": "Role-Playing"
      },
      "date": 1681969937193
    },
    {
      "id": "c4d44b0f8186c24e",
      "type": "add",
      "item": {
        "type": "paragraph",
        "id": "c4d44b0f8186c24e",
        "text": "[https://mobile.twitter.com/simonw/status/1577785656238960640 Tweet] showing intermediary questions prompt engineering technique [https://github.com/ofirpress/self-ask github], [https://arxiv.org/abs/2210.03350 arxiv]\n "
      },
      "after": "ce86e15a9019ab41",
      "attribution": {
        "page": "Role-Playing"
      },
      "date": 1681969949372
    },
    {
      "id": "c4d44b0f8186c24e",
      "type": "move",
      "order": [
        "31e963735f73bf64",
        "0c7f5903c3db90c2",
        "983e77dbf9d07619",
        "c4d44b0f8186c24e",
        "ce86e15a9019ab41",
        "3a5796bfc0b50443",
        "b67786df01b86a72"
      ],
      "date": 1681969952064
    },
    {
      "id": "9048c9f533824bd4",
      "type": "add",
      "item": {
        "type": "video",
        "id": "9048c9f533824bd4",
        "text": "YOUTUBE A3GtlwwWDhI\nThe Compositionality Gap Explained (with GPT-3)"
      },
      "after": "ce86e15a9019ab41",
      "attribution": {
        "page": "Role-Playing"
      },
      "date": 1681970031456
    },
    {
      "id": "ce86e15a9019ab41",
      "type": "move",
      "order": [
        "31e963735f73bf64",
        "0c7f5903c3db90c2",
        "983e77dbf9d07619",
        "c4d44b0f8186c24e",
        "9048c9f533824bd4",
        "ce86e15a9019ab41",
        "3a5796bfc0b50443",
        "b67786df01b86a72"
      ],
      "date": 1681970035627
    },
    {
      "type": "edit",
      "id": "983e77dbf9d07619",
      "item": {
        "type": "paragraph",
        "id": "983e77dbf9d07619",
        "text": "[00:36:16]\nSo one thing that I was really amazed by, I'll share a link to this tweet, but I saw this demo where this was actually with GPT-3, but this example stuck with me where somebody was finding that GPT-3 did a poor job if you asked it questions that went through sort of several steps."
      },
      "date": 1681970112820
    },
    {
      "item": {
        "type": "factory",
        "id": "233e71f729ae1e1e"
      },
      "id": "233e71f729ae1e1e",
      "type": "add",
      "after": "b67786df01b86a72",
      "date": 1681970192573
    },
    {
      "id": "233e71f729ae1e1e",
      "type": "move",
      "order": [
        "31e963735f73bf64",
        "0c7f5903c3db90c2",
        "983e77dbf9d07619",
        "c4d44b0f8186c24e",
        "9048c9f533824bd4",
        "233e71f729ae1e1e",
        "ce86e15a9019ab41",
        "3a5796bfc0b50443",
        "b67786df01b86a72"
      ],
      "date": 1681970196420
    },
    {
      "type": "remove",
      "id": "b67786df01b86a72",
      "date": 1681970203593
    },
    {
      "type": "fork",
      "date": 1681970228678
    },
    {
      "type": "edit",
      "id": "233e71f729ae1e1e",
      "item": {
        "type": "paragraph",
        "id": "233e71f729ae1e1e",
        "text": "[00:36:40]\nLike if you said, what is the capital of the country where the Taj Mahal is?\n[00:36:47]\nThen it would give Agra or something like the city where the Taj Mahal is instead of\n[00:36:53]\nNew Delhi, which is the capital of India.\n[00:36:55]\nSo what they did is they did some prompt engineering."
      },
      "date": 1681970249129
    },
    {
      "type": "edit",
      "id": "233e71f729ae1e1e",
      "item": {
        "type": "paragraph",
        "id": "233e71f729ae1e1e",
        "text": "[00:36:40]\nLike if you said, what is the capital of the country where the Taj Mahal is?\n[00:36:47]\nThen it would give Agra or something like the city where the Taj Mahal is instead of\n[00:36:53]\nNew Delhi, which is the capital of India.\n[00:36:55]\nSo what they did is they did some [[Prompt Engineering]]."
      },
      "date": 1681970296991
    },
    {
      "type": "add",
      "id": "5097295a97819f24",
      "item": {
        "type": "paragraph",
        "id": "5097295a97819f24",
        "text": "[00:37:00]\nSo they gave it a starting prompt, which said, here's an example of doing this thing.\n[00:37:06]\nAnd they kind of gave an example question.\n[00:37:09]\nThey gave some intermediaries questions where it said, okay, well, in order to answer this\n[00:37:14]\nquestion, I need to answer an intermediary question first."
      },
      "after": "233e71f729ae1e1e",
      "date": 1681970362338
    },
    {
      "type": "edit",
      "id": "3a5796bfc0b50443",
      "item": {
        "type": "paragraph",
        "id": "3a5796bfc0b50443",
        "text": "PRESS, Ofir, ZHANG, Muru, MIN, Sewon, SCHMIDT, Ludwig, SMITH, Noah A. and LEWIS, Mike, 2022. Measuring and Narrowing the Compositionality Gap in Language Models. Online. 7 October 2022. arXiv. arXiv:2210.03350. [Accessed 19 April 2023]. We investigate the ability of language models to perform compositional reasoning tasks where the overall solution depends on correctly composing the answers to sub-problems. We measure how often models can correctly answer all sub-problems but not generate the overall solution, a ratio we call the compositionality gap. We evaluate this ratio by asking multi-hop questions with answers that require composing multiple facts unlikely to have been observed together during pretraining. In the GPT-3 family of models, as model size increases we show that the single-hop question answering performance improves faster than the multi-hop performance does, therefore the compositionality gap does not decrease. This surprising result suggests that while more powerful models memorize and recall more factual knowledge, they show no corresponding improvement in their ability to perform this kind of compositional reasoning. "
      },
      "date": 1681970464698
    },
    {
      "type": "add",
      "id": "4bdc37e5d8d0d1e3",
      "item": {
        "type": "paragraph",
        "id": "4bdc37e5d8d0d1e3",
        "text": "We then demonstrate how elicitive prompting (such as chain of thought) narrows the compositionality gap by reasoning explicitly instead of implicitly. We present a new method, self-ask, that further improves on chain of thought. In our method, the model explicitly asks itself (and then answers) follow-up questions before answering the initial question. We finally show that self-ask’s structured prompting lets us easily plug in a search engine to answer the follow-up questions, which additionally improves accuracy.arXiv:2210.03350 [cs]\n"
      },
      "after": "3a5796bfc0b50443",
      "date": 1681970477370
    },
    {
      "type": "edit",
      "id": "3a5796bfc0b50443",
      "item": {
        "type": "paragraph",
        "id": "3a5796bfc0b50443",
        "text": "PRESS, Ofir, ZHANG, Muru, MIN, Sewon, SCHMIDT, Ludwig, SMITH, Noah A. and LEWIS, Mike, 2022. Measuring and Narrowing the Compositionality Gap in Language Models. Online. 7 October 2022. arXiv. arXiv:2210.03350. [Accessed 19 April 2023]. "
      },
      "date": 1681970480705
    },
    {
      "type": "add",
      "id": "062f1a0ea56e4d55",
      "item": {
        "type": "paragraph",
        "id": "062f1a0ea56e4d55",
        "text": "We investigate the ability of language models to perform compositional reasoning tasks where the overall solution depends on correctly composing the answers to sub-problems. We measure how often models can correctly answer all sub-problems but not generate the overall solution, a ratio we call the compositionality gap. We evaluate this ratio by asking multi-hop questions with answers that require composing multiple facts unlikely to have been observed together during pretraining. In the GPT-3 family of models, as model size increases we show that the single-hop question answering performance improves faster than the multi-hop performance does, therefore the compositionality gap does not decrease. "
      },
      "after": "3a5796bfc0b50443",
      "date": 1681970491750
    },
    {
      "type": "add",
      "id": "49d5ae7db55a996d",
      "item": {
        "type": "paragraph",
        "id": "49d5ae7db55a996d",
        "text": "This surprising result suggests that while more powerful models memorize and recall more factual knowledge, they show no corresponding improvement in their ability to perform this kind of compositional reasoning. "
      },
      "after": "062f1a0ea56e4d55",
      "date": 1681970492849
    },
    {
      "type": "edit",
      "id": "4bdc37e5d8d0d1e3",
      "item": {
        "type": "paragraph",
        "id": "4bdc37e5d8d0d1e3",
        "text": "We then demonstrate how elicitive prompting (such as chain of thought) narrows the compositionality gap by reasoning explicitly instead of implicitly. We present a new method, self-ask, that further improves on chain of thought. In our method, the model explicitly asks itself (and then answers) follow-up questions before answering the initial question. We finally show that self-ask’s structured prompting lets us easily plug in a search engine to answer the follow-up questions, which additionally improves accuracy. arXiv:2210.03350 [cs]\n"
      },
      "date": 1681970539726
    },
    {
      "item": {
        "type": "factory",
        "id": "2a8a1b6f7d5f8d29"
      },
      "id": "2a8a1b6f7d5f8d29",
      "type": "add",
      "after": "4bdc37e5d8d0d1e3",
      "date": 1681970601278
    },
    {
      "type": "edit",
      "id": "2a8a1b6f7d5f8d29",
      "item": {
        "type": "paragraph",
        "id": "2a8a1b6f7d5f8d29",
        "text": "⇒ [[Self-Ask]]"
      },
      "date": 1681970612658
    },
    {
      "type": "add",
      "id": "fb9ecb977614fe5f",
      "item": {
        "type": "paragraph",
        "id": "fb9ecb977614fe5f",
        "text": "[00:37:18]\nAnd so they gave an example of that as the sort of context for the prompt.\n[00:37:23]\nAnd then they said, now answer this question.\n[00:37:25]\nQuestion, what is the capital of the place where the Taj Mahal is, the country where\n[00:37:32]\nthe Taj Mahal is?"
      },
      "after": "5097295a97819f24",
      "date": 1681970730947
    },
    {
      "type": "add",
      "id": "6e845b55eef2613c",
      "item": {
        "type": "paragraph",
        "id": "6e845b55eef2613c",
        "text": "[00:37:33]\nAnd then it went ahead and followed that set of steps.\n[00:37:37]\nIntermediary question, what country is the Taj Mahal in?\n[00:37:41]\nAnswer, India."
      },
      "after": "fb9ecb977614fe5f",
      "date": 1681970752971
    },
    {
      "type": "add",
      "id": "fdec677959ad34bb",
      "item": {
        "type": "paragraph",
        "id": "fdec677959ad34bb",
        "text": "[00:37:43]\nIntermediary question, what is the capital of India?\n[00:37:47]\nNew Delhi.\n[00:37:48]\nSimple answer, New Delhi.\n[00:37:50]\nAnd it got the correct answer."
      },
      "after": "6e845b55eef2613c",
      "date": 1681970770414
    },
    {
      "type": "add",
      "id": "200b77e3d79c247d",
      "item": {
        "type": "paragraph",
        "id": "200b77e3d79c247d",
        "text": "[00:37:51]\nSo it got higher quality results because it was guided to break the problem down into\n[00:37:57]\nsub problems.\n[00:37:58]\nAnd pretty interesting, right?\n[00:38:01]\nYeah."
      },
      "after": "fdec677959ad34bb",
      "date": 1681970808265
    },
    {
      "type": "add",
      "id": "c9f8c46bebe9318b",
      "item": {
        "type": "paragraph",
        "id": "c9f8c46bebe9318b",
        "text": "[00:38:02]\nIt's a bit funny because I feel like everyone has this like, oh, well, you know, if I tried\n[00:38:09]\nto chat to JPT and didn't give me great results, but then I tried to prime it or I tried to\n[00:38:16]\ngive this kind of prompt or written this way, and now we get great results.\n[00:38:21]\nAnd I feel like maybe everyone will have their own ideal prompt and people will share it.\n[00:38:29]\nIt's kind of like, well, I have my set of key bindings of shortcuts for my computer."
      },
      "after": "200b77e3d79c247d",
      "date": 1681970854591
    },
    {
      "type": "add",
      "id": "cfb9e82f99b590b4",
      "item": {
        "type": "paragraph",
        "id": "cfb9e82f99b590b4",
        "text": "[00:38:35]\nOh, you don't have a shortcut for this action in your ID?\n[00:38:39]\nOh, let me share it with you.\n[00:38:41]\nOr have their own proprietary prompts.\n[00:38:44]\nMaybe yeah.\n[00:38:45]\nAnd we will start to have like our very custom experience around working with AI.\n[00:38:51]\nIt's like, hey, this is how I do it.\n[00:38:54]\nAnd this works for me.\n[00:38:55]\nAnd this might not work for you."
      },
      "after": "c9f8c46bebe9318b",
      "date": 1681970880696
    },
    {
      "type": "add",
      "id": "8307b8381391611a",
      "item": {
        "type": "paragraph",
        "id": "8307b8381391611a",
        "text": "[00:38:58]\nAnd then it'll be like, here's a very good prompt for generating the best prompt.\n[00:39:06]\nI kind of feel like maybe people who use Vim will have something like that.\n[00:39:13]\nThere's a real art to it."
      },
      "after": "cfb9e82f99b590b4",
      "date": 1681970906686
    },
    {
      "type": "add",
      "id": "f18324022d08441a",
      "item": {
        "type": "paragraph",
        "id": "f18324022d08441a",
        "text": "[00:39:18]\nAnd I mean, you're getting it to break problems.\n[00:39:21]\nSo I took this concept, and I applied this idea of breaking the problem down into sub\n[00:39:27]\nproblems.\n[00:39:28]\nI actually had written this blog post years back about like solving Elm code, like solving\n[00:39:36]\ntype puzzles in Elm, like a jigsaw puzzle frame then fill in.\n[00:39:41]\nSo like a jigsaw puzzle, you start by filling in the borders and the corner.\n[00:39:47]\nThe corner pieces are easy to find."
      },
      "after": "8307b8381391611a",
      "date": 1681970934268
    },
    {
      "type": "add",
      "id": "095ef4d5e8e40b18",
      "item": {
        "type": "paragraph",
        "id": "095ef4d5e8e40b18",
        "text": "[00:39:48]\nSo you find the corners, then you've got sort of a set of fixed points.\n[00:39:53]\nSo that's like one low hanging fruit.\n[00:39:56]\nIt's easy to solve those problems.\n[00:39:58]\nThen you find the edge pieces and you can fill those in.\n[00:40:00]\nAnd now that you've got the edges, it makes solving the rest of the puzzle easier, right?\n[00:40:05]\nSo that's one approach to solving jigsaw puzzles to break it down into sub problems."
      },
      "after": "f18324022d08441a",
      "date": 1681970972254
    },
    {
      "item": {
        "type": "factory",
        "id": "34e10df97d1d54d6"
      },
      "id": "34e10df97d1d54d6",
      "type": "add",
      "after": "2a8a1b6f7d5f8d29",
      "date": 1681971009018
    },
    {
      "id": "34e10df97d1d54d6",
      "type": "move",
      "order": [
        "31e963735f73bf64",
        "0c7f5903c3db90c2",
        "983e77dbf9d07619",
        "c4d44b0f8186c24e",
        "9048c9f533824bd4",
        "233e71f729ae1e1e",
        "5097295a97819f24",
        "fb9ecb977614fe5f",
        "6e845b55eef2613c",
        "fdec677959ad34bb",
        "200b77e3d79c247d",
        "c9f8c46bebe9318b",
        "cfb9e82f99b590b4",
        "8307b8381391611a",
        "34e10df97d1d54d6",
        "f18324022d08441a",
        "095ef4d5e8e40b18",
        "ce86e15a9019ab41",
        "3a5796bfc0b50443",
        "062f1a0ea56e4d55",
        "49d5ae7db55a996d",
        "4bdc37e5d8d0d1e3",
        "2a8a1b6f7d5f8d29"
      ],
      "date": 1681971015342
    },
    {
      "type": "edit",
      "id": "34e10df97d1d54d6",
      "item": {
        "type": "pagefold",
        "id": "34e10df97d1d54d6",
        "text": "Solving Jigsaw Puzzles"
      },
      "date": 1681971017268
    },
    {
      "type": "edit",
      "id": "f18324022d08441a",
      "item": {
        "type": "paragraph",
        "id": "f18324022d08441a",
        "text": "[00:39:18]\nAnd I mean, you're getting it to break problems.\n[00:39:21]\nSo I took this concept, and I applied this idea of breaking the problem down into sub problems.\n[00:39:28]\nI actually had written this blog post years back about like solving Elm code, like solving\n[00:39:36]\ntype puzzles in Elm, like a jigsaw puzzle frame then fill in.\n[00:39:41]\nSo like a jigsaw puzzle, you start by filling in the borders and the corner.\n[00:39:47]\nThe corner pieces are easy to find."
      },
      "date": 1681971038777
    },
    {
      "type": "add",
      "id": "4b182713a4ef0dfb",
      "item": {
        "type": "paragraph",
        "id": "4b182713a4ef0dfb",
        "text": "[00:40:09]\nBut like with Elm types, I kind of, I use this technique a lot when I'm writing Elm\n[00:40:15]\ncode as a human.\n[00:40:16]\nI will, I'll say like, okay, I don't know exactly what's going to fit here in this pipeline.\n[00:40:23]\nBut I know I want to like take this starting value, I want to do something to it.\n[00:40:29]\nAnd then I want it to be passed through in this pipeline to this next function."
      },
      "after": "095ef4d5e8e40b18",
      "date": 1681971101314
    },
    {
      "type": "edit",
      "id": "4b182713a4ef0dfb",
      "item": {
        "type": "paragraph",
        "id": "4b182713a4ef0dfb",
        "text": "[00:40:09]\nBut like with Elm types, I kind of, I use this technique a lot when I'm writing Elm code as a human.\n[00:40:16]\nI will, I'll say like, okay, I don't know exactly what's going to fit here in this pipeline.\n[00:40:23]\nBut I know I want to like take this starting value, I want to do something to it.\n[00:40:29]\nAnd then I want it to be passed through in this pipeline to this next function."
      },
      "date": 1681971138084
    },
    {
      "type": "add",
      "id": "dc8645262bf98c84",
      "item": {
        "type": "paragraph",
        "id": "dc8645262bf98c84",
        "text": "[00:40:38]\nSo sometimes I'll just like put a debug.todo there.\n[00:40:41]\nAnd then maybe I'll extract that debug.todo to a function or a let binding.\n[00:40:46]\nAnd then I'll try to get a type annotation for that value I have in my let binding.\n[00:40:52]\nThat would satisfy the compiler.\n[00:40:55]\nExactly."
      },
      "after": "4b182713a4ef0dfb",
      "date": 1681971222589
    },
    {
      "type": "add",
      "id": "94ac1923324b382f",
      "item": {
        "type": "paragraph",
        "id": "94ac1923324b382f",
        "text": "[00:40:56]\nNow I've broken it down into a sub problem.\n[00:40:59]\nSo I took this sort of like, fill in this code, I don't know what goes here, I've turned\n[00:41:03]\nit into, okay, I know the type I need.\n[00:41:06]\nSo that's sort of like finding the edge pieces in the puzzle.\n[00:41:10]\nSo now I've created the sub problem for myself."
      },
      "after": "dc8645262bf98c84",
      "date": 1681971251653
    },
    {
      "type": "add",
      "id": "663b5589a2ed5dc3",
      "item": {
        "type": "paragraph",
        "id": "663b5589a2ed5dc3",
        "text": "[00:41:13]\nAnd now I can do things like, so I've got a debug.todo with a type annotation.\n[00:41:20]\nNow I can turn that into maybe result.map around a debug.todo or list.map with a debug.todo."
      },
      "after": "94ac1923324b382f",
      "date": 1681971270430
    },
    {
      "type": "add",
      "id": "0e445fe6db36302e",
      "item": {
        "type": "paragraph",
        "id": "0e445fe6db36302e",
        "text": "[00:41:29]\nSo now I'm saying, well, I know that if I apply some function over a list, it will work.\n[00:41:38]\nAnd now I've further broken down that sub problem.\n[00:41:40]\nAnd now I can follow that step again and say, okay, we'll break out another, that debug.todo,\n[00:41:46]\ngive that a type annotation."
      },
      "after": "663b5589a2ed5dc3",
      "date": 1681971284710
    },
    {
      "type": "add",
      "id": "e6f7f44c459d2fed",
      "item": {
        "type": "paragraph",
        "id": "e6f7f44c459d2fed",
        "text": "[00:41:47]\nSo now it's list.map, some function, I don't know what, now follow that same process with\n[00:41:52]\nthat.\n[00:41:53]\nSo it's breaking it down into sub problems.\n[00:41:55]\nI use this technique all the time when I'm like, often with like API design, you're doing\n[00:42:01]\nweird type puzzles, but also just with like user code, like trying to parse some markdown\n[00:42:08]\nand take the markdown blocks and find and traverse them and map them into this type\n[00:42:13]\nand whatever."
      },
      "after": "0e445fe6db36302e",
      "date": 1681971299795
    },
    {
      "type": "edit",
      "id": "e6f7f44c459d2fed",
      "item": {
        "type": "paragraph",
        "id": "e6f7f44c459d2fed",
        "text": "[00:41:47]\nSo now it's list.map, some function, I don't know what, now follow that same process with\n[00:41:52]\nthat.\n"
      },
      "date": 1681971336069
    },
    {
      "type": "add",
      "id": "6e073e814c99dd23",
      "item": {
        "type": "paragraph",
        "id": "6e073e814c99dd23",
        "text": "[00:41:53]\nSo it's breaking it down into sub problems.\n[00:41:55]\nI use this technique all the time when I'm like, often with like API design, you're doing\n[00:42:01]\nweird type puzzles, but also just with like user code, like trying to parse some markdown\n[00:42:08]\nand take the markdown blocks and find and traverse them and map them into this type\n[00:42:13]\nand whatever."
      },
      "after": "e6f7f44c459d2fed",
      "date": 1681971338636
    },
    {
      "type": "edit",
      "id": "e6f7f44c459d2fed",
      "item": {
        "type": "paragraph",
        "id": "e6f7f44c459d2fed",
        "text": "[00:41:47]\nSo now it's list.map, some function, I don't know what, now follow that same process with that.\n"
      },
      "date": 1681971344622
    },
    {
      "type": "edit",
      "id": "6e073e814c99dd23",
      "item": {
        "type": "paragraph",
        "id": "6e073e814c99dd23",
        "text": "[00:41:53]\nSo it's breaking it down into sub problems.\n[00:41:55]\nI use this technique all the time when I'm like, often with like API design, you're doing\n[00:42:01]\nweird type puzzles, but also just with like user code, like trying to parse some markdown\n[00:42:08]\nand take the markdown blocks and find and traverse them and map them into this type and whatever."
      },
      "date": 1681971372480
    },
    {
      "type": "add",
      "id": "d0d8a7ca18815fec",
      "item": {
        "type": "paragraph",
        "id": "d0d8a7ca18815fec",
        "text": "[00:42:16]\nNow I tried to use this sort of same prompt engineering idea to teach GPT how to follow\n[00:42:24]\nthis set of steps of breaking down a type puzzle.\n[00:42:28]\nAnd it was actually really good at it."
      },
      "after": "6e073e814c99dd23",
      "date": 1681971397798
    },
    {
      "type": "add",
      "id": "aac88cfca664167c",
      "item": {
        "type": "paragraph",
        "id": "aac88cfca664167c",
        "text": "Dillon's prompt engineering type puzzle examples\n\n    Decode mapping solution (correct on first try)\n\n    Markdown solution with 2 corrections from compiler feedback\n\n    Dillon's Frame Then Fill In blog post describes a similar method to the GPT prompt"
      },
      "after": "d0d8a7ca18815fec",
      "date": 1681971437024
    },
    {
      "type": "edit",
      "id": "aac88cfca664167c",
      "item": {
        "type": "paragraph",
        "id": "aac88cfca664167c",
        "text": "Dillon's prompt engineering type puzzle examples"
      },
      "date": 1681971464208
    },
    {
      "type": "add",
      "id": "73c28551a0944dae",
      "item": {
        "type": "paragraph",
        "id": "73c28551a0944dae",
        "text": " * Decode mapping solution (correct on first try) [https://gist.github.com/dillonkearns/def823d06ef2b880bf600f0c53468e78 gist]\n\n    Markdown solution with 2 corrections from compiler feedback\n\n    Dillon's Frame Then Fill In blog post describes a similar method to the GPT prompt"
      },
      "after": "aac88cfca664167c",
      "date": 1681971474543
    },
    {
      "type": "edit",
      "id": "73c28551a0944dae",
      "item": {
        "type": "markdown",
        "id": "73c28551a0944dae",
        "text": " * Decode mapping solution (correct on first try) [https://gist.github.com/dillonkearns/def823d06ef2b880bf600f0c53468e78 gist]\n\n    Markdown solution with 2 corrections from compiler feedback\n\n    Dillon's Frame Then Fill In blog post describes a similar method to the GPT prompt"
      },
      "date": 1681971477129
    },
    {
      "type": "edit",
      "id": "73c28551a0944dae",
      "item": {
        "type": "markdown",
        "id": "73c28551a0944dae",
        "text": " * Decode mapping solution (correct on first try) [https://gist.github.com/dillonkearns/def823d06ef2b880bf600f0c53468e78 gist]\n\n * Markdown solution with 2 corrections from compiler feedback [https://gist.github.com/dillonkearns/46548b587d2fe3bf5e88f8214e1b3ce3 gist]\n\n    Dillon's Frame Then Fill In blog post describes a similar method to the GPT prompt"
      },
      "date": 1681971638678
    },
    {
      "type": "edit",
      "id": "73c28551a0944dae",
      "item": {
        "type": "markdown",
        "id": "73c28551a0944dae",
        "text": " * Decode mapping solution (correct on first try) [https://gist.github.com/dillonkearns/def823d06ef2b880bf600f0c53468e78 gist]\n\n * Markdown solution with 2 corrections from compiler feedback [https://gist.github.com/dillonkearns/46548b587d2fe3bf5e88f8214e1b3ce3 gist]\n\n * Dillon's Frame Then Fill In blog [https://incrementalelm.com/frame-then-fill-in/ post] describes a similar method to the GPT prompt"
      },
      "date": 1681971717471
    },
    {
      "item": {
        "type": "factory",
        "id": "411712fddaa86a48"
      },
      "id": "411712fddaa86a48",
      "type": "add",
      "after": "2a8a1b6f7d5f8d29",
      "date": 1681971863346
    },
    {
      "id": "411712fddaa86a48",
      "type": "move",
      "order": [
        "31e963735f73bf64",
        "0c7f5903c3db90c2",
        "983e77dbf9d07619",
        "c4d44b0f8186c24e",
        "9048c9f533824bd4",
        "233e71f729ae1e1e",
        "5097295a97819f24",
        "fb9ecb977614fe5f",
        "6e845b55eef2613c",
        "fdec677959ad34bb",
        "200b77e3d79c247d",
        "c9f8c46bebe9318b",
        "cfb9e82f99b590b4",
        "8307b8381391611a",
        "34e10df97d1d54d6",
        "f18324022d08441a",
        "095ef4d5e8e40b18",
        "4b182713a4ef0dfb",
        "dc8645262bf98c84",
        "94ac1923324b382f",
        "663b5589a2ed5dc3",
        "0e445fe6db36302e",
        "e6f7f44c459d2fed",
        "6e073e814c99dd23",
        "d0d8a7ca18815fec",
        "aac88cfca664167c",
        "73c28551a0944dae",
        "411712fddaa86a48",
        "ce86e15a9019ab41",
        "3a5796bfc0b50443",
        "062f1a0ea56e4d55",
        "49d5ae7db55a996d",
        "4bdc37e5d8d0d1e3",
        "2a8a1b6f7d5f8d29"
      ],
      "date": 1681971869986
    },
    {
      "type": "edit",
      "id": "411712fddaa86a48",
      "item": {
        "type": "paragraph",
        "id": "411712fddaa86a48",
        "text": "[00:42:30]\nSo I'll share like a little GitHub gist of my GPT prompt and the results it got.\n[00:42:39]\nBut what I basically did is I told it, I said, your job is to solve this type puzzle.\n[00:42:46]\nAnd I gave it some guardrails.\n[00:42:48]\nSo like the guardrails I gave it were, I'm going to give you some code, which has debug.todo\n[00:42:54]\nreplace me in it.\n[00:42:56]\nYour job is to, you know, get a, satisfy the type for that debug.todo.\n[00:43:02]\nAnd your final solution cannot include debug.todo."
      },
      "date": 1681971872382
    },
    {
      "type": "add",
      "id": "8556920e402e4a98",
      "item": {
        "type": "paragraph",
        "id": "8556920e402e4a98",
        "text": "[00:43:06]\nYou can write intermediary steps, which may include debug.todo.\n[00:43:10]\nAnd you are not allowed to change any code other than the section that says debug.todo.\n[00:43:16]\nSo I gave it these guardrails.\n[00:43:17]\nAlso these are verifiable things, right?"
      },
      "after": "411712fddaa86a48",
      "date": 1681971915644
    },
    {
      "type": "add",
      "id": "21da0cec9af67bb5",
      "item": {
        "type": "paragraph",
        "id": "21da0cec9af67bb5",
        "text": "[00:43:19]\nSo you can test for this to see if it's given you a valid solution, given the guardrails\n[00:43:25]\nyou wanted it to honor, because it might hallucinate and not do that, but you can check that."
      },
      "after": "8556920e402e4a98",
      "date": 1681971958313
    },
    {
      "type": "add",
      "id": "15b83cca1f6c6ff4",
      "item": {
        "type": "paragraph",
        "id": "15b83cca1f6c6ff4",
        "text": "[00:43:32]\nSo one thing that I'm thinking of is, will you be able to verify things accurately?\n[00:43:39]\nMaybe I'm being too, I'm trying to play the devil's advocate here a bit, and I might be\n[00:43:44]\na bit too hard on chat.gpt.\n[00:43:47]\nBut for instance, whenever you're working in that TD style, when you do things one step\n[00:43:52]\nat a time, you discover edge cases, right?"
      },
      "after": "21da0cec9af67bb5",
      "date": 1681971987309
    },
    {
      "type": "add",
      "id": "19928b006afd0a5c",
      "item": {
        "type": "paragraph",
        "id": "19928b006afd0a5c",
        "text": "[00:43:56]\nSo for instance, you give a list as an argument and needs to return a number.\n[00:44:01]\nAnd first you hard code that number.\n[00:44:03]\nAnd then you notice, Oh, well, what if that list is, is, is empty then?\n[00:44:08]\nOh, well then I need to write a test for if the, the, the list is empty.\n[00:44:14]\nAh, okay."
      },
      "after": "15b83cca1f6c6ff4",
      "date": 1681972046963
    },
    {
      "type": "add",
      "id": "6311e1260bd4aaf0",
      "item": {
        "type": "paragraph",
        "id": "6311e1260bd4aaf0",
        "text": "[00:44:17]\nBut the, the AI might not do that, might not notice that.\n[00:44:20]\nSo maybe it's, it is going to fix things correctly.\n[00:44:24]\nMaybe not, but let's say it's going to do it correctly, but it's not going to have a\n[00:44:27]\ntest for that."
      },
      "after": "19928b006afd0a5c",
      "date": 1681972098918
    },
    {
      "type": "add",
      "id": "42cdfe9009b64520",
      "item": {
        "type": "paragraph",
        "id": "42cdfe9009b64520",
        "text": "[00:44:29]\nOr you're not going to know, or you're going to, I mean, you are not going to notice that\n[00:44:36]\nyou're going to need to write a test with an empty list.\n[00:44:39]\nSo that's the process is a bit hard to figure out if you don't do it yourself.\n[00:44:45]\nIt's kind of like, I think also one of the reasons why people say, well, you should pair\n[00:44:49]\nprogram rather than review someone else's code, because you will discover those, those\n[00:44:55]\nthings while you're working."
      },
      "after": "6311e1260bd4aaf0",
      "date": 1681972148959
    },
    {
      "type": "add",
      "id": "1829aaa6d808fe34",
      "item": {
        "type": "paragraph",
        "id": "1829aaa6d808fe34",
        "text": "[00:45:04]\nI think we're going to see like a lot of junior developers using these AI tools in exactly\n[00:45:10]\nthe kind of way you're describing where maybe they trust it too much to do too many steps.\n[00:45:18]\nAnd then what happens is you're not really engaging with the problem intellectually, and\n[00:45:24]\nyou're not thinking about these test cases that come up."
      },
      "after": "42cdfe9009b64520",
      "date": 1681972212365
    },
    {
      "type": "add",
      "id": "93f7635f63d1f32f",
      "item": {
        "type": "paragraph",
        "id": "93f7635f63d1f32f",
        "text": "[00:45:27]\nSo I think there's an art to knowing when to use it.\n[00:45:31]\nSo like the type of problem here for this sort of frame then fill in problem I'm talking\n[00:45:36]\nabout, this is this is a class of problem that I find myself spending a lot of mental\n[00:45:43]\neffort solving on a regular basis."
      },
      "after": "1829aaa6d808fe34",
      "date": 1681973268558
    },
    {
      "type": "edit",
      "id": "93f7635f63d1f32f",
      "item": {
        "type": "paragraph",
        "id": "93f7635f63d1f32f",
        "text": "[00:45:27]\nSo I think there's an art to knowing when to use it.\n[00:45:31]\nSo like the type of problem here for this sort of frame then fill in problem I'm talking about, this is this is a class of problem that I find myself spending a lot of mental effort solving on a regular basis."
      },
      "date": 1681973928663
    },
    {
      "type": "add",
      "id": "a35befcc1b5fde38",
      "item": {
        "type": "paragraph",
        "id": "a35befcc1b5fde38",
        "text": "[00:45:45]\nThat is kind of this, this, you know, it has this quality we talked about with a traveling\n[00:45:50]\nsalesman where you know it when you see it, if you have a good solution, you can easily\n[00:45:54]\nverify that it that it solved it."
      },
      "after": "93f7635f63d1f32f",
      "date": 1681974068953
    },
    {
      "type": "add",
      "id": "04a93a2b681083d7",
      "item": {
        "type": "paragraph",
        "id": "04a93a2b681083d7",
        "text": "[00:45:57]\nAnd yet it's not really doing anything too creative, because it's fitting pieces together.\n[00:46:02]\nIt's not really writing too many implementation details.\n[00:46:06]\nAnd I find that often with Elm code, you arrive at these types of situations where like, if\n[00:46:11]\nyou could make the types work, you would trust that the code worked because like, there's\n[00:46:16]\nonly really one good way to fit these functions together to get the right thing.\n[00:46:20]\nLike you're not doing too much logic of like, give it this empty value and give it this\n[00:46:25]\nnow it might hallucinate these types of things."
      },
      "after": "a35befcc1b5fde38",
      "date": 1681974131009
    },
    {
      "item": {
        "type": "factory",
        "id": "44be41a65fe85152"
      },
      "id": "44be41a65fe85152",
      "type": "add",
      "after": "2a8a1b6f7d5f8d29",
      "date": 1681974149285
    },
    {
      "id": "44be41a65fe85152",
      "type": "move",
      "order": [
        "31e963735f73bf64",
        "0c7f5903c3db90c2",
        "983e77dbf9d07619",
        "c4d44b0f8186c24e",
        "9048c9f533824bd4",
        "233e71f729ae1e1e",
        "5097295a97819f24",
        "fb9ecb977614fe5f",
        "6e845b55eef2613c",
        "fdec677959ad34bb",
        "200b77e3d79c247d",
        "c9f8c46bebe9318b",
        "cfb9e82f99b590b4",
        "8307b8381391611a",
        "34e10df97d1d54d6",
        "f18324022d08441a",
        "095ef4d5e8e40b18",
        "4b182713a4ef0dfb",
        "dc8645262bf98c84",
        "94ac1923324b382f",
        "663b5589a2ed5dc3",
        "0e445fe6db36302e",
        "e6f7f44c459d2fed",
        "6e073e814c99dd23",
        "d0d8a7ca18815fec",
        "aac88cfca664167c",
        "73c28551a0944dae",
        "411712fddaa86a48",
        "8556920e402e4a98",
        "21da0cec9af67bb5",
        "15b83cca1f6c6ff4",
        "19928b006afd0a5c",
        "6311e1260bd4aaf0",
        "42cdfe9009b64520",
        "1829aaa6d808fe34",
        "93f7635f63d1f32f",
        "a35befcc1b5fde38",
        "44be41a65fe85152",
        "04a93a2b681083d7",
        "ce86e15a9019ab41",
        "3a5796bfc0b50443",
        "062f1a0ea56e4d55",
        "49d5ae7db55a996d",
        "4bdc37e5d8d0d1e3",
        "2a8a1b6f7d5f8d29"
      ],
      "date": 1681974162125
    },
    {
      "type": "edit",
      "id": "44be41a65fe85152",
      "item": {
        "type": "pagefold",
        "id": "44be41a65fe85152",
        "text": "You Know It When You See It"
      },
      "date": 1681974167126
    },
    {
      "id": "44be41a65fe85152",
      "type": "move",
      "order": [
        "31e963735f73bf64",
        "0c7f5903c3db90c2",
        "983e77dbf9d07619",
        "c4d44b0f8186c24e",
        "9048c9f533824bd4",
        "233e71f729ae1e1e",
        "5097295a97819f24",
        "fb9ecb977614fe5f",
        "6e845b55eef2613c",
        "fdec677959ad34bb",
        "200b77e3d79c247d",
        "c9f8c46bebe9318b",
        "cfb9e82f99b590b4",
        "8307b8381391611a",
        "34e10df97d1d54d6",
        "f18324022d08441a",
        "095ef4d5e8e40b18",
        "4b182713a4ef0dfb",
        "dc8645262bf98c84",
        "94ac1923324b382f",
        "663b5589a2ed5dc3",
        "0e445fe6db36302e",
        "e6f7f44c459d2fed",
        "6e073e814c99dd23",
        "d0d8a7ca18815fec",
        "aac88cfca664167c",
        "73c28551a0944dae",
        "411712fddaa86a48",
        "8556920e402e4a98",
        "21da0cec9af67bb5",
        "15b83cca1f6c6ff4",
        "19928b006afd0a5c",
        "6311e1260bd4aaf0",
        "42cdfe9009b64520",
        "1829aaa6d808fe34",
        "93f7635f63d1f32f",
        "44be41a65fe85152",
        "a35befcc1b5fde38",
        "04a93a2b681083d7",
        "ce86e15a9019ab41",
        "3a5796bfc0b50443",
        "062f1a0ea56e4d55",
        "49d5ae7db55a996d",
        "4bdc37e5d8d0d1e3",
        "2a8a1b6f7d5f8d29"
      ],
      "date": 1681974168850
    },
    {
      "type": "edit",
      "id": "04a93a2b681083d7",
      "item": {
        "type": "paragraph",
        "id": "04a93a2b681083d7",
        "text": "[00:45:57]\nAnd yet it's not really doing anything too creative, because it's fitting pieces together.\n[00:46:02]\nIt's not really writing too many implementation details.\n[00:46:06]\nAnd I find that often with Elm code, you arrive at these types of situations where like, if\n[00:46:11]\nyou could make the types work, you would trust that the code worked because like, there's\n[00:46:16]\nonly really one good way to fit these functions together to get the right thing.\n[00:46:20]\nLike you're not doing too much logic of like, give it this empty value and give it this now it might hallucinate these types of things."
      },
      "date": 1681974209000
    },
    {
      "type": "add",
      "id": "d4adc29b76297f46",
      "item": {
        "type": "paragraph",
        "id": "d4adc29b76297f46",
        "text": "[00:46:27]\nBut you could even use prompt engineering to tell it like, you're just fitting these\n[00:46:33]\nfunctions together.\n[00:46:34]\nI don't want you to write new logic or use default values.\n[00:46:37]\nSo I think these types of things can be improved through prompt engineering and also through\n[00:46:41]\nselecting the right types of problems."
      },
      "after": "04a93a2b681083d7",
      "date": 1681974239162
    },
    {
      "type": "add",
      "id": "4c57532c5ebc2730",
      "item": {
        "type": "paragraph",
        "id": "4c57532c5ebc2730",
        "text": "[00:46:43]\nBut like, for example, the I gave it a pretty, pretty challenging problem with this sort\n[00:46:50]\nof prompt I designed.\n[00:46:52]\nI had it fill in this, this thing in a in an Elm pages example that I have where it\n[00:46:58]\ntakes markdown blocks and it traverses these headings and it and I what I did is I primed\n[00:47:08]\nit with a list of all of the available functions that it could use.\n[00:47:15]\nAnd another thing you can do a set of guardrails is you can say only use these functions.\n[00:47:19]\nAnd you could even say you must use these functions.\n[00:47:23]\nAnd these other functions are available and you may not use any other functions.\n[00:47:27]\nAnd of course, these things are verifiable in the in the final output easily."
      },
      "after": "d4adc29b76297f46",
      "date": 1681974253578
    },
    {
      "type": "add",
      "id": "73adb271b044b06a",
      "item": {
        "type": "paragraph",
        "id": "73adb271b044b06a",
        "text": "[00:47:32]\nBut why would you tell it you can only use these functions because you're now limiting limiting its creativity."
      },
      "after": "4c57532c5ebc2730",
      "date": 1681974316433
    },
    {
      "item": {
        "type": "factory",
        "id": "1664ab2e7bedbcd2"
      },
      "id": "1664ab2e7bedbcd2",
      "type": "add",
      "after": "2a8a1b6f7d5f8d29",
      "date": 1681974323548
    },
    {
      "id": "1664ab2e7bedbcd2",
      "type": "move",
      "order": [
        "31e963735f73bf64",
        "0c7f5903c3db90c2",
        "983e77dbf9d07619",
        "c4d44b0f8186c24e",
        "9048c9f533824bd4",
        "233e71f729ae1e1e",
        "5097295a97819f24",
        "fb9ecb977614fe5f",
        "6e845b55eef2613c",
        "fdec677959ad34bb",
        "200b77e3d79c247d",
        "c9f8c46bebe9318b",
        "cfb9e82f99b590b4",
        "8307b8381391611a",
        "34e10df97d1d54d6",
        "f18324022d08441a",
        "095ef4d5e8e40b18",
        "4b182713a4ef0dfb",
        "dc8645262bf98c84",
        "94ac1923324b382f",
        "663b5589a2ed5dc3",
        "0e445fe6db36302e",
        "e6f7f44c459d2fed",
        "6e073e814c99dd23",
        "d0d8a7ca18815fec",
        "aac88cfca664167c",
        "73c28551a0944dae",
        "411712fddaa86a48",
        "8556920e402e4a98",
        "21da0cec9af67bb5",
        "15b83cca1f6c6ff4",
        "19928b006afd0a5c",
        "6311e1260bd4aaf0",
        "42cdfe9009b64520",
        "1829aaa6d808fe34",
        "93f7635f63d1f32f",
        "44be41a65fe85152",
        "a35befcc1b5fde38",
        "04a93a2b681083d7",
        "d4adc29b76297f46",
        "4c57532c5ebc2730",
        "1664ab2e7bedbcd2",
        "73adb271b044b06a",
        "ce86e15a9019ab41",
        "3a5796bfc0b50443",
        "062f1a0ea56e4d55",
        "49d5ae7db55a996d",
        "4bdc37e5d8d0d1e3",
        "2a8a1b6f7d5f8d29"
      ],
      "date": 1681974326619
    },
    {
      "type": "edit",
      "id": "1664ab2e7bedbcd2",
      "item": {
        "type": "pagefold",
        "id": "1664ab2e7bedbcd2",
        "text": "Limiting Its Creativity"
      },
      "date": 1681974329646
    },
    {
      "type": "add",
      "id": "019de178e14f013d",
      "item": {
        "type": "paragraph",
        "id": "019de178e14f013d",
        "text": "[00:47:41]\nFor instance, if you forget to mention list.map, then it's not going to use that.\n[00:47:46]\nAnd it's going to use something else like list.fold instead.\n[00:47:50]\nWell, so the the way basically I was doing this as a proof of concept of saying, I'm\n[00:47:58]\ngoing to give you all of the functions that are in scope in this particular code base.\n[00:48:04]\nAnd I'm going to give you like all of the functions from from the list module and from\n[00:48:09]\nthe result module."
      },
      "after": "73adb271b044b06a",
      "date": 1681974349668
    },
    {
      "type": "edit",
      "id": "019de178e14f013d",
      "item": {
        "type": "paragraph",
        "id": "019de178e14f013d",
        "text": "[00:47:41]\nFor instance, if you forget to mention list.map, then it's not going to use that.\n[00:47:46]\nAnd it's going to use something else like list.fold instead.\n"
      },
      "date": 1681974368445
    },
    {
      "type": "add",
      "id": "6c6ee3c1310d2799",
      "item": {
        "type": "paragraph",
        "id": "6c6ee3c1310d2799",
        "text": "[00:47:50]\nWell, so the the way basically I was doing this as a proof of concept of saying, I'm\n[00:47:58]\ngoing to give you all of the functions that are in scope in this particular code base.\n[00:48:04]\nAnd I'm going to give you like all of the functions from from the list module and from\n[00:48:09]\nthe result module."
      },
      "after": "019de178e14f013d",
      "date": 1681974369472
    },
    {
      "type": "add",
      "id": "2e4bb89421e4392a",
      "item": {
        "type": "paragraph",
        "id": "2e4bb89421e4392a",
        "text": "[00:48:10]\nSo you can give it like a certain set of available functions and say, these are the types and\n[00:48:14]\nI taught it like I even taught it how partial application works."
      },
      "after": "6c6ee3c1310d2799",
      "date": 1681974399314
    },
    {
      "type": "add",
      "id": "f153ff121b572366",
      "item": {
        "type": "paragraph",
        "id": "f153ff121b572366",
        "text": "[00:48:18]\nSo I can take an example.\n[00:48:20]\nAnd I said, given this type, if you pass in this function, now the type annotation is this."
      },
      "after": "2e4bb89421e4392a",
      "date": 1681974460668
    },
    {
      "type": "add",
      "id": "bc4bb3c69e950bcb",
      "item": {
        "type": "paragraph",
        "id": "bc4bb3c69e950bcb",
        "text": "[00:48:26]\nAnd it I played around with it and tweaked it in these ways.\n[00:48:29]\nAnd it did a better job at solving these puzzles.\n[00:48:32]\nSo it's pretty interesting.\n[00:48:33]\nYou can kind of teach it in these prompts."
      },
      "after": "f153ff121b572366",
      "date": 1681974498949
    },
    {
      "type": "add",
      "id": "d44f089538f82eb0",
      "item": {
        "type": "paragraph",
        "id": "d44f089538f82eb0",
        "text": "[00:48:45]\nI wanted to solve a sort of uncreative problem of wiring things together that I don't really\n[00:48:52]\nlike if I could automate that as an atomic step, I would love to like if I could, you\n[00:48:57]\ncould even think of it this way, like, AI, give me all of the possible solutions using\n[00:49:04]\nthe functions in scope here to satisfy this type, right?"
      },
      "after": "bc4bb3c69e950bcb",
      "date": 1681974533674
    },
    {
      "type": "add",
      "id": "88fc33915ad3d433",
      "item": {
        "type": "paragraph",
        "id": "88fc33915ad3d433",
        "text": "[00:49:09]\nJust like, and then you can just select, okay, these are all the valid ways to do that.\n[00:49:13]\nSo if I can teach through a GPT prompt, the AI to solve that type of puzzle, and give\n[00:49:20]\nme all the possible results, and then I can use a tool to actually verify those results.\n[00:49:25]\nSo I so I know I can 100% trust them."
      },
      "after": "d44f089538f82eb0",
      "date": 1681974578240
    },
    {
      "type": "add",
      "id": "b5f6bc296a446886",
      "item": {
        "type": "paragraph",
        "id": "b5f6bc296a446886",
        "text": "[00:49:28]\nThat becomes a very interesting tool in my toolkit, where now I'm more capable as a programmer.\n[00:49:34]\nAnd I'm not sort of like hallucinating weird things into my code base, or as you said,\n[00:49:39]\nlike having it write out these new cases that I'm not considering in my testing or considering\n[00:49:45]\nhow it affects the user experience."
      },
      "after": "88fc33915ad3d433",
      "date": 1681974603185
    },
    {
      "type": "add",
      "id": "952531ff933fd270",
      "item": {
        "type": "paragraph",
        "id": "952531ff933fd270",
        "text": "[00:49:47]\nAnd if that's what I want the experience to be, it's just like, how do I solve this type\n[00:49:51]\nproblem?"
      },
      "after": "b5f6bc296a446886",
      "date": 1681974620288
    },
    {
      "type": "edit",
      "id": "952531ff933fd270",
      "item": {
        "type": "paragraph",
        "id": "952531ff933fd270",
        "text": "[00:49:47]\nAnd if that's what I want the experience to be, it's just like, how do I solve this type problem?"
      },
      "date": 1681974629100
    },
    {
      "type": "add",
      "id": "eb9e426e16e1cd30",
      "item": {
        "type": "paragraph",
        "id": "eb9e426e16e1cd30",
        "text": "[00:49:52]\nOh, yeah, that's the only one sensible, sensible, meaningful solution, and it found it.\n[00:49:58]\nAnd I can easily look at it and say, oh, yeah, result dot map, tuple dot map first list dot\n[00:50:05]\nmap."
      },
      "after": "952531ff933fd270",
      "date": 1681974641649
    },
    {
      "type": "edit",
      "id": "eb9e426e16e1cd30",
      "item": {
        "type": "paragraph",
        "id": "eb9e426e16e1cd30",
        "text": "[00:49:52]\nOh, yeah, that's the only one sensible, sensible, meaningful solution, and it found it.\n[00:49:58]\nAnd I can easily look at it and say, oh, yeah, result dot map, tuple dot map first list dot map. Yes."
      },
      "date": 1681974672889
    },
    {
      "type": "add",
      "id": "10fd20dec4d045e7",
      "item": {
        "type": "paragraph",
        "id": "10fd20dec4d045e7",
        "text": "[00:50:06]\n[…], that it didn't use anything too crazy.\n[00:50:10]\nIt satisfies the types.\n[00:50:11]\nIt's good.\n[00:50:12]\nI can easily look at it and see it did the right thing.\n[00:50:14]\nBut it would have taken me a long time to solve it myself.\n[00:50:18]\nAnd so in case it wasn't clear, my idea is to like, this is something I want to experiment\n[00:50:24]\na little more with the OpenAI API to fully automate this."
      },
      "after": "eb9e426e16e1cd30",
      "date": 1681974710458
    },
    {
      "type": "edit",
      "id": "10fd20dec4d045e7",
      "item": {
        "type": "paragraph",
        "id": "10fd20dec4d045e7",
        "text": "[00:50:06]\n[…], that it didn't use anything too crazy.\n[00:50:10]\nIt satisfies the types.\n[00:50:11]\nIt's good.\n[00:50:12]\nI can easily look at it and see it did the right thing.\n[00:50:14]\nBut it would have taken me a long time to solve it myself.\n"
      },
      "date": 1681974737137
    },
    {
      "type": "add",
      "id": "0399d986158f1c7f",
      "item": {
        "type": "paragraph",
        "id": "0399d986158f1c7f",
        "text": "[00:50:18]\nAnd so in case it wasn't clear, my idea is to like, this is something I want to experiment\n[00:50:24]\na little more with the OpenAI API to fully automate this."
      },
      "after": "10fd20dec4d045e7",
      "date": 1681974738207
    },
    {
      "type": "add",
      "id": "425ce9c38b354683",
      "item": {
        "type": "paragraph",
        "id": "425ce9c38b354683",
        "text": "[00:50:28]\nAnd because it's a pretty easy thing to automate to just say, what are all the types of all\n[00:50:34]\nthe functions in in scope here?\n[00:50:37]\nLike that's a an automatable thing.\n[00:50:40]\nSo feed it that into the prompt and give it the ability through, you know, through writing\n[00:50:45]\na small script that hits the OpenAI API, tell it what the compiler error is to let it iterate\n[00:50:52]\non."
      },
      "after": "0399d986158f1c7f",
      "date": 1681974772745
    },
    {
      "type": "edit",
      "id": "425ce9c38b354683",
      "item": {
        "type": "paragraph",
        "id": "425ce9c38b354683",
        "text": "[00:50:28]\nAnd because it's a pretty easy thing to automate to just say, what are all the types of all the functions in in scope here?\n[00:50:37]\nLike that's a an automatable thing.\n[00:50:40]\nSo feed it that into the prompt and give it the ability through, you know, through writing\n[00:50:45]\na small script that hits the OpenAI API, tell it what the compiler error is to let it iterate\n[00:50:52]\non."
      },
      "date": 1681974793344
    },
    {
      "type": "edit",
      "id": "425ce9c38b354683",
      "item": {
        "type": "paragraph",
        "id": "425ce9c38b354683",
        "text": "[00:50:28]\nAnd because it's a pretty easy thing to automate to just say, what are all the types of all the functions in in scope here?\n[00:50:37]\nLike that's a an automatable thing.\n[00:50:40]\nSo feed it that into the prompt and give it the ability through, you know, through writing a small script that hits the OpenAI API, tell it what the compiler error is to let it iterate\n[00:50:52]\non."
      },
      "date": 1681974808022
    },
    {
      "type": "edit",
      "id": "425ce9c38b354683",
      "item": {
        "type": "paragraph",
        "id": "425ce9c38b354683",
        "text": "[00:50:28]\nAnd because it's a pretty easy thing to automate to just say, what are all the types of all the functions in in scope here?\n[00:50:37]\nLike that's a an automatable thing.\n[00:50:40]\nSo feed it that into the prompt and give it the ability through, you know, through writing a small script that hits the OpenAI API, tell it what the compiler error is to let it iterate on."
      },
      "date": 1681974818979
    },
    {
      "type": "add",
      "id": "bad873b217cd8bf6",
      "item": {
        "type": "paragraph",
        "id": "bad873b217cd8bf6",
        "text": "[00:50:53]\nSo when I gave it this problem as a proof of concept manually, I manually told it the\n[00:50:58]\ncompiler errors and it with two iterations with telling it the compiler error, it was\n[00:51:03]\nable to get the correct result, which I thought was pretty cool."
      },
      "after": "425ce9c38b354683",
      "date": 1681974852914
    },
    {
      "type": "add",
      "id": "2065f15e0e18c4cd",
      "item": {
        "type": "paragraph",
        "id": "2065f15e0e18c4cd",
        "text": "[…]"
      },
      "after": "bad873b217cd8bf6",
      "date": 1681974906823
    },
    {
      "type": "add",
      "id": "51d5e033f9545448",
      "item": {
        "type": "paragraph",
        "id": "51d5e033f9545448",
        "text": "[00:52:09]\nSo a lot of our work as developers is not writing new code, it's editing existing code.\n[00:52:15]\nSo I feel like that's going to be somewhat missing now, but it's probably going to be\n[00:52:21]\nsolved pretty soon."
      },
      "after": "2065f15e0e18c4cd",
      "date": 1681974908104
    },
    {
      "type": "add",
      "id": "2f47b62a1a3c2e35",
      "item": {
        "type": "paragraph",
        "id": "2f47b62a1a3c2e35",
        "text": "[00:52:31]\nActually, GPT-4, can't it take like 25,000 tokens as input?\n[00:52:36]\nSo you can feed it a huge input."
      },
      "after": "51d5e033f9545448",
      "date": 1681974950866
    },
    {
      "type": "add",
      "id": "04d7fc8191f9ac8c",
      "item": {
        "type": "paragraph",
        "id": "04d7fc8191f9ac8c",
        "text": "[00:52:40]\nThat's a game changer."
      },
      "after": "2f47b62a1a3c2e35",
      "date": 1681974972870
    },
    {
      "type": "add",
      "id": "460f5f4914e4ce19",
      "item": {
        "type": "paragraph",
        "id": "460f5f4914e4ce19",
        "text": "[00:52:50]\nBut until then, I'm thinking, for instance, if we had a tool that's extracted information\n[00:52:56]\nfrom your codebase, and that you can then just copy paste into the prompt, that could\n[00:53:02]\nbe pretty cool.\n[00:53:03]\nSo like having all the types for the functions.\n[00:53:06]\nAnd there is a tool that is called Elm Review, which has an extract feature."
      },
      "after": "04d7fc8191f9ac8c",
      "date": 1681975010623
    },
    {
      "type": "add",
      "id": "f2acf7266c98cdbb",
      "item": {
        "type": "paragraph",
        "id": "f2acf7266c98cdbb",
        "text": "[…]"
      },
      "after": "04d7fc8191f9ac8c",
      "date": 1681975017431
    },
    {
      "type": "add",
      "id": "b0cda91d8b906f50",
      "item": {
        "type": "paragraph",
        "id": "b0cda91d8b906f50",
        "text": "[00:53:25]\nUnless you automate it, and why not?\n[00:53:27]\nIt gives good results."
      },
      "after": "460f5f4914e4ce19",
      "date": 1681975097845
    },
    {
      "type": "add",
      "id": "d526153a5fc4a0db",
      "item": {
        "type": "paragraph",
        "id": "d526153a5fc4a0db",
        "text": "[00:53:40]\nLike I work on a 200,000 lines of code, codebase.\n[00:53:46]\nBut how many type annotations does that represent, right?\n[00:53:51]\nLike hundreds of thousands, probably?\n[00:53:54]\nYou think so?\n[00:53:55]\nThat are in scope in a particular point in code?\n[00:53:58]\nWell, you can import anything.\n[00:54:00]\nNot everything is exposed, probably."
      },
      "after": "b0cda91d8b906f50",
      "date": 1681975131764
    },
    {
      "type": "add",
      "id": "002abf10e2ec15cd",
      "item": {
        "type": "paragraph",
        "id": "002abf10e2ec15cd",
        "text": "[00:54:03]\nAnd a lot of things are going to be values that are locally scoped to let like I would\n[00:54:08]\nI would venture to guess in a 200,000 line codebase.\n[00:54:12]\nWith code comments?\n[00:54:13]\nOr maybe there are a thousand.\n[00:54:16]\nMaybe there are like on the order of one to 10,000.\n[00:54:20]\nNo more than definitely no more than 10,000."
      },
      "after": "d526153a5fc4a0db",
      "date": 1681975249474
    },
    {
      "type": "add",
      "id": "62355bbb42671424",
      "item": {
        "type": "paragraph",
        "id": "62355bbb42671424",
        "text": "[00:54:28]\nOh, there's also dependencies, but that's also not that much.\n[00:54:33]\nRight, maybe it's doable.\n[00:54:36]\nAnd you can do heuristics to filter and not even heuristics, like reliable heuristics\n[00:54:43]\nto filter out."
      },
      "after": "002abf10e2ec15cd",
      "date": 1681975268187
    },
    {
      "type": "add",
      "id": "18109f9ee743be41",
      "item": {
        "type": "paragraph",
        "id": "18109f9ee743be41",
        "text": "[00:54:44]\nYou know, you know that if you're trying to arrive at this type, but none of the types\n[00:54:51]\nconnect in any way."
      },
      "after": "62355bbb42671424",
      "date": 1681975286948
    },
    {
      "type": "add",
      "id": "ea59ad4de2a6c3fd",
      "item": {
        "type": "paragraph",
        "id": "ea59ad4de2a6c3fd",
        "text": "[00:54:52]\nSo if you can take a string and use it on this thing, and you can take an int and turn\n[00:54:58]\nit into a string, then those two things connect."
      },
      "after": "18109f9ee743be41",
      "date": 1681975294972
    },
    {
      "type": "add",
      "id": "9d998f0a26d8af13",
      "item": {
        "type": "paragraph",
        "id": "9d998f0a26d8af13",
        "text": "[00:55:01]\nBut if a if this custom type can't be turned into a string, then you know it, it's not\n[00:55:09]\ngoing to be involved in your problem at all, because your problem is dealing with strings,\n[00:55:13]\nand you can't turn that to or from a string, for example."
      },
      "after": "ea59ad4de2a6c3fd",
      "date": 1681975305592
    },
    {
      "type": "add",
      "id": "3eeb4b5495a49725",
      "item": {
        "type": "paragraph",
        "id": "3eeb4b5495a49725",
        "text": "[00:55:17]\nYeah, you can also remove all the modules that would create an import cycle.\n[00:55:22]\nRight.\n[00:55:23]\nSo basically, you can't import anything that imports this file directly or indirectly.\n[00:55:28]\nExactly."
      },
      "after": "9d998f0a26d8af13",
      "date": 1681975322218
    },
    {
      "type": "add",
      "id": "a731bcad492f7b6a",
      "item": {
        "type": "paragraph",
        "id": "a731bcad492f7b6a",
        "text": "[00:55:30]\nSo to me, this is the really interesting intersection.\n[00:55:33]\nSo now you were mentioning earlier that you think that these tools will start to understand\n[00:55:38]\nyour code more over time, but we're not there yet.\n[00:55:41]\nI actually, I don't see it that way."
      },
      "after": "3eeb4b5495a49725",
      "date": 1681975338385
    },
    {
      "type": "add",
      "id": "0f44d5af800ad63d",
      "item": {
        "type": "paragraph",
        "id": "0f44d5af800ad63d",
        "text": "[00:55:44]\nI believe that these tools are going to continue doing what they're doing, which is that they've\n[00:55:49]\nbeen remarkably successful in being able to solve complex problems just through this crazy\n[00:55:56]\nsynthesis and predictive text sort of thing."
      },
      "after": "a731bcad492f7b6a",
      "date": 1681975366480
    },
    {
      "type": "add",
      "id": "4cbe0838aa2302f1",
      "item": {
        "type": "paragraph",
        "id": "4cbe0838aa2302f1",
        "text": "[00:56:00]\nNo, I didn't mean it in the sense of understanding.\n[00:56:02]\nI meant it's just of gathering the information."
      },
      "after": "0f44d5af800ad63d",
      "date": 1681975383106
    },
    {
      "type": "add",
      "id": "60969bacc744e63b",
      "item": {
        "type": "paragraph",
        "id": "60969bacc744e63b",
        "text": "[00:56:07]\nLike every time you ask something to ChatGPT, you need to provide information about your\n[00:56:12]\ncode base.\n[00:56:13]\nAt the moment, it does not look at your code base."
      },
      "after": "4cbe0838aa2302f1",
      "date": 1681975448422
    },
    {
      "type": "add",
      "id": "c16b733883b62561",
      "item": {
        "type": "paragraph",
        "id": "c16b733883b62561",
        "text": "[00:56:19]\nBut I don't think that they will, for example, know type information about your code base,\n[00:56:25]\nexcept insofar as it's part of the predictive text because it's in there."
      },
      "after": "60969bacc744e63b",
      "date": 1681975497551
    },
    {
      "type": "add",
      "id": "6507b979bc039c68",
      "item": {
        "type": "paragraph",
        "id": "6507b979bc039c68",
        "text": "[00:56:29]\nBut I think that they're getting enough mileage solving problems through this sort of predictive\n[00:56:36]\ntext, that they're going to keep going with that.\n[00:56:39]\nBut I think the interesting intersection, especially with typed pure functional programming\n[00:56:46]\nlanguages is if you, so humans have their role, these sort of like compiler tools and\n[00:56:55]\nstatic analysis tools have their role, and these AI tools have their role."
      },
      "after": "c16b733883b62561",
      "date": 1681975538545
    },
    {
      "type": "add",
      "id": "e7afa56f4327711c",
      "item": {
        "type": "paragraph",
        "id": "e7afa56f4327711c",
        "text": "⇒ [[Role-Playing]]"
      },
      "after": "6507b979bc039c68",
      "date": 1681975626984
    }
  ]
}