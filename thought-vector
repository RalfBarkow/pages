{
  "title": "Thought Vector",
  "story": [
    {
      "type": "paragraph",
      "id": "7e7c3eb9ef8406ce",
      "text": "is a term popularized by [[Geoffrey Hinton]], the prominent deep-learning researcher now at Google, which is using vectors based on natural language to improve its search results. [https://web.archive.org/web/20170211043631/https://deeplearning4j.org/thoughtvectors archive]"
    },
    {
      "type": "paragraph",
      "id": "cbb344b5accb57e2",
      "text": "A thought vector is like a word vector, which is typically a vector of 300-500 numbers that represent a word. A word vector represents a word’s meaning as it relates to other words (its context) with a single column of numbers."
    },
    {
      "type": "paragraph",
      "id": "aeac04176ced4a9d",
      "text": "That is, the word is embedded in a vector space using a shallow neural network like word2vec, which learns to generate the word’s context through repeated guesses."
    },
    {
      "type": "paragraph",
      "id": "a5910963aa7ea390",
      "text": "A thought vector, therefore, is a vectorized thought, and the vector represents one thought’s relations to others. A thought vector is trained to generate a thought’s context. Just as a words are linked by grammar (a sentence is just a path drawn across words), so thoughts are linked by a chain of reasoning, a logical path of sorts."
    },
    {
      "type": "paragraph",
      "id": "2d1a5dda3020addf",
      "text": "So training an algorithm to represent any thought in its relation to others might be called the artificial construction of common sense. Given one thought, a neural network might predict the thoughts that are likely to follow, much like recurrent neural networks do with characters and words. [[Conversation as Search]]."
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Thought Vector",
        "story": []
      },
      "date": 1692688329638
    },
    {
      "item": {
        "type": "factory",
        "id": "7e7c3eb9ef8406ce"
      },
      "id": "7e7c3eb9ef8406ce",
      "type": "add",
      "date": 1692688330679
    },
    {
      "type": "edit",
      "id": "7e7c3eb9ef8406ce",
      "item": {
        "type": "paragraph",
        "id": "7e7c3eb9ef8406ce",
        "text": "is a term popularized by [[Geoffrey Hinton]], the prominent deep-learning researcher now at Google, which is using vectors based on natural language to improve its search results."
      },
      "date": 1692688352059
    },
    {
      "type": "edit",
      "id": "7e7c3eb9ef8406ce",
      "item": {
        "type": "paragraph",
        "id": "7e7c3eb9ef8406ce",
        "text": "is a term popularized by [[Geoffrey Hinton]], the prominent deep-learning researcher now at Google, which is using vectors based on natural language to improve its search results. [https://web.archive.org/web/20170211043631/https://deeplearning4j.org/thoughtvectors archive]"
      },
      "date": 1692688357705
    },
    {
      "item": {
        "type": "factory",
        "id": "cbb344b5accb57e2"
      },
      "id": "cbb344b5accb57e2",
      "type": "add",
      "after": "7e7c3eb9ef8406ce",
      "date": 1692688399835
    },
    {
      "type": "edit",
      "id": "cbb344b5accb57e2",
      "item": {
        "type": "paragraph",
        "id": "cbb344b5accb57e2",
        "text": "A thought vector is like a word vector, which is typically a vector of 300-500 numbers that represent a word. A word vector represents a word’s meaning as it relates to other words (its context) with a single column of numbers."
      },
      "date": 1692688401074
    },
    {
      "item": {
        "type": "factory",
        "id": "aeac04176ced4a9d"
      },
      "id": "aeac04176ced4a9d",
      "type": "add",
      "after": "cbb344b5accb57e2",
      "date": 1692688420804
    },
    {
      "type": "edit",
      "id": "aeac04176ced4a9d",
      "item": {
        "type": "paragraph",
        "id": "aeac04176ced4a9d",
        "text": "That is, the word is embedded in a vector space using a shallow neural network like word2vec, which learns to generate the word’s context through repeated guesses."
      },
      "date": 1692688421907
    },
    {
      "item": {
        "type": "factory",
        "id": "a5910963aa7ea390"
      },
      "id": "a5910963aa7ea390",
      "type": "add",
      "after": "aeac04176ced4a9d",
      "date": 1692688430026
    },
    {
      "type": "edit",
      "id": "a5910963aa7ea390",
      "item": {
        "type": "paragraph",
        "id": "a5910963aa7ea390",
        "text": "A thought vector, therefore, is a vectorized thought, and the vector represents one thought’s relations to others. A thought vector is trained to generate a thought’s context. Just as a words are linked by grammar (a sentence is just a path drawn across words), so thoughts are linked by a chain of reasoning, a logical path of sorts."
      },
      "date": 1692688431464
    },
    {
      "item": {
        "type": "factory",
        "id": "2d1a5dda3020addf"
      },
      "id": "2d1a5dda3020addf",
      "type": "add",
      "after": "a5910963aa7ea390",
      "date": 1692688446738
    },
    {
      "type": "edit",
      "id": "2d1a5dda3020addf",
      "item": {
        "type": "paragraph",
        "id": "2d1a5dda3020addf",
        "text": "So training an algorithm to represent any thought in its relation to others might be called the artificial construction of common sense. Given one thought, a neural network might predict the thoughts that are likely to follow, much like recurrent neural networks do with characters and words. Conversation as search."
      },
      "date": 1692688448694
    },
    {
      "type": "edit",
      "id": "2d1a5dda3020addf",
      "item": {
        "type": "paragraph",
        "id": "2d1a5dda3020addf",
        "text": "So training an algorithm to represent any thought in its relation to others might be called the artificial construction of common sense. Given one thought, a neural network might predict the thoughts that are likely to follow, much like recurrent neural networks do with characters and words. [[Conversation as Search]]."
      },
      "date": 1692688678079
    }
  ]
}