{
  "title": "Superposition",
  "story": [
    {
      "type": "reference",
      "id": "7eeeed5711649e9f",
      "site": "wiki.ralfbarkow.ch",
      "slug": "review-of-kanervas-sdm",
      "title": "Review of Kanerva’s SDM",
      "text": "Here, we present a short overview of SDM. A deeper review on the motivations behind SDM and the features that make it biologically plausible can be found in [13, 15]. SDM provides an algorithm for how memories (patterns) are stored in, and retrieved from, neurons in the brain. There are three primitives that all exist in the space of n dimensional binary vectors: …"
    },
    {
      "type": "reference",
      "id": "f2db2329ea82ceee",
      "site": "wiki.ralfbarkow.ch",
      "slug": "sdm-read-operation",
      "title": "SDM Read Operation",
      "text": "For the connection to [[Attention]] we focus on the SDM read operation and briefly summarize the write operation: all patterns write their pointers pp in a distributed fashion to all neuron addresses located within [[Hamming Distance]] d. This means that each neuron will store a [[Superposition]] of pattern pointers from those pattern addresses within d: x⌧v = P {p:d(paμ,x⌧a)d,8μ} pp. Having stored patterns in a distributed fashion across nearby neurons, SDM’s read operation retrieves stored pattern pointers from all neurons within distance d of the que"
    },
    {
      "type": "reference",
      "id": "dbd90cc1cd6c7864",
      "site": "wiki.ralfbarkow.ch",
      "slug": "superposition-of-authors",
      "title": "Superposition of Authors",
      "text": "REYNOLDS, Laria and MCDONELL, Kyle, 2021. Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm. In: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. New York, NY, USA: Association for Computing Machinery. 2021. p. 1–7. CHI EA ’21. ISBN 978-1-4503-8095-9. DOI 10.1145/3411763.3451760. "
    },
    {
      "type": "markdown",
      "id": "b139fa37238a28eb",
      "text": "> In this paper we will address two such ways: its resemblance not to a single human author but a superposition of authors, which motivates a subtractive approach to prompt programming (§4.5), and its constrained ability to predict dynamics in situations where a substantial amount of silent reasoning happens between tokens, a limitation which can be partially overcome by prompting techniques (§4.6)."
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Superposition",
        "story": []
      },
      "date": 1673945156728
    },
    {
      "item": {
        "type": "factory",
        "id": "7eeeed5711649e9f"
      },
      "id": "7eeeed5711649e9f",
      "type": "add",
      "date": 1673945160038
    },
    {
      "type": "edit",
      "id": "7eeeed5711649e9f",
      "item": {
        "type": "reference",
        "id": "7eeeed5711649e9f",
        "site": "wiki.ralfbarkow.ch",
        "slug": "review-of-kanervas-sdm",
        "title": "Review of Kanerva’s SDM",
        "text": "Here, we present a short overview of SDM. A deeper review on the motivations behind SDM and the features that make it biologically plausible can be found in [13, 15]. SDM provides an algorithm for how memories (patterns) are stored in, and retrieved from, neurons in the brain. There are three primitives that all exist in the space of n dimensional binary vectors:"
      },
      "date": 1673945161879
    },
    {
      "item": {
        "type": "factory",
        "id": "f2db2329ea82ceee"
      },
      "id": "f2db2329ea82ceee",
      "type": "add",
      "after": "7eeeed5711649e9f",
      "date": 1673945163763
    },
    {
      "type": "edit",
      "id": "f2db2329ea82ceee",
      "item": {
        "type": "reference",
        "id": "f2db2329ea82ceee",
        "site": "wiki.ralfbarkow.ch",
        "slug": "sdm-read-operation",
        "title": "SDM Read Operation",
        "text": "For the connection to [[Attention]] we focus on the SDM read operation and briefly summarize the write operation: all patterns write their pointers pp in a distributed fashion to all neuron addresses located within [[Hamming Distance]] d. This means that each neuron will store a [[Superposition]] of pattern pointers from those pattern addresses within d: x⌧v = P {p:d(paμ,x⌧a)d,8μ} pp. Having stored patterns in a distributed fashion across nearby neurons, SDM’s read operation retrieves stored pattern pointers from all neurons within distance d of the que"
      },
      "date": 1673945166243
    },
    {
      "type": "edit",
      "id": "7eeeed5711649e9f",
      "item": {
        "type": "reference",
        "id": "7eeeed5711649e9f",
        "site": "wiki.ralfbarkow.ch",
        "slug": "review-of-kanervas-sdm",
        "title": "Review of Kanerva’s SDM",
        "text": "Here, we present a short overview of SDM. A deeper review on the motivations behind SDM and the features that make it biologically plausible can be found in [13, 15]. SDM provides an algorithm for how memories (patterns) are stored in, and retrieved from, neurons in the brain. There are three primitives that all exist in the space of n dimensional binary vectors: …"
      },
      "date": 1673945191450
    },
    {
      "item": {
        "type": "factory",
        "id": "5108013bf5b27fcc"
      },
      "id": "5108013bf5b27fcc",
      "type": "add",
      "after": "f2db2329ea82ceee",
      "date": 1675059865353
    },
    {
      "type": "edit",
      "id": "5108013bf5b27fcc",
      "item": {
        "type": "paragraph",
        "id": "5108013bf5b27fcc",
        "text": "[[Superposition of Authors]]"
      },
      "date": 1675059867153
    },
    {
      "item": {
        "type": "factory",
        "id": "dbd90cc1cd6c7864"
      },
      "id": "dbd90cc1cd6c7864",
      "type": "add",
      "after": "5108013bf5b27fcc",
      "date": 1675059896734
    },
    {
      "type": "edit",
      "id": "dbd90cc1cd6c7864",
      "item": {
        "type": "reference",
        "id": "dbd90cc1cd6c7864",
        "site": "wiki.ralfbarkow.ch",
        "slug": "superposition-of-authors",
        "title": "Superposition of Authors",
        "text": "This motivates an Anthropomorphic Approach to [[Prompt Programming]], since modelling how [[GPT-3]] will react to a prompt involves modelling virtual human writer(s). An anthropomorphic approach is distinct from anthropomorphizing the model. GPT-3’s dynamics entail sophisticated predictions of humans, but it behaves unlike a human in several important ways."
      },
      "date": 1675059899004
    },
    {
      "id": "8c45bddd9e3ccabf",
      "type": "add",
      "item": {
        "type": "reference",
        "id": "8c45bddd9e3ccabf",
        "site": "wiki.ralfbarkow.ch",
        "slug": "prompt-programming",
        "title": "Prompt Programming",
        "text": "REYNOLDS, Laria and MCDONELL, Kyle, 2021. Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm. In: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. New York, NY, USA: Association for Computing Machinery. 2021. p. 1–7. CHI EA ’21. ISBN 978-1-4503-8095-9. DOI 10.1145/3411763.3451760. "
      },
      "after": "5108013bf5b27fcc",
      "date": 1675059918231
    },
    {
      "type": "remove",
      "id": "5108013bf5b27fcc",
      "date": 1675059920817
    },
    {
      "id": "b139fa37238a28eb",
      "type": "add",
      "item": {
        "type": "paragraph",
        "id": "b139fa37238a28eb",
        "text": "In this paper we will address two such ways: its resemblance not to a single human author but a [[Superposition]] of authors, which motivates a subtractive approach to prompt programming (§4.5), and its constrained ability to predict dynamics in situations where a substantial amount of silent reasoning happens between tokens, a limitation which can be partially overcome by prompting techniques (§4.6)."
      },
      "after": "8c45bddd9e3ccabf",
      "date": 1675059927151
    },
    {
      "type": "remove",
      "id": "8c45bddd9e3ccabf",
      "date": 1675059940368
    },
    {
      "type": "edit",
      "id": "dbd90cc1cd6c7864",
      "item": {
        "type": "reference",
        "id": "dbd90cc1cd6c7864",
        "site": "wiki.ralfbarkow.ch",
        "slug": "superposition-of-authors",
        "title": "Superposition of Authors",
        "text": "REYNOLDS, Laria and MCDONELL, Kyle, 2021. Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm. In: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. New York, NY, USA: Association for Computing Machinery. 2021. p. 1–7. CHI EA ’21. ISBN 978-1-4503-8095-9. DOI 10.1145/3411763.3451760. "
      },
      "date": 1675059942746
    },
    {
      "id": "dbd90cc1cd6c7864",
      "type": "move",
      "order": [
        "7eeeed5711649e9f",
        "f2db2329ea82ceee",
        "dbd90cc1cd6c7864",
        "b139fa37238a28eb"
      ],
      "date": 1675059944295
    },
    {
      "type": "edit",
      "id": "b139fa37238a28eb",
      "item": {
        "type": "paragraph",
        "id": "b139fa37238a28eb",
        "text": "> In this paper we will address two such ways: its resemblance not to a single human author but a superposition of authors, which motivates a subtractive approach to prompt programming (§4.5), and its constrained ability to predict dynamics in situations where a substantial amount of silent reasoning happens between tokens, a limitation which can be partially overcome by prompting techniques (§4.6)."
      },
      "date": 1675059959109
    },
    {
      "type": "edit",
      "id": "b139fa37238a28eb",
      "item": {
        "type": "markdown",
        "id": "b139fa37238a28eb",
        "text": "> In this paper we will address two such ways: its resemblance not to a single human author but a superposition of authors, which motivates a subtractive approach to prompt programming (§4.5), and its constrained ability to predict dynamics in situations where a substantial amount of silent reasoning happens between tokens, a limitation which can be partially overcome by prompting techniques (§4.6)."
      },
      "date": 1675059960518
    }
  ]
}