{
  "title": "Instruction",
  "story": [
    {
      "type": "reference",
      "id": "a693a40706ffdf3f",
      "site": "wiki.ralfbarkow.ch",
      "slug": "task-location",
      "title": "Task Location",
      "text": "Contrary to the interpretation of implied by the title of the original GPT-3 paper by Brown et al. [3], Language models are few-shot learners, we argue that GPT-3 is often not actually learning the task during run time from few-shot examples."
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Instruction",
        "story": []
      },
      "date": 1675074649312
    },
    {
      "item": {
        "type": "factory",
        "id": "a693a40706ffdf3f"
      },
      "id": "a693a40706ffdf3f",
      "type": "add",
      "date": 1675074651874
    },
    {
      "type": "edit",
      "id": "a693a40706ffdf3f",
      "item": {
        "type": "reference",
        "id": "a693a40706ffdf3f",
        "site": "wiki.ralfbarkow.ch",
        "slug": "task-location",
        "title": "Task Location",
        "text": "Contrary to the interpretation of implied by the title of the original GPT-3 paper by Brown et al. [3], Language models are few-shot learners, we argue that GPT-3 is often not actually learning the task during run time from few-shot examples."
      },
      "date": 1675074660436
    }
  ]
}