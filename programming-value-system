{
  "title": "Programming Value System",
  "story": [
    {
      "type": "html",
      "text": "From a comment by [[Ralph Johnson]] on the [[Extreme Programming]] page:",
      "id": "2aed6009f6af72572b242ba368b7a3f3"
    },
    {
      "type": "html",
      "text": "<i>... with the right value system, making good short term decisions leads to good long term results. The problem is getting the right value system.</i>",
      "id": "4e8e8621582ce7d1aac622de87bb3456"
    },
    {
      "type": "html",
      "text": "<i>This is true outside the realm of programming, too. I think that is the purpose of a value system. We need to figure out the way to live so that when we are the middle of life we \"do the right thing\". When our neighbor comes over to argue with us, we are not going to start thinking about how this will effect our life ten years from now, but we react according to the way we were taught, and the way we taught ourselves. The time for reflection is when things are quiet, and that is when we should decide to be peaceful or to stand up for our rights.</i>",
      "id": "c08d9af4fc0295f02f11e44eed98a27c"
    },
    {
      "type": "html",
      "text": "<hr>",
      "id": "adf24ed754b585e1c1ddbdbce137ae0e"
    },
    {
      "type": "html",
      "text": "\nThe problem with the notion of value system is that it is recursive. What value system do you use to know if a value system is good? -- oogoody",
      "id": "273d39242c49739e95115a72546b706d"
    },
    {
      "type": "html",
      "text": "<i>Your feelings, more or less.</i>",
      "id": "6a41b60147b8df8e9f2c72ac0b9c3c96"
    },
    {
      "type": "html",
      "text": "\nVery true, which is the problem. As long as people realized this and acted accordingly more would be well. Instead people actually think their beliefs have a meaningful existence that must be defended. -- oogoody",
      "id": "4b4d3f0b4637a3f84c4e3b1613bba3c4"
    },
    {
      "type": "html",
      "text": "<i>What people? What beliefs?</i>",
      "id": "c25aece92cf9555fe88923fdc4eab2e9"
    },
    {
      "type": "html",
      "text": "<hr>",
      "id": "adf24ed754b585e1c1ddbdbce137ae0e"
    },
    {
      "type": "html",
      "text": "\nI think this reasoning is exactly backwards. It's like saying all the decisions made by a soldier in the trenches will win the war. It don't work that way. -- oogoody",
      "id": "46dcca8c75dc86b5c4e691a71b01aa29"
    },
    {
      "type": "html",
      "text": "<i>How do you get that from [[Ralph Johnson]]'s bit? It's more saying that a soldier acts according to his training. If his training is good he will help win the war. -- [[Tom Ayerst]]</i>",
      "id": "dd77a25c34addc807459f53834cb1d33"
    },
    {
      "type": "html",
      "text": "\nHe essentially said maximizing locally (short term decisions) maximizes globally (long term results) and that the same values that work locally work globally. The individual training of a soldier does not win the war. You fuzzed by saying help win the war, which is unarguably true, but is not the correct sense. -- oogoody",
      "id": "9de30b5e2c08e1d7d2c9d9623986c9be"
    },
    {
      "type": "html",
      "text": "<i>I'm sorry but that </i>really<i> isn't how I read it. Consider the growth of the brain.</i> -- [[Tom Ayerst]]",
      "id": "b6b511ad727fe667faca4f736d1b0819"
    },
    {
      "type": "html",
      "text": "\nWhat needs to be defined is the scope of what 'short term' means. What is good short-term for the soldier, is not necessarily the same for his unit. The needs/desires of the individual do not always coincide with the needs/desires of the whole. The question is, where do we place the emphasis, the whole or the individual?",
      "id": "f335bfc3d2683837ce5fc58de9c6960d"
    },
    {
      "type": "html",
      "text": "<hr>",
      "id": "adf24ed754b585e1c1ddbdbce137ae0e"
    },
    {
      "type": "html",
      "text": "\nWhat he actually said is that <i>with the right value system</i> local maximization does a good global job. This isn't the same as saying that local maximization of your actual long-term objectives will work; it's saying that our global problems <i>can</i> be solved locally if we decide our local priorities carefully enough. He specifically did <i>not</i> say that \"the same values that work locally work globally\". (He could be paraphrased as saying \"there are local values that work globally\", I suppose.) -- [[Gareth Mc Caughan]]",
      "id": "4e255679f0f4247db12fcc253e0e2810"
    },
    {
      "type": "html",
      "text": "<hr>",
      "id": "adf24ed754b585e1c1ddbdbce137ae0e"
    },
    {
      "type": "html",
      "text": "\nLet's look at this logically. A decision made based on short term evaluations has an unknown affect on the long term. Similarly a decision based on long term evaluations has an unknown affect on the short term. Decisions should be based on both short term and long term evaluations. To ignore one or the other is to invite disaster. -- [[Wayne Mack]]",
      "id": "0f0b36bb822d9df4511ee41c3a75bfdc"
    },
    {
      "type": "html",
      "text": "<i>Consider an [[Ant Colony]]. Each ant makes a series of simple, short term, local decision and yet the colony exists over a large area for a long time... -- [[Tom Ayerst]]</i>",
      "id": "92e091e67d047fe7dea580655a42e538"
    },
    {
      "type": "html",
      "text": "\nIt's a study in feedback. Short term optimization is easy to understand because feedback on short cycles is still working on initial states (approximately). In other words, it's easier to remember how the action produced the effect. Long term feedback is more difficult because by the time you are in the effects, you've likely forgotten the actions (causes). It takes a more mature memory system to make long term feedback work. In an intellectual society, this means you have to write things down and revisit the subject periodically without external stimulus. If you do that, then you may learn interesting techniques, like \"losing the battle to win the war\". Ants don't have intellect, yet they make the short term individual sacrifices that further the colony. Why do they do that? For lack of a better explanation, <i>because it feels right,</i> even though to an observer it may look as though it should feel wrong. That, I believe, is the value system Ralph is talking about, although he was definitely discussing humans. Something - and it doesn't have to be through logical, intellectual construction - makes doing the \"wrong\" short term thing (which happens to be the \"right\" long term thing) <i>feel</i> right at the time of the doing.  It would make an interesting study to find out how such value systems evolve in non-intellectual life, such as ants. I envision staggered or cascading feedback loops that over time become a reward system of sorts. -- [[Walden Mathews]]",
      "id": "2a357fd9d89adf435fe23c8e9cced1f2"
    },
    {
      "type": "html",
      "text": "<i>Going back to an earlier comment:</i>",
      "id": "b43366092062f76f69be7b30a890eda0"
    },
    {
      "type": "html",
      "text": "A decision made based on short term evaluations has an unknown affect on the long term. Similarly a decision based on long term evaluations has an unknown affect on the short term. Decisions should be based on both short term and long term evaluations.",
      "id": "45f5fe6680d88aa4e391a8e1b11c934f"
    },
    {
      "type": "html",
      "text": "<i>This is true but incomplete. A decision based on </i>long<i> term evaluations has an unknown effect on the </i>long<i> term. A decision based on any evaluation will have an unknown effect on all reference frames. The best we can hope for is some fast feedback to steer by.</i>",
      "id": "420d49a85e3f88af1e6cdc08b8111a9f"
    },
    {
      "type": "html",
      "text": "<i>A huge amount can be done with localized control. The trick is building the structure (value system) right to let it work. -- [[Tom Ayerst]]</i>",
      "id": "b3350061d2d40c907a1d703781d0c1f9"
    },
    {
      "type": "html",
      "text": "\nExactly. I think [[Wayne Mack]] may be missing the point that choosing what local optimizations to do is itself an exercise in global optimization. No one is proposing to \"ignore long-term evaluations\". -- [[Gareth Mc Caughan]]",
      "id": "2eb3222ccb7718fc0458062fe74c6663"
    },
    {
      "type": "html",
      "text": "<hr>",
      "id": "adf24ed754b585e1c1ddbdbce137ae0e"
    },
    {
      "type": "html",
      "text": "(I'm aware that much of the following is a restatement of what Tom wrote above. But sometimes I think it's helpful to explain things from two different directions... -- glv)",
      "id": "b796eef2975186172ddae983f3f7c903"
    },
    {
      "type": "html",
      "text": "<i>Let's look at this logically. A decision made based on short term evaluations has an unknown affect on the long term. Similarly a decision based on long term evaluations has an unknown affect on the short term. Decisions should be based on both short term and long term evaluations. To ignore one or the other is to invite disaster. -- [[Wayne Mack]]</i>",
      "id": "23052d19405a35fb123f26ae149248a3"
    },
    {
      "type": "html",
      "text": "\nThis is true, and (as Gareth notes) we aren't proposing to ignore either.",
      "id": "f9e6395cde78d0399b60c884b62d28d7"
    },
    {
      "type": "html",
      "text": "\nThe difficulty is that it's impossible in a practical sense to make a thorough, reliable evaluation of the long-term consequences of any non-trivial decision. Furthermore, it's impossible to even come close in the short span of time we frequently have to make a decision.",
      "id": "fea96843f9eb3fe1d22cc653f445cf6f"
    },
    {
      "type": "html",
      "text": "\nSo what to do?  The answer is that over time, by observing and experiencing the results of decisions, you can build a \"value system\" (that is, a set of rules for making quick decisions based on local or short-term input) that will, more often than not, result in good long-term results. This is one form of [[Emergent Behavior]].",
      "id": "6c38c46bb7c9f1ed30825b16c309e66a"
    },
    {
      "type": "html",
      "text": "\"Value system\" is an unfortunately loaded term in this context. Ralph's quote seems to me to be focusing on the purely practical aspects of value systems: they are distillations of long experience about the way the world works and the results of different kinds of actions. This is independent of any inherent moral correctness that a value system may or may not have. As a Christian, I believe that my value system is rooted in objective reality about what is right and wrong. But that doesn't stop me from observing that (for example) being honest about things isn't just right, but also nearly always produces better practical results. -- [[Glenn Vanderburg]]",
      "id": "816c57db0d67761c0fe3506036cb8724"
    },
    {
      "type": "html",
      "text": "\nIt gives me a funny feeling to see people debate about the meaning of my words. Are my words really that important? It is also odd that nobody asked me what I meant. I think Glenn figured it out pretty well. -- [[Ralph Johnson]]",
      "id": "57d74f0ba626050f1d2857ea162b7714"
    },
    {
      "type": "html",
      "text": "\nFor Ralph: What important thing did he miss?",
      "id": "897ff4489cd11c091fcf448f443e4dca"
    },
    {
      "type": "html",
      "text": "<hr>",
      "id": "adf24ed754b585e1c1ddbdbce137ae0e"
    },
    {
      "type": "html",
      "text": "\nSee [http://www.fastcompany.com/online/38/klein.html www.fastcompany.com].",
      "id": "d2cb53acc8351597f7cbd030a65ac410"
    },
    {
      "type": "html",
      "text": "<i>A fascinating article. I hypothesise that small organizations can do this, but large ones can't. Also the more people you have, the more likely it is that one expert's intuition will conflict with another's. Note it says, \"They don't need the best solution. They just need the one that works.\" -- [[Matthew Astley]]</i>",
      "id": "51550be3c4c305e7a158665e22204057"
    },
    {
      "type": "html",
      "text": "<hr>",
      "id": "adf24ed754b585e1c1ddbdbce137ae0e"
    },
    {
      "type": "html",
      "text": "\nSee [[Emergent Behavior]]",
      "id": "e13368172b314dbf0668dfe5f510c9de"
    },
    {
      "type": "html",
      "text": "See original on  [http://c2.com/cgi/wiki?ProgrammingValueSystem c2.com]",
      "id": "076b17389e3a63e62a9291b2995cb81e"
    }
  ],
  "journal": [
    {
      "date": 1153221414000,
      "id": "cb9674d8e15127f8bb6b9a08a4c7b1d7",
      "type": "create",
      "item": {
        "title": "Programming Value System",
        "story": [
          {
            "type": "html",
            "text": "From a comment by [[Ralph Johnson]] on the [[Extreme Programming]] page:",
            "id": "2aed6009f6af72572b242ba368b7a3f3"
          },
          {
            "type": "html",
            "text": "<i>... with the right value system, making good short term decisions leads to good long term results. The problem is getting the right value system.</i>",
            "id": "4e8e8621582ce7d1aac622de87bb3456"
          },
          {
            "type": "html",
            "text": "<i>This is true outside the realm of programming, too. I think that is the purpose of a value system. We need to figure out the way to live so that when we are the middle of life we \"do the right thing\". When our neighbor comes over to argue with us, we are not going to start thinking about how this will effect our life ten years from now, but we react according to the way we were taught, and the way we taught ourselves. The time for reflection is when things are quiet, and that is when we should decide to be peaceful or to stand up for our rights.</i>",
            "id": "c08d9af4fc0295f02f11e44eed98a27c"
          },
          {
            "type": "html",
            "text": "<hr>",
            "id": "adf24ed754b585e1c1ddbdbce137ae0e"
          },
          {
            "type": "html",
            "text": "\nThe problem with the notion of value system is that it is recursive. What value system do you use to know if a value system is good? -- oogoody",
            "id": "273d39242c49739e95115a72546b706d"
          },
          {
            "type": "html",
            "text": "<i>Your feelings, more or less.</i>",
            "id": "6a41b60147b8df8e9f2c72ac0b9c3c96"
          },
          {
            "type": "html",
            "text": "\nVery true, which is the problem. As long as people realized this and acted accordingly more would be well. Instead people actually think their beliefs have a meaningful existence that must be defended. -- oogoody",
            "id": "4b4d3f0b4637a3f84c4e3b1613bba3c4"
          },
          {
            "type": "html",
            "text": "<i>What people? What beliefs?</i>",
            "id": "c25aece92cf9555fe88923fdc4eab2e9"
          },
          {
            "type": "html",
            "text": "<hr>",
            "id": "adf24ed754b585e1c1ddbdbce137ae0e"
          },
          {
            "type": "html",
            "text": "\nI think this reasoning is exactly backwards. It's like saying all the decisions made by a soldier in the trenches will win the war. It don't work that way. -- oogoody",
            "id": "46dcca8c75dc86b5c4e691a71b01aa29"
          },
          {
            "type": "html",
            "text": "<i>How do you get that from [[Ralph Johnson]]'s bit? It's more saying that a soldier acts according to his training. If his training is good he will help win the war. -- [[Tom Ayerst]]</i>",
            "id": "dd77a25c34addc807459f53834cb1d33"
          },
          {
            "type": "html",
            "text": "\nHe essentially said maximizing locally (short term decisions) maximizes globally (long term results) and that the same values that work locally work globally. The individual training of a soldier does not win the war. You fuzzed by saying help win the war, which is unarguably true, but is not the correct sense. -- oogoody",
            "id": "9de30b5e2c08e1d7d2c9d9623986c9be"
          },
          {
            "type": "html",
            "text": "<i>I'm sorry but that </i>really<i> isn't how I read it. Consider the growth of the brain.</i> -- [[Tom Ayerst]]",
            "id": "b6b511ad727fe667faca4f736d1b0819"
          },
          {
            "type": "html",
            "text": "\nWhat needs to be defined is the scope of what 'short term' means. What is good short-term for the soldier, is not necessarily the same for his unit. The needs/desires of the individual do not always coincide with the needs/desires of the whole. The question is, where do we place the emphasis, the whole or the individual?",
            "id": "f335bfc3d2683837ce5fc58de9c6960d"
          },
          {
            "type": "html",
            "text": "<hr>",
            "id": "adf24ed754b585e1c1ddbdbce137ae0e"
          },
          {
            "type": "html",
            "text": "\nWhat he actually said is that <i>with the right value system</i> local maximization does a good global job. This isn't the same as saying that local maximization of your actual long-term objectives will work; it's saying that our global problems <i>can</i> be solved locally if we decide our local priorities carefully enough. He specifically did <i>not</i> say that \"the same values that work locally work globally\". (He could be paraphrased as saying \"there are local values that work globally\", I suppose.) -- [[Gareth Mc Caughan]]",
            "id": "4e255679f0f4247db12fcc253e0e2810"
          },
          {
            "type": "html",
            "text": "<hr>",
            "id": "adf24ed754b585e1c1ddbdbce137ae0e"
          },
          {
            "type": "html",
            "text": "\nLet's look at this logically. A decision made based on short term evaluations has an unknown affect on the long term. Similarly a decision based on long term evaluations has an unknown affect on the short term. Decisions should be based on both short term and long term evaluations. To ignore one or the other is to invite disaster. -- [[Wayne Mack]]",
            "id": "0f0b36bb822d9df4511ee41c3a75bfdc"
          },
          {
            "type": "html",
            "text": "<i>Consider an [[Ant Colony]]. Each ant makes a series of simple, short term, local decision and yet the colony exists over a large area for a long time... -- [[Tom Ayerst]]</i>",
            "id": "92e091e67d047fe7dea580655a42e538"
          },
          {
            "type": "html",
            "text": "\nIt's a study in feedback. Short term optimization is easy to understand because feedback on short cycles is still working on initial states (approximately). In other words, it's easier to remember how the action produced the effect. Long term feedback is more difficult because by the time you are in the effects, you've likely forgotten the actions (causes). It takes a more mature memory system to make long term feedback work. In an intellectual society, this means you have to write things down and revisit the subject periodically without external stimulus. If you do that, then you may learn interesting techniques, like \"losing the battle to win the war\". Ants don't have intellect, yet they make the short term individual sacrifices that further the colony. Why do they do that? For lack of a better explanation, <i>because it feels right,</i> even though to an observer it may look as though it should feel wrong. That, I believe, is the value system Ralph is talking about, although he was definitely discussing humans. Something - and it doesn't have to be through logical, intellectual construction - makes doing the \"wrong\" short term thing (which happens to be the \"right\" long term thing) <i>feel</i> right at the time of the doing.  It would make an interesting study to find out how such value systems evolve in non-intellectual life, such as ants. I envision staggered or cascading feedback loops that over time become a reward system of sorts. -- [[Walden Mathews]]",
            "id": "2a357fd9d89adf435fe23c8e9cced1f2"
          },
          {
            "type": "html",
            "text": "<i>Going back to an earlier comment:</i>",
            "id": "b43366092062f76f69be7b30a890eda0"
          },
          {
            "type": "html",
            "text": "A decision made based on short term evaluations has an unknown affect on the long term. Similarly a decision based on long term evaluations has an unknown affect on the short term. Decisions should be based on both short term and long term evaluations.",
            "id": "45f5fe6680d88aa4e391a8e1b11c934f"
          },
          {
            "type": "html",
            "text": "<i>This is true but incomplete. A decision based on </i>long<i> term evaluations has an unknown effect on the </i>long<i> term. A decision based on any evaluation will have an unknown effect on all reference frames. The best we can hope for is some fast feedback to steer by.</i>",
            "id": "420d49a85e3f88af1e6cdc08b8111a9f"
          },
          {
            "type": "html",
            "text": "<i>A huge amount can be done with localized control. The trick is building the structure (value system) right to let it work. -- [[Tom Ayerst]]</i>",
            "id": "b3350061d2d40c907a1d703781d0c1f9"
          },
          {
            "type": "html",
            "text": "\nExactly. I think [[Wayne Mack]] may be missing the point that choosing what local optimizations to do is itself an exercise in global optimization. No one is proposing to \"ignore long-term evaluations\". -- [[Gareth Mc Caughan]]",
            "id": "2eb3222ccb7718fc0458062fe74c6663"
          },
          {
            "type": "html",
            "text": "<hr>",
            "id": "adf24ed754b585e1c1ddbdbce137ae0e"
          },
          {
            "type": "html",
            "text": "(I'm aware that much of the following is a restatement of what Tom wrote above. But sometimes I think it's helpful to explain things from two different directions... -- glv)",
            "id": "b796eef2975186172ddae983f3f7c903"
          },
          {
            "type": "html",
            "text": "<i>Let's look at this logically. A decision made based on short term evaluations has an unknown affect on the long term. Similarly a decision based on long term evaluations has an unknown affect on the short term. Decisions should be based on both short term and long term evaluations. To ignore one or the other is to invite disaster. -- [[Wayne Mack]]</i>",
            "id": "23052d19405a35fb123f26ae149248a3"
          },
          {
            "type": "html",
            "text": "\nThis is true, and (as Gareth notes) we aren't proposing to ignore either.",
            "id": "f9e6395cde78d0399b60c884b62d28d7"
          },
          {
            "type": "html",
            "text": "\nThe difficulty is that it's impossible in a practical sense to make a thorough, reliable evaluation of the long-term consequences of any non-trivial decision. Furthermore, it's impossible to even come close in the short span of time we frequently have to make a decision.",
            "id": "fea96843f9eb3fe1d22cc653f445cf6f"
          },
          {
            "type": "html",
            "text": "\nSo what to do?  The answer is that over time, by observing and experiencing the results of decisions, you can build a \"value system\" (that is, a set of rules for making quick decisions based on local or short-term input) that will, more often than not, result in good long-term results. This is one form of [[Emergent Behavior]].",
            "id": "6c38c46bb7c9f1ed30825b16c309e66a"
          },
          {
            "type": "html",
            "text": "\"Value system\" is an unfortunately loaded term in this context. Ralph's quote seems to me to be focusing on the purely practical aspects of value systems: they are distillations of long experience about the way the world works and the results of different kinds of actions. This is independent of any inherent moral correctness that a value system may or may not have. As a Christian, I believe that my value system is rooted in objective reality about what is right and wrong. But that doesn't stop me from observing that (for example) being honest about things isn't just right, but also nearly always produces better practical results. -- [[Glenn Vanderburg]]",
            "id": "816c57db0d67761c0fe3506036cb8724"
          },
          {
            "type": "html",
            "text": "\nIt gives me a funny feeling to see people debate about the meaning of my words. Are my words really that important? It is also odd that nobody asked me what I meant. I think Glenn figured it out pretty well. -- [[Ralph Johnson]]",
            "id": "57d74f0ba626050f1d2857ea162b7714"
          },
          {
            "type": "html",
            "text": "\nFor Ralph: What important thing did he miss?",
            "id": "897ff4489cd11c091fcf448f443e4dca"
          },
          {
            "type": "html",
            "text": "<hr>",
            "id": "adf24ed754b585e1c1ddbdbce137ae0e"
          },
          {
            "type": "html",
            "text": "\nSee [http://www.fastcompany.com/online/38/klein.html www.fastcompany.com].",
            "id": "d2cb53acc8351597f7cbd030a65ac410"
          },
          {
            "type": "html",
            "text": "<i>A fascinating article. I hypothesise that small organizations can do this, but large ones can't. Also the more people you have, the more likely it is that one expert's intuition will conflict with another's. Note it says, \"They don't need the best solution. They just need the one that works.\" -- [[Matthew Astley]]</i>",
            "id": "51550be3c4c305e7a158665e22204057"
          },
          {
            "type": "html",
            "text": "<hr>",
            "id": "adf24ed754b585e1c1ddbdbce137ae0e"
          },
          {
            "type": "html",
            "text": "\nSee [[Emergent Behavior]]",
            "id": "e13368172b314dbf0668dfe5f510c9de"
          },
          {
            "type": "html",
            "text": "See original on  [http://c2.com/cgi/wiki?ProgrammingValueSystem c2.com]",
            "id": "076b17389e3a63e62a9291b2995cb81e"
          }
        ]
      }
    },
    {
      "type": "fork",
      "site": "sfw.c2.com",
      "date": 1660315377115
    }
  ]
}