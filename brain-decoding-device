{
  "title": "Brain Decoding Device",
  "story": [
    {
      "type": "paragraph",
      "id": "54e535e90a632344",
      "text": "Quantitative modeling of human brain activity can provide crucial insights about cortical representations [1, 2] and can form the basis for brain decoding devices [3, 4, 5]. "
    },
    {
      "type": "paragraph",
      "id": "4efc32d4d04d1b83",
      "text": "Recent functional magnetic resonance imaging (fMRI) studies have modeled brain activity elicited by static visual patterns and have reconstructed these patterns from brain activity [6, 7, 8]. "
    },
    {
      "type": "paragraph",
      "id": "bcb4e5d03b928af8",
      "text": "However, blood oxygen level-dependent (BOLD) signals measured via fMRI are very slow [9], so it has been difficult to model brain activity elicited by dynamic stimuli such as natural movies. "
    },
    {
      "type": "paragraph",
      "id": "3adb5367ed191f5f",
      "text": "Here we present a new motion-energy [10, 11] encoding model that largely overcomes this limitation. The model describes fast visual information and slow hemodynamics by separate components. We recorded BOLD signals in occipitotemporal visual cortex of human subjects who watched natural movies and fit the model separately to individual voxels. Visualization of the fit models reveals how early visual areas represent the information in movies. "
    },
    {
      "type": "paragraph",
      "id": "d407331106ace784",
      "text": "To demonstrate the power of our approach, we also constructed a Bayesian decoder [8] by combining estimated encoding models with a sampled natural movie prior. The decoder provides remarkable reconstructions of the viewed movies. These results demonstrate that dynamic brain activity measured under naturalistic conditions can be decoded using current fMRI technology.\n"
    },
    {
      "type": "pagefold",
      "id": "4b9d29af182450c8",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "4111ff53036144e8",
      "text": "NISHIMOTO, Shinji, VU, An T., NASELARIS, Thomas, BENJAMINI, Yuval, YU, Bin and GALLANT, Jack L., 2011. Reconstructing Visual Experiences from Brain Activity Evoked by Natural Movies. Current Biology. Online. 11 October 2011. Vol. 21, no. 19, p. 1641–1646. [Accessed 22 March 2023]. DOI 10.1016/j.cub.2011.08.031. "
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Brain Decoding Device",
        "story": []
      },
      "date": 1679498499311
    },
    {
      "id": "4111ff53036144e8",
      "type": "add",
      "item": {
        "type": "paragraph",
        "id": "4111ff53036144e8",
        "text": "NISHIMOTO, Shinji, VU, An T., NASELARIS, Thomas, BENJAMINI, Yuval, YU, Bin and GALLANT, Jack L., 2011. Reconstructing Visual Experiences from Brain Activity Evoked by Natural Movies. Current Biology. Online. 11 October 2011. Vol. 21, no. 19, p. 1641–1646. [Accessed 22 March 2023]. DOI 10.1016/j.cub.2011.08.031. "
      },
      "attribution": {
        "page": "2023-03-22"
      },
      "date": 1679498502799
    },
    {
      "type": "fork",
      "date": 1679498551992
    },
    {
      "type": "add",
      "id": "54e535e90a632344",
      "item": {
        "type": "paragraph",
        "id": "54e535e90a632344",
        "text": "Quantitative modeling of human brain activity can provide crucial insights about cortical representations [1, 2] and can form the basis for brain decoding devices [3, 4, 5]. Recent functional magnetic resonance imaging (fMRI) studies have modeled brain activity elicited by static visual patterns and have reconstructed these patterns from brain activity [6, 7, 8]. However, blood oxygen level-dependent (BOLD) signals measured via fMRI are very slow [9], so it has been difficult to model brain activity elicited by dynamic stimuli such as natural movies. Here we present a new motion-energy [10, 11] encoding model that largely overcomes this limitation. The model describes fast visual information and slow hemodynamics by separate components. We recorded BOLD signals in occipitotemporal visual cortex of human subjects who watched natural movies and fit the model separately to individual voxels. Visualization of the fit models reveals how early visual areas represent the information in movies. To demonstrate the power of our approach, we also constructed a Bayesian decoder [8] by combining estimated encoding models with a sampled natural movie prior. The decoder provides remarkable reconstructions of the viewed movies. These results demonstrate that dynamic brain activity measured under naturalistic conditions can be decoded using current fMRI technology.\n"
      },
      "after": "4111ff53036144e8",
      "date": 1679498559976,
      "error": {
        "type": "error",
        "msg": ""
      }
    },
    {
      "type": "edit",
      "id": "4111ff53036144e8",
      "item": {
        "type": "paragraph",
        "id": "4111ff53036144e8",
        "text": "NISHIMOTO, Shinji, VU, An T., NASELARIS, Thomas, BENJAMINI, Yuval, YU, Bin and GALLANT, Jack L., 2011. Reconstructing Visual Experiences from Brain Activity Evoked by Natural Movies. Current Biology. Online. 11 October 2011. Vol. 21, no. 19, p. 1641–1646. [Accessed 22 March 2023]. DOI 10.1016/j.cub.2011.08.031. "
      },
      "date": 1679498558786,
      "error": {
        "type": "error",
        "msg": ""
      }
    },
    {
      "type": "fork",
      "date": 1679498565930
    },
    {
      "id": "54e535e90a632344",
      "type": "move",
      "order": [
        "54e535e90a632344",
        "4111ff53036144e8"
      ],
      "date": 1679498569349
    },
    {
      "item": {
        "type": "factory",
        "id": "4b9d29af182450c8"
      },
      "id": "4b9d29af182450c8",
      "type": "add",
      "after": "4111ff53036144e8",
      "date": 1679498572145
    },
    {
      "type": "edit",
      "id": "4b9d29af182450c8",
      "item": {
        "type": "pagefold",
        "id": "4b9d29af182450c8",
        "text": "~"
      },
      "date": 1679498576306
    },
    {
      "id": "4b9d29af182450c8",
      "type": "move",
      "order": [
        "54e535e90a632344",
        "4b9d29af182450c8",
        "4111ff53036144e8"
      ],
      "date": 1679498578385
    },
    {
      "type": "edit",
      "id": "54e535e90a632344",
      "item": {
        "type": "paragraph",
        "id": "54e535e90a632344",
        "text": "Quantitative modeling of human brain activity can provide crucial insights about cortical representations [1, 2] and can form the basis for brain decoding devices [3, 4, 5]. "
      },
      "date": 1679498609271
    },
    {
      "type": "add",
      "id": "4efc32d4d04d1b83",
      "item": {
        "type": "paragraph",
        "id": "4efc32d4d04d1b83",
        "text": "Recent functional magnetic resonance imaging (fMRI) studies have modeled brain activity elicited by static visual patterns and have reconstructed these patterns from brain activity [6, 7, 8]. However, blood oxygen level-dependent (BOLD) signals measured via fMRI are very slow [9], so it has been difficult to model brain activity elicited by dynamic stimuli such as natural movies. Here we present a new motion-energy [10, 11] encoding model that largely overcomes this limitation. The model describes fast visual information and slow hemodynamics by separate components. We recorded BOLD signals in occipitotemporal visual cortex of human subjects who watched natural movies and fit the model separately to individual voxels. Visualization of the fit models reveals how early visual areas represent the information in movies. To demonstrate the power of our approach, we also constructed a Bayesian decoder [8] by combining estimated encoding models with a sampled natural movie prior. The decoder provides remarkable reconstructions of the viewed movies. These results demonstrate that dynamic brain activity measured under naturalistic conditions can be decoded using current fMRI technology.\n"
      },
      "after": "54e535e90a632344",
      "date": 1679498610126
    },
    {
      "type": "edit",
      "id": "4efc32d4d04d1b83",
      "item": {
        "type": "paragraph",
        "id": "4efc32d4d04d1b83",
        "text": "Recent functional magnetic resonance imaging (fMRI) studies have modeled brain activity elicited by static visual patterns and have reconstructed these patterns from brain activity [6, 7, 8]. "
      },
      "date": 1679498624799
    },
    {
      "type": "add",
      "id": "bcb4e5d03b928af8",
      "item": {
        "type": "paragraph",
        "id": "bcb4e5d03b928af8",
        "text": "However, blood oxygen level-dependent (BOLD) signals measured via fMRI are very slow [9], so it has been difficult to model brain activity elicited by dynamic stimuli such as natural movies. Here we present a new motion-energy [10, 11] encoding model that largely overcomes this limitation. The model describes fast visual information and slow hemodynamics by separate components. We recorded BOLD signals in occipitotemporal visual cortex of human subjects who watched natural movies and fit the model separately to individual voxels. Visualization of the fit models reveals how early visual areas represent the information in movies. To demonstrate the power of our approach, we also constructed a Bayesian decoder [8] by combining estimated encoding models with a sampled natural movie prior. The decoder provides remarkable reconstructions of the viewed movies. These results demonstrate that dynamic brain activity measured under naturalistic conditions can be decoded using current fMRI technology.\n"
      },
      "after": "4efc32d4d04d1b83",
      "date": 1679498625615
    },
    {
      "type": "edit",
      "id": "bcb4e5d03b928af8",
      "item": {
        "type": "paragraph",
        "id": "bcb4e5d03b928af8",
        "text": "However, blood oxygen level-dependent (BOLD) signals measured via fMRI are very slow [9], so it has been difficult to model brain activity elicited by dynamic stimuli such as natural movies. "
      },
      "date": 1679498636783
    },
    {
      "type": "add",
      "id": "3adb5367ed191f5f",
      "item": {
        "type": "paragraph",
        "id": "3adb5367ed191f5f",
        "text": "Here we present a new motion-energy [10, 11] encoding model that largely overcomes this limitation. The model describes fast visual information and slow hemodynamics by separate components. We recorded BOLD signals in occipitotemporal visual cortex of human subjects who watched natural movies and fit the model separately to individual voxels. Visualization of the fit models reveals how early visual areas represent the information in movies. To demonstrate the power of our approach, we also constructed a Bayesian decoder [8] by combining estimated encoding models with a sampled natural movie prior. The decoder provides remarkable reconstructions of the viewed movies. These results demonstrate that dynamic brain activity measured under naturalistic conditions can be decoded using current fMRI technology.\n"
      },
      "after": "bcb4e5d03b928af8",
      "date": 1679498637788
    },
    {
      "type": "edit",
      "id": "3adb5367ed191f5f",
      "item": {
        "type": "paragraph",
        "id": "3adb5367ed191f5f",
        "text": "Here we present a new motion-energy [10, 11] encoding model that largely overcomes this limitation. The model describes fast visual information and slow hemodynamics by separate components. We recorded BOLD signals in occipitotemporal visual cortex of human subjects who watched natural movies and fit the model separately to individual voxels. Visualization of the fit models reveals how early visual areas represent the information in movies. "
      },
      "date": 1679498661806
    },
    {
      "type": "add",
      "id": "d407331106ace784",
      "item": {
        "type": "paragraph",
        "id": "d407331106ace784",
        "text": "To demonstrate the power of our approach, we also constructed a Bayesian decoder [8] by combining estimated encoding models with a sampled natural movie prior. The decoder provides remarkable reconstructions of the viewed movies. These results demonstrate that dynamic brain activity measured under naturalistic conditions can be decoded using current fMRI technology.\n"
      },
      "after": "3adb5367ed191f5f",
      "date": 1679498662215
    }
  ]
}