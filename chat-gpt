{
  "title": "Chat GPT",
  "story": [
    {
      "type": "paragraph",
      "id": "3261dbd48748eb86",
      "text": "Italy is the first country to put a stop to Chat GPT, and at the same time the tech industry is warning against artificial intelligence. In Silicon Valley, however, the fears are quickly met with rather dubious ones. ([https://www.woz.ch/2314/chatbots/leiden-am-und-fuer-den-algorithmus/!NJSMPXBJY1DB woz.ch] by [[Joschka Schaffner]])\n\n"
    },
    {
      "type": "paragraph",
      "id": "d5de46fa9fd6ddaa",
      "text": "It took four months for the first country to put the brakes on Chat GPT: According to the Italian data protection authority, the chatbot from the US company Open AI is not compliant with the European data protection regulation. Last Friday, it ordered Open AI to suspend the tool in Italy for at least twenty days and threatened to fine it millions if the accusations are not refuted."
    },
    {
      "type": "paragraph",
      "id": "4978b47c00db5564",
      "text": "For a full six months, tech companies should stop training artificial intelligence (AI) that is even more powerful than GPT-4, an open letter also called for last week. It was published on the website of the American non-profit organization Future of Life Institute (FLI). The main signatories are tech billionaires, philosophers and academics. Twitter CEO [[Elon Musk]], Apple co-founder [[Steve Wozniak]] and bestselling author [[Yuval Noah Harari]], among others, see unregulated AI algorithms as a great danger. They call for government certification measures, liability for AI developers, and labeling systems to make AI-generated content recognizable."
    },
    {
      "type": "paragraph",
      "id": "4550de499cdbd631",
      "text": "A dubious philosophy"
    },
    {
      "type": "paragraph",
      "id": "41d52a4b173bbbf5",
      "text": "At first glance, Italy's decision and the appeal around the rich men of Silicon Valley seem to go hand in hand. In fact, however, there are fundamentally different views on how exactly artificial intelligence could endanger society – and accordingly also on how the legal framework must be designed to take account of the social costs of innovations in this area.\n\n"
    },
    {
      "type": "paragraph",
      "id": "aee6002eed95c467",
      "text": "At the center of the tech industry complainants is the Swedish philosopher [[Nick Bostrom]], who heads the Future of Humanity Institute at Oxford University. Bostrom is a proponent of \"long-termism,\" a utilitarian ideology dedicated to addressing the big questions of the future. Current problems are regarded as mere collateral damage as long as they do not pose an existential threat to humanity. Bostrom's views are well received in Silicon Valley, where his institute is funded by Musk and Skype co-founder and FLI member [[Jaan Tallinn]], among others."
    },
    {
      "type": "paragraph",
      "id": "2369558fec0ba15a",
      "text": "The \"Techbros\" from California have made a kind of secular belief system out of the principles of \"[[Longtermism]]\": They consider the fusion of man with a superpowerful superintelligence as the next stage of [[Evolution]]. This would solve all of humanity's problems in the long run. In this narrative, artificial intelligence takes on the role of the great threat – in the form of a supposedly impending AI apocalypse, triggered by omnipotent algorithms that will eventually turn against humans."
    },
    {
      "type": "paragraph",
      "id": "a0cd0efae70edee7",
      "text": "Sober assessment"
    },
    {
      "type": "paragraph",
      "id": "7407e99b38e4408d",
      "text": "The FLI, whose main patrons include the Musk Foundation, is therefore trying to influence the EU's planned AI regulations in Brussels. Many of the demands that the institute wants to see anchored in European legislation can also be found in the open letter. Of all things, it cites a paper by the progressive AI institute DAIR, led by former Google researcher [[Timnit Gebru]]. There, however, the potential of AI is assessed much more soberly. Together with linguistics professor [[Emily M. Bender]] and two other co-authors, Gebru coined the term \"stochastic parrot\": Large Language Models (LLMs) such as Chat GPT are merely models that parrot words using probabilities.\n"
    },
    {
      "type": "paragraph",
      "id": "0a90ab2f3a6721fd",
      "text": "Gebru and Bender are among the few voices from the field of AI research that warn against the world of ideas of \"longtermism\". This is why the researchers also criticize the open letter from Silicon Valley: the fact that no AI tool today operates anywhere near human performance capability, let alone possesses a consciousness, is ignored. The invocation of the dangers posed by \"evil\" super-algorithms also obscures current problems. \"The letter does not address any of the existing harms that AI systems cause,\" the statement said."
    },
    {
      "type": "paragraph",
      "id": "b6e814d63aad0075",
      "text": "These harms include exploitative practices in AI development. In January, the U.S. magazine \"Time\" revealed that the training data for Chat GPT was evaluated by the American company Sama in Kenya. The workers there acted as a kind of shield for the chatbot: they were supposed to filter out pornographic images or those of violence or child abuse that had become entangled in the Open AI libraries. Employees described the traumatizing work as \"torture,\" and psychological support was rarely offered. In exchange, they reportedly earned between $1.32 and $2 per hour."
    },
    {
      "type": "paragraph",
      "id": "ffb3e7f741a1bc96",
      "text": "Nevertheless, Sama unabashedly calls itself an \"ethical AI company\" that claims to have already helped thousands out of poverty. In fact, when Open AI prematurely terminated its contract with the company, resistance came from unexpected quarters: the Kenyan workers relied on the bonuses they received for editing particularly disturbing content. Sama is currently already on trial in connection with contracts for Facebook's Meta Group in Kenya – on charges including suppression of unions and inhumane working conditions."
    },
    {
      "type": "paragraph",
      "id": "d8a963ea7faa3612",
      "text": "But the Kenyan data sorters are only one link in an exploitative value chain. Another is the data they process – the very foundation of the Large Language Models. They are picked up from the Internet. In February, media such as CNN and the Wall Street Journal criticized Chat GPT, saying that the AI uses journalistic content for its training without copyright compensation. Artists and authors also accuse the tech start-ups of data theft."
    },
    {
      "type": "paragraph",
      "id": "aed9548e42206b14",
      "text": "Non-transparent data sets"
    },
    {
      "type": "paragraph",
      "id": "e1cd81e6982c495c",
      "text": "There are no regulations that could prevent this. With many algorithms, it is difficult to trace whose intellectual property is in the models anyway. For example, Open AI does not disclose which data is used in GPT-4. The lack of transparency is justified by competitive pressure. This can lead companies that create content for the Internet into a dilemma: refuse or join in? At the beginning of the year, \"Buzzfeed\" was the first journalistic medium to announce that in the future it would create content using chat GPT. The share price of the US online magazine doubled as a result."
    },
    {
      "type": "paragraph",
      "id": "e20f0a1e56dd094c",
      "text": "It is indicative of the lack of a legal framework that Italy is now cracking down by means of the European Data Protection Regulation, which is not actually aimed at AI. Both the EU and the Council of Europe therefore want to move forward with AI regulations. However, there is no consensus on what these should look like in concrete terms. A 2019 study by ETH Zurich revealed that not a single common principle emerged in 84 policy documents dealing with \"ethical AI.\" Not surprisingly, then, the European drive to keep AI in check opens the door to lobbying from Silicon Valley."
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Chat GPT",
        "story": []
      },
      "date": 1680893903016
    },
    {
      "id": "3261dbd48748eb86",
      "type": "add",
      "item": {
        "type": "paragraph",
        "id": "3261dbd48748eb86",
        "text": "Italy is the first country to put a stop to [[Chat GPT]], and at the same time the tech industry is warning against artificial intelligence. In Silicon Valley, however, the fears are quickly met with rather dubious ones.\n\n"
      },
      "attribution": {
        "page": "2023-04-07"
      },
      "date": 1680893909234
    },
    {
      "type": "edit",
      "id": "3261dbd48748eb86",
      "item": {
        "type": "paragraph",
        "id": "3261dbd48748eb86",
        "text": "Italy is the first country to put a stop to Chat GPT, and at the same time the tech industry is warning against artificial intelligence. In Silicon Valley, however, the fears are quickly met with rather dubious ones.\n\n"
      },
      "date": 1680893919169
    },
    {
      "type": "edit",
      "id": "3261dbd48748eb86",
      "item": {
        "type": "paragraph",
        "id": "3261dbd48748eb86",
        "text": "Italy is the first country to put a stop to Chat GPT, and at the same time the tech industry is warning against artificial intelligence. In Silicon Valley, however, the fears are quickly met with rather dubious ones. [https://www.woz.ch/2314/chatbots/leiden-am-und-fuer-den-algorithmus/!NJSMPXBJY1DB woz.ch]\n\n"
      },
      "date": 1680893960268
    },
    {
      "item": {
        "type": "factory",
        "id": "d5de46fa9fd6ddaa"
      },
      "id": "d5de46fa9fd6ddaa",
      "type": "add",
      "after": "3261dbd48748eb86",
      "date": 1680893983486
    },
    {
      "type": "edit",
      "id": "d5de46fa9fd6ddaa",
      "item": {
        "type": "paragraph",
        "id": "d5de46fa9fd6ddaa",
        "text": "It took four months for the first country to put the brakes on Chat GPT: According to the Italian data protection authority, the chatbot from the US company Open AI is not compliant with the European data protection regulation. Last Friday, it ordered Open AI to suspend the tool in Italy for at least twenty days and threatened to fine it millions if the accusations are not refuted.s"
      },
      "date": 1680893986381
    },
    {
      "type": "edit",
      "id": "3261dbd48748eb86",
      "item": {
        "type": "paragraph",
        "id": "3261dbd48748eb86",
        "text": "Italy is the first country to put a stop to Chat GPT, and at the same time the tech industry is warning against artificial intelligence. In Silicon Valley, however, the fears are quickly met with rather dubious ones. [https://www.woz.ch/2314/chatbots/leiden-am-und-fuer-den-algorithmus/!NJSMPXBJY1DB woz.ch] by [[Joschka Schaffner]]\n\n"
      },
      "date": 1680894010458
    },
    {
      "item": {
        "type": "factory",
        "id": "4978b47c00db5564"
      },
      "id": "4978b47c00db5564",
      "type": "add",
      "after": "d5de46fa9fd6ddaa",
      "date": 1680899911852
    },
    {
      "type": "edit",
      "id": "4978b47c00db5564",
      "item": {
        "type": "paragraph",
        "id": "4978b47c00db5564",
        "text": "For a full six months, tech companies should stop training artificial intelligence (AI) that is even more powerful than GPT-4, an open letter also called for last week. It was published on the website of the American non-profit organization Future of Life Institute (FLI). The main signatories are tech billionaires, philosophers and academics. Twitter CEO Elon Musk, Apple co-founder Steve Wozniak and bestselling author Yuval Noah Harari, among others, see unregulated AI algorithms as a great danger. They call for government certification measures, liability for AI developers, and labeling systems to make AI-generated content recognizable."
      },
      "date": 1680899915258
    },
    {
      "item": {
        "type": "factory",
        "id": "4550de499cdbd631"
      },
      "id": "4550de499cdbd631",
      "type": "add",
      "after": "4978b47c00db5564",
      "date": 1680899960915
    },
    {
      "type": "edit",
      "id": "4550de499cdbd631",
      "item": {
        "type": "paragraph",
        "id": "4550de499cdbd631",
        "text": "A dubious philosophy"
      },
      "date": 1680899963494
    },
    {
      "item": {
        "type": "factory",
        "id": "41d52a4b173bbbf5"
      },
      "id": "41d52a4b173bbbf5",
      "type": "add",
      "after": "4550de499cdbd631",
      "date": 1680899975517
    },
    {
      "type": "edit",
      "id": "41d52a4b173bbbf5",
      "item": {
        "type": "paragraph",
        "id": "41d52a4b173bbbf5",
        "text": "At first glance, Italy's decision and the appeal around the rich men of Silicon Valley seem to go hand in hand. In fact, however, there are fundamentally different views on how exactly artificial intelligence could endanger society - and accordingly also on how the legal framework must be designed to take account of the social costs of innovations in this area.\n\n"
      },
      "date": 1680899977288
    },
    {
      "type": "edit",
      "id": "41d52a4b173bbbf5",
      "item": {
        "type": "paragraph",
        "id": "41d52a4b173bbbf5",
        "text": "At first glance, Italy's decision and the appeal around the rich men of Silicon Valley seem to go hand in hand. In fact, however, there are fundamentally different views on how exactly artificial intelligence could endanger society – and accordingly also on how the legal framework must be designed to take account of the social costs of innovations in this area.\n\n"
      },
      "date": 1680899993825
    },
    {
      "item": {
        "type": "factory",
        "id": "aee6002eed95c467"
      },
      "id": "aee6002eed95c467",
      "type": "add",
      "after": "41d52a4b173bbbf5",
      "date": 1680900014127
    },
    {
      "type": "edit",
      "id": "aee6002eed95c467",
      "item": {
        "type": "paragraph",
        "id": "aee6002eed95c467",
        "text": "At the center of the tech industry complainants is the Swedish philosopher Nick Bostrom, who heads the Future of Humanity Institute at Oxford University. Bostrom is a proponent of \"long-termism,\" a utilitarian ideology dedicated to addressing the big questions of the future. Current problems are regarded as mere collateral damage as long as they do not pose an existential threat to humanity. Bostrom's views are well received in Silicon Valley, where his institute is funded by Musk and Skype co-founder and FLI member Jaan Tallinn, among others."
      },
      "date": 1680900016063
    },
    {
      "type": "edit",
      "id": "aee6002eed95c467",
      "item": {
        "type": "paragraph",
        "id": "aee6002eed95c467",
        "text": "At the center of the tech industry complainants is the Swedish philosopher [[Nick Bostrom]], who heads the Future of Humanity Institute at Oxford University. Bostrom is a proponent of \"long-termism,\" a utilitarian ideology dedicated to addressing the big questions of the future. Current problems are regarded as mere collateral damage as long as they do not pose an existential threat to humanity. Bostrom's views are well received in Silicon Valley, where his institute is funded by Musk and Skype co-founder and FLI member Jaan Tallinn, among others."
      },
      "date": 1680900026838
    },
    {
      "item": {
        "type": "factory",
        "id": "2369558fec0ba15a"
      },
      "id": "2369558fec0ba15a",
      "type": "add",
      "after": "aee6002eed95c467",
      "date": 1680900047758
    },
    {
      "type": "edit",
      "id": "2369558fec0ba15a",
      "item": {
        "type": "paragraph",
        "id": "2369558fec0ba15a",
        "text": "The \"Techbros\" from California have made a kind of secular belief system out of the principles of \"Longtermism\": They consider the fusion of man with a superpowerful superintelligence as the next stage of evolution. This would solve all of humanity's problems in the long run. In this narrative, artificial intelligence takes on the role of the great threat - in the form of a supposedly impending AI apocalypse, triggered by omnipotent algorithms that will eventually turn against humans."
      },
      "date": 1680900049604
    },
    {
      "type": "edit",
      "id": "aee6002eed95c467",
      "item": {
        "type": "paragraph",
        "id": "aee6002eed95c467",
        "text": "At the center of the tech industry complainants is the Swedish philosopher [[Nick Bostrom]], who heads the Future of Humanity Institute at Oxford University. Bostrom is a proponent of \"long-termism,\" a utilitarian ideology dedicated to addressing the big questions of the future. Current problems are regarded as mere collateral damage as long as they do not pose an existential threat to humanity. Bostrom's views are well received in Silicon Valley, where his institute is funded by Musk and Skype co-founder and FLI member [[Jaan Tallinn]], among others."
      },
      "date": 1680900060314
    },
    {
      "type": "edit",
      "id": "2369558fec0ba15a",
      "item": {
        "type": "paragraph",
        "id": "2369558fec0ba15a",
        "text": "The \"Techbros\" from California have made a kind of secular belief system out of the principles of \"Longtermism\": They consider the fusion of man with a superpowerful superintelligence as the next stage of evolution. This would solve all of humanity's problems in the long run. In this narrative, artificial intelligence takes on the role of the great threat – in the form of a supposedly impending AI apocalypse, triggered by omnipotent algorithms that will eventually turn against humans."
      },
      "date": 1680900086030
    },
    {
      "item": {
        "type": "factory",
        "id": "a0cd0efae70edee7"
      },
      "id": "a0cd0efae70edee7",
      "type": "add",
      "after": "2369558fec0ba15a",
      "date": 1680900105473
    },
    {
      "type": "edit",
      "id": "a0cd0efae70edee7",
      "item": {
        "type": "paragraph",
        "id": "a0cd0efae70edee7",
        "text": "Sober assessment"
      },
      "date": 1680900108104
    },
    {
      "item": {
        "type": "factory",
        "id": "7407e99b38e4408d"
      },
      "id": "7407e99b38e4408d",
      "type": "add",
      "after": "a0cd0efae70edee7",
      "date": 1680900122568
    },
    {
      "type": "edit",
      "id": "7407e99b38e4408d",
      "item": {
        "type": "paragraph",
        "id": "7407e99b38e4408d",
        "text": "The FLI, whose main patrons include the Musk Foundation, is therefore trying to influence the EU's planned AI regulations in Brussels. Many of the demands that the institute wants to see anchored in European legislation can also be found in the open letter. Of all things, it cites a paper by the progressive AI institute DAIR, led by former Google researcher Timnit Gebru. There, however, the potential of AI is assessed much more soberly. Together with linguistics professor Emily M. Bender and two other co-authors, Gebru coined the term \"stochastic parrot\": Large Language Models (LLMs) such as Chat GPT are merely models that parrot words using probabilities.\n"
      },
      "date": 1680900124320
    },
    {
      "type": "edit",
      "id": "7407e99b38e4408d",
      "item": {
        "type": "paragraph",
        "id": "7407e99b38e4408d",
        "text": "The FLI, whose main patrons include the Musk Foundation, is therefore trying to influence the EU's planned AI regulations in Brussels. Many of the demands that the institute wants to see anchored in European legislation can also be found in the open letter. Of all things, it cites a paper by the progressive AI institute DAIR, led by former Google researcher [[Timnit Gebru]]. There, however, the potential of AI is assessed much more soberly. Together with linguistics professor [[Emily M. Bender]] and two other co-authors, Gebru coined the term \"stochastic parrot\": Large Language Models (LLMs) such as Chat GPT are merely models that parrot words using probabilities.\n"
      },
      "date": 1680900176856
    },
    {
      "item": {
        "type": "factory",
        "id": "0a90ab2f3a6721fd"
      },
      "id": "0a90ab2f3a6721fd",
      "type": "add",
      "after": "7407e99b38e4408d",
      "date": 1680900193630
    },
    {
      "type": "edit",
      "id": "0a90ab2f3a6721fd",
      "item": {
        "type": "paragraph",
        "id": "0a90ab2f3a6721fd",
        "text": "Gebru and Bender are among the few voices from the field of AI research that warn against the world of ideas of \"longtermism\". This is why the researchers also criticize the open letter from Silicon Valley: the fact that no AI tool today operates anywhere near human performance capability, let alone possesses a consciousness, is ignored. The invocation of the dangers posed by \"evil\" super-algorithms also obscures current problems. \"The letter does not address any of the existing harms that AI systems cause,\" the statement said."
      },
      "date": 1680900195301
    },
    {
      "item": {
        "type": "factory",
        "id": "b6e814d63aad0075"
      },
      "id": "b6e814d63aad0075",
      "type": "add",
      "after": "0a90ab2f3a6721fd",
      "date": 1680900242847
    },
    {
      "type": "edit",
      "id": "b6e814d63aad0075",
      "item": {
        "type": "paragraph",
        "id": "b6e814d63aad0075",
        "text": "These harms include exploitative practices in AI development. In January, the U.S. magazine \"Time\" revealed that the training data for Chat GPT was evaluated by the American company Sama in Kenya. The workers there acted as a kind of shield for the chatbot: they were supposed to filter out pornographic images or those of violence or child abuse that had become entangled in the Open AI libraries. Employees described the traumatizing work as \"torture,\" and psychological support was rarely offered. In exchange, they reportedly earned between $1.32 and $2 per hour."
      },
      "date": 1680900244601
    },
    {
      "item": {
        "type": "factory",
        "id": "ffb3e7f741a1bc96"
      },
      "id": "ffb3e7f741a1bc96",
      "type": "add",
      "after": "b6e814d63aad0075",
      "date": 1680900266554
    },
    {
      "type": "edit",
      "id": "ffb3e7f741a1bc96",
      "item": {
        "type": "paragraph",
        "id": "ffb3e7f741a1bc96",
        "text": "Nevertheless, Sama unabashedly calls itself an \"ethical AI company\" that claims to have already helped thousands out of poverty. In fact, when Open AI prematurely terminated its contract with the company, resistance came from unexpected quarters: the Kenyan workers relied on the bonuses they received for editing particularly disturbing content. Sama is currently already on trial in connection with contracts for Facebook's Meta Group in Kenya - on charges including suppression of unions and inhumane working conditions."
      },
      "date": 1680900268358
    },
    {
      "item": {
        "type": "factory",
        "id": "d8a963ea7faa3612"
      },
      "id": "d8a963ea7faa3612",
      "type": "add",
      "after": "ffb3e7f741a1bc96",
      "date": 1680900288169
    },
    {
      "type": "edit",
      "id": "d8a963ea7faa3612",
      "item": {
        "type": "paragraph",
        "id": "d8a963ea7faa3612",
        "text": "But the Kenyan data sorters are only one link in an exploitative value chain. Another is the data they process - the very foundation of the Large Language Models. They are picked up from the Internet. In February, media such as CNN and the Wall Street Journal criticized Chat GPT, saying that the AI uses journalistic content for its training without copyright compensation. Artists and authors also accuse the tech start-ups of data theft."
      },
      "date": 1680900290042
    },
    {
      "type": "edit",
      "id": "d8a963ea7faa3612",
      "item": {
        "type": "paragraph",
        "id": "d8a963ea7faa3612",
        "text": "But the Kenyan data sorters are only one link in an exploitative value chain. Another is the data they process – the very foundation of the Large Language Models. They are picked up from the Internet. In February, media such as CNN and the Wall Street Journal criticized Chat GPT, saying that the AI uses journalistic content for its training without copyright compensation. Artists and authors also accuse the tech start-ups of data theft."
      },
      "date": 1680900299654
    },
    {
      "item": {
        "type": "factory",
        "id": "aed9548e42206b14"
      },
      "id": "aed9548e42206b14",
      "type": "add",
      "after": "d8a963ea7faa3612",
      "date": 1680900320396
    },
    {
      "type": "edit",
      "id": "aed9548e42206b14",
      "item": {
        "type": "paragraph",
        "id": "aed9548e42206b14",
        "text": "Non-transparent data sets"
      },
      "date": 1680900324908
    },
    {
      "item": {
        "type": "factory",
        "id": "e1cd81e6982c495c"
      },
      "id": "e1cd81e6982c495c",
      "type": "add",
      "after": "aed9548e42206b14",
      "date": 1680900334713
    },
    {
      "type": "edit",
      "id": "e1cd81e6982c495c",
      "item": {
        "type": "paragraph",
        "id": "e1cd81e6982c495c",
        "text": "There are no regulations that could prevent this. With many algorithms, it is difficult to trace whose intellectual property is in the models anyway. For example, Open AI does not disclose which data is used in GPT-4. The lack of transparency is justified by competitive pressure. This can lead companies that create content for the Internet into a dilemma: refuse or join in? At the beginning of the year, \"Buzzfeed\" was the first journalistic medium to announce that in the future it would create content using chat GPT. The share price of the US online magazine doubled as a result."
      },
      "date": 1680900336534
    },
    {
      "item": {
        "type": "factory",
        "id": "e20f0a1e56dd094c"
      },
      "id": "e20f0a1e56dd094c",
      "type": "add",
      "after": "e1cd81e6982c495c",
      "date": 1680900348420
    },
    {
      "type": "edit",
      "id": "e20f0a1e56dd094c",
      "item": {
        "type": "paragraph",
        "id": "e20f0a1e56dd094c",
        "text": "It is indicative of the lack of a legal framework that Italy is now cracking down by means of the European Data Protection Regulation, which is not actually aimed at AI. Both the EU and the Council of Europe therefore want to move forward with AI regulations. However, there is no consensus on what these should look like in concrete terms. A 2019 study by ETH Zurich revealed that not a single common principle emerged in 84 policy documents dealing with \"ethical AI.\" Not surprisingly, then, the European drive to keep AI in check opens the door to lobbying from Silicon Valley."
      },
      "date": 1680900351175
    },
    {
      "type": "edit",
      "id": "d5de46fa9fd6ddaa",
      "item": {
        "type": "paragraph",
        "id": "d5de46fa9fd6ddaa",
        "text": "It took four months for the first country to put the brakes on Chat GPT: According to the Italian data protection authority, the chatbot from the US company Open AI is not compliant with the European data protection regulation. Last Friday, it ordered Open AI to suspend the tool in Italy for at least twenty days and threatened to fine it millions if the accusations are not refuted."
      },
      "date": 1680905425472
    },
    {
      "type": "edit",
      "id": "4978b47c00db5564",
      "item": {
        "type": "paragraph",
        "id": "4978b47c00db5564",
        "text": "For a full six months, tech companies should stop training artificial intelligence (AI) that is even more powerful than GPT-4, an open letter also called for last week. It was published on the website of the American non-profit organization Future of Life Institute (FLI). The main signatories are tech billionaires, philosophers and academics. Twitter CEO [[Elon Musk]], Apple co-founder [[Steve Wozniak]] and bestselling author [[Yuval Noah Harari]], among others, see unregulated AI algorithms as a great danger. They call for government certification measures, liability for AI developers, and labeling systems to make AI-generated content recognizable."
      },
      "date": 1680905748574
    },
    {
      "type": "edit",
      "id": "2369558fec0ba15a",
      "item": {
        "type": "paragraph",
        "id": "2369558fec0ba15a",
        "text": "The \"Techbros\" from California have made a kind of secular belief system out of the principles of \"Longtermism\": They consider the fusion of man with a superpowerful superintelligence as the next stage of [[Evolution]]. This would solve all of humanity's problems in the long run. In this narrative, artificial intelligence takes on the role of the great threat – in the form of a supposedly impending AI apocalypse, triggered by omnipotent algorithms that will eventually turn against humans."
      },
      "date": 1680905844910
    },
    {
      "type": "edit",
      "id": "ffb3e7f741a1bc96",
      "item": {
        "type": "paragraph",
        "id": "ffb3e7f741a1bc96",
        "text": "Nevertheless, Sama unabashedly calls itself an \"ethical AI company\" that claims to have already helped thousands out of poverty. In fact, when Open AI prematurely terminated its contract with the company, resistance came from unexpected quarters: the Kenyan workers relied on the bonuses they received for editing particularly disturbing content. Sama is currently already on trial in connection with contracts for Facebook's Meta Group in Kenya – on charges including suppression of unions and inhumane working conditions."
      },
      "date": 1680905979697
    },
    {
      "type": "edit",
      "id": "3261dbd48748eb86",
      "item": {
        "type": "paragraph",
        "id": "3261dbd48748eb86",
        "text": "Italy is the first country to put a stop to Chat GPT, and at the same time the tech industry is warning against artificial intelligence. In Silicon Valley, however, the fears are quickly met with rather dubious ones. ([https://www.woz.ch/2314/chatbots/leiden-am-und-fuer-den-algorithmus/!NJSMPXBJY1DB woz.ch] by [[Joschka Schaffner]])\n\n"
      },
      "date": 1680906081149
    },
    {
      "type": "edit",
      "id": "2369558fec0ba15a",
      "item": {
        "type": "paragraph",
        "id": "2369558fec0ba15a",
        "text": "The \"Techbros\" from California have made a kind of secular belief system out of the principles of \"[[Longtermism]]\": They consider the fusion of man with a superpowerful superintelligence as the next stage of [[Evolution]]. This would solve all of humanity's problems in the long run. In this narrative, artificial intelligence takes on the role of the great threat – in the form of a supposedly impending AI apocalypse, triggered by omnipotent algorithms that will eventually turn against humans."
      },
      "date": 1680906427014
    }
  ]
}