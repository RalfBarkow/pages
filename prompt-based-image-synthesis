{
  "title": "Prompt Based Image Synthesis",
  "story": [
    {
      "type": "paragraph",
      "id": "49588c4392260b44",
      "text": "Here we learn the real application for prompt based image synthesis:"
    },
    {
      "type": "reference",
      "id": "66843b5095d6b693",
      "site": "found.ward.fed.wiki",
      "slug": "zork-meets-imagen",
      "title": "Zork Meets Imagen",
      "text": "Some adventure game fans at Google wondered what would happen if you used the output from the classic text adventure game \"Zork\" as the input to [[Imagen]], Google's text-to-image diffusion model.   To support the results we wanted we made some additions to Zork itself, which was a fascinating journey through an arcane language and a lost but now re-engineered toolchain."
    },
    {
      "type": "paragraph",
      "id": "2240c74503a59a9f",
      "text": "Nishat via [https://matrix.to/#/!ORfrUEFeWFcHAMLFLr:matrix.org/$1674062260208672GdFPK:matrix.org?via=matrix.org&via=matrix.allmende.io&via=chat.weho.st matrix]\nHello \nWard\n: Thanks for the Zork post. I'm quite interested in these kind of projects and data visualization projects. My masters thesis was based upon that and published as a research paper"
    },
    {
      "type": "paragraph",
      "id": "4f2eaa3cd303f188",
      "text": "Image Synthesis with Semantic Diffusion Guidance [https://xh-liu.github.io/sdg/ github.io]"
    },
    {
      "type": "paragraph",
      "id": "8018024535508c26",
      "text": "Controllable image synthesis models allow creation of diverse images based on text instructions or guidance from an example image. Recently, denoising diffusion probabilistic models have been shown to generate more realistic imagery than prior methods, and have been successfully demonstrated in unconditional and class-conditional settings. "
    },
    {
      "type": "paragraph",
      "id": "6fd265d4b459c52e",
      "text": "⇒ [[Denoising diffusion probabilistic model]] ⇒ [[Diffusion Model]]"
    },
    {
      "type": "paragraph",
      "id": "e5ca8186bb1e960e",
      "text": "We explore fine-grained, continuous control of this model class, and introduce a novel unified framework for semantic diffusion guidance, which allows either language or image guidance, or both. Guidance is injected into a pretrained unconditional diffusion model using the gradient of image-text or image matching scores. We explore CLIP-based textual guidance as well as both content and style-based image guidance in a unified form. Our text-guided synthesis approach can be applied to datasets without associated text annotations. We conduct experiments on FFHQ and LSUN datasets, and show results on fine-grained text-guided image synthesis, synthesis of images related to a style or content example image, and examples with both textual and image guidance."
    },
    {
      "type": "pagefold",
      "id": "87ed4d16483af132",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "d4e29809012e5479",
      "text": "\nLIU, Xihui, PARK, Dong Huk, AZADI, Samaneh, ZHANG, Gong, CHOPIKYAN, Arman, HU, Yuxiao, SHI, Humphrey, ROHRBACH, Anna and DARRELL, Trevor, 2023. More Control for Free! Image Synthesis With Semantic Diffusion Guidance. In: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. Online. 2023. p. 289–299. [Accessed 19 January 2023]. Available from: https://openaccess.thecvf.com/content/WACV2023/html/Liu_More_Control_for_Free_Image_Synthesis_With_Semantic_Diffusion_Guidance_WACV_2023_paper.html\n"
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Prompt Based Image Synthesis",
        "story": []
      },
      "date": 1674102140196
    },
    {
      "id": "49588c4392260b44",
      "type": "add",
      "item": {
        "type": "paragraph",
        "id": "49588c4392260b44",
        "text": "Here we learn the real application for prompt based image synthesis:"
      },
      "date": 1674102143337
    },
    {
      "id": "66843b5095d6b693",
      "type": "add",
      "item": {
        "type": "reference",
        "id": "66843b5095d6b693",
        "site": "found.ward.fed.wiki",
        "slug": "zork-meets-imagen",
        "title": "Zork Meets Imagen",
        "text": "Some adventure game fans at Google wondered what would happen if you used the output from the classic text adventure game \"Zork\" as the input to [[Imagen]], Google's text-to-image diffusion model.   To support the results we wanted we made some additions to Zork itself, which was a fascinating journey through an arcane language and a lost but now re-engineered toolchain."
      },
      "after": "49588c4392260b44",
      "date": 1674102170489
    },
    {
      "id": "2240c74503a59a9f",
      "type": "add",
      "item": {
        "type": "paragraph",
        "id": "2240c74503a59a9f",
        "text": "Nishat via [https://matrix.to/#/!ORfrUEFeWFcHAMLFLr:matrix.org/$1674062260208672GdFPK:matrix.org?via=matrix.org&via=matrix.allmende.io&via=chat.weho.st matrix]\nHello \nWard\n: Thanks for the Zork post. I'm quite interested in these kind of projects and data visualization projects. My masters thesis was based upon that and published as a research paper"
      },
      "after": "66843b5095d6b693",
      "date": 1674102177074
    },
    {
      "id": "1dec8031eb44afc0",
      "type": "add",
      "item": {
        "type": "reference",
        "id": "1dec8031eb44afc0",
        "site": "found.ward.fed.wiki",
        "slug": "colossal-cave-adventure",
        "title": "Colossal Cave Adventure",
        "text": "Colossal Cave Adventure is a text-based adventure game, released in 1976 by developer Will Crowther for the PDP-10 mainframe computer. It was expanded upon in 1977 by Don Woods. In the game, the player explores a cave system rumored to be filled with treasure. [https://en.wikipedia.org/wiki/Colossal_Cave_Adventure wikipedia]"
      },
      "after": "2240c74503a59a9f",
      "date": 1674102181247
    },
    {
      "item": {
        "type": "factory",
        "id": "d4e29809012e5479"
      },
      "id": "d4e29809012e5479",
      "type": "add",
      "after": "1dec8031eb44afc0",
      "date": 1674102202083
    },
    {
      "type": "edit",
      "id": "d4e29809012e5479",
      "item": {
        "type": "paragraph",
        "id": "d4e29809012e5479",
        "text": "\nLIU, Xihui, PARK, Dong Huk, AZADI, Samaneh, ZHANG, Gong, CHOPIKYAN, Arman, HU, Yuxiao, SHI, Humphrey, ROHRBACH, Anna and DARRELL, Trevor, 2023. More Control for Free! Image Synthesis With Semantic Diffusion Guidance. In: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. Online. 2023. p. 289–299. [Accessed 19 January 2023]. Available from: https://openaccess.thecvf.com/content/WACV2023/html/Liu_More_Control_for_Free_Image_Synthesis_With_Semantic_Diffusion_Guidance_WACV_2023_paper.html\n"
      },
      "date": 1674102204052
    },
    {
      "item": {
        "type": "factory",
        "id": "87ed4d16483af132"
      },
      "id": "87ed4d16483af132",
      "type": "add",
      "after": "d4e29809012e5479",
      "date": 1674102250073
    },
    {
      "type": "edit",
      "id": "87ed4d16483af132",
      "item": {
        "type": "pagefold",
        "id": "87ed4d16483af132",
        "text": "~"
      },
      "date": 1674102254431
    },
    {
      "id": "87ed4d16483af132",
      "type": "move",
      "order": [
        "49588c4392260b44",
        "66843b5095d6b693",
        "2240c74503a59a9f",
        "1dec8031eb44afc0",
        "87ed4d16483af132",
        "d4e29809012e5479"
      ],
      "date": 1674102256947
    },
    {
      "item": {
        "type": "factory",
        "id": "4f2eaa3cd303f188"
      },
      "id": "4f2eaa3cd303f188",
      "type": "add",
      "after": "d4e29809012e5479",
      "date": 1674102258802
    },
    {
      "type": "edit",
      "id": "4f2eaa3cd303f188",
      "item": {
        "type": "paragraph",
        "id": "4f2eaa3cd303f188",
        "text": "Image Synthesis with Semantic Diffusion Guidance"
      },
      "date": 1674102260440
    },
    {
      "id": "4f2eaa3cd303f188",
      "type": "move",
      "order": [
        "49588c4392260b44",
        "66843b5095d6b693",
        "2240c74503a59a9f",
        "1dec8031eb44afc0",
        "4f2eaa3cd303f188",
        "87ed4d16483af132",
        "d4e29809012e5479"
      ],
      "date": 1674102262999
    },
    {
      "type": "edit",
      "id": "4f2eaa3cd303f188",
      "item": {
        "type": "paragraph",
        "id": "4f2eaa3cd303f188",
        "text": "Image Synthesis with Semantic Diffusion Guidance [https://xh-liu.github.io/sdg/ github.io]"
      },
      "date": 1674102286555
    },
    {
      "item": {
        "type": "factory",
        "id": "8018024535508c26"
      },
      "id": "8018024535508c26",
      "type": "add",
      "after": "d4e29809012e5479",
      "date": 1674102371210
    },
    {
      "id": "8018024535508c26",
      "type": "move",
      "order": [
        "49588c4392260b44",
        "66843b5095d6b693",
        "2240c74503a59a9f",
        "1dec8031eb44afc0",
        "4f2eaa3cd303f188",
        "87ed4d16483af132",
        "8018024535508c26",
        "d4e29809012e5479"
      ],
      "date": 1674102374263
    },
    {
      "id": "8018024535508c26",
      "type": "move",
      "order": [
        "49588c4392260b44",
        "66843b5095d6b693",
        "2240c74503a59a9f",
        "1dec8031eb44afc0",
        "4f2eaa3cd303f188",
        "8018024535508c26",
        "87ed4d16483af132",
        "d4e29809012e5479"
      ],
      "date": 1674102376759
    },
    {
      "type": "edit",
      "id": "8018024535508c26",
      "item": {
        "type": "paragraph",
        "id": "8018024535508c26",
        "text": "Controllable image synthesis models allow creation of diverse images based on text instructions or guidance from an example image. Recently, denoising diffusion probabilistic models have been shown to generate more realistic imagery than prior methods, and have been successfully demonstrated in unconditional and class-conditional settings. We explore fine-grained, continuous control of this model class, and introduce a novel unified framework for semantic diffusion guidance, which allows either language or image guidance, or both. Guidance is injected into a pretrained unconditional diffusion model using the gradient of image-text or image matching scores. We explore CLIP-based textual guidance as well as both content and style-based image guidance in a unified form. Our text-guided synthesis approach can be applied to datasets without associated text annotations. We conduct experiments on FFHQ and LSUN datasets, and show results on fine-grained text-guided image synthesis, synthesis of images related to a style or content example image, and examples with both textual and image guidance."
      },
      "date": 1674102378375
    },
    {
      "type": "edit",
      "id": "8018024535508c26",
      "item": {
        "type": "paragraph",
        "id": "8018024535508c26",
        "text": "Controllable image synthesis models allow creation of diverse images based on text instructions or guidance from an example image. Recently, denoising diffusion probabilistic models have been shown to generate more realistic imagery than prior methods, and have been successfully demonstrated in unconditional and class-conditional settings. "
      },
      "date": 1674102719066
    },
    {
      "type": "add",
      "id": "e5ca8186bb1e960e",
      "item": {
        "type": "paragraph",
        "id": "e5ca8186bb1e960e",
        "text": "We explore fine-grained, continuous control of this model class, and introduce a novel unified framework for semantic diffusion guidance, which allows either language or image guidance, or both. Guidance is injected into a pretrained unconditional diffusion model using the gradient of image-text or image matching scores. We explore CLIP-based textual guidance as well as both content and style-based image guidance in a unified form. Our text-guided synthesis approach can be applied to datasets without associated text annotations. We conduct experiments on FFHQ and LSUN datasets, and show results on fine-grained text-guided image synthesis, synthesis of images related to a style or content example image, and examples with both textual and image guidance."
      },
      "after": "8018024535508c26",
      "date": 1674102727486
    },
    {
      "type": "add",
      "id": "6fd265d4b459c52e",
      "item": {
        "type": "paragraph",
        "id": "6fd265d4b459c52e",
        "text": "⇒ [[Denoising diffusion probabilistic model]]"
      },
      "after": "8018024535508c26",
      "date": 1674102854628
    },
    {
      "type": "edit",
      "id": "6fd265d4b459c52e",
      "item": {
        "type": "paragraph",
        "id": "6fd265d4b459c52e",
        "text": "⇒ [[Denoising diffusion probabilistic model]] ⇒ [[Diffusion Model]]"
      },
      "date": 1674102912338
    },
    {
      "id": "1dec8031eb44afc0",
      "type": "remove",
      "date": 1674117219594
    }
  ]
}