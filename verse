{
  "title": "Verse",
  "story": [
    {
      "type": "reference",
      "id": "60cf763ee66ca771",
      "site": "wiki.ralfbarkow.ch",
      "slug": "write-wiki-pages-in-a-poetic-form",
      "title": "Write Wiki Pages in a Poetic Form",
      "text": "\"What would it mean to [[write]] wiki pages in a poetic form, inspired by [[Richard Gabriel]]'s [[Haiku]] practice? Can other people feel the delightful unfolding that [[I]] feel?\" [https://matrix.to/#/!ORfrUEFeWFcHAMLFLr:matrix.org/%24169074029828042PfEtk%3Amatrix.org matrix] (2023-07-30-Sunday-Explorers-with-Thompson.txt, 09:29:45 From Jeff Miller To Everyone)"
    },
    {
      "type": "paragraph",
      "id": "5f510f91e5110c63",
      "text": "⇒ [[Vers]], [[Poem]]"
    },
    {
      "type": "paragraph",
      "id": "660a4ebf46da9bbc",
      "text": "TSITSULIN, Anton, MOTTIN, Davide, KARRAS, Panagiotis and MÜLLER, Emmanuel, 2018. VERSE: Versatile Graph Embeddings from Similarity Measures. In: Proceedings of the 2018 World Wide Web Conference on World Wide Web - WWW ’18. Lyon, France: ACM Press. 2018. p. 539–548. ISBN 978-1-4503-5639-8. DOI 10.1145/3178876.3186120. [Accessed 10 April 2024]. \n"
    },
    {
      "type": "paragraph",
      "id": "3676495980a5e19c",
      "text": "Embedding a web-scale information network into a low-dimensional vector space facilitates tasks such as [[Link Prediction]], classification, and visualization. Past research has addressed the problem of extracting such embeddings by adopting methods from words to graphs, without defining a clearly comprehensible graph-related objective. Yet, as we show, the objectives used in past works implicitly utilize similarity measures among graph nodes. In this paper, we carry the similarity orientation of previous works to its logical conclusion; we propose VERtex Similarity Embeddings (VERSE), a simple, versatile, and memory-efficient method that derives graph embeddings explicitly calibrated to preserve the distributions of a selected vertex-to-vertex similarity measure. VERSE learns such embeddings by training a single-layer neural network. While its default, scalable version does so via sampling similarity information, we also develop a variant using the full information per vertex. Our experimental study on standard benchmarks and real-world datasets demonstrates that VERSE, instantiated with diverse similarity measures, outperforms state-of-the-art methods in terms of precision and recall in major data mining tasks and supersedes them in time and space efficiency, while the scalable sampling-based variant achieves equally good result as the non-scalable full variant."
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Verse",
        "story": []
      },
      "date": 1692276163621
    },
    {
      "item": {
        "type": "factory",
        "id": "60cf763ee66ca771"
      },
      "id": "60cf763ee66ca771",
      "type": "add",
      "date": 1692276166497
    },
    {
      "type": "edit",
      "id": "60cf763ee66ca771",
      "item": {
        "type": "reference",
        "id": "60cf763ee66ca771",
        "site": "wiki.ralfbarkow.ch",
        "slug": "write-wiki-pages-in-a-poetic-form",
        "title": "Write Wiki Pages in a Poetic Form",
        "text": "\"What would it mean to [[write]] wiki pages in a poetic form, inspired by [[Richard Gabriel]]'s [[Haiku]] practice? Can other people feel the delightful unfolding that [[I]] feel?\" [https://matrix.to/#/!ORfrUEFeWFcHAMLFLr:matrix.org/%24169074029828042PfEtk%3Amatrix.org matrix] (2023-07-30-Sunday-Explorers-with-Thompson.txt, 09:29:45 From Jeff Miller To Everyone)"
      },
      "date": 1692276168659
    },
    {
      "item": {
        "type": "factory",
        "id": "5f510f91e5110c63"
      },
      "id": "5f510f91e5110c63",
      "type": "add",
      "after": "60cf763ee66ca771",
      "date": 1692276183327
    },
    {
      "type": "edit",
      "id": "5f510f91e5110c63",
      "item": {
        "type": "paragraph",
        "id": "5f510f91e5110c63",
        "text": "⇒ [[Vers]"
      },
      "date": 1692276185066
    },
    {
      "type": "edit",
      "id": "5f510f91e5110c63",
      "item": {
        "type": "paragraph",
        "id": "5f510f91e5110c63",
        "text": "⇒ [[Vers]]"
      },
      "date": 1692276202559
    },
    {
      "id": "660a4ebf46da9bbc",
      "type": "add",
      "item": {
        "type": "paragraph",
        "id": "660a4ebf46da9bbc",
        "text": "TSITSULIN, Anton, MOTTIN, Davide, KARRAS, Panagiotis and MÜLLER, Emmanuel, 2018. VERSE: Versatile Graph Embeddings from Similarity Measures. In: Proceedings of the 2018 World Wide Web Conference on World Wide Web - WWW ’18. Lyon, France: ACM Press. 2018. p. 539–548. ISBN 978-1-4503-5639-8. DOI 10.1145/3178876.3186120. [Accessed 10 April 2024]. \n"
      },
      "after": "5f510f91e5110c63",
      "attribution": {
        "page": "2024-04-10"
      },
      "date": 1712782037350
    },
    {
      "type": "edit",
      "id": "5f510f91e5110c63",
      "item": {
        "type": "paragraph",
        "id": "5f510f91e5110c63",
        "text": "⇒ [[Vers]], [[Poem]]"
      },
      "date": 1712782044242
    },
    {
      "id": "3676495980a5e19c",
      "type": "add",
      "item": {
        "type": "paragraph",
        "id": "3676495980a5e19c",
        "text": "Embedding a web-scale information network into a low-dimensional vector space facilitates tasks such as [[Link Prediction]], classification, and visualization. Past research has addressed the problem of extracting such embeddings by adopting methods from words to graphs, without defining a clearly comprehensible graph-related objective. Yet, as we show, the objectives used in past works implicitly utilize similarity measures among graph nodes. In this paper, we carry the similarity orientation of previous works to its logical conclusion; we propose VERtex Similarity Embeddings (VERSE), a simple, versatile, and memory-efficient method that derives graph embeddings explicitly calibrated to preserve the distributions of a selected vertex-to-vertex similarity measure. VERSE learns such embeddings by training a single-layer neural network. While its default, scalable version does so via sampling similarity information, we also develop a variant using the full information per vertex. Our experimental study on standard benchmarks and real-world datasets demonstrates that VERSE, instantiated with diverse similarity measures, outperforms state-of-the-art methods in terms of precision and recall in major data mining tasks and supersedes them in time and space efficiency, while the scalable sampling-based variant achieves equally good result as the non-scalable full variant."
      },
      "after": "660a4ebf46da9bbc",
      "attribution": {
        "page": "2024-04-10"
      },
      "date": 1712782048009
    }
  ]
}