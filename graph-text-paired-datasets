{
  "title": "Graph-Text Paired Datasets",
  "story": [
    {
      "type": "markdown",
      "id": "f3c53ee992b4450e",
      "text": "WikiGraphs: A Wikipedia Text - Knowledge Graph Paired Dataset. [https://deepai.org/publication/wikigraphs-a-wikipedia-text-knowledge-graph-paired-dataset deepai], [https://arxiv.org/pdf/2107.09556v1.pdf pdf]"
    },
    {
      "type": "markdown",
      "id": "2061c5e2bcde3580",
      "text": "> We present a new dataset of Wikipedia articles each paired with a [[knowledge graph]], to facilitate the research in conditional text generation, graph generation and graph representation learning. Existing graph-text paired datasets typically contain small graphs and short text (1 or few sentences), thus limiting the capabilities of the models that can be learned on the data. Our new dataset WikiGraphs is collected by pairing each Wikipedia article from the established WikiText-103 benchmark (Merity et al., 2016) with a subgraph from the Freebase knowledge graph (Bollacker et al., 2008). This makes it easy to benchmark against other state-of-the-art text generative models that are capable of generating long paragraphs of coherent text. Both the graphs and the text data are of significantly larger scale compared to prior graph-text paired datasets. We present baseline graph neural network and [[transformer model]] results on our dataset for 3 tasks: graph -> text generation, graph -> text retrieval and text -> graph retrieval. We show that better conditioning on the graph provides gains in generation and retrieval quality but there is still large room for improvement."
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Graph-Text Paired Datasets",
        "story": []
      },
      "date": 1649782474388
    },
    {
      "id": "f3c53ee992b4450e",
      "type": "add",
      "item": {
        "type": "markdown",
        "id": "f3c53ee992b4450e",
        "text": "WikiGraphs: A Wikipedia Text - Knowledge Graph Paired Dataset. [https://deepai.org/publication/wikigraphs-a-wikipedia-text-knowledge-graph-paired-dataset deepai], [https://arxiv.org/pdf/2107.09556v1.pdf pdf]"
      },
      "date": 1649782504904
    },
    {
      "item": {
        "type": "factory",
        "id": "2061c5e2bcde3580"
      },
      "id": "2061c5e2bcde3580",
      "type": "add",
      "after": "f3c53ee992b4450e",
      "date": 1649782535408
    },
    {
      "type": "edit",
      "id": "2061c5e2bcde3580",
      "item": {
        "type": "markdown",
        "id": "2061c5e2bcde3580",
        "text": "> We present a new dataset of Wikipedia articles each paired with a knowledge graph, to facilitate the research in conditional text generation, graph generation and graph representation learning. Existing graph-text paired datasets typically contain small graphs and short text (1 or few sentences), thus limiting the capabilities of the models that can be learned on the data. Our new dataset WikiGraphs is collected by pairing each Wikipedia article from the established WikiText-103 benchmark (Merity et al., 2016) with a subgraph from the Freebase knowledge graph (Bollacker et al., 2008). This makes it easy to benchmark against other state-of-the-art text generative models that are capable of generating long paragraphs of coherent text. Both the graphs and the text data are of significantly larger scale compared to prior graph-text paired datasets. We present baseline graph neural network and transformer model results on our dataset for 3 tasks: graph -> text generation, graph -> text retrieval and text -> graph retrieval. We show that better conditioning on the graph provides gains in generation and retrieval quality but there is still large room for improvement."
      },
      "date": 1649782539247
    },
    {
      "type": "edit",
      "id": "2061c5e2bcde3580",
      "item": {
        "type": "markdown",
        "id": "2061c5e2bcde3580",
        "text": "> We present a new dataset of Wikipedia articles each paired with a [[knowledge graph]], to facilitate the research in conditional text generation, graph generation and graph representation learning. Existing graph-text paired datasets typically contain small graphs and short text (1 or few sentences), thus limiting the capabilities of the models that can be learned on the data. Our new dataset WikiGraphs is collected by pairing each Wikipedia article from the established WikiText-103 benchmark (Merity et al., 2016) with a subgraph from the Freebase knowledge graph (Bollacker et al., 2008). This makes it easy to benchmark against other state-of-the-art text generative models that are capable of generating long paragraphs of coherent text. Both the graphs and the text data are of significantly larger scale compared to prior graph-text paired datasets. We present baseline graph neural network and transformer model results on our dataset for 3 tasks: graph -> text generation, graph -> text retrieval and text -> graph retrieval. We show that better conditioning on the graph provides gains in generation and retrieval quality but there is still large room for improvement."
      },
      "date": 1649782553557
    },
    {
      "type": "edit",
      "id": "2061c5e2bcde3580",
      "item": {
        "type": "markdown",
        "id": "2061c5e2bcde3580",
        "text": "> We present a new dataset of Wikipedia articles each paired with a [[knowledge graph]], to facilitate the research in conditional text generation, graph generation and graph representation learning. Existing graph-text paired datasets typically contain small graphs and short text (1 or few sentences), thus limiting the capabilities of the models that can be learned on the data. Our new dataset WikiGraphs is collected by pairing each Wikipedia article from the established WikiText-103 benchmark (Merity et al., 2016) with a subgraph from the Freebase knowledge graph (Bollacker et al., 2008). This makes it easy to benchmark against other state-of-the-art text generative models that are capable of generating long paragraphs of coherent text. Both the graphs and the text data are of significantly larger scale compared to prior graph-text paired datasets. We present baseline graph neural network and [[transformer model]] results on our dataset for 3 tasks: graph -> text generation, graph -> text retrieval and text -> graph retrieval. We show that better conditioning on the graph provides gains in generation and retrieval quality but there is still large room for improvement."
      },
      "date": 1649802820369
    }
  ]
}