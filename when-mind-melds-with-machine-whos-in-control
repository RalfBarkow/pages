{
  "title": "When Mind Melds With Machine, Who's in Control?",
  "story": [
    {
      "type": "paragraph",
      "id": "29f5b2faa83debe0",
      "text": "These aren't hypothetical questions for a distant future. We're wrestling with them today. How do we assign responsibility when self-driving cars hit pedestrians, or when passenger planes crash on autopilot? In the Air France 447 and Boeing 737 Max crashes, the autonomous systems got confused by faulty sensor information and the pilots couldn;t recover from the malfunction. This belies the promise, touted by many corporations, that keeping humans in the loop will prevent things from spiraling out of control. It may, in fact, just be a legal sleight of hand to pin [[liability]] on an entity that courts are already equipped to hold responsible. A key difference, however, is that a brain interface is part of the body, which makes responsibility harder to demarcate."
    },
    {
      "type": "paragraph",
      "id": "665ab7cf265b60c7",
      "text": "There are also, of course, major privacy and security questions with brain interfaces. By virtue of the fact that many signals are globally available throughout the brain, a recording device could be picking up signals about your sensory experience, your perceptual processes, your conscious cognition, your emotional states. Ads could be targeted not to your clicks but to your thoughts and feelings. These signals could even potentially be used for surveillance. Ten years ago, members of Jack Gallant's lab at UC Berkeley were able to hazily reconstruct visual scenes from the brain activity of people watching video clips. The technique has gotten better with time. If, one day in the far future, someone tapped into your wireless neural receiver, imagine what they could see and hear. Certainly a lot more than if they hacked your webcam or smart speaker. Through our own eyes and ears, we might become the unwitting operatives of a distributed panopticon."
    },
    {
      "type": "markdown",
      "id": "d7927625b47c47f0",
      "text": "Direct brain-to-brain communication is just as ethically fraught. It's a beautiful, utopian impulse&#8212;the sense that if only we could fully see what's inside one another contentions would cease. Should it prove technically possible, however, the question of privacy becomes all the more salient. In the same way that social media companies must grapple with content moderation, brain devices would need to filter inter-brain communication for harmful, hateful, or violent thoughts. There might even be patterns of problematic neural activity that can be passed between people like computer viruses. Epileptic seizures, for example, can be learned by the brain in a process known as *kindling*. Like arsonists setting fire to a city, malicious actors might seek to inject such maladaptive brain activity in a bid to harm other users."
    },
    {
      "type": "markdown",
      "id": "2067d4bd379cfad4",
      "text": "The history of technology, the history of humankind, is one of relentlessly extended agency&#8212;exerting control over materials, plants, animals, and perhaps, one day, minds. The invention of computers has transmuted that agency to a programmable realm, wherein a hand can control a mouse that is by turns a digital paintbrush, a text cursor, or a drone's gun sight. While I&#8217;m still hopeful about what brain-machine interfaces will be able to do for people with impaired motor function, we should acknowledge where good intentions might be obfuscating a potential ethical catastrophe. We've got to reckon with the implications of agency and privacy as they pertain to AI today, before they&#8217;re interfaced with our bodies and minds. We&#8217;re being promised new avenues of human control, when it is precisely control we&#8217;d be ceding in what could be the largest deprivatization of thought since the invention of language."
    },
    {
      "type": "paragraph",
      "id": "097cba3d55c544e0",
      "text": "[https://www.wired.com/story/when-mind-melds-machine-whos-in-control-brain-computer-interface/ https://www.wired.com/story/when-mind-melds-machine-whos-in-control-brain-computer-interface/]"
    },
    {
      "type": "markdown",
      "id": "cb21a97bf7433d96",
      "text": "Source: WiReD via [https://catless.ncl.ac.uk/Risks/33/04/#subj2.1 The Risks Digest]"
    }
  ],
  "journal": [
    {
      "type": "create",
      "date": 1643331663000,
      "item": {
        "title": "When Mind Melds With Machine, Who's in Control?",
        "story": [
          {
            "type": "paragraph",
            "id": "29f5b2faa83debe0",
            "text": "These aren't hypothetical questions for a distant future. We're wrestling with them today. How do we assign responsibility when self-driving cars hit pedestrians, or when passenger planes crash on autopilot? In the Air France 447 and Boeing 737 Max crashes, the autonomous systems got confused by faulty sensor information and the pilots couldn;t recover from the malfunction. This belies the promise, touted by many corporations, that keeping humans in the loop will prevent things from spiraling out of control. It may, in fact, just be a legal sleight of hand to pin liability on an entity that courts are already equipped to hold responsible. A key difference, however, is that a brain interface is part of the body, which makes responsibility harder to demarcate."
          },
          {
            "type": "paragraph",
            "id": "665ab7cf265b60c7",
            "text": "There are also, of course, major privacy and security questions with brain interfaces. By virtue of the fact that many signals are globally available throughout the brain, a recording device could be picking up signals about your sensory experience, your perceptual processes, your conscious cognition, your emotional states. Ads could be targeted not to your clicks but to your thoughts and feelings. These signals could even potentially be used for surveillance. Ten years ago, members of Jack Gallant's lab at UC Berkeley were able to hazily reconstruct visual scenes from the brain activity of people watching video clips. The technique has gotten better with time. If, one day in the far future, someone tapped into your wireless neural receiver, imagine what they could see and hear. Certainly a lot more than if they hacked your webcam or smart speaker. Through our own eyes and ears, we might become the unwitting operatives of a distributed panopticon."
          },
          {
            "type": "markdown",
            "id": "d7927625b47c47f0",
            "text": "Direct brain-to-brain communication is just as ethically fraught. It's a beautiful, utopian impulse&#8212;the sense that if only we could fully see what's inside one another contentions would cease. Should it prove technically possible, however, the question of privacy becomes all the more salient. In the same way that social media companies must grapple with content moderation, brain devices would need to filter inter-brain communication for harmful, hateful, or violent thoughts. There might even be patterns of problematic neural activity that can be passed between people like computer viruses. Epileptic seizures, for example, can be learned by the brain in a process known as *kindling*. Like arsonists setting fire to a city, malicious actors might seek to inject such maladaptive brain activity in a bid to harm other users."
          },
          {
            "type": "markdown",
            "id": "2067d4bd379cfad4",
            "text": "The history of technology, the history of humankind, is one of relentlessly extended agency&#8212;exerting control over materials, plants, animals, and perhaps, one day, minds. The invention of computers has transmuted that agency to a programmable realm, wherein a hand can control a mouse that is by turns a digital paintbrush, a text cursor, or a drone's gun sight. While I&#8217;m still hopeful about what brain-machine interfaces will be able to do for people with impaired motor function, we should acknowledge where good intentions might be obfuscating a potential ethical catastrophe. We've got to reckon with the implications of agency and privacy as they pertain to AI today, before they&#8217;re interfaced with our bodies and minds. We&#8217;re being promised new avenues of human control, when it is precisely control we&#8217;d be ceding in what could be the largest deprivatization of thought since the invention of language."
          },
          {
            "type": "paragraph",
            "id": "097cba3d55c544e0",
            "text": "[https://www.wired.com/story/when-mind-melds-machine-whos-in-control-brain-computer-interface/ https://www.wired.com/story/when-mind-melds-machine-whos-in-control-brain-computer-interface/]"
          },
          {
            "type": "markdown",
            "id": "cb21a97bf7433d96",
            "text": "Source: WiReD via [https://catless.ncl.ac.uk/Risks/33/04/#subj2.1 The Risks Digest]"
          }
        ]
      }
    },
    {
      "type": "fork",
      "site": "risks.rodwell.me",
      "date": 1643355430298
    },
    {
      "type": "edit",
      "id": "29f5b2faa83debe0",
      "item": {
        "type": "paragraph",
        "id": "29f5b2faa83debe0",
        "text": "These aren't hypothetical questions for a distant future. We're wrestling with them today. How do we assign responsibility when self-driving cars hit pedestrians, or when passenger planes crash on autopilot? In the Air France 447 and Boeing 737 Max crashes, the autonomous systems got confused by faulty sensor information and the pilots couldn;t recover from the malfunction. This belies the promise, touted by many corporations, that keeping humans in the loop will prevent things from spiraling out of control. It may, in fact, just be a legal sleight of hand to pin [[liability]] on an entity that courts are already equipped to hold responsible. A key difference, however, is that a brain interface is part of the body, which makes responsibility harder to demarcate."
      },
      "date": 1645177897155
    }
  ]
}