{
  "title": "BLOOMZ",
  "story": [
    {
      "type": "paragraph",
      "id": "3d0d7c95e5c93398",
      "text": "We present BLOOMZ & mT0, a family of models capable of following human instructions in dozens of languages zero-shot. We finetune BLOOM & mT5 pretrained multilingual language models on our crosslingual task mixture (xP3) and find the resulting models capable of crosslingual generalization to unseen tasks & languages [https://huggingface.co/bigscience/bloomz page], [https://github.com/bigscience-workshop/xmtf github]\n"
    },
    {
      "type": "paragraph",
      "id": "09c6a0c585f1ce3d",
      "text": "Paper:  Crosslingual Generalization through Multitask Finetuning [https://arxiv.org/abs/2211.01786 arxiv]"
    },
    {
      "type": "pagefold",
      "id": "dbb645c496386c89",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "af812d56ae08f0cc",
      "text": "Liesenfeld, Andreas, Alianda Lopez, and Mark Dingemanse. 2023. “Opening up ChatGPT: Tracking Openness, Transparency, and Accountability in Instruction-Tuned Text Generators.” In CUI '23: Proceedings of the 5th International Conference on Conversational User Interfaces. July 19-21, Eindhoven. [https://doi.org/10.1145/3571884.3604316 doi], [https://scholar.social/@dingemansemark/110728766949576969 post], [https://opening-up-chatgpt.github.io site]"
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "BLOOMZ",
        "story": []
      },
      "date": 1694786075454
    },
    {
      "item": {
        "type": "factory",
        "id": "3d0d7c95e5c93398"
      },
      "id": "3d0d7c95e5c93398",
      "type": "add",
      "date": 1694786088946
    },
    {
      "type": "edit",
      "id": "3d0d7c95e5c93398",
      "item": {
        "type": "paragraph",
        "id": "3d0d7c95e5c93398",
        "text": "\n\n    We present BLOOMZ & mT0, a family of models capable of following human instructions in dozens of languages zero-shot. We finetune BLOOM & mT5 pretrained multilingual language models on our crosslingual task mixture (xP3) and find the resulting models capable of crosslingual generalization to unseen tasks & languages.\n"
      },
      "date": 1694786090693
    },
    {
      "type": "edit",
      "id": "3d0d7c95e5c93398",
      "item": {
        "type": "paragraph",
        "id": "3d0d7c95e5c93398",
        "text": "We present BLOOMZ & mT0, a family of models capable of following human instructions in dozens of languages zero-shot. We finetune BLOOM & mT5 pretrained multilingual language models on our crosslingual task mixture (xP3) and find the resulting models capable of crosslingual generalization to unseen tasks & languages [https://huggingface.co/bigscience/bloomz page]\n"
      },
      "date": 1694786130314
    },
    {
      "type": "edit",
      "id": "3d0d7c95e5c93398",
      "item": {
        "type": "paragraph",
        "id": "3d0d7c95e5c93398",
        "text": "We present BLOOMZ & mT0, a family of models capable of following human instructions in dozens of languages zero-shot. We finetune BLOOM & mT5 pretrained multilingual language models on our crosslingual task mixture (xP3) and find the resulting models capable of crosslingual generalization to unseen tasks & languages [https://huggingface.co/bigscience/bloomz page], , [https://github.com/bigscience-workshop/xmtf github]\n"
      },
      "date": 1694786151834
    },
    {
      "type": "edit",
      "id": "3d0d7c95e5c93398",
      "item": {
        "type": "paragraph",
        "id": "3d0d7c95e5c93398",
        "text": "We present BLOOMZ & mT0, a family of models capable of following human instructions in dozens of languages zero-shot. We finetune BLOOM & mT5 pretrained multilingual language models on our crosslingual task mixture (xP3) and find the resulting models capable of crosslingual generalization to unseen tasks & languages [https://huggingface.co/bigscience/bloomz page] , [https://github.com/bigscience-workshop/xmtf github]\n"
      },
      "date": 1694786157211
    },
    {
      "type": "edit",
      "id": "3d0d7c95e5c93398",
      "item": {
        "type": "paragraph",
        "id": "3d0d7c95e5c93398",
        "text": "We present BLOOMZ & mT0, a family of models capable of following human instructions in dozens of languages zero-shot. We finetune BLOOM & mT5 pretrained multilingual language models on our crosslingual task mixture (xP3) and find the resulting models capable of crosslingual generalization to unseen tasks & languages [https://huggingface.co/bigscience/bloomz page], [https://github.com/bigscience-workshop/xmtf github]\n"
      },
      "date": 1694786162737
    },
    {
      "item": {
        "type": "factory",
        "id": "4b0e39d792dcf123"
      },
      "id": "4b0e39d792dcf123",
      "type": "add",
      "after": "3d0d7c95e5c93398",
      "date": 1694786169548
    },
    {
      "type": "edit",
      "id": "4b0e39d792dcf123",
      "item": {
        "type": "paragraph",
        "id": "4b0e39d792dcf123",
        "text": "Paper: "
      },
      "date": 1694786174720
    },
    {
      "id": "09c6a0c585f1ce3d",
      "type": "add",
      "item": {
        "type": "paragraph",
        "id": "09c6a0c585f1ce3d",
        "text": "Crosslingual Generalization through Multitask Finetuning [https://arxiv.org/abs/2211.01786 arxiv]"
      },
      "after": "4b0e39d792dcf123",
      "attribution": {
        "page": "2023-09-15"
      },
      "date": 1694786177031
    },
    {
      "type": "remove",
      "id": "4b0e39d792dcf123",
      "date": 1694786179385
    },
    {
      "type": "edit",
      "id": "09c6a0c585f1ce3d",
      "item": {
        "type": "paragraph",
        "id": "09c6a0c585f1ce3d",
        "text": "Paper:  Crosslingual Generalization through Multitask Finetuning [https://arxiv.org/abs/2211.01786 arxiv]"
      },
      "date": 1694786182149
    },
    {
      "item": {
        "type": "factory",
        "id": "dbb645c496386c89"
      },
      "id": "dbb645c496386c89",
      "type": "add",
      "after": "09c6a0c585f1ce3d",
      "date": 1694786364359
    },
    {
      "type": "edit",
      "id": "dbb645c496386c89",
      "item": {
        "type": "pagefold",
        "id": "dbb645c496386c89",
        "text": "~"
      },
      "date": 1694786367071
    },
    {
      "id": "af812d56ae08f0cc",
      "type": "add",
      "item": {
        "type": "paragraph",
        "id": "af812d56ae08f0cc",
        "text": "Opening up ChatGPT: Tracking openness, transparency, and accountability in instruction-tuned text generators [https://doi.org/10.1145/3571884.3604316 doi], [https://scholar.social/@dingemansemark/110728766949576969 post], [https://opening-up-chatgpt.github.io site]"
      },
      "after": "09c6a0c585f1ce3d",
      "attribution": {
        "page": "2023-09-15"
      },
      "date": 1694786372812
    },
    {
      "id": "af812d56ae08f0cc",
      "type": "move",
      "order": [
        "3d0d7c95e5c93398",
        "09c6a0c585f1ce3d",
        "dbb645c496386c89",
        "af812d56ae08f0cc"
      ],
      "date": 1694786375635
    },
    {
      "type": "edit",
      "id": "af812d56ae08f0cc",
      "item": {
        "type": "paragraph",
        "id": "af812d56ae08f0cc",
        "text": "Opening up ChatGPT: Tracking openness, transparency, and accountability in instruction-tuned text generators. [https://doi.org/10.1145/3571884.3604316 doi], [https://scholar.social/@dingemansemark/110728766949576969 post], [https://opening-up-chatgpt.github.io site]"
      },
      "date": 1694786421990
    },
    {
      "item": {
        "type": "factory",
        "id": "e895a29d0d3b3fad"
      },
      "id": "e895a29d0d3b3fad",
      "type": "add",
      "after": "af812d56ae08f0cc",
      "date": 1694786494598
    },
    {
      "type": "remove",
      "id": "e895a29d0d3b3fad",
      "date": 1694786512581
    },
    {
      "type": "edit",
      "id": "af812d56ae08f0cc",
      "item": {
        "type": "paragraph",
        "id": "af812d56ae08f0cc",
        "text": "Liesenfeld, Andreas, Alianda Lopez, and Mark Dingemanse. 2023. “Opening up ChatGPT: Tracking Openness, Transparency, and Accountability in Instruction-Tuned Text Generators.” In CUI '23: Proceedings of the 5th International Conference on Conversational User Interfaces. July 19-21, Eindhoven. [https://doi.org/10.1145/3571884.3604316 doi], [https://scholar.social/@dingemansemark/110728766949576969 post], [https://opening-up-chatgpt.github.io site]"
      },
      "date": 1694786536812
    }
  ]
}