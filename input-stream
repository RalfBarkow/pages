{
  "title": "Input Stream",
  "story": [
    {
      "type": "reference",
      "id": "d3d45aef7cd2d9ec",
      "site": "wiki.ralfbarkow.ch",
      "slug": "peg",
      "title": "PEG",
      "text": "A [[Parser]] has an [[Input]] [[Stream]], a set of rules (generated from an extended **PEG**) that [[recognise]] input [[Structure]] and generate output structures, an output stream to collect generated output, and a current result (semantic value from the most recent [[Expression]]) that can be read and written within rules."
    },
    {
      "type": "reference",
      "id": "19afe6d0ff55dec1",
      "site": "wiki.ralfbarkow.ch",
      "slug": "entropy-on-a-data-stream",
      "title": "Entropy on a Data Stream",
      "text": "We consider the problem of computing information theoretic functions such as [[Entropy]] on a [[Data Stream]], using sublinear space. Our first result deals with a measure we call the “entropy norm” of an input stream: it is closely related to entropy but is structurally similar to the well-studied notion of frequency moments. We give a polylogarithmic space one-pass algorithm for estimating this norm under certain conditions on the input stream. We also prove a lower bound that rules out such an algorithm if these conditions do not hold. Our second group of res"
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Input Stream",
        "story": []
      },
      "date": 1695454109863
    },
    {
      "item": {
        "type": "factory",
        "id": "d3d45aef7cd2d9ec"
      },
      "id": "d3d45aef7cd2d9ec",
      "type": "add",
      "date": 1695454111155
    },
    {
      "type": "edit",
      "id": "d3d45aef7cd2d9ec",
      "item": {
        "type": "reference",
        "id": "d3d45aef7cd2d9ec",
        "site": "wiki.ralfbarkow.ch",
        "slug": "peg",
        "title": "PEG",
        "text": "A [[Parser]] has an input stream, a set of rules (generated from an extended **PEG**) that [[recognise]] input [[Structure]] and generate output structures, an output stream to collect generated output, and a current result (semantic value from the most recent [[Expression]]) that can be read and written within rules."
      },
      "date": 1695454114023
    },
    {
      "type": "edit",
      "id": "d3d45aef7cd2d9ec",
      "item": {
        "type": "reference",
        "id": "d3d45aef7cd2d9ec",
        "site": "wiki.ralfbarkow.ch",
        "slug": "peg",
        "title": "PEG",
        "text": "A [[Parser]] has an [[Input]] [[Stream]], a set of rules (generated from an extended **PEG**) that [[recognise]] input [[Structure]] and generate output structures, an output stream to collect generated output, and a current result (semantic value from the most recent [[Expression]]) that can be read and written within rules."
      },
      "date": 1695454129673
    },
    {
      "item": {
        "type": "factory",
        "id": "19afe6d0ff55dec1"
      },
      "id": "19afe6d0ff55dec1",
      "type": "add",
      "after": "d3d45aef7cd2d9ec",
      "date": 1695454200106
    },
    {
      "type": "edit",
      "id": "19afe6d0ff55dec1",
      "item": {
        "type": "reference",
        "id": "19afe6d0ff55dec1",
        "site": "wiki.ralfbarkow.ch",
        "slug": "entropy-on-a-data-stream",
        "title": "Entropy on a Data Stream",
        "text": "We consider the problem of computing information theoretic functions such as entropy on a data stream, using sublinear space. Our first result deals with a measure we call the “entropy norm” of an input stream: it is closely related to entropy but is structurally similar to the well-studied notion of frequency moments. We give a polylogarithmic space one-pass algorithm for estimating this norm under certain conditions on the input stream. We also prove a lower bound that rules out such an algorithm if these conditions do not hold. Our second group of res"
      },
      "date": 1695454202190
    },
    {
      "type": "edit",
      "id": "19afe6d0ff55dec1",
      "item": {
        "type": "reference",
        "id": "19afe6d0ff55dec1",
        "site": "wiki.ralfbarkow.ch",
        "slug": "entropy-on-a-data-stream",
        "title": "Entropy on a Data Stream",
        "text": "We consider the problem of computing information theoretic functions such as [[Entropy]] on a [[[Data Stream]], using sublinear space. Our first result deals with a measure we call the “entropy norm” of an input stream: it is closely related to entropy but is structurally similar to the well-studied notion of frequency moments. We give a polylogarithmic space one-pass algorithm for estimating this norm under certain conditions on the input stream. We also prove a lower bound that rules out such an algorithm if these conditions do not hold. Our second group of res"
      },
      "date": 1695454224510
    },
    {
      "type": "edit",
      "id": "19afe6d0ff55dec1",
      "item": {
        "type": "reference",
        "id": "19afe6d0ff55dec1",
        "site": "wiki.ralfbarkow.ch",
        "slug": "entropy-on-a-data-stream",
        "title": "Entropy on a Data Stream",
        "text": "We consider the problem of computing information theoretic functions such as [[Entropy]] on a [[Data Stream]], using sublinear space. Our first result deals with a measure we call the “entropy norm” of an input stream: it is closely related to entropy but is structurally similar to the well-studied notion of frequency moments. We give a polylogarithmic space one-pass algorithm for estimating this norm under certain conditions on the input stream. We also prove a lower bound that rules out such an algorithm if these conditions do not hold. Our second group of res"
      },
      "date": 1695454231317
    }
  ]
}