{
  "title": "Denoising diffusion probabilistic model",
  "story": [
    {
      "type": "paragraph",
      "id": "da79349b68b7dffc",
      "text": "a class of latent variable models inspired by considerations from nonequilibrium thermodynamics."
    },
    {
      "type": "pagefold",
      "id": "33f557c2d9f8aec1",
      "text": "~"
    },
    {
      "type": "reference",
      "id": "430e255878332dc1",
      "site": "wiki.ralfbarkow.ch",
      "slug": "prompt-based-image-synthesis",
      "title": "Prompt Based Image Synthesis",
      "text": "Here we learn the real application for prompt based image synthesis:"
    },
    {
      "type": "paragraph",
      "id": "a8e00b64c07c73a2",
      "text": "HO, Jonathan, JAIN, Ajay and ABBEEL, Pieter, 2020. Denoising Diffusion Probabilistic Models. In: Advances in Neural Information Processing Systems. Online. Curran Associates, Inc. 2020. p. 6840–6851. [Accessed 19 January 2023]. Available from: https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html"
    },
    {
      "type": "paragraph",
      "id": "3ecd3a34961899fe",
      "text": "We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.\n"
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Denoising diffusion probabilistic model",
        "story": []
      },
      "date": 1674102859886
    },
    {
      "item": {
        "type": "factory",
        "id": "430e255878332dc1"
      },
      "id": "430e255878332dc1",
      "type": "add",
      "date": 1674102866303
    },
    {
      "type": "edit",
      "id": "430e255878332dc1",
      "item": {
        "type": "reference",
        "id": "430e255878332dc1",
        "site": "wiki.ralfbarkow.ch",
        "slug": "prompt-based-image-synthesis",
        "title": "Prompt Based Image Synthesis",
        "text": "Here we learn the real application for prompt based image synthesis:"
      },
      "date": 1674102868661
    },
    {
      "item": {
        "type": "factory",
        "id": "da79349b68b7dffc"
      },
      "id": "da79349b68b7dffc",
      "type": "add",
      "after": "430e255878332dc1",
      "date": 1674102995838
    },
    {
      "type": "edit",
      "id": "da79349b68b7dffc",
      "item": {
        "type": "paragraph",
        "id": "da79349b68b7dffc",
        "text": "a class of latent variable models inspired by considerations from nonequilibrium thermodynamics."
      },
      "date": 1674102998184
    },
    {
      "id": "da79349b68b7dffc",
      "type": "move",
      "order": [
        "da79349b68b7dffc",
        "430e255878332dc1"
      ],
      "date": 1674102999458
    },
    {
      "item": {
        "type": "factory",
        "id": "33f557c2d9f8aec1"
      },
      "id": "33f557c2d9f8aec1",
      "type": "add",
      "after": "430e255878332dc1",
      "date": 1674103000965
    },
    {
      "type": "edit",
      "id": "33f557c2d9f8aec1",
      "item": {
        "type": "pagefold",
        "id": "33f557c2d9f8aec1",
        "text": "~"
      },
      "date": 1674103004513
    },
    {
      "id": "33f557c2d9f8aec1",
      "type": "move",
      "order": [
        "da79349b68b7dffc",
        "33f557c2d9f8aec1",
        "430e255878332dc1"
      ],
      "date": 1674103006974
    },
    {
      "item": {
        "type": "factory",
        "id": "a8e00b64c07c73a2"
      },
      "id": "a8e00b64c07c73a2",
      "type": "add",
      "after": "430e255878332dc1",
      "date": 1674103092134
    },
    {
      "type": "edit",
      "id": "a8e00b64c07c73a2",
      "item": {
        "type": "paragraph",
        "id": "a8e00b64c07c73a2",
        "text": "\nHO, Jonathan, JAIN, Ajay and ABBEEL, Pieter, 2020. Denoising Diffusion Probabilistic Models. In: Advances in Neural Information Processing Systems. Online. Curran Associates, Inc. 2020. p. 6840–6851. [Accessed 19 January 2023]. Available from: https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.htmlWe present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.\n"
      },
      "date": 1674103094873
    },
    {
      "type": "edit",
      "id": "a8e00b64c07c73a2",
      "item": {
        "type": "paragraph",
        "id": "a8e00b64c07c73a2",
        "text": "HO, Jonathan, JAIN, Ajay and ABBEEL, Pieter, 2020. Denoising Diffusion Probabilistic Models. In: Advances in Neural Information Processing Systems. Online. Curran Associates, Inc. 2020. p. 6840–6851. [Accessed 19 January 2023]. Available from: https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html"
      },
      "date": 1674103108849
    },
    {
      "type": "add",
      "id": "3ecd3a34961899fe",
      "item": {
        "type": "paragraph",
        "id": "3ecd3a34961899fe",
        "text": "We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.\n"
      },
      "after": "a8e00b64c07c73a2",
      "date": 1674103110076
    }
  ]
}