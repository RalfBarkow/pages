{
  "title": "Intelligent Machine",
  "story": [
    {
      "type": "markdown",
      "id": "26a25992c81b464f",
      "text": "## Why Artificial Intelligence Needs Philosophy"
    },
    {
      "type": "paragraph",
      "id": "811c2da4780541d9",
      "text": "The idea of an intelligent machine is old, but serious work on the problem of [[Artificial Intelligence]] or even serious understanding of what the problem is awaited the stored-program computer."
    },
    {
      "type": "paragraph",
      "id": "8d903f195a54074b",
      "text": "We may regard the subject of artificial intelligence as beginning with Turing’s article ‘Computing Machinery and Intelligence’ (Turing 1950) and with Shannon’s (1950) discussion of how a machine might be programmed to play chess."
    },
    {
      "type": "paragraph",
      "id": "0f40f8c2dc12331d",
      "text": "[…]"
    },
    {
      "type": "pagefold",
      "id": "4154bc4cb56ca148",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "971cc2eb5156c133",
      "text": "MCCARTHY, J. and HAYES, P. J., 1981. Some Philosophical Problems from the Standpoint of Artificial Intelligence. In: WEBBER, Bonnie Lynn and NILSSON, Nils J. (eds.), Readings in Artificial Intelligence. Online. Morgan Kaufmann. p. 431–450. [Accessed 10 October 2022]. ISBN 978-0-934613-03-3. "
    },
    {
      "type": "markdown",
      "id": "32e6dc9a00496f81",
      "text": "> A computer program capable of acting intelligently in the world must have a general representation of the world in terms of which its inputs are interpreted. Designing such a program requires commitments about what [[Knowledge]] is and how it is obtained. \n\n⇒ [[What-Questions]] vs. [[How-Questions]]"
    },
    {
      "type": "markdown",
      "id": "36d68522e7ca16f0",
      "text": "> Thus, some of the major traditional problems of philosophy arise in artificial intelligence. More specifically, we want a computer program that decides what to do by inferring in a formal language that a certain strategy will achieve its assigned goal. This requires formalizing concepts of causality, ability, and knowledge. Such formalisms are also considered in philosophical logic. The first part of the paper begins with a philosophical point of view that seems to arise naturally once we take seriously the idea of actually making an intelligent machine. We go on to the notions of metaphysically and epistemo-logically adequate representations of the world and then to an explanation of can, causes, and knows in terms of a representation of the world by a system of interacting automata. A proposed resolution of the problem of freewill in a deterministic universe and of counterfactual conditional sentences is presented. The second part is mainly concerned with formalisms within which it can be proved that a strategy will achieve a goal. Concepts of situation, fluent, future operator, action, strategy, result of a strategy and knowledge are formalized. A method is given of constructing a sentence of first-order logic which will be true in all models of certain axioms if and only if a certain strategy will achieve a certain goal. The formalism of this paper represents an advance over McCarthy (1963) and Green (1969) in that it permits proof of the correctness of strategies that contain loops and strategies that involve the acquisition of knowledge; and it is also somewhat more concise. The third part discusses open problems in extending the formalism of part 2. The fourth part is a review of work in philosophical logic in relation to problems of artificial intelligence and a discussion of previous efforts to program ‘general intelligence’ from the point of view of this paper.\n"
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Intelligent Machine",
        "story": []
      },
      "date": 1665435883842
    },
    {
      "item": {
        "type": "factory",
        "id": "26a25992c81b464f"
      },
      "id": "26a25992c81b464f",
      "type": "add",
      "date": 1665435899227
    },
    {
      "type": "edit",
      "id": "26a25992c81b464f",
      "item": {
        "type": "paragraph",
        "id": "26a25992c81b464f",
        "text": "## Why artificial intelligence needs philosophy "
      },
      "date": 1665435907973
    },
    {
      "type": "add",
      "id": "811c2da4780541d9",
      "item": {
        "type": "paragraph",
        "id": "811c2da4780541d9",
        "text": "The idea of an intelligent machine is old, but serious work on the problem of artificial intelligence or even serious understanding of what the problem is awaited the stored-program computer. We may regard the subject of artificial intelligence as beginning with Turing’s article ‘Computing Machinery and Intelligence’ (Turing 1950) and with Shannon’s (1950) discussion of how a machine might be programmed to play chess."
      },
      "after": "26a25992c81b464f",
      "date": 1665435908670
    },
    {
      "type": "edit",
      "id": "26a25992c81b464f",
      "item": {
        "type": "markdown",
        "id": "26a25992c81b464f",
        "text": "## Why artificial intelligence needs philosophy "
      },
      "date": 1665435910186
    },
    {
      "type": "add",
      "id": "0f40f8c2dc12331d",
      "item": {
        "type": "paragraph",
        "id": "0f40f8c2dc12331d",
        "text": "[…]"
      },
      "after": "811c2da4780541d9",
      "date": 1665435963801
    },
    {
      "item": {
        "type": "factory",
        "id": "4154bc4cb56ca148"
      },
      "id": "4154bc4cb56ca148",
      "type": "add",
      "after": "0f40f8c2dc12331d",
      "date": 1665435966118
    },
    {
      "type": "edit",
      "id": "4154bc4cb56ca148",
      "item": {
        "type": "pagefold",
        "id": "4154bc4cb56ca148",
        "text": "~"
      },
      "date": 1665435969772
    },
    {
      "item": {
        "type": "factory",
        "id": "971cc2eb5156c133"
      },
      "id": "971cc2eb5156c133",
      "type": "add",
      "after": "4154bc4cb56ca148",
      "date": 1665435971787
    },
    {
      "type": "edit",
      "id": "971cc2eb5156c133",
      "item": {
        "type": "paragraph",
        "id": "971cc2eb5156c133",
        "text": "\nMCCARTHY, J. and HAYES, P. J., 1981. Some Philosophical Problems from the Standpoint of Artificial Intelligence. In: WEBBER, Bonnie Lynn and NILSSON, Nils J. (eds.), Readings in Artificial Intelligence. Online. Morgan Kaufmann. p. 431–450. [Accessed 10 October 2022]. ISBN 978-0-934613-03-3. A computer program capable of acting intelligently in the world must have a general representation of the world in terms of which its inputs are interpreted. Designing such a program requires commitments about what knowledge is and how it is obtained. Thus, some of the major traditional problems of philosophy arise in artificial intelligence. More specifically, we want a computer program that decides what to do by inferring in a formal language that a certain strategy will achieve its assigned goal. This requires formalizing concepts of causality, ability, and knowledge. Such formalisms are also considered in philosophical logic. The first part of the paper begins with a philosophical point of view that seems to arise naturally once we take seriously the idea of actually making an intelligent machine. We go on to the notions of metaphysically and epistemo-logically adequate representations of the world and then to an explanation of can, causes, and knows in terms of a representation of the world by a system of interacting automata. A proposed resolution of the problem of freewill in a deterministic universe and of counterfactual conditional sentences is presented. The second part is mainly concerned with formalisms within which it can be proved that a strategy will achieve a goal. Concepts of situation, fluent, future operator, action, strategy, result of a strategy and knowledge are formalized. A method is given of constructing a sentence of first-order logic which will be true in all models of certain axioms if and only if a certain strategy will achieve a certain goal. The formalism of this paper represents an advance over McCarthy (1963) and Green (1969) in that it permits proof of the correctness of strategies that contain loops and strategies that involve the acquisition of knowledge; and it is also somewhat more concise. The third part discusses open problems in extending the formalism of part 2. The fourth part is a review of work in philosophical logic in relation to problems of artificial intelligence and a discussion of previous efforts to program ‘general intelligence’ from the point of view of this paper.\n"
      },
      "date": 1665435974187
    },
    {
      "type": "edit",
      "id": "971cc2eb5156c133",
      "item": {
        "type": "paragraph",
        "id": "971cc2eb5156c133",
        "text": "MCCARTHY, J. and HAYES, P. J., 1981. Some Philosophical Problems from the Standpoint of Artificial Intelligence. In: WEBBER, Bonnie Lynn and NILSSON, Nils J. (eds.), Readings in Artificial Intelligence. Online. Morgan Kaufmann. p. 431–450. [Accessed 10 October 2022]. ISBN 978-0-934613-03-3. "
      },
      "date": 1665435989597
    },
    {
      "type": "add",
      "id": "32e6dc9a00496f81",
      "item": {
        "type": "paragraph",
        "id": "32e6dc9a00496f81",
        "text": "> A computer program capable of acting intelligently in the world must have a general representation of the world in terms of which its inputs are interpreted. Designing such a program requires commitments about what knowledge is and how it is obtained. Thus, some of the major traditional problems of philosophy arise in artificial intelligence. More specifically, we want a computer program that decides what to do by inferring in a formal language that a certain strategy will achieve its assigned goal. This requires formalizing concepts of causality, ability, and knowledge. Such formalisms are also considered in philosophical logic. The first part of the paper begins with a philosophical point of view that seems to arise naturally once we take seriously the idea of actually making an intelligent machine. We go on to the notions of metaphysically and epistemo-logically adequate representations of the world and then to an explanation of can, causes, and knows in terms of a representation of the world by a system of interacting automata. A proposed resolution of the problem of freewill in a deterministic universe and of counterfactual conditional sentences is presented. The second part is mainly concerned with formalisms within which it can be proved that a strategy will achieve a goal. Concepts of situation, fluent, future operator, action, strategy, result of a strategy and knowledge are formalized. A method is given of constructing a sentence of first-order logic which will be true in all models of certain axioms if and only if a certain strategy will achieve a certain goal. The formalism of this paper represents an advance over McCarthy (1963) and Green (1969) in that it permits proof of the correctness of strategies that contain loops and strategies that involve the acquisition of knowledge; and it is also somewhat more concise. The third part discusses open problems in extending the formalism of part 2. The fourth part is a review of work in philosophical logic in relation to problems of artificial intelligence and a discussion of previous efforts to program ‘general intelligence’ from the point of view of this paper.\n"
      },
      "after": "971cc2eb5156c133",
      "date": 1665435990300
    },
    {
      "type": "edit",
      "id": "32e6dc9a00496f81",
      "item": {
        "type": "markdown",
        "id": "32e6dc9a00496f81",
        "text": "> A computer program capable of acting intelligently in the world must have a general representation of the world in terms of which its inputs are interpreted. Designing such a program requires commitments about what knowledge is and how it is obtained. Thus, some of the major traditional problems of philosophy arise in artificial intelligence. More specifically, we want a computer program that decides what to do by inferring in a formal language that a certain strategy will achieve its assigned goal. This requires formalizing concepts of causality, ability, and knowledge. Such formalisms are also considered in philosophical logic. The first part of the paper begins with a philosophical point of view that seems to arise naturally once we take seriously the idea of actually making an intelligent machine. We go on to the notions of metaphysically and epistemo-logically adequate representations of the world and then to an explanation of can, causes, and knows in terms of a representation of the world by a system of interacting automata. A proposed resolution of the problem of freewill in a deterministic universe and of counterfactual conditional sentences is presented. The second part is mainly concerned with formalisms within which it can be proved that a strategy will achieve a goal. Concepts of situation, fluent, future operator, action, strategy, result of a strategy and knowledge are formalized. A method is given of constructing a sentence of first-order logic which will be true in all models of certain axioms if and only if a certain strategy will achieve a certain goal. The formalism of this paper represents an advance over McCarthy (1963) and Green (1969) in that it permits proof of the correctness of strategies that contain loops and strategies that involve the acquisition of knowledge; and it is also somewhat more concise. The third part discusses open problems in extending the formalism of part 2. The fourth part is a review of work in philosophical logic in relation to problems of artificial intelligence and a discussion of previous efforts to program ‘general intelligence’ from the point of view of this paper.\n"
      },
      "date": 1665435991442
    },
    {
      "type": "edit",
      "id": "32e6dc9a00496f81",
      "item": {
        "type": "markdown",
        "id": "32e6dc9a00496f81",
        "text": "> A computer program capable of acting intelligently in the world must have a general representation of the world in terms of which its inputs are interpreted. Designing such a program requires commitments about what [[Knowledge]] is and how it is obtained. Thus, some of the major traditional problems of philosophy arise in artificial intelligence. More specifically, we want a computer program that decides what to do by inferring in a formal language that a certain strategy will achieve its assigned goal. This requires formalizing concepts of causality, ability, and knowledge. Such formalisms are also considered in philosophical logic. The first part of the paper begins with a philosophical point of view that seems to arise naturally once we take seriously the idea of actually making an intelligent machine. We go on to the notions of metaphysically and epistemo-logically adequate representations of the world and then to an explanation of can, causes, and knows in terms of a representation of the world by a system of interacting automata. A proposed resolution of the problem of freewill in a deterministic universe and of counterfactual conditional sentences is presented. The second part is mainly concerned with formalisms within which it can be proved that a strategy will achieve a goal. Concepts of situation, fluent, future operator, action, strategy, result of a strategy and knowledge are formalized. A method is given of constructing a sentence of first-order logic which will be true in all models of certain axioms if and only if a certain strategy will achieve a certain goal. The formalism of this paper represents an advance over McCarthy (1963) and Green (1969) in that it permits proof of the correctness of strategies that contain loops and strategies that involve the acquisition of knowledge; and it is also somewhat more concise. The third part discusses open problems in extending the formalism of part 2. The fourth part is a review of work in philosophical logic in relation to problems of artificial intelligence and a discussion of previous efforts to program ‘general intelligence’ from the point of view of this paper.\n"
      },
      "date": 1665436025096
    },
    {
      "type": "edit",
      "id": "32e6dc9a00496f81",
      "item": {
        "type": "markdown",
        "id": "32e6dc9a00496f81",
        "text": "> A computer program capable of acting intelligently in the world must have a general representation of the world in terms of which its inputs are interpreted. Designing such a program requires commitments about what [[Knowledge]] is and how it is obtained. \n"
      },
      "date": 1665436095954
    },
    {
      "type": "add",
      "id": "36d68522e7ca16f0",
      "item": {
        "type": "markdown",
        "id": "36d68522e7ca16f0",
        "text": "> Thus, some of the major traditional problems of philosophy arise in artificial intelligence. More specifically, we want a computer program that decides what to do by inferring in a formal language that a certain strategy will achieve its assigned goal. This requires formalizing concepts of causality, ability, and knowledge. Such formalisms are also considered in philosophical logic. The first part of the paper begins with a philosophical point of view that seems to arise naturally once we take seriously the idea of actually making an intelligent machine. We go on to the notions of metaphysically and epistemo-logically adequate representations of the world and then to an explanation of can, causes, and knows in terms of a representation of the world by a system of interacting automata. A proposed resolution of the problem of freewill in a deterministic universe and of counterfactual conditional sentences is presented. The second part is mainly concerned with formalisms within which it can be proved that a strategy will achieve a goal. Concepts of situation, fluent, future operator, action, strategy, result of a strategy and knowledge are formalized. A method is given of constructing a sentence of first-order logic which will be true in all models of certain axioms if and only if a certain strategy will achieve a certain goal. The formalism of this paper represents an advance over McCarthy (1963) and Green (1969) in that it permits proof of the correctness of strategies that contain loops and strategies that involve the acquisition of knowledge; and it is also somewhat more concise. The third part discusses open problems in extending the formalism of part 2. The fourth part is a review of work in philosophical logic in relation to problems of artificial intelligence and a discussion of previous efforts to program ‘general intelligence’ from the point of view of this paper.\n"
      },
      "after": "32e6dc9a00496f81",
      "date": 1665436099199
    },
    {
      "type": "edit",
      "id": "32e6dc9a00496f81",
      "item": {
        "type": "markdown",
        "id": "32e6dc9a00496f81",
        "text": "> A computer program capable of acting intelligently in the world must have a general representation of the world in terms of which its inputs are interpreted. Designing such a program requires commitments about what [[Knowledge]] is and how it is obtained. \n\n– [[What-Questions]] vs. [[How-Questions]]"
      },
      "date": 1665436130235
    },
    {
      "type": "edit",
      "id": "32e6dc9a00496f81",
      "item": {
        "type": "markdown",
        "id": "32e6dc9a00496f81",
        "text": "> A computer program capable of acting intelligently in the world must have a general representation of the world in terms of which its inputs are interpreted. Designing such a program requires commitments about what [[Knowledge]] is and how it is obtained. \n\n⇒  [[What-Questions]] vs. [[How-Questions]]"
      },
      "date": 1665436137090
    },
    {
      "type": "edit",
      "id": "32e6dc9a00496f81",
      "item": {
        "type": "markdown",
        "id": "32e6dc9a00496f81",
        "text": "> A computer program capable of acting intelligently in the world must have a general representation of the world in terms of which its inputs are interpreted. Designing such a program requires commitments about what [[Knowledge]] is and how it is obtained. \n\n⇒ [[What-Questions]] vs. [[How-Questions]]"
      },
      "date": 1665436150103
    },
    {
      "type": "edit",
      "id": "26a25992c81b464f",
      "item": {
        "type": "markdown",
        "id": "26a25992c81b464f",
        "text": "## Why Artificial Intelligence Needs Philosophy"
      },
      "date": 1692824404326
    },
    {
      "type": "edit",
      "id": "811c2da4780541d9",
      "item": {
        "type": "paragraph",
        "id": "811c2da4780541d9",
        "text": "The idea of an intelligent machine is old, but serious work on the problem of [[Artificial Intelligence]] or even serious understanding of what the problem is awaited the stored-program computer. We may regard the subject of artificial intelligence as beginning with Turing’s article ‘Computing Machinery and Intelligence’ (Turing 1950) and with Shannon’s (1950) discussion of how a machine might be programmed to play chess."
      },
      "date": 1692824436034
    },
    {
      "type": "edit",
      "id": "811c2da4780541d9",
      "item": {
        "type": "paragraph",
        "id": "811c2da4780541d9",
        "text": "The idea of an intelligent machine is old, but serious work on the problem of [[Artificial Intelligence]] or even serious understanding of what the problem is awaited the stored-program computer."
      },
      "date": 1692824457916
    },
    {
      "type": "add",
      "id": "8d903f195a54074b",
      "item": {
        "type": "paragraph",
        "id": "8d903f195a54074b",
        "text": "We may regard the subject of artificial intelligence as beginning with Turing’s article ‘Computing Machinery and Intelligence’ (Turing 1950) and with Shannon’s (1950) discussion of how a machine might be programmed to play chess."
      },
      "after": "811c2da4780541d9",
      "date": 1692824459001
    }
  ]
}