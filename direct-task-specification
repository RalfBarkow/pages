{
  "title": "Direct Task Specification",
  "story": [
    {
      "type": "paragraph",
      "id": "250bf85351450cfe",
      "text": "Constructing the Signifier"
    },
    {
      "type": "paragraph",
      "id": "7c54d5a75f3c9a6d",
      "text": "Pre-GPT-3 models had much less capability to understand abstract descriptions of tasks due to their limited model of the world and human concepts. GPT-3’s impressive performance on 0-shot prompts indicates a new realm of possibilities for direct task specification."
    },
    {
      "type": "paragraph",
      "id": "664d575908acd9de",
      "text": "A direct task specification is a 0-shot prompt which tells the model to perform a task that it already knows how to do using a signifier for the task. A [[Signifier]] is a [[Pattern]] which keys the intended behavior. It could be the name of the task, such as “translate”, a compound description, such as “rephrase this paragraph so that a 2nd grader can understand it, emphasizing real-world applications”, or purely contextual, such as the simple colon prompt from Figure 1. […]"
    },
    {
      "type": "paragraph",
      "id": "b4d6997f48908562",
      "text": "In none of these cases does the signifier explain how to accomplish the task or provide examples of intended behavior; instead, it explicitly or implicitly calls functions which it assumes the language model has already learned."
    },
    {
      "type": "paragraph",
      "id": "e8d197bd4872d905",
      "text": "Direct specifications can supervene on an infinity of implicit examples, like a closed-form expression on an infinite sequence, making them very powerful and compact. For instance, the phrase “translate French to English” [[supervene]]s on a list of mappings from all possible French phrases to English."
    },
    {
      "type": "paragraph",
      "id": "8ac42918d3172003",
      "text": "A [[Large Language Model]], like a [[Person]], has also learned behaviors for which it is less obvious how to construct a direct signifier. Task specification by demonstration (§4.3) and by proxy (§4.4) may be viable alternative strategies for eliciting those behaviors."
    },
    {
      "type": "paragraph",
      "id": "d63c056fb08bc50c",
      "text": "⇒ §4.3 ⇒ [[Task Specification by Memetic Proxy]]"
    },
    {
      "type": "pagefold",
      "id": "6e47d9b56b60e738",
      "text": "~"
    },
    {
      "type": "paragraph",
      "id": "7f97a6bb8fcf767c",
      "text": "REYNOLDS, Laria and MCDONELL, Kyle, 2021. [[Prompt Programming]] for [[Large Language Model]]s: Beyond the Few-Shot Paradigm. In: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. Online. New York, NY, USA: Association for Computing Machinery. 2021. p. 1–7. [Accessed 29 January 2023]. CHI EA ’21. ISBN 978-1-4503-8095-9. DOI 10.1145/3411763.3451760. "
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Direct Task Specification",
        "story": []
      },
      "date": 1675075929603
    },
    {
      "item": {
        "type": "factory",
        "id": "250bf85351450cfe"
      },
      "id": "250bf85351450cfe",
      "type": "add",
      "date": 1675075931326
    },
    {
      "type": "edit",
      "id": "250bf85351450cfe",
      "item": {
        "type": "paragraph",
        "id": "250bf85351450cfe",
        "text": "Constructing the Signifier"
      },
      "date": 1675075934384
    },
    {
      "item": {
        "type": "factory",
        "id": "7c54d5a75f3c9a6d"
      },
      "id": "7c54d5a75f3c9a6d",
      "type": "add",
      "after": "250bf85351450cfe",
      "date": 1675075942121
    },
    {
      "type": "edit",
      "id": "7c54d5a75f3c9a6d",
      "item": {
        "type": "paragraph",
        "id": "7c54d5a75f3c9a6d",
        "text": "Pre-GPT-3 models had much less capability to understand abstract descriptions of tasks due to their limited model of the world and human concepts. GPT-3’s impressive performance on 0-shot prompts indicates a new realm of possibilities for direct task specification."
      },
      "date": 1675075943340
    },
    {
      "id": "6e47d9b56b60e738",
      "type": "add",
      "item": {
        "type": "pagefold",
        "id": "6e47d9b56b60e738",
        "text": "~"
      },
      "after": "7c54d5a75f3c9a6d",
      "date": 1675075955113
    },
    {
      "id": "7f97a6bb8fcf767c",
      "type": "add",
      "item": {
        "type": "paragraph",
        "id": "7f97a6bb8fcf767c",
        "text": "REYNOLDS, Laria and MCDONELL, Kyle, 2021. [[Prompt Programming]] for [[Large Language Model]]s: Beyond the Few-Shot Paradigm. In: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. Online. New York, NY, USA: Association for Computing Machinery. 2021. p. 1–7. [Accessed 29 January 2023]. CHI EA ’21. ISBN 978-1-4503-8095-9. DOI 10.1145/3411763.3451760. "
      },
      "after": "6e47d9b56b60e738",
      "date": 1675075959628
    },
    {
      "type": "add",
      "id": "664d575908acd9de",
      "item": {
        "type": "paragraph",
        "id": "664d575908acd9de",
        "text": "A direct task specification is a 0-shot prompt which tells the model to perform a task that it already knows how to do using a signifier for the task. A signifier is a pattern which keys the intended behavior. It could be the name of the task, such as “translate”, a compound description, such as “rephrase this paragraph so that a 2nd grader can understand it, emphasizing real-world applications”, or purely contextual, such as the simple colon prompt from Figure 1. […]"
      },
      "after": "7c54d5a75f3c9a6d",
      "date": 1675075983393
    },
    {
      "type": "add",
      "id": "b4d6997f48908562",
      "item": {
        "type": "paragraph",
        "id": "b4d6997f48908562",
        "text": "In none of these cases does the signifier explain how to accomplish the task or provide examples of intended behavior; instead, it explicitly or implicitly calls functions which it assumes the language model has already learned."
      },
      "after": "664d575908acd9de",
      "date": 1675076024352
    },
    {
      "type": "add",
      "id": "e8d197bd4872d905",
      "item": {
        "type": "paragraph",
        "id": "e8d197bd4872d905",
        "text": "Direct specifications can supervene on an infinity of implicit examples, like a closed-form expression on an infinite sequence, making them very powerful and compact. For instance, the phrase “translate French to English” supervenes on a list of mappings from all possible French phrases to English."
      },
      "after": "b4d6997f48908562",
      "date": 1675076045013
    },
    {
      "type": "add",
      "id": "8ac42918d3172003",
      "item": {
        "type": "paragraph",
        "id": "8ac42918d3172003",
        "text": "A large language model, like a person, has also learned behaviors for which it is less obvious how to construct a direct signifier. Task specification by demonstration (§4.3) and by proxy (§4.4) may be viable alternative strategies for eliciting those behaviors."
      },
      "after": "e8d197bd4872d905",
      "date": 1675076054904
    },
    {
      "type": "edit",
      "id": "e8d197bd4872d905",
      "item": {
        "type": "paragraph",
        "id": "e8d197bd4872d905",
        "text": "Direct specifications can supervene on an infinity of implicit examples, like a closed-form expression on an infinite sequence, making them very powerful and compact. For instance, the phrase “translate French to English” [[supervene]]s on a list of mappings from all possible French phrases to English."
      },
      "date": 1675076160663
    },
    {
      "type": "edit",
      "id": "8ac42918d3172003",
      "item": {
        "type": "paragraph",
        "id": "8ac42918d3172003",
        "text": "A [[Large Language Model]], like a [[Person]], has also learned behaviors for which it is less obvious how to construct a direct signifier. Task specification by demonstration (§4.3) and by proxy (§4.4) may be viable alternative strategies for eliciting those behaviors."
      },
      "date": 1675076233713
    },
    {
      "type": "add",
      "id": "d63c056fb08bc50c",
      "item": {
        "type": "paragraph",
        "id": "d63c056fb08bc50c",
        "text": "⇒ [[Task Specification by Memetic Proxy]]"
      },
      "after": "8ac42918d3172003",
      "date": 1675076354487
    },
    {
      "type": "edit",
      "id": "d63c056fb08bc50c",
      "item": {
        "type": "paragraph",
        "id": "d63c056fb08bc50c",
        "text": "⇒ §4.3 ⇒ [[Task Specification by Memetic Proxy]]"
      },
      "date": 1675076365517
    },
    {
      "type": "edit",
      "id": "664d575908acd9de",
      "item": {
        "type": "paragraph",
        "id": "664d575908acd9de",
        "text": "A direct task specification is a 0-shot prompt which tells the model to perform a task that it already knows how to do using a signifier for the task. A [[Signifier]] is a [[Pattern]] which keys the intended behavior. It could be the name of the task, such as “translate”, a compound description, such as “rephrase this paragraph so that a 2nd grader can understand it, emphasizing real-world applications”, or purely contextual, such as the simple colon prompt from Figure 1. […]"
      },
      "date": 1709549915799
    }
  ]
}